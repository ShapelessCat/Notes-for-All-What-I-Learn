#+TITLE: Learning Concurrent Programming in Scala
#+SUBTITLE: Learn the art of building intricate, modern, scalable, and concurrent applications using Scala
#+VERSION: 2nd - 2017
#+FOREWORD BY: Martin Odersky, Professor at EPFL, the creator of Scala
#+AUTHOR: Aleksandar Prokopec
#+STARTUP: overview
#+STARTUP: entitiespretty

* DONE Preface - 1
  CLOSED: [2021-08-31 Tue 00:57]
  - As *the level of abstraction GROWS* in _modern languages_ and _concurrency frameworks_,
    it is becoming crucial to know *how* and *when* to use them:

    1. Having a good grasp of the _CLASSICAL /concurrency and synchronization
       primitives/,_ such as /threads/, /locks/, and /monitors/,
       *is NO LONGER SUFFICIENT*.

    2. /High-level concurrency frameworks/, which
       + solve many issues of traditional concurrency and
       + are tailored towards specific tasks,
       are gradually overtaking the world of /concurrent programming/.

  - This book describes _high-level concurrent programming_ in Scala.
    * It
      + presents detailed explanations of _various concurrency topics_ and
      + covers the _basic theory of concurrent programming_.

    * Simultaneously, it
      + describes _MODERN concurrency frameworks_,
      + shows their DETAILED /semantics/, and
      + teaches you _how to use them_.

      Its goal is to *introduce* important _concurrency abstractions_ and, at the
      same time, *show* _how they work in real code_.

  - We are convinced that, by reading this book,
    1. you will both 
       + GAIN a SOLID _theoretical understanding_ of /concurrent programming/
       + DEVELOP a set of _useful practical skills_ that are required to write
         _CORRECT and EFFICIENT concurrent programs._

    2. These skills are the *first steps* toward becoming a _modern concurrency
       expert_.

** DONE What this book covers - 1
   CLOSED: [2021-08-31 Tue 00:51]
   This book is organized into a sequence of chapters with various topics on
   /concurrent programming/.

   - The book
     * covers the _fundamental concurrent APIs_ that are a part of /the Scala runtime/,
     * introduces _MORE COMPLEX_ /concurrency primitives/, and
     * gives an _extensive overview_ of /high-level concurrency abstractions/.

   - _Chapter 1, Introduction,_
     * explains the *need* for /concurrent programming/ and
     * gives some philosophical background.
       
     * At the same time,
       it covers the basics of the _Scala programming language_ that are
       required for understanding the rest of this book.
     
   - _Chapter 2, Concurrency on the JVM and the Java Memory Model,_
     teaches you the basics of concurrent programming.
       This chapter will teach you
     * how to use /threads/ and
     * how to *protect access to* /shared memory/ and
     * introduce the /Java Memory Model/.
     
   - _Chapter 3, Traditional Building Blocks of Concurrency,_
     presents *classic concurrency utilities*, such as
     * /thread pools/,
     * /atomic variables/, and
     * /concurrent collections/,
     * with a particular focus on the interaction with the features of the Scala
       language.

     The emphasis in this book is on the /modern, high-level concurrent
     programming frameworks/. Consequently, this chapter presents an _overview
     of *TRADITIONAL* /concurrent programming/ techniques,_ but it does not aim
     to be extensive.
     
   - _Chapter 4, Asynchronous Programming with Futures and Promises,_ is the
     first chapter that deals with _a *Scala-specific* concurrency framework._

     * This chapter presents the /futures/ and /promises/ API and shows how to
       correctly use them when implementing /asynchronous programs/.
     
   - _Chapter 5, Data-Parallel Collections,_
     describes the /Scala parallel collections/ framework.
     * In this chapter,
       you will learn
       + *how* to _PARALLELIZE collection operations_,
       + *when* it is _ALLOWED to parallelize them_, and
       + *how* to assess the _performance benefits_ of doing so.
     
   - _Chapter 6, Concurrent Programming with Reactive Extensions,_
     teaches you
     how to use the /Reactive Extensions framework/ for event-based and
     /asynchronous programming/.

     * You will see
       + how the *operations* on /event streams/ correspond to _collection operations_,
       + how to *pass* events *from* one /thread/ to another, and
       + how to *design* a /reactive user interface/ using /event streams/.
     
   - _Chapter 7, Software Transactional Memory,_
     introduces *the ScalaSTM library* for /transactional programming/,
     which aims to provide a *safer*, *more intuitive*, /shared-memory
     programming model/.

     * In this chapter,
       you will learn
       + how to *protect access to* /shared data/ using /scalable memory
         transactions/ and,

       + at the same time, *reduce* the risk of /deadlocks/ and /race conditions/.
     
   - _Chapter 8, Actors,_
     presents the /actor programming model/ and the /Akka framework/.
     * In this chapter,
       you will learn
       + how to /transparently *build* message-passing distributed programs/
         that run on multiple machines.

   - _Chapter 9, Concurrency in Practice,_
     summarizes the _DIFFERENT_ /concurrency libraries/ introduced in the earlier
     chapters.
     * In this chapter, you will learn
       + how to *choose* the /correct concurrency abstraction/ to solve a given
         problem, and
       + how to *combine* _different_ /concurrency abstractions/ together
         when *designing* LARGER /concurrent applications/.
     
   - _Chapter 10, Reactors,_
     presents the /reactor programming model/, whose focus is *improved
     composition* in /concurrent and distributed programs/.
     * This emerging model enables
       *separation* of /concurrent and distributed programming patterns/
       *into* /modular components/ called /protocols/.

   While we recommend that you read the chapters in the order in which they
   appear, this is not strictly necessary.

** DONE What you need for this book - 3
   CLOSED: [2021-08-31 Tue 00:51]
*** Installing the JDK
*** Installing and using SBT
*** Using Eclipse, IntelliJ IDEA, or another IDE
    
** DONE Who this book is for - 8
   CLOSED: [2021-08-31 Tue 00:56]
   This book is primarily intended for developers
   who *have learned* how to write /sequential Scala programs/, and
   *wish to learn* how to write correct /concurrent programs/.

   - Basic understanding of OO or FP should be a sufficient prerequisite.

** DONE Conventions - 8
   CLOSED: [2021-08-31 Tue 00:56]
** DONE Reader feedback - 10
   CLOSED: [2021-08-31 Tue 00:56]
** DONE Customer support - 10
   CLOSED: [2021-08-31 Tue 00:57]
** DONE Downloading the example code - 10
   CLOSED: [2021-08-30 Mon 21:06]
** TODO Errata - 11
   https://www.packtpub.com/support/code-downloads

** DONE Piracy - 11
   CLOSED: [2021-08-31 Tue 00:57]
** DONE Questions - 12
   CLOSED: [2021-08-31 Tue 00:57]
   
* TODO Chapter 1: Introduction - 13
  - This chapter _explains the basics of concurrent computing and presents some
    Scala preliminaries required for this book_. Specifically, it does the following:
    * Shows a brief _overview_ of /concurrent programming/
    * Studies the _advantages_ of using Scala when it comes to concurrency
    * Covers the Scala _preliminaries required_ for reading this book

  - We will start by examining
    * *What* /concurrent programming/ is
    * *Why* it is important
    
** TODO Concurrent programming - 14
   - Concurrent programming :: we express a program as a set of concurrent
        computations that execute _during OVERLAPPING time intervals and
        coordinate_ in some way.

   - /Concurrent programming/ has MULTIPLE _advantages_:
     1. Increased concurrency can _improve program performance_.
        Instead of executing the entire program on a single processor, different
        subcomputations can be performed on separate processors, making the
        program run faster.

        

   - =TODO=

*** A brief overview of traditional concurrency - 15
    - There are
      + Operating system level concurrency
      + Programming language level concurrency

    - We'll focus mainly on *programming-language-level concurrency*.

    - synchronization :: the coordination of multiple executions in a concurrent
         system.

    - /synchronization/ is a key part in successfully *implementing* concurrency.

    - /Synchronization/
      + includes *mechanisms* used to order concurrent executions in time.

      + specifies *how concurrent executions communicate*, that is, how they
        exchange information.

    - Java uses shared memory.

      Its /synchronization/ is called /shared memory communication/.

      Establishing _an /order/ between_ the /threads/ *ensures* that the memory
      modifications done by one /thread/ are *visible* to a /thread/ that
      executes later.

    - The *crucial difference* lies in the fact that a /high-level concurrency/
      framework _expresses which goal to achieve_, RATHER THAN _how to achieve
      that goal_.

*** Modern concurrency paradigms - 15

** TODO The advantages of Scala - 17
** TODO Preliminaries - 18
*** Execution of a Scala program - 18
*** A Scala primer - 20

** TODO Overview of new features in Scala 2.12 - 25
** TODO Summary - 26
** TODO Exercises - 26
   =TODO=
   6, 7, 8, 9

* TODO Chapter 2: Concurrency on the JVM and the Java Memory Model - 29
  - Since Scala has run _primarily on top of JVM_, and this fact has *driven* the
    design of many of its _concurrency libraries_.
    * When we talk about /concurrency/ in Scala, we should know Scala inherits
      things from the JVM
      + /memory model/
      + /multithreading capabilities/
      + /inter-thread synchronization/

  - Most, if not all, /higher-level Scala concurrency constructs/
    *are implemented in terms of* the /low-level primitives/
    presented in this chapter.
    * In a way, the /APIs/ and /synchronization primitives/ in this chapter
      constitute the assembly of /concurrent programming on the JVM/.

  - In most cases,
    you should
    *avoid* /low-level concurrency constructs/
    *in place of* /higher-level constructs/
    =TODO= introduced later.
    * However, it is _IMPORTANT_ for you to understand
      + what a /thread/ is, that
      + a /guarded block/ is better than /busy-waiting/, =TODO=
      + _why a /memory model/ is useful_. =TODO=
      This is essential for a better understanding of /high-level concurrency
      abstractions/.

    * *In practice, all abstractions are to some extent leaky.*
      This is why you need to understand what are *behind* the /abstraction/.

  - In what follows, we =TODO=
    * not only *explain* _the CORNERSTONES of /concurrency on JVM/,_
    * but also *discuss* _HOW they *interact* with some /Scala-specific features/._

  - In particular, _we will cover the following topics in this chapter_: =TODO=
    * *Creating* and *starting* /threads/ and *waiting* for their completion

    * *Communication between* /threads/
      USING /object monitors/ and the /synchronized statement/ =???=

    * How to *avoid* /busy-waiting/ using /guarded blocks/ =???=

    * The /semantics/ of /volatile variables/ =???=

    * The specifics of the /Java Memory Model (JMM)/, and *why* the /JMM/ is
      _important_

  - In the following section, we will study how to use /threads/ -- the BASIC WAY
    to *express* /concurrent computations/.

** TODO Processes and threads - 30
   - In OS's of _MODERN_, /pre-emptive/, /multitasking/,
     the programmer has _LITTLE or NO control_ over the choice of processor on
     which the program will be executed --
     it is usually the task of the OS to
     *assign* executable parts of the program
     *to* SPECIFIC /processors/.

   - multitasking :: the /concurrent execution/ of MULTIPLE /tasks/ (also known as /processes/)
                     over a certain period of time. 
                     =from Jian= from Wikipedia

   - /Multitasking/ happens _transparently_ for the computer users.
     * =from Jian=
       Computer users can use computers without noticing the details of /multitasking/:
       The same program might
       + run on _MANY *different* processors_ during its execution
         AND
       + sometimes even *simultaneously* on several _processors_.

     * Historically,
       /Multitasking/ was introduced to OS's to _improve the user experience_ by
       allowing multiple users or programs to share resources of the same computer
       simutaneously.

   - In cooperative /multitasking/,
     * OLD solution (easy to be out of control):
       + *programs were able to decide*
         1. when to stop using the processor
            AND
         2. yield control to other programs.

       + _HOWEVER_,
         - this required a lot of discipline on the programmer's part
         - programs could easily give the impression of being *unresponsive*.

         *Blocking* the execution _UNTIL_ a non-short-term job complete often
         *ruin* the /user experience/.

     * Modern solution:
       _MOST_ OS's today _rely on_ /pre-emptive multitasking/, in which each
       program is *repetitively assigned* _slices of execution time (/time
       slices/)_ at a specific processor.

     Thus, /multitasking/ happens *transparently* for the application programmer
     as well as the user -- OS's do the control, not programmers.

   - The same computer program
     can be started _more than once_, or _even simultaneously_ within the same OS.

   - process :: an instance of a computer program that *is being executed*.
     1. When a /process/ starts,
        the OS *reserves*
        * a part of the /memory/ and
        * OTHER _computational resources_ and
         *associates* them *with* a _SPECIFIC computer program_.
     2. The OS then associates a /processor/ with this /process/, and this /process/
        executes during _ONE /time slice/._

     3. Eventually, the OS gives _OTHER_ /processes/ control over the /processor/.

   - Importantly, the /memory/ and _other computational resources_ of one /process/ are
     *ISOLATED* from the _other_ /processes/:
     * they CAN'T read each other's /memory/ _directly_
       or
     * they CAN'T _simultaneously_ use MOST of the resources.

   - For /multiple processes programs/,
     DIFFERENT /tasks/ within the program are expressed as _SEPARATE_ /processes/.
     Since SEPARATE /processes/ *cannot* access the SAME /memory/ areas
     directly, *it _can be CUMBERSOME_ to express /multitasking/ using MULTIPLE
     /processes/.*

   - /Multitasking/ was important long *BEFORE* recent years when /multicore
     computers/ became mainstream. Large programs such as _web browsers/ are the
     examples.

   - Large programs are divided into many logical modules.
     For example, web browsers:
     * A browser's _download manager_ downloads files *independent* of
       _rendering_ the web page or updating the HTML /Document Object Model
       (DOM)/.

     * *BUT*
       both INDEPENDENT computations (/threads/) occur as part of the *SAME*
       /process/.

   - threads :: independent computations occurring in the *SAME* /process/.

   - In a typical OS,
     there are *MANY MORE* /threads/ *than* /processors/.

   - Every /thread/ describes
     * the _current state_ of the /program stack/
       + program stack :: a sequence of /method invocations/ that are currently
                          being executed, along with the /local variables/ and
                          /method parameters of each method/.

     * the /program counter/ _DURING_ program execution
       + program counter :: describes the *position* of the CURRENT /instruction/
                             in the current /method/.

   - A /processor/ can _advance_ the computation in some /thread/
     by MANIPULATING
     * the /STATE/ of its /stack/
       or
     * the /STATE/ of the program objects

     and
     *executing* the /instruction/ at the /current program counter/.

   - When we say that
     _a /thread/ performs an action such as writing to a memory location_,
     we mean that
     _the /processor/ executing that /thread/ performs that action._

   - In /pre-emptive multitasking/, /thread/ execution is *scheduled by* the OS.
     * A programmer *must assume* that the /processor/ _time assigned_ to their
       /thread/ is *UNBIASED* towards other /threads/ in the system.

   - /OS threads/ are a programming facility _provided by_ the OS,
     usually exposed THROUGH an /OS-specific programming interface/.
     * *UNLIKE* separate /processes/,
       SEPARATE /OS threads/ _within_ the same /process/ *share*
       + a region of /memory/, and
       + *communicate* by _writing_ to and _reading_ parts of that /memory/.

   - /process/ :: (alternative definition)
                  a set of OS /threads/ along with the /memory/ and /resources/
                  *shared* by these /threads/.

   - We _turn our attention to_ see
     * HOW these concepts relate to the JVM,
       the runtime on top of which Scala programs execute.

   - _Starting_ a _NEW_ /JVM instance/
     ALWAYS CREATES *only one* /process/.
     * _WITHIN_ the JVM /process/, MULTIPLE /threads/ can run simultaneously.
       The JVM represents its /threads/ with the ~java.lang.Thread~ /class/.

   - *UNLIKE* /runtimes/ for languages such as Python,
     the JVM _does *NOT* implement its custom /threads/._
     INSTEAD, each /Java thread/ is _directly mapped to_ an /OS thread/.

     * This means that Java /threads/
       + behave in a _very similar_ way to the /OS threads/
       + the JVM _depends on_ the OS and its RESTRICTIONS.

   - Scala is a programming language that is by default compiled to the JVM
     bytecode, and the Scala compiler output is largely equivalent to that of
     Java from the JVM's perspective. This allows Scala programs to
     transparently call Java libraries, and in some cases, even vice versa.

   - Scala *reuses* the /threading API/ from Java for _several REASONS_:
     * Scala can _transparently_ *interact with* the existing /Java thread model/,
       which is already sufficiently comprehensive.

     * it is useful to *retain* the same /threading API/ *for compatibility
       reasons*, and _there is *NOTHING* fundamentally new_ that Scala can
       introduce with respect to the /Java thread API/.

   - =TODO=
     The rest of this chapter shows
     * HOW to *create* /JVM threads/ using Scala
     * HOW they can be *executed*
     * HOW they can *communicate*.

   - We will show and discuss several concrete examples.
     Java aficionados, already well-versed in this subject, might choose to *SKIP*
     the rest of this chapter.

*** TODO Creating and starting threads - 33
    - Every time a new /JVM process/ starts,
      *it creates several /threads/ _by default_.*

    - The most important /thread/ among them is *the /main thread/,*
      which executes the ~main~ /method/ of the Scala program.

    - We will show this in the following program, which _gets the NAME of the
      CURRENT /thread/_ and prints it to the standard output:
      #+BEGIN_SRC scala
        object ThreadsMain extends App {
          val t: Thread = Thread.currentThread
          val name = t.getName
          println(s"I am the thread $name")
        }
      #+END_SRC
      * If you run this program directly, you can see
        =[info] I am the thread main=

      * If you run this program *in SBT*, BY DEFAULT, you can see
        =[info] I am the thread run-main-0=
        + By default (~fork := false~),
          SBT started this program *INSIDE its /process/, on a SEPARATE /thread/.*

        + To ensure that the program runs *INSIDE a SEPARATE JVM /process/,*
          type ~set fork := true~ in SBT console or add ~fork := true~ to the
          project =build.sbt=, and then you can see:
          =[info] I am the thread main=

    - EVERY /thread/ *goes through* several /thread states/ during its existence.
      1. When a ~Thread~ object is *created*, it is initially in _the *NEW* state_.
      2. After the newly created /thread/ object *starts executing*, it goes into
         _the *runnable* state_.
      3. After the /thread/ is *done* executing, the /thread/ object goes into
         _the *terminated* state_, and _CANNOT execute anymore_.

    - Starting an independent /thread/ of computation consists of
      *TWO steps*:
      1. *Create* a ~Thread~ /object/
         to *allocate* the /memory/ for the /stack/ and /thread state/.

      2. Call the ~start~ /method/ to _start the computation_.

    - ~ThreadsCreation~:
      #+BEGIN_SRC scala
        object ThreadsCreation extends App {
          class MyThread extends Thread {
            override def run(): Unit = {
              println("New thread running.")
            }
          }

          val t = new MyThread
          t.start()
          t.join()
          println("New thread joined.")
        }
      #+END_SRC
      A JVM application starts and creates the /main thread/ to execute the
      /method/ call ~main~ from a specified /class/, in this case, the
      ~ThreadsCreation~ /object/.
      
      In this example, the /main thread/
      1. Creates another /thread/ of the ~MyThread~ type
         AND
         assigns it to ~t~.

      2. Starts ~t~ by calling the ~start~ /method/.
         1) Calling the ~start~ /method/ eventually
            *results in* executing the ~run~ /method/ from _the NEW /thread/._

         2) The OS is notified that ~t~ *MUST start executing*.
            * *NOT* start executing IMMEDIATELY!

         3) When the OS decides to assign _the NEW /thread/_ to some /processor/
            is largely *out of the programmer's control*,
            BUT the OS must *ensure* that this _eventually happens._

         4) After the /main thread/ *starts* the _NEW /thread/ ~t~,_
            it calls the ~join~ /method/ of ~t~. This /method/
            *halts* the execution of the /main thread/
            *until* ~t~ _completes_ its execution.

            * The ~join~ operation
              *puts* the /main thread/ into the waiting state
              *until* ~t~ terminates.

              + Importantly,
                _the WAITING /thread/_ *relinquishes* its control over the /processor/, and
                the OS can *assign* that /processor/ *to* _some OTHER /thread/._
                - /Waiting threads/
                  * *notify* the OS that they
                    are *waiting* for some _CONDITION_
                    AND
                    *cease spending* /CPU cycles/,

                  * INSTEAD of *repetitively checking* that _CONDITION_.

*** TODO Atomic execution - 38
*** TODO Reordering - 42

** TODO Monitors and synchronization - 45
*** TODO Deadlocks - 47
*** TODO Guarded blocks - 50
*** TODO Interrupting threads and the graceful shutdown - 55

** TODO Volatile variables - 56
** TODO The Java Memory Model - 58
*** TODO Immutable objects and final fields - 60

** TODO Summary - 62
** TODO Exercises - 63

* TODO Chapter 3: Traditional Building Blocks of Concurrency - 67
** The Executor and ExecutionContext objects - 68
** Atomic primitives - 72
*** Atomic variables - 73
*** Lock-free programming - 76
*** Implementing locks explicitly - 78
*** The ABA problem - 80

** Lazy values - 83
** Concurrent collections - 88
*** Concurrent queues - 89
*** Concurrent sets and maps - 93
*** Concurrent traversals - 98

** Custom concurrent data structures - 101
*** Implementing a lock-free concurrent pool - 102
*** Creating and handling processes - 106

** Summary - 108
** Exercises - 109

* TODO Chapter 4: Asynchronous Programming with Futures and Promises - 112
** Futures - 113
*** Starting future computations - 115
*** Future callbacks - 117
*** Futures and exceptions - 120
*** Using the Try type - 121
*** Fatal exceptions - 123
*** Functional composition on futures - 124

** Promises - 132
*** Converting callback-based APIs - 134
*** Extending the future API - 137
*** Cancellation of asynchronous computations - 138

** Futures and blocking - 141
*** Awaiting futures - 141
*** Blocking in asynchronous computations - 142

** The Scala Async library - 143
** Alternative future frameworks - 146
** Summary - 148
** Exercises - 148

* TODO Chapter 5: Data-Parallel Collections - 152
** Scala collections in a nutshell - 153
** Using parallel collections - 154
*** Parallel collection class hierarchy - 158
*** Configuring the parallelism level - 160
*** Measuring the performance on the JVM - 161

** Caveats with parallel collections - 164
*** Non-parallelizable collections - 164
*** Non-parallelizable operations - 165
*** Side effects in parallel operations - 168
*** Nondeterministic parallel operations - 169
*** Commutative and associative operators - 170

** Using parallel and concurrent collections together - 173
*** Weakly consistent iterators - 174

** Implementing custom parallel collections - 175
*** Splitters - 176
*** Combiners - 179

** Summary - 182
** Exercises - 184

* TODO Chapter 6: Concurrent Programming with Reactive Extensions - 186
** Creating Observable objects - 188
*** Observables and exceptions - 190
*** The Observable contract - 192
*** Implementing custom Observable objects - 194
*** Creating Observables from futures - 195
*** Subscriptions - 196

** Composing Observable objects - 199
*** Nested Observables - 201
*** Failure handling in Observables - 206

** Rx schedulers - 209
*** Using custom schedulers for UI applications - 211

** Subjects and top-down reactive programming - 218
** Summary - 223
** Exercises - 223

* TODO Chapter 7: Software Transactional Memory - 227
** The trouble with atomic variables - 228
** Using Software Transactional Memory - 232
*** Transactional references - 235
*** Using the atomic statement - 236

** Composing transactions - 238
*** The interaction between transactions and side effects - 238
*** Single-operation transactions - 243
*** Nesting transactions - 244
*** Transactions and exceptions - 247

** Retrying transactions - 252
*** Retrying with timeouts - 256

** Transactional collections - 258
*** Transaction-local variables - 258
*** Transactional arrays - 259
*** Transactional maps - 261

** Summary - 263
** Exercises - 264

* TODO Chapter 8: Actors - 267
** Working with actors - 268
*** Creating actor systems and actors - 271
*** Managing unhandled messages - 274
*** Actor behavior and state - 276
*** Akka actor hierarchy - 282
*** Identifying actors - 285
*** The actor lifecycle - 288

** Communication between actors - 292
*** The ask pattern - 294
*** The forward pattern - 297
*** Stopping actors - 298

** Actor supervision - 300
** Remote actors - 306
** Summary - 310
** Exercises - 310

* TODO Chapter 9: Concurrency in Practice - 313
** Choosing the right tools for the job - 314
** Putting it all together – a remote file browser - 319
*** Modeling the filesystem - 320
*** The server interface - 324
*** Client navigation API - 326
*** The client user interface - 330
*** Implementing the client logic - 334
*** Improving the remote file browser - 339

** Debugging concurrent programs - 340
*** Deadlocks and lack of progress - 341
*** Debugging incorrect program outputs - 346
*** Performance debugging - 351

** Summary - 358
** Exercises - 359

* TODO Chapter 10: Reactors - 361
** The need for reactors - 362
** Getting started with Reactors - 364
** The “Hello World” program - 364
** Event streams - 366
*** Lifecycle of an event stream - 367
*** Functional composition of event streams - 369

** Reactors - 371
*** Defining and configuring reactors - 373
*** Using channels - 374

** Schedulers - 377
** Reactor lifecycle - 378
** Reactor system services - 381
*** The logging service - 381
*** The clock service - 382
*** The channels service - 383
*** Custom services - 384

** Protocols - 387
*** Custom server-client protocol - 387
*** Standard server-client protocol - 390
**** Using an existing connector - 391
**** Creating a new connector - 391
**** Creating a protocol-specific reactor prototype - 392
**** Spawning a protocol-specific reactor directly - 393

*** Router protocol - 393
*** Two-way protocol - 395
** Summary - 399
** Exercises - 399

* Index - 402
