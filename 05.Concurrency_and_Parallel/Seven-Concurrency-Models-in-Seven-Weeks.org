#+TITLE: Seven Concurrency Models in Seven Weeks
#+SUBTITLE: When Threads Unravel
#+VERSION: 2014
#+AUTHOR: Paul Butcher
#+STARTUP: entitiespretty
#+STARTUP: indent
#+STARTUP: overview

* Foreword - vii
* Acknowledgments - ix
* Preface - xi
* 1. Introduction - 1
** Concurrent or Parallel? - 1
** Parallel Architecture - 3
** Concurrency: Beyond Multiple Cores - 4
** The Seven Models - 7

* 2. Threads and Locks - 9
** The Simplest Thing That Could Possibly Work - 9
** Day 1: Mutual Exclusion and Memory Models - 10
** Day 2: Beyond Intrinsic Locks - 21
** Day 3: On the Shoulders of Giants - 32
** Wrap-Up - 44

* TODO 3. Functional Programming - 49
** If It Hurts, Stop Doing It - 49
** Day 1: Programming Without Mutable State - 50
*** The Perils of Mutable State - 50
**** Hidden Mutable State - 50
**** Escapologist Mutable State - 51

*** A Whirlwind Tour of Clojure - 52
*** Our First Functional Program - 53
*** Effortless Parallelism - 54
*** Counting Words Functionally - 56
**** Functional Maps - 57
**** Frequencies - 57
**** More Sequence Functions - 58
**** Putting It All Together - 58

*** It's Good to Be Lazy - 59
*** Day 1 Wrap-Up - 60
**** What We Learned in Day 1 - 60
**** Day 1 Self-Study - 60
***** Find - 60
***** Do - 61

** Day 2: Functional Parallelism - 61
*** One Page at a Time - 61
*** Batching for Performance - 63
*** Reducers - 64
*** Reducers' Internals - 65
*** Divide and Conquer - 67
*** Supporting Fold - 68
*** Frequencies with Fold - 69
*** Day 2 Wrap-Up - 70
**** What We Learned in Day 2 - 70
**** Day 2 Self-Study - 70
***** Find - 71
***** Do - 72

** Day 3: Functional Concurrency - 71
*** Same Structure, Different Evaluation Order - 71
*** Referential Transparency - 72
*** Dataflow - 73
*** Futures - 74
*** Promises - 74
*** A Functional Web Service - 75
**** Accepting Snippets - 76
**** Sentences - 78
**** Translating Sentences - 79
**** Putting It All Together - 80

*** Day 3 Wrap-Up - 81
**** What We Learned in Day 3 - 81
**** Day 3 Self-Study - 82
***** Find - 82
***** Do - 82

** Wrap-Up - 82
*** Strengths - 83
*** Weaknesses - 84
*** Other Languages - 84
*** Final Thoughts - 84

* TODO 4. The Clojure Way -- Separating Identity from State - 85
** TODO The Best of Both Worlds - 85
** TODO Day 1: Atoms and Persistent Data Structures - 85
*** Atoms - 86
*** A Multithreaded Web Service with Mutable State - 87
*** Persistent Data Structures - 88
*** Identity or State? - 91
*** Retries - 92
*** Validators - 92
*** Watchers - 92
*** A Hybrid Web Service - 93
**** Session Management - 93
**** Session Expiration - 94
**** Putting It All Together - 95

*** Day 1 Wrap-Up - 96
**** What We Learned in Day 1 - 96
**** Day 1 Self-Study - 97
***** Find - 60
***** Do - 61

** TODO Day 2: Agents and Software Transactional Memory - 97
*** Agents - 97
**** Waiting for Agent Actions to Complete - 98
**** Error Handling - 99

*** An In-Memory Log - 101
*** Software Transactional Memory - 101
**** Transactions - 102
**** Multiple Refs - 103
**** Retrying Transactions - 103
**** Safe Side Effects in Transactions - 105

*** Shared Mutable State in Clojure - 105
*** Day 2 Wrap-Up - 106
**** What We Learned in Day 2 - 106
**** Day 2 Self-Study - 106
***** Find - 106
***** Do - 106

** TODO Day 3: In Depth - 106
*** Dining Philosophers with STM - 107
**** A First Attempt - 108
**** Ensuring That a Value Does Not Change - 108

*** Dining Philosophers Without STM - 109
*** Atoms or STM ? - 110
*** Custom Concurrency - 110
*** Day 3 Wrap-Up - 112
**** What We Learned in Day 3 - 112
**** Day 3 Self-Study - 113
***** Find - 113
***** Do - 113

** TODO Wrap-Up - 113
*** Strengths - 113
*** Weaknesses - 113
*** Other Languages - 114
*** Final Thoughts - 114

* TODO 5. Actors - 115
  - =from Jian=
    Originally /BEAM/ was short for /Bogdan's Erlang Abstract Machine/, named
    after Bogumil "Bogdan" Hausman, who wrote the original version, but the name
    may also be referred to as /Björn's Erlang Abstract Machine/, after Björn
    Gustavsson, who wrote and maintains the current version. Both developers
    worked on the system while at Ericsson.

** TODO More Object-Oriented than Objects - 115
   - Functional programming AVOIDS the problems associated with *shared mutable state*,
     by *avoiding* /mutable state/

     /Actor model/ AVOIDS *share*, but retains *mutable state*.

   - Many concepts in /actor modle/ is similar to the ones in the _popular OO
     program_, but they have some significant differences:
     + /actors/ run concurrently with each other

     + /actors/ _REALLY_ communicate by passing messages.

       However, the message passing of _popular OO program_ is mostly limited to
       calling /methods/.

   - Use Elixir code as an illustration!

   - In day 1
     The basics of the actor model -- creating actors and sending and receiving
     messages.

     In day 2
     How failure detection, coupled with the "let it crash" philosophy, allows
     actor programs to be fault-tolerant.

     In day 3
     How actors' support for distributed programming allows us to both scale
     beyond a single machine and recover from failure of one or more of those
     machines.

** DONE Day 1: Messages and Mailboxes - 116 - =TODO - Wrap-Up=
   CLOSED: [2018-09-23 Sun 00:15]
   - *Joe asks: Actor or Process?*
     =TODO=

*** DONE Our First Actor - 116
    CLOSED: [2018-09-22 Sat 14:20]
    #+BEGIN_SRC elixir
      # Actors/hello_actors/hello_actors.exs
      defmodule Talker do
        def loop do
          receive do
            {:greet,     name     } -> IO.puts {"Hello #{name}"}
            {:praise,    name     } -> IO.puts {"#{name}, you're amazing"}
            {:celebrate, name, age} -> IO.puts {"Here's to another #{age} years, #{name}"}
          end
          loop
        end
      end

      pid = spawn(&Talker.loop/0)  ## Create an actor, and use `pid` to refer it.
      send(pid, {:greet, "Huey"})
      send(pid, {:praise, "Dewey"})
      send(pid, {:celebrate, "Louie", 16})
      sleep(1000)  ## NOT a good way, learn a better way later!

      # Hello Huey
      # Dewey, you're amazing
      # Here's to another 16 years, Louie
    #+END_SRC

    See what's going on under the hood.

*** DONE Mailboxes Are Queues - 117
    CLOSED: [2018-09-22 Sat 14:28]
    - One of the most important features of /actor/ programming is that
      _messages are sent /asynchronously/_ -- to each /mailbox/ of the receiver
      /actors/.

    - This means that actors are *decoupled* --
      /actors/ run at their own speed and do _NOT block_ when sending messages.

    - An /actor/ *runs* /concurrently/ with other /actors/
      but *handles messages* /sequentially/, in the order they were added to the
      mailbox, moving on to the next message only when it's finished processing
      the current message.

      =TODO= =IMPORTANT=
      We only have to worry about concurrency when sending messages.

*** DONE Receiving Messages - 118
    CLOSED: [2018-09-22 Sat 14:34]
    - An /actor/ typically sits in an _infinite loop_, waiting for a message to
      arrive with receive and then processing it.

      Our ~loop~ function (in ~Talker~ module) implements an _infinite loop_ by
      calling itself recursively

    - *Joe asks: Won’t Infinite Recursion Blow Up the Stack?*
     Exilir implements /tail-call elimination/
    1
*** DONE Linking Processes - 119
    CLOSED: [2018-09-22 Sat 15:50]
    - We need two things to be able to shut down cleanly.
      1. we need a way to tell our /actor/ to stop when it's finished processing
         all the messages in its queue.

         + solution: add a new kind of message and its handler:
           ~{:shutdown} -> exit(:normal)~

      2. we need some way to know that it has done so.

         + solution:
           Use
           #+BEGIN_SRC elixir
             Process.flag(:trap_exit, true)
             pid = spawn_link(&Talker.loop/0)
           #+END_SRC

           and then, after sending ~{:shutdown}~,

           #+BEGIN_SRC elixir
             receive do
               {:EXIT, ^pid, reason} -> IO.puts("Talker has exited (#{reason})")
             end
           #+END_SRC

    - Solution:
      #+BEGIN_SRC elixir
        defmodule Talker do
          def loop do
            receive do
              {:greet,     name}      -> IO.puts("Hello #{name}")
              {:praise,    name}      -> IO.puts("#{name}, you're amazing")
              {:celebrate, name, age} -> IO.puts("Here's to another #{age} years, #{name}")
              {:shutdown}             -> exit(:normal)
            end
            loop
          end
        end

        Process.flag(:trap_exit, true)
        pid = spawn_link(&Talker.loop/0)
        send(pid, {:greet, "Huey"})
        send(pid, {:praise, "Dewey"})
        send(pid, {:celebrate, "Louie", 16})
        send(pid, {:shutdown})

        receive do
          {:EXIT, ^pid, reason} -> IO.puts("Talker has exited (#{reason})")
        end

        # Hello Huey
        # Dewey, you're amazing
        # Here's to another 16 years, Louie
        # Talker has exited (normal)
      #+END_SRC

    - 

*** DONE Stateful Actors - 120
    CLOSED: [2018-09-22 Sat 16:02]
    They are actually recursions.
    #+BEGIN_SRC elixir
      ## Actors/counter/counter.ex
      defmodule Counter do
        def loop(count) do
          receive do
            {:next} ->
              IO.puts("Current count: #{count}")
              loop(count + 1)
          end
        end
      end

      counter = spawn(Counter, :loop, [1])
      send(counter, {:next})  # Current count: 1
      send(counter, {:next})  # Current count: 2
      send(counter, {:next})  # Current count: 3
    #+END_SRC

    This is the actor, which can safely access the states withough any
    concurrency bugs -- messages are *handled sequentially*.

*** DONE Hiding Messages Behind an API - 121
    CLOSED: [2018-09-22 Sat 16:47]
    #+BEGIN_SRC elixir
      defmodule Counter do
        def start(count) do
          spawn(__MODULE__, :loop, [count])
        end

        def next(counter) do
          send(counter, {:next})
        end

        def loop(count) do
          receive do
            {:next} ->
              IO.puts("Current count: #{count}")
              loop(count + 1)
          end
        end
      end

      counter = Counter.start(42)  ## #PID<0.44.0>
      Counter.next(counter)  ## Current count: 42 # {:next}
      Counter.next(counter)  ## Current count: 43 # {:next}
    #+END_SRC

    Next, let's make bidirectional communication, and then we can do something
    more interesting than just print out states.

*** DONE Bidirectional Communication - 122
    CLOSED: [2018-09-22 Sat 22:31]
    The /actor model/ does *NOT* provide direct support for replies,

    but it's something we can _build for ourselves very easily_ *by including
    the identifier of the sending process in the message*, which allows the
    recipient to send a reply:
    #+BEGIN_SRC elixir
      defmodule Counter do
        def start(count) do
          spawn(__MODULE__, :loop, [count])
        end

        def next(counter) do
          ref = make_ref()
          send(counter, {:next, self(), ref})
          receive do
            {:ok, ^ref, count} -> count
          end
        end

        def loop(count) do
          receive do
            {:next, sender, ref} ->
              send(sender, {:ok, ref, count})
              loop(count + 1)
          end
        end
      end

      counter = Counter.start(42)  ## #PID<0.47.0>
      Counter.next(counter)        ## 42
      Counter.next(counter)        ## 43
    #+END_SRC
    
    - *Joe asks: Why Reply with a Tuple?*
      Certainly, you can simply reply the _count_, like ~send(sender, count)~,
      rather than a tuple contains it.

      However, *idiomatic Elixir* typically uses _tuples as messages_, where
      + the first element indicates success or failure.

      In this instance, we also include a unique reference generated by the
      client, which ensures that the reply will be correctly identified in the
      event that there are multiple messages waiting in the client's mailbox.

    - NEXT: =TODO=
      We'll make one further improvement to ~Counter~ before we move on --
      _giving it a name to make it discoverable_.

*** DONE Naming Processes - 123
    CLOSED: [2018-09-22 Sat 22:31]
    - Unitl now, we only sent messages to /actors/ we created. Then,
      + Q :: How to send messages to /actors/ that are NOT created by us???

      + A :: There are several ways!
             The most convenient is to _register a name_ for the /process (actor
             in Elixir)/.

    - Example:
      #+BEGIN_SRC elixir
        pid = Counter.start(42)              # #PID<0.47.0>
        Process.register(pid, :counter)      # true
        counter = Process.whereis(:counter)  # #PID<0.47.0>
        Counter.next(counter)                # 42
      #+END_SRC

      + Run ~Process.registered~ to see all registered /actors (or processes,
        another name of actor in Elixir)/.

        As you can see, the virtual machine _automatically_ registers a number
        of standard processes at startup.

      + The ~send~ function can take a /process name/ instead of a /process identifier/.
        #+BEGIN_SRC elixir
          send(:counter, {:next, self(), make_ref()})  # {:next, #PID<0.45.0>, #Reference<0.0.0.107>}
          receive do msg -> msg end                    # {:ok, #Reference<0.0.0.107>, 43}
        #+END_SRC

    - Modified code that use /process name/ rather than /process identifier/:
      #+BEGIN_SRC elixir
        def start(count) do
          pid = spawn(__MODULE__, :loop, [count])
          Process.register(pid, :counter)
          pid
        end

        def next do
          ref = make_ref()
          send(:counter, {:next, self(), ref})
          receive do
            {:ok, ^ref, count} -> count
          end
        end

        Counter.start(42)  # #PID<0.47.0>
        Counter.next       # 42
        Counter.next       # 43
      #+END_SRC

    - Next:
      Parallel Map,
      First, its prelude

*** DONE Interlude—First-Class Functions - 124
    CLOSED: [2018-09-22 Sat 22:37]
    #+BEGIN_SRC elixir
      Enum.map([1, 2, 3, 4], fn(x) -> x * 2 end)
      # Shorthand syntax
      Enum.map([1, 2, 3, 4], &(&1 * 2))

      double = &(&1 * 2)    # #Function<erl_eval.6.80484245>
      double.(3)            # 6

      twice = fn(fun) -> fn(x) -> fun.(fun.(x)) end end  # #Function<erl_eval.680484245>
      twice.(double).(3)                                 # 12
    #+END_SRC

*** DONE Parallel Map - 125
    CLOSED: [2018-09-23 Sun 00:06]
    Here this "map" is the operation, not the same name data structure.

    #+BEGIN_SRC elixir
      defmodule Parallel do
        def map(collection, fun) do
          parent = self()

          processes = Enum.map(collection, fn(e) ->
            spawn_link(
              fn() ->
                send(parent, {self(), fun.(e)})
              end)
            end)

          Enum.map(processes,
            fn(pid) ->
              receive do
                {^pid, result} -> result
              end
            end)
        end
      end
    #+END_SRC

    + =from Jian=
      It seems the cost of creating /processes (actor)/ in sequential does NOT
      have much overhead.

    + Test:
      #+BEGIN_SRC elixir
        slow_double = fn(x) -> :timer.sleep(1000); x * 2 end            # #Function<6.80484245 in :erl_eval.expr/5>
        :timer.tc(fn() -> Enum.map([1, 2, 3, 4], slow_double) end)      # {4003414, [2, 4, 6, 8]}
        :timer.tc(fn() -> Parallel.map([1, 2, 3, 4], slow_double) end)  # {1001131, [2, 4, 6, 8]}
      #+END_SRC

*** TODO Day 1 Wrap-Up - 126
    End day 1!

    In day 2, learn how the actor model helps with _error handling_ and
    _resilience_.

**** What We Learned in Day 1 - 126
     - Actors (processes)
       + run concurrently
       + do not share state
       + communicate by asynchronously sending messages to mailboxes.

     - We covered how to do the following:
       + *Create* a new /process/ with ~spawn()~

       + *Send* a /message/ to a /process/ with ~send()~

       + Use /pattern matching/ to *handle* /messages/

       + *Create* a _link between two processes_ and _receive notification when
         one terminates_

       + *Implement* _bidirectional_, _synchronous messaging_ ON TOP OF the _standard
         asynchronous messaging_

       + *Register* a name for a /process/

**** Day 1 Self-Study - 126
***** Find
      - =TODO=
        The video of Erik Meijer and Clemens Szyperski talking to Carl Hewitt
        about the actor model at Lang.NEXT 2012

***** TODO Do
      - =TODO=
        Measure the cost of creating a process on the BEAM.
        How does it compare with the cost of creating a thread on the JVM?

      - =TODO=
        Measure the cost of the parallel map function we created compared to a
        sequential map. When would it make sense to use a parallel map, and when
        a sequential map?

      - =TODO=
        Write a parallel reduce function along the lines of the parallel map
        function we just created.

** DONE Day 2: Error Handling and Resilience - 127 - =TODO= =RE-READ=
   CLOSED: [2018-09-23 Sun 21:19]
   One of the key benefits of /concurrency/ is that it enables us to write
   /fault-tolerant/ code -- ech concurrency modle has their own way. We will show
   how the /actor modle/ do this.

   Create a more complicated and realistic example as a basis for today's
   discussion.

*** TODO A Caching Actor - 127
    - We'll use the map data structure.
      #+BEGIN_SRC elixir
        d = Map.new                            ### %{}
        d1 = Map.put(d, :a, "A value for a")   ### %{a: "A value for a"}
        d2 = Map.put(d1, :b, "A value for b")  ### %{a: "A value for a", b: "A value for b"}
        d1                                     ### %{a: "A value for a"}
        d2[:a]                                 ### "A value for a"
      #+END_SRC

    - Then,
      #+BEGIN_SRC elixir
        defmodule Cache do
          def loop(pages, size) do
            receive do
              {:put, url, page} ->
                new_pages = Map.put(pages, url, page)
                new_size = size + byte_size(page)
                loop(new_pages, new_size)

              {:get, sender, ref, url} ->
                send(sender, {:ok, ref, pages[url]})
                loop(pages, size)

              {:size, sender, ref} ->
                send(sender, {:ok, ref, size})
                loop(pages, size)

              {:terminate} -> # Terminate request - don't recurse
            end
          end
        end
      #+END_SRC

      To provide a better API, we add these functions to ~Cache~:
      #+BEGIN_SRC elixir
        def start_link do
          pid = spawn_link(__MODULE__, :loop, (Map.new, 0))
          Process.register(pid, :cache)
          pid
        end

        def put(url, page) do
          send(:cache, {:put, url, page})
        end

        def get(url) do
          ref = make_ref()
          send(:cache, {:get, self(), ref, url})
          receive do
            {:ok, ^ref, page} -> page
          end
        end

        def size do
          ref = make_ref()
          send(:cache, {:size, self(), ref})
          receive do
            {:ok, ^ref, s} -> s
          end
        end

        def terminate do
          send(:cache, {:terminate})
        end
      #+END_SRC

    - For this program, if you try to put a ~nil~ as page into it, the ~byte_size~
      function invocation will crash.

      We will see how does the /actor model/ deal with it.
      (Use /supervisor process/).

*** DONE Fault Detection - 130
    CLOSED: [2018-09-23 Sun 18:52]
    - In Linking Processes, on page 119,

      we used ~spawn_link()~ to *create a link between two processes*
      so that we could *detect when one of them terminated*.

    - /Links/ are one of the *most important concepts* in Elixir programming.

**** DONE Links Propagate Abnormal Termination - 130
     CLOSED: [2018-09-23 Sun 14:33]
     - We can establish a /link/ between two /processes/ at _any time_ with
       ~Process.link()~.
       #+BEGIN_SRC elixir
         defmodule LinkTest do
           def loop do
             receive do
               {:exit_because, reason} -> exit(reason)
               {:link_to, pid}         -> Process.link(pid)
               {:EXIT, pid, reason}    -> IO.puts("#{inspect(pid)} exited because #{reason}")
             end
             loop
           end
         end
       #+END_SRC

     - Create a couple of instances of THIS /actor/, _link them_, and
       see what happens when one of them fails:
       #+BEGIN_SRC elixir
         pid1 = spawn(&LinkTest.loop/0)                    # #PID<0.47.0>
         pid2 = spawn(&LinkTest.loop/0)                    # #PID<0.49.0>
         send(pid1, {:link_to, pid2})                      # {:link_to, #PID<0.49.0>}
         send(pid2, {:exit_because, :bad_thing_happened})  # {:exit_because, :bad_thing_happened}

         Process.info(pid2, :status)  # nil
         Process.info(pid1, :status)  # nil
       #+END_SRC

     - Though when we check the status of ~pid1~ and ~pid2~, we found they both exit,
       we may also want to say something when we send the exit message to ~pid2~.
       This need set ~:trap_exit~.

**** DONE Links Are Bidirectional - 131
     CLOSED: [2018-09-23 Sun 18:42]
     /links/ are *bidirectional*, if you do
     ~send(pid1, {:exit_because, :another_bad_thing_happened})~
     Then, check the /status/, you'll see the same results as in the last section.

**** DONE Normal Termination - 131
     CLOSED: [2018-09-23 Sun 18:48]
     #+BEGIN_SRC elixir
       pid1 = spawn(&LinkTest.loop/0)          # #PID<0.47.0>
       pid2 = spawn(&LinkTest.loop/0)          # #PID<0.49.0>
       send(pid1, {:link_to, pid2})            # {:link_to, #PID<0.49.0>}
       send(pid2, {:exit_because, :normal})    # {:exit_because, :normal}

       Process.info(pid2, :status)  # nil
       Process.info(pid1, :status)  # {:status, :waiting}
     #+END_SRC

     If a /process/ quit normally, the linked one won't quit.

     =from Jian= ~:normal~ is special???

**** DONE System Processes - 132
     CLOSED: [2018-09-23 Sun 18:52]
     Allow a /process/ to _trap_ another's /exit/ by setting its ~:trap_exit~ flag.
     This is known in the jargon as making it into a /system process/: =???=
     #+BEGIN_SRC elixir
       def loop_system do
         Process.flag(:trap_exit, true)
         loop
       end

       pid1 = spawn(&LinkTest.loop_system/0)
       pid2 = spawn(&LinkTest.loop_system/0)
       send(pid1, {:link_to, pid2})
       send(pid2, {:exit_because, :yet_another_bad_thing_happend})
       # #PID<0.49.0> exited because yet_another_bad_thing_happened

       Process.info(pid2, :status)  # nil
       Process.info(pid2, :status)  # {:status, :waiting}
     #+END_SRC

*** DONE Supervising a Process - 132
    CLOSED: [2018-09-23 Sun 19:11]
    We now have enough tools at our fingertips to implement a /supervisor/, a
    /system process/ that monitors one or more /worker processes/ and takes
    appropriate action if they fail.

    - Example: simply restart its supervisee when it fails:
      #+BEGIN_SRC elixir
        defmodule CacheSupervisor do
          def start do
            spawn(__MODULE__, :loop_system, [])
          end

          def loop do
            pid = Cache.start_link
            receive do
              {:EXIT, ^pid, :normal} ->
                IO.puts("Cache exited normally")
                :ok

              {:EXIT, ^pid, reason} ->
                IO.puts("Cache failed with reason #{inspect reason} - restarting it")
                loop
            end
          end

          def loop_system do
            Process.flag(:trap_exit, true)
            loop
          end
        end
      #+END_SRC

    - In this example, we lose whatever was in the cache when it crashed, of course,
      but at least there's still a cache for us to use subsequently.
      #+BEGIN_SRC elixir
        CacheSupervisor.start                             # #PID<0.47.0>
        Cache.put("google.com", "Welcome to Google ...")  # {:put, "google.com", "Welcome to Google ..."}
        Cache.size                                        # 21

        ## If Cache crashes, it’s automatically restarted:
        Cache.put("paulbutcher.com", nil)  # {:put, "paulbutcher.com", nil}
                                           # Cache failed with reason {:badarg, [{:erlang, :byte_size, [nil], []}, ...
                                           #iex>
                                           # =ERROR REPORT==== 22-Aug-2013::17:49:24 ===
                                           #     Error in process <0.48.0> with exit value: {badarg,[{erlang,byte_size,[nil],[]}, ...

        Cache.size  # 0
        Cache.put("google.com", "Welcome to Google ...")  # {:put, "google.com", "Welcome to Google ..."}
        Cache.get("google.com")                           # "Welcome to Google ...
      #+END_SRC

*** DONE Timeouts - 133
    CLOSED: [2018-09-23 Sun 19:34]
    Automatically restarting the cache is great, but it's not a panacea.

    - If two processes both send messages to one cache /process/ at around the
      same time, for example, we might see the following sequence:
      1. Process 1 sends a ~:put~ message to the cache.
  
      2. Process 2 sends a ~:get~ message to the cache.
  
      3. The cache crashes while processing process 1's message.
  
      4. The /supervisor/ _restarts_ the cache, but process 2's message is *lost*.
  
      5. Process 2 is now _DEADLOCKED in a receive_, waiting for a reply that will
         never arrive.

    - We can use /timeout/ to solve the _deadlock of process 2_:
      #+BEGIN_SRC elixir
        def get(url) do
          ref = make_ref()
          send(:cache, {:get, self(), ref, url})
          receive do
            {:ok, ^ref, page} -> page
            after 1000 -> nil  ## The timeout part
          end
        end
      #+END_SRC

    - *Joe asks: Is Message Delivery Guaranteed?*
      There are *two basic guarantees*:
      + If _nothing breaks_,
        Message delivery is guaranteed 

      + If _something does break_,
        you'll know about it (assuming you've /linked to/, or /monitored/, the
        /process/ in question).

      *It's this second guarantee that forms the bedrock of Elixir's support for
      writing fault-tolerant code*.

*** DONE The Error-Kernel Pattern - 134
    CLOSED: [2018-09-23 Sun 19:52]
    /Actor/ programming naturally supports an approach to writing fault-tolerant
    code that leverages this observation: /the error-kernel pattern/.

    - error kernel :: The part of a software system that *must be correct if the
                      system is to function correctly*.

    - Well-written programs make this /error kernel/ *as small and as simple as
      possible* -- so small and simple that there are obviously no deficiencies.

    - *An /actor program/'s /error kernel/ is its _top-level supervisors_.*
        These supervise their children -- starting, stopping, and restarting
      them as necessary.

    - error kernel pattern ::
      Each module of a program has its own error kernel in turn—the part of the
         module that must be correct for it to function correctly. Submodules
         also have error kernels, and so on. This leads to a hierarchy of error
         kernels in which risky operations are pushed down toward the
         lower-level actors.
         See =Figure 8 - A hierarchy of error kernels=

    - Closely related to the /error-kernel pattern/ is the thorny subject of
      /defensive programming/. =TODO= =???= =TODO=

*** TODO Let It Crash! - 135
    - xx

*** TODO Day 2 Wrap-Up - 137
    Summary
    - Day 1
      _introduced_ the basics of the /actor model/

    - Day 2,
      we saw _how_ it facilitates _fault tolerance_.

    - Day 3,
      we'll see _how_ the /actor model/ helps with /distributed programming/.

**** DONE What We Learned in Day 2 - 137
     CLOSED: [2018-09-23 Sun 20:01]
     Elixir provides /fault detection/ BY allowing /processes/ to be /linked/,
     which can be used to create /supervisors/:
     - /Links/ are *bidirectional* -- if /process/ a is _linked_ to /process/ b,
       then b is also _linked_ to a.

     - /Links/ *propagate* errors -- if two /processes/ are _linked_ and one of
       them _terminates abnormally_, so will the other.

     - If a /process/ is marked as a /system process/,
       INSTEAD OF _exiting_ when a /linked process/ TERMINATES ABNORMALLY,
       it's notified with an ~:EXIT~ message.

**** TODO Day 2 Self-Study - 137
***** Find
      - The documentation for ~Process.monitor()~ -- how does monitoring a process
        differ from linking? _When_ might you use /monitors/ and _when_ /links/?
        =TODO=

      - How do /exceptions/ work in Elixir?
        *When* might you choose to use /exception/ handling instead of /supervision/
        and the “let it crash” pattern?
        =TODO=

***** Do
      - /Messages/ that do NOT match a pattern in a ~receive~ block *remain* in a
        /process's mailbox/.

        Use this fact, together with /timeouts/, to implement a /priority mailbox/,
        in which /high-priority messages/ are handled *ahead of* any /low-priority
        messages/ that might have been sent earlier.

      - Create a version of the cache we created in A /Caching Actor/, on page 127,
        that
        + distributes cache entries across /multiple actors/ according to a hash
          function.

        Create a /supervisor/ that starts MULTIPLE /cache actors/ and routes
        incoming messages to the appropriate cache worker. What action should
        this /supervisor/ take if one of the cache workers fails?
        =from Jian= try next actor that may match till no candidate actors left,
        and crash.

** TODO Day 3: Distribution - 137
   The /actor model/ supports both concurrency and distributed systems.

   Before talking about /distribution/, however, we'll take a quick look at one
   of the most powerful reasons for using Elixir -- the /OTP library/.

*** TODO OTP - 138
    - *Joe asks: What Does OTP Stand For?*
      OTP was "Open Telecom Platform", but now it's just a name by itself.

    - Before the OTP examples, we'll take a brief interlude to examine how /functions/
      and /pattern matching/ interact in Elixir.

**** DONE Functions and Pattern Matching - 138
     CLOSED: [2018-09-23 Sun 21:43]
     - Function definition in Elixir uses /pattern matching/.
       #+BEGIN_SRC elixir
         defmodule Patterns do
           def foo({x, y}) do
             IO.puts("Got a pair, first element #{x}, second #{y}")
           end
         end
       #+END_SRC

     - Any functions in Elixir can be considered as /partial functions/:
       #+BEGIN_SRC elixir
         Patterns.foo("something else")
         # ** (FunctionClauseError) no function clause matching in Patterns.foo/1
         #     patterns.ex:3: Patterns.foo("something else")
         #     erl_eval.erl:569: :erl_eval.do_apply/6
         #     src/elixir.erl:147: :elixir.eval_fo
       #+END_SRC

     - You can add as many pattern as you want.
       For example, make ~foo~ support another /pattern/:
       #+BEGIN_SRC elixir
         def foo({x, y, z}) do
           IO.puts("Got a triple: #{x}, #{y}, #{z}")
         end
       #+END_SRC

**** TODO Reimplementing Cache with GenServer - 139
     - ~GenServer~ (from OTP): a /behaviour/ that allows us to automate the details
       of creating a /stateful actor/.

     - A /behaviour/ is very similar to an _interface in Java_ -- it defines a set
       of functions.

       A module specifies that it *implements* a /behaviour/ with ~use~:
       #+BEGIN_SRC elixir
         defmodule Cache do
           use GenServer.Behaviour
           def
         end
       #+END_SRC

**** TODO An OTP Supervisor - 141
     - *Joe asks: What Is a Restart Strategy?*

*** TODO Nodes - 141
    Whenever we create an /instance/ of the BEAM, we create a /node/.
    So far, SINGLE /node/.
    This seciton, learn to create MULTIPLE /nodes/.

    - *Joe asks: What Else Does OTP Do?*
      Among other things, the OTP provide the following:
      
      + Better restart logic:
        The simple supervisor we wrote for ourselves has a very dumb approach to
        restarting its worker—if it terminates abnormally, it’s restarted. If
        the worker process crashed immediately on startup, this supervisor would
        simply restart it over and over again forever. An OTP supervisor, by
        contrast, has a maximum restart frequency which, if exceeded, results in
        the supervisor itself terminating abnormally.

      + Debugging and logging:
        An OTP server can be started with various options to enable logging and
        debugging, which can be very helpful during development.

      + Hot code swapping:
        An OTP server can be upgraded dynamically without taking the whole
        system down.

      + Lots, lots more:
        Release management, failover, automated scaling ...

      They're powerful reasons to prefer OTP over handwritten code in most
      circumstances.

**** TODO Connecting Nodes - 142
     - *Joe asks: What If I Only Have One Computer?*

**** TODO Remote Execution - 143
**** TODO Remote Messaging - 143
     - *Joe asks: How Do I Manage My Cluster?*

*** TODO Distributed Word Count - 145
**** Counting Words - 145
**** Keeping Track of Totals - 147
**** Parsing and Fault Tolerance - 147
**** The Big Win - 149

*** TODO Day 3 Wrap-Up - 150
**** What We Learned in Day 3 - 150
**** Day 3 Self-Study - 150
***** Find
***** Do

** TODO Wrap-Up - 150
   #+BEGIN_QUOTE
   I’m sorry that I long ago coined the term “objects” for this topic because it
   gets many people to focus on the lesser idea.

   The big idea is “messaging” ... The Japanese have a small word—ma—for “that
   which is in-between”—perhaps the nearest English equivalent is
   “interstitial.” The key in making great and growable systems is much more to
   design how its modules communicate rather than what their internal properties
   and behaviors should be.     -- by Alan Kay (http://c2.com/cgi/wiki?AlanKayOnMessaging)
   #+END_QUOTE

*** Strengths - 151
**** Messaging and Encapsulation - 151
**** Fault Tolerance - 151
**** Distributed Programming - 151

*** DONE Weaknesses - 152 - =RE-READ=
    CLOSED: [2018-09-22 Sat 14:18]
    - actors are still susceptible to problems
      like deadlock plus a few failure modes unique to actors (such as overflowing
      an actor’s mailbox).
      Although a program constructed with /actors/ is easier to debug than one
      constructed with threads and locks,

    - As with /threads/ and /locks/, /actors/ provide *no direct support for
      parallelism*.
      Parallel solutions need to be built from concurrent building blocks,
      raising the specter of nondeterminism. =TODO= =???=

      And because /actors/ do _NOT share state_ and can ONLY communicate through
      message passing, /actors/ are *not a suitable choice if you need fine-grained
      parallelism*.

*** DONE Other Languages - 152
    CLOSED: [2018-09-22 Sat 14:14]
    - The /actor model/ is first described in the 1970s, most notably by Carl Hewitt.

    - The most popular one: Erlang

    - Now, many languages have actor model library:
      Akka for Scala and Java (theoretically and more generally, JVM-based languages).

*** Final Thoughts - 152

* 6. Communicating Sequential Processes - 153
** Communication Is Everything - 153
** Day 1: Channels and Go Blocks - 154
** Day 2: Multiple Channels and IO - 166
** Day 3: Client-Side CSP - 177
** Wrap-Up - 185

* 7. Data Parallelism - 189
** The Supercomputer Hidden in Your Laptop - 189
** Day 1: GPGPU Programming - 190
** Day 2: Multiple Dimensions and Work-Groups - 201
** Day 3: OpenCL and OpenGL—Keeping It on the GPU - 212
** Wrap-Up - 220

* 8. The Lambda Architecture - 223
** Parallelism Enables Big Data - 223
** Day 1: MapReduce - 224
** Day 2: The Batch Layer - 237
** Day 3: The Speed Layer - 249
** Wrap-Up - 261

* 9. Wrapping Up - 263
** Where Are We Going? - 263
** Roads Not Taken - 265
** Over to You - 267

* Bibliography - 269
* Index - 271
