#+TITLE: Publishing Python Packages
#+SUBTITLE: Test, share, and automate your projects
#+VERSION: 2023
#+AUTHOR: Dane Hillard
#+FOREWORD BY: David Beazley
#+STARTUP: entitiespretty
#+STARTUP: indent
#+STARTUP: overview

** foreword - xi
** preface - xiii
** acknowledgments - xv
** about this book - xvii
** about the author - xxi
** about the cover illustration - xxii
* DONE PART 1 FOUNDATIONS - 1
CLOSED: [2024-10-27 Sun 21:36]
This part covers
1. what packaging is,
2. what you'll need to get started with your own Python package
3. what constitutes a minimal working package

** 1 The what and why of Python packages - 3
- This chapter covers
  * Packaging code to make it more accessible to others
  * Using packages to make your own projects more manageable
  * Building Python packages for different platforms

- =en=
  * go through all the _gory_ details of

  * _chasm_

- In this book, you'll learn
  * _how distributing your Python project as an installable package can make it
    more accessible to others._

  * _how to create a repeatable process for managing your projects, reducing the
    effort you'll spend maintaining them.

- Although the Python community has developed _standards for some areas of packaging_,
  the One True Way© of doing things *has not yet emerged*. Nor may it ever do so!

- *Python packaging* has
  * a messy history
  * many current alternative options,

  so IN ADDITION TO seeing and using the tools available now,
  you'll ALSO LEARN
  _the methodology behind how they work to continue adapting as the landscape
  matures_.

- To that end, it's important to first understand why software is packaged at
  all.

*** 1.1 What is a package, anyway? - 4
- packaging :: the act of archiving software along with metadata that describes
               those files.

- *IMPORTANT*
  The Python ecosystem uses the word /package/ for _TWO distinct concepts_.
  The /Python Packaging Authority (PyPA)/ differentiates the terms in the
  _Python Packaging User Guide (https://packaging.python.org)_ as follows:
  * Import packages :: organize multiple /Python modules/ into a directory for
    discovery purposes (http://mng.bz/wypg).

  * Distribution packages :: archive _Python projects_ to be published for others
    to install (http://mng.bz/qoNz).

**** 1.1.1 Standardizing packaging for automation - 5
- =TODO= NOTE

- *The early days of package management*

- =TODO= NOTE

- package management systems :: the systems used for maintainers and users of
  that software manage expectations and reduce manual work.

- Packages :: _software_ and _metadata_ rolled together in an agreed-upon format,
              codified in the relevant package management system.

  * At a more granular level,
    /packages/ also typically
    + INCLUDE a way to build the software on a user's system,
      OR
    + they may provide several _prebuilt versions_ of the software for a variety
      of target systems.

**** 1.1.2 The contents of a distribution package - 6 - =TODO: Note=
**** 1.1.3 The challenges of sharing software - 7
- =en= Crisis narrowly averted

- Software communities
  *create* _conventions and standards_ for
  1. managing packages,
  2. codifying those practices into the /package management systems/ you use
  to get your work done.

*** 1.2 How packaging helps you - 7
/Packaging/ is not only for _sharing software_ with people across the globe, but
also provides some of the following benefits that packaging brings _when
developing software_:
- Stronger cohesion and encapsulation
- Clearer definition of ownership
- Looser coupling between areas of the code
- More opportunity for composition

The following sections cover these benefits in detail.

**** 1.2.1 Enforcing cohesion and encapsulation through packaging - 8
- A particular area of code should generally have one job. Cohesion measures how
  dutifully the code sticks to that job. The more stray functionality is
  floating around, the less cohesive the code is.

**** 1.2.2 Promoting clear ownership of code - 9
**** 1.2.3 Decoupling implementation from usage - 10
**** 1.2.4 Filling roles by composing small packages - 12

*** Summary - 14

** 2 Preparing for package development - 15
- This chapter covers
  * *Managing* /virtual environments/ using ~venv~
  * *Isolating* _project dependencies_ using /virtual environments/
  * *Managing* /virtual environment/ _creation_ and _activation_ using ~venv~
  * *Listing* installed dependencies using _pip_

- In this chapter, you'll use *asdf* and *venv* to
  _CREATE a development environment for the /package/ you'll work on_ for the
  rest of this book.

*** 2.1 Managing Python virtual environments - 16
- You can achieve isolation of package dependencies in Python using /virtual
  environments/.

- Python virtual environments ::
  _an isolated copy of Python_ with an _isolated site packages directory_.

**** 2.1.1 Creating virtual environments with venv - 18

** DONE 3 The anatomy of a minimal Python package - 21
CLOSED: [2024-10-27 Sun 21:36]
- =from Jian=
  Now it is 2024, we should avoid the =setup.cfg= way in this section, and use
  =pyproject.toml=, which means the knowledge in this section is useful, but we'd
  better read:
  1. [[https://packaging.python.org/en/latest/][Python Packaging User Guide]]
  2. [[https://setuptools.pypa.io/en/stable/index.html][SETUPTOOLS Documentation]] or the manuals of other build tools.

- This chapter covers
  * The Python package _build system_
  * Building a package using _Setuptools_
  * The _directory structure_ of a Python package
  * Building a package for MULTIPLE targets

- _Python package builds_ are the product of coordination between a few different
  tools driven by a *standardized process*.

  * One of the biggest choices you have as a package author is
    *which set of tools to use.*
    + It can be difficult to assess the nuances of each, especially if you're new
      to packaging.

    Fortunately,
    *tools are STANDARDIZING around _the SAME core workflow_,*
    so once you learn it, you've got the agility to switch between tools with
    minimal effort.

- This chapter covers
  1. what each category of these tools accomplishes and
  2. how they work together to produce a package, as well as
  3. how package builds vary for different systems.

- *IMPORTANT*
  Before reading on, visit _appendix B_ to install the tools you'll need for
  this chapter.

*** DONE 3.1 The Python build workflow - 22
CLOSED: [2024-10-25 Fri 21:28]
- The following sections cover
  * *what happens when you build a package* and
  * *what you need to do to build a package successfully*.

- You first need to learn about the pieces of
  _the Python build system itself._

**** 3.1.1 Parts of the Python build system - 22
- In the root directory for your project, start by running _build_ using the
  following command: ~pyproject-build~
  * Because your package has no content yet, you should see an error like the
    following:
    #+begin_src text
      * Creating isolated environment: venv+pip...
      ERROR Source /home/shapeless-cat/Learning/py-build does not appear to be a
      Python project: no pyproject.toml or setup.py
    #+end_src
    The output makes two file suggestions.
    =pyproject.toml= is the newer standard file for configuring Python packaging
    introduced in _PEP 518 (https://www.python.org/dev/peps/pep-0518/)_ and
    should be preferred unless a third-party tool you want to use is only
    compatible with =setup.py=.
    + The file uses _TOML (https://toml.io/en/)_, an INI-like language, to split
      configuration into relevant sections.

- Run ~touch pyproject.toml~, and then ~pyproject-build~.
  This time the build should run successfully.

  * _At a high level,_ the build command
    CONSUMES
       your source code and
       the metadata you supply,
       along with some files it generates, to

    CREATE the following
    1. A *source distribution package*
       A /Python source distribution/, or /sdist/, is a compressed archive file
       of the source code with a =.tgz= extension.
       + a /source distribution/ allows almost anyone to build your code on
          their platform,

    2. A *binary distribution package*
       A /Python built distribution package/ is a *binary* file.
       The current standard for built distributions is what's known as a /wheel/
       or /bdist_wheel/, a file with a =.whl= extension.
       + a /binary distribution/ is _prebuilt_ for a given platform and saves
         users the work of building it themselves.

    =TODO: NEXT=
    The importance of these two distribution types will be covered in depth in
    chapter 4.

- *Listing 3.1 The result of building an empty Python package*
  Because you haven't supplied any metadata yet, the build process alerts you to
  the fact that it's missing some important information like a README file, the
  author, and so on. =TODO= Adding this information is covered later in this
  chapter.

- Notice that the build process installs the *setuptools* and *wheel* packages.
  * _Setuptools (https://setuptools.readthedocs.io)_ is a library that *WAS, for
    a long time, one of the ONLY ways* to create Python packages.
    + Now, Setuptools is one of a variety of available /build backends/ for
      Python package builds.

- build backend :: a Python object that provides several _required and optional
  hooks_ that implement packaging behavior.
  * The core build backend interface is defined in _PEP 517 (http://mng.bz/o5Rj)_.

- A /build backend/ does the logistical work of creating package artifacts during
  the build process, namely through the ~build_sdist~ and ~build_wheel~ /hooks/.
  * /Setuptools/ uses the ~wheel~ package to build the /wheel/ during the
    ~build_wheel~ step.
    + The _build tool_ uses /Setuptools/ as a /build backend/ *BY DEFAULT*
      when you don't specify one.

- The *build tool* is a /build frontend/!

- build frontend :: a tool you run to initiate building a package from source code.
  * The /build frontend/
    + PROVIDES a /user interface/ and
    + INTEGRATES with the /build backend/
    VIA the /hook interface/.

- *Figure 3.1 The Python build system consists of a frontend user interface that
  integrates with a backend to build package artifacts.*

- *Other build system tools*
  Other options exist for both _build frontends and backends_.

  * Some packages provide BOTH a /frontend/ and a /backend/.
    Through the rest of this book, continue using *build* and *Setuptools* as
    the /frontend/ and /backend/ for your builds.

  * If you want to explore some alternative build tools, check out
    + Poetry (https://python-poetry.org/)
    + flit (https://flit.readthedocs.io)
    + hatch (https://hatch.pypa.io)
    Each build system makes different trade-offs between ease of configuration,
    capability, and user interface.

    + As an example,
      - *flit* and *poetry* are geared toward pure-Python packages,
      - whereas *Setuptools* can support extensions in other languages.

    =TODO: NEXT= Chapter 4 covers this in more detail.

  * You can switch to another build system in a few steps, shown here:
    1. Install the new /build frontend/ package.
    2. Update =pyproject.toml= to *specify* the new /build backend/ and its
       requirements.
    3. *MOVE* the /metadata/ about the package to the location expected by the
       new /build backend/.

- Recall that /build/ used /Setuptools/ as the *FALLBACK* /build backend/
  BECAUSE you didn't specify one.

  You can specify /Setuptools/ as the /build backend/ for your package by adding
  the lines in listing 3.2 to =pyproject.toml=.
  *Listing 3.2 A build system backend specification to use Setuptools*
  #+begin_src toml
    [build-system]
    requires = ["setuptools", "wheel"]
    build-backend = "setuptools.build_meta"
  #+end_src
  These lines specify the following:
  1. ~build-system~ - This section describes the /package build system/.

  2. ~requires~ - These are a list of /dependencies/, as strings,
     which _must be installed for the build system to work._
     * A /Setuptools/ /build system/ needs ~setuptools~ and ~wheel~

  3. ~build-backend~ - This identifies the _entry point_ to the /build backend/
     object, _using the dotted path as a string_.
     * The /Setuptools/ /build backend/ object is available at
       ~setuptools.build_meta~.

- Now that you've got a handle on the /Python package build system/,
  you need to _ADD some /metadata/ about your package._

*** DONE 3.2 Authoring package metadata - 26
CLOSED: [2024-10-27 Sun 21:12]
EACH /build backend/ may look for /package metadata/ in
*DIFFERENT* _places and formats_.

- For the /Setuptools/ backend, you can specify /STATIC metadata/ in an
  *INI-style* file called =setup.cfg= *in the root directory* of your project.
  * You'll add sections of key-value pairs to this file that provide information
    about the package and its contents

- _Some /metadata/ is ESSENTIAL_ to build a package that can be identified
  properly.
  * When you ran the build, it resulted in files with ="UNKNOWN-0.0.0"= in the
    name, which is the result of *some MISSING CORE /metadata/.*
    + =NEXT= Start by fixing these core metadata issues first.

**** 3.2.1 Required core metadata - 26
The information in this section is a little bit outdated.
Check [[https://packaging.python.org/en/latest/guides/writing-pyproject-toml/][Writing your pyproject.toml]].

- After update the core metadata and build again,
  you can also confirm that the metadata you specified has been faithfully
  reproduced in the package. Unpack your sdist version build target, and open
  either of the =PKG-INFO= files and take a look at the contents.
  * The =PKG-INFO= file contains _a normalized version of the metadata._

- =from Jian=
  The PKG-INFO content part in section is outdated.
  See below, which comes from my experiment.
  If we provide the =pyproject.toml= with content:
  #+begin_src toml
    [project]
    name = "first-python-package"
    version = "0.0.1"
  #+end_src

  The content of PKG-INFO:
  #+begin_src text
    Metadata-Version: 2.1
    Name: first-python-package
    Version: 0.0.1
  #+end_src

**** 3.2.2 Optional core metadata - 28
- The ~name~ and ~version~ are the only two strictly required fields, per the
  /core metadata specification (http://mng.bz/nez8)/,
  _BUT_ several other fields are indexed by search engines or surfaced in highly
  visible ways on sites like PyPI.

- *A rundown on package metadata*

- *Author* and *URL*:
  In =PKG-INFO=:
  #+begin_src text
    Author-email: Given Family <given.family@example.com>, Given Family 1 <given.family.1@example.com>
    Project-URL: Repository, https://github.com/username/package_repo_name.git
    Project-URL: HomePage, https://example.com
  #+end_src

  * =setup.cfg=
    #+begin_src text
      [metadata]
      url = https://github.com/<username>/<package repo name>
      author = Given Family
      author_email = "Given Family" <given.family@example.com>
    #+end_src

  * =pyproject.toml=
    #+begin_src toml
      [project]
      authors = [
          {name = "Given Family", email = "given.family@example.com"},
      ]

      [project.urls]
      Repository = "https:/ /github.com/<username>/<package repo name>"
    #+end_src

- _If you skimp on the metadata, it's likely that no one will find it._

- =en= further down the line

- *Summary*:
  * In =setup.cfg=: ~description = This package does amazing things.~
  * In =pyproject.toml=: ~description = "This package does amazing things."~

- *Long description*:
  In =PKG-INFO=:
  #+begin_src text
    Description-Content-Type: text/markdown

    # Project Title

    A detailed description of the project can go here if not using an external file.
  #+end_src

  * In =setup.cfg=:
    #+begin_src text
      long_description = file: README.md
      long_description_content_type = text/markdown
    #+end_src

  * In =pyproject.toml=:
    #+begin_src toml
      readme: "README.md"
    #+end_src
    The content-type can be inferred.

    or

    #+begin_src toml
      [project.readme]
      content-type = "text/markdown"
      file = "README.md"
    #+end_src

    or

    #+begin_src toml
      [project.readme]
      content-type = "text/markdown"
      text = """# Project Title

      A detailed description of the project can go here if not using an external file."""
    #+end_src

**** 3.2.3 Specifying a license - 31 - =TODO: MORE NOTES=
- *License granularity*
  * Most often, you need to specify the _license_ that pertains to your
    *entire package* _ONLY ONCE_ at the package metadata level.

  * If you need to give a more permissive or restrictive license to a *SPECIFIC
    file or files*, you can include the overriding license _directly in those files._
    + The Python packaging process *DOESN'T* provide a way to handle complex per-file
      license granularity within a project, _but third-party tools may exist to
      help with this._

*** DONE 3.3 Controlling source code and file discovery - 33
CLOSED: [2024-10-27 Sun 21:12]
*** DONE 3.4 Including non-Python files in a package - 35
CLOSED: [2024-10-27 Sun 21:31]
- Way 1:
  Use =MANIFEST.in=, which should be in the /project root/, the save level as
  =setup.py= or =pyproject.toml=.
  * Usages:
    + See *Figure 3.3 MANIFEST.in file directives to include non-Python files in packages*
      - Everytime you use ~graft~, you many need a companion ~recursive-exclude~
        to exclude ~__pycache__~ and ~*.py[cod]~. For example,
        #+begin_src text
          graft src
          recursive-exclude __pycache__ *.py[cod]
        #+end_src
        *Includes* all files from the =src/ directory=
        *Except* ~__pycache__~ directories or files that end in =.pyc=, =.pyo=,
        or =.pyd=

- Way 2:
  Use =setup.cfg= or =pyproject.toml=.

* TODO PART 2 CREATING A VIABLE PACKAGE - 39
- Q :: WHY are you building a package?

- A :: You may want to
  * share some code, mostly as a library, with your team to use in multiple
    projects.

  * create a command-line interface that others can install and run.

  * abstract performant code in a low-level language like C with an easy-to-use
    layer of interaction in Python.

** TODO 4 Handling package dependencies, entry points, and extensions - 41
- This chapter covers
  * Defining dependencies for your package
  * Making functionality available as command-line tools
  * Packaging extensions written in C

*** DONE 4.1 A package for calculating vehicle drift - 41
CLOSED: [2024-11-09 Sat 00:40]
- *Harmonic mean*
  =TODO=

- Exercise 4.1
  In your project, create a =harmonic_mean.py= module, which should contains a
  ~harmonic_mean~ function that accepts accepts an arbitrarily long list of
  floatingpoint numbers and returns their harmonic mean.

- Use built-in ~timeit~ to measure its performance.
  If you do this in command line, you can type
  #+begin_src shell
    python -m timeit \
      --setup 'from harmonic_mean import harmonic_mean' \
      --setup 'from random import randint' \
      --setup 'nums = [randint(1, 1_000_000) for _ in range(1_000_000)]' \
      'harmonic_mean(nums)'
  #+end_src
  * The _setup code_ will run *only once* and will *not be counted* toward the
    measurement of your code.

  * Output is in this form: _5 loops, best of 5: 52.8 msec per loop_

*** DONE 4.2 Creating a C extension for Python - 44 - =NOTE= =PRACTICE=
CLOSED: [2024-11-09 Sat 01:30]
- Because the reference Python interpreter is written in the C programming
  language, C is a common choice for these extensions,
  BUT people also write extensions in
  * C++ (http://mng.bz/M0om),
  * Rust (http://mng.bz/aPwY), and
  * even Fortran (http://mng.bz/gRgn).

**** DONE 4.2.1 Creating C extension source code - 44
CLOSED: [2024-11-09 Sat 00:52]
- Cython :: a compiler and language for creating _Python C extensions_.

- The _Cython compiler_ converts _Cython source code_ to _optimized C code_,
  which will then be compiled *DURING a package's build process* (see figure
  4.1)

- The file name extenion of Cython source files is .pyx

- =IMPORTANT=
  Because _the Cython language is a *superset* of Python_,
  *a valid Python program is also a valid Cython program.*

  * RENAME your =harmonic_mean.py= module to =harmonic_mean.pyx= and
    MOVE it into the =src/imppkg/= directory (=from Jian= Here =imppkg= is just
    a package name the author chose, nothing special).
    Now that you have a Cython source code file, you need to _integrate Cython
    into your /package's build process/._

- *Figure 4.1 Extensions are compiled into shared libraries that are included in
  binary wheel distributions.*

**** TODO 4.2.2 Integrating Cython into a Python package build - 45 - =NOTE=
**** TODO 4.2.3 Installing and profiling your C extension - 47 - =NOTE=
**** DONE 4.2.4 Build targets for binary wheel distributions - 48
CLOSED: [2024-11-09 Sat 01:30]
- =IMPORTANT!!!=
  *Figure 4.2 The anatomy of a binary wheel distribution filename*
  #+begin_src text
    a_cool_package-5.4.7-4-cp310-cp310-macosx_11_0_x86_64.whl
  #+end_src
  * Normalized package name: ~a_cool_python~
  * Package version: ~5.4.7~
  * Optional build number: ~4~
  * Python implementation and C ABI: ~cp310-cp310~
  * Platform (OS and CPU): ~macosx_11_0_x86_64.whl~

- _When you install packages_,
  your PACKAGE MANAGER will determine which binary wheel distributions are
  available and use these tags to identify which of those it should download for
  your system.

- The *NUMBER of binary wheel distributions* you need to build is roughly the
  following:
  N_PythonImplementations x N_OSs x N_CPUArchs

- For example,
  _Numpy_ supports CPython 3.7, 3.8, and 3.9 as well as PyPy 3.7.
  Each release of NumPy makes 27 wheels available.

- 
**** DONE 4.2.5 Specifying required Python versions - 50
CLOSED: [2024-11-09 Sat 01:18]
=from Jian=
This section setup Python version requirement in =setup.cfg=.

This is an old way. We can do it in =pyproject.toml=. Different tools use
different option name. Please check the manual of the tool you want to use.

*** TODO 4.3 Offering command-line tools from a Python package - 50 - =NOTE=
**** 4.3.1 Creating commands with Setuptools entry points - 50

*** TODO 4.4 Specifying dependencies for Python packages - 53 - =START=
*** TODO 4.5 Answer to exercises - 54
*** DONE Summary
CLOSED: [2024-11-09 Sat 01:38]
- Explore _non-Python extensions_ by first using a high-level translation layer
  like *Cython*.

- Providing a _non-Python extension_
  GAINS runtime performance
  BUT ADDS BUILD TIME COMPLEXITY, either for you or your consumer.

- /Entry points/ into your package offer more ways of interacting with its
  behavior than just importing the code.

- Leverage the power of package management systems to handle dependency
  resolution for you.

** TODO 5 Building and maintaining a test suite - 56 - =START HERE=
- This chapter covers
  * Running unit tests with *pytest*
  * Creating test coverage reports with *pytest-cov*
  * Reducing duplicated test code with parameterization
  * Automating packaging for testing using *tox*
  * Creating a /test matrix/

- In this chapter, you'll learn some beneficial aspects of testing and how to
  introduce them to your package’s test suite, with an eye toward automation and
  scalability

*** 5.1 Integrating a testing setup - 57
- Built-in ~unittest~ pros and cons.
  =TODO=

- =NEXT=
  You'll
  USE _pytest_ throughout the rest of this chapter and
  LEARN some of the *ADVANTAGES it has OVER* the _unittest_ module.

**** DONE 5.1.1 The pytest testing framework - 57
CLOSED: [2024-11-22 Fri 02:09]
_pytest_ aims to make it easier to write simple tests and support increasingly
complex projects as they grow.

- It can run unittest-based test suites out of the box
  BUT also provides
  _its own assertion syntax_ and
  _a plugin-based architecture_ to extend and change its behavior to suit your needs.

- The framework also provides a number of utilities for designing scalable
  tests, such as
  * Test fixtures :: Functions that provide additional dependencies to a test, such
                     as data or database connections.
  * Parameterized tests :: The ability to write a single test function and multiple
                           sets of input arguments to create a unique test for
                           each set of inputs.

- _pytest_ must be in your virtual environment.

- By default, _pytest_ is looking everywhere under the project's root directory
  for tests. *This is not ideal!* Should put all tests in the =test/= directory,
  and in =pyproject.toml=, add
  #+begin_src toml
    [tool.pytest.ini_options]
    testpaths = [
        "tests",
    ]
  #+end_src

- Naming conventions for tests that can be discovered by _pytest_:
  1. Start in any directory in ~testpaths~.
  2. Find /modules/ named =test_*.py=.
  3. Find /classes/ in those modules named ~Test*~.
  4. Find /functions/ in those /modules/, or /methods/ in those /classes/, named
     ~test_*~.

**** TODO 5.1.2 Adding test coverage measurement - 59
**** TODO 5.1.3 Increasing test coverage - 65

*** 5.2 Addressing testing tedium - 69
**** Addressing repetitive, data-driven tests - 69
**** Addressing frequent package installation - 70
**** Configuring test environments - 74
**** Tips for quicker and safer testing - 76

*** 5.3 Answers to exercises - 80

** TODO 6 Automating code quality tooling - 82
*** 6.1 The true power of tox environments - 83
**** Creating nondefault tox environments - 83
**** Managing dependencies across tox environments - 85

*** 6.2 Analyzing type safety - 88
**** Creating a tox environment for type checking - 90
**** Configuring mypy - 91

*** 6.3 Creating a tox environment for code formatting - 93
**** Configuring black - 95

*** 6.4 Creating a tox environment for linting - 96
**** Configuring flake8 - 97

*** 6.5 Answers to exercises - 99

* TODO PART 3 GOING PUBLIC - 101
** 7 Automating work through continuous integration - 103
*** 7.1 The continuous integration workflow - 104
*** 7.2 Continuous integration with GitHub Actions - 105
**** 7.2.1 A high-level GitHub Actions workflow - 106
**** 7.2.2 Understanding GitHub Actions terminology - 106
**** 7.2.3 Starting a GitHub Actions workflow configuration - 109

*** 7.3 Converting manual tasks to GitHub Actions - 112
**** 7.3.1 Running a job multiple times with a build matrix - 114
**** 7.3.2 Building Python package distributions for a variety of platforms - 117

*** 7.4 Publishing a package - 119

** 8 Authoring and maintaining documentation - 128
*** 8.1 Some quick philosophy on documentation - 129
*** 8.2 Starting your documentation with Sphinx - 130
**** 8.2.1 Automating documentation refresh during development - 135
**** 8.2.2 Automating extraction of code documentation - 135

*** 8.3 Publishing documentation to Read the Docs - 143
**** 8.3.1 Configuring Read the Docs - 149

*** 8.4 Documentation best practices - 153
**** 8.4.1 What to document - 154
**** 8.4.2 Prefer linking over repetition - 154
**** 8.4.3 Use consistent, empathetic language - 155
**** 8.4.4 Avoid assumptions and create context - 156
**** 8.4.5 Create visual interest and coherent structure - 156
**** 8.4.6 Powering up your documentation - 156

** 9 Making a package evergreen - 158
*** 9.1 Choosing a package-versioning strategy - 159
**** 9.1.1 Direct and indirect dependencies - 159
**** 9.1.2 Python dependency specifiers and dependency hell - 162
**** 9.1.3 Semantic versioning and calendar versioning - 164

*** 9.2 Getting the most out of GitHub - 166
**** 9.2.1 The GitHub dependency graph - 166
**** 9.2.2 Mitigating security vulnerabilities with Dependabot - 168

*** 9.3 Thresholding test coverage - 172
*** 9.4 Updating Python syntax using pyupgrade - 173
*** 9.5 Reducing rework using pre-commit hooks - 174
*** 9.6 Answers to exercises - 176

* TODO PART 4 THE LONG HAUL - 177
** 10 Scaling and solidifying your practices - 179
*** 10.1 Creating a project template for future packages - 180
**** 10.1.1 Creating a cookiecutter configuration - 180
**** 10.1.2 Extracting a cookiecutter template from an existing project - 185

*** 10.2 Using namespace packages - 188
**** 10.2.1 Converting an existing package to a namespace package - 191

*** 10.3 Scaling packaging in your organization - 191
**** 10.3.1 Private package repository servers - 192

** 11 Building a community - 195
*** 11.1 Your README needs to make a value proposition - 196
*** 11.2 Provide supporting documentation for different user types - 197
*** 11.3 Establish, provide, and enforce a code of conduct - 199
*** 11.4 Conveying the project’s road map, status, and changes - 201
**** 11.4.1 Using GitHub projects for kanban management - 201
**** 11.4.2 Use GitHub labels to track status for individual tasks - 201
**** 11.4.3 Track high-level changes in a log - 203

*** 11.5 Gather consistent information with issue templates - 205
*** 11.6 Go forth - 207

* DONE appendix A Installing asdf and python-launcher - 209
CLOSED: [2024-10-24 Thu 22:56]
- In this book, you'll need to
  1. manage the installation of *MULTIPLE Python versions* and /virtual
     environments/
     and
  2. the *switching between them*.

- This appendix covers the installation of tools to ease this burden, which
  you'll learn more about in the chapters.

- *Important*
  * Alternatives to *asdf* that I would recommend for
    *base Python version management* follow in order of preference based on my
    experience with them:
    1. _pyenv_ (https://github.com/pyenv/pyenv) or
       _pyenv-win_ (https://pyenv-win.github.io/pyenv-win) for Windows users
       =from Jian= I use this

    2. Direct installation from source or a prebuilt binary for your platform
       (https://www.python.org/downloads/)

    3. Homebrew (https://brew.sh/) or your platform's official system package manager

  * Alternatives to _python-launcher_ and _venv_ that I would recommend for
    *virtual environment management* follow in order of preference based on my
    experience with them:
    1. _pyenv-virtualenv_ (https://github.com/pyenv/pyenv-virtualenv)
       =from Jian= I use this
    3. _poetry_ (https://python-poetry.org/)
    4. _virtualenv_ (https://virtualenv.pypa.io/en/latest/) and
       _virtualenvwrapper_ (http://mng.bz/rndy) for added management convenience
    5. _pipenv_ (https://github.com/pypa/pipenv)

** TODO A.1 Installing asdf - 210 - =NOTE=
** TODO A.2 Installing python-launcher - 212 - =NOTE=
** TODO Answer to exercise A.1 - 214

* TODO appendix B Installing pipx, build, tox, pre-commit, and cookiecutter - 215
** B.1 Installing pipx
** B.2 Installing build
** B.3 Installing tox
** B.4 Installing pre-commit
** B.5 Installing cookiecutter

* index - 219
