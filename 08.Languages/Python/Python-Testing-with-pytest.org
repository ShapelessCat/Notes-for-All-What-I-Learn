#+TITLE: Python Testing with pytest
#+SUBTITLE: Simple, Rapid, Effective, and Scalable
#+VERSION: 2nd
#+AUTHOR: Brian Okken
#+STARTUP: entitiespretty
#+STARTUP: indent
#+STARTUP: overview

* Acknowledgments - xi
* Preface - xiii
* Part I — Primary Power
** DONE 1. Getting Started with pytest - 3
CLOSED: [2025-01-06 Mon 14:49]
A test example:
#+file_name: ch1/test_one.py
#+begin_src python
  def test_passing():
      assert (1, 2, 3) == (1, 2, 3)
#+end_src
- _pytest_ can discover this ~test_passing~ because
  * it starts with ~test_~
  * it is in a file that starts with =test_=.

- Any /uncaught exception/ raised _within a test_ will cause the test to fail.
  * Although any type of /uncaught exception/ can cause a test to fail,
    _TRADITIONALLY we stick with ~AssertionError~ from assert to determine
    pass/fail for tests._

*** DONE Installing pytest - 3
CLOSED: [2025-01-06 Mon 14:40]
Use _pip_ to install _pytest_ in your virtual environment.

*** DONE Running pytest - 4
CLOSED: [2025-01-06 Mon 14:40]
- To run _pytest_,
  * You have the option to specify files and directories.
  * If you don't specify any files or directories, _pytest_ will look for tests
    in the _current working directory and subdirectories_. It looks for =.py=
    files starting with ~test_~ or ending with ~_test~.

- Run all tests in =ch1=. Turn off tracebacks, because we don't need the full
  output right now: ~pytest --tb=no~.

- Other ways to run with ~pytest~:
  * Inside the folder =ch1=: ~pytest --tb=no test_one.py test_two.py~
  * One level up from =ch1=: ~pytest --tb=no ch1~
  * Specify a test function within a test file to run by adding ~::test_name~:
    ~pytest -v ch1/test_one.py::test_passing~

**** Test Discovery - 7
Here's a brief overview of the /naming conventions/ to keep your test code
discoverable by _pytest_:
• /Test files/ should be named ~test_<something>.py~ or ~<something>_test.py~.
• /Test methods and functions/ should be named ~test_<something>~.
• /Test classes/ should be named ~Test<Something>~.

Because our _test files and functions_ start with ~test_~, we're good. There are
ways to *ALTER* these discovery rules if you have a bunch of tests named
differently.
=TODO=
=TODO=
=TODO=
I'll cover how to do that in Chapter 8, Configuration Files, on page 113

**** Test Outcomes - 8
_Pass_ and _fail_ are NOT the only outcomes possible.

Here are the possible outcomes of a test:
- *PASSED* (~.~) - The test ran successfully.

- *FAILED* (~F~) - The test did not run successfully.

- *SKIPPED* (~s~) - The test was skipped.
  You can tell pytest to skip a test by using either the ~@pytest.mark.skip()~
  or ~@pytest.mark.skipif()~ decorators, which are discussed in
  =TODO= Skipping Tests with ~pytest.mark.skip~, on page 74.

- *XFAIL* (~x~) - The test was not supposed to pass, and it ran and failed. You
  can tell pytest that a test is expected to fail by using the
  ~@pytest.mark.xfail()~ decorator, which is discussed in =TODO= Expecting Tests
  to Fail with ~pytest.mark.xfail~, on page 77.

- *XPASS* (~X~) - The test was marked with xfail, but it ran and passed.

- *ERROR* (~E~) - An exception happened
  either *during* the execution of a /fixture/ or /hook function/, and
  *NOT during* the execution of a test function.
  * /Fixtures/ are discussed in Chapter 3, pytest Fixtures, on page 31, and
  * /hook functions/ are discussed in Chapter 15, Building Plugins, on page 205.

*** DONE Review - 8
CLOSED: [2025-01-06 Mon 14:42]
*** DONE Exercises - 9
CLOSED: [2025-01-06 Mon 14:48]
*** DONE What's Next - 10
CLOSED: [2025-01-06 Mon 14:48]
- =NEXT=
  In the next chapter, we'll look at
  * writing test functions, and
  * grouping tests into /classes/, /modules/, and /directories/.

** DONE 2. Writing Test Functions - 11
CLOSED: [2025-01-07 Tue 00:14]
We're going to write tests for a simple task-tracking command-line application
called Cards.

- We'll look at

  how to use assert in tests,
  how tests handle unexpected exceptions, and
  how to test for expected exceptions.

- Eventually, we'll have a lot of tests. Therefore,
  we'll look at
  how to *ORGANIZE* tests into
  * /classes/,
  * /modules/, and
  * /directories/.

*** DONE Installing the Sample Application - 11
CLOSED: [2025-01-06 Mon 15:30]
1. Install the example project:
   ~pip install ./cards_proj/~

2. Try this application: =read this secion in book=

*** DONE Writing Knowledge-Building Tests - 13
CLOSED: [2025-01-06 Mon 16:27]
*FIRST* build some tests for fundamental understanding of application code.
Not exhaustive tests, not for corner cases or failure cases.

It is a good start for testing my own understanding, and really of using tests
as little playgrounds to play with the application code.

- Only use old ~assert~ statements in the examples of this subsection.

*** DONE Using assert Statements - 16
CLOSED: [2025-01-06 Mon 16:37]
- _pytest_ includes a feature called _“assert rewriting”_ that
  1. *intercepts* assert calls and
  2. *replaces* them *with* something that can tell you more about why your
     assertions failed.

- Try to run a test inside ~if __name__ == "__main__"~, without using _pytest_,
  you can see the original _assert failure_ can provide enough useful info.

*** DONE Failing with ~pytest.fail()~ and Exceptions - 19
CLOSED: [2025-01-06 Mon 16:42]
- A _test will fail_ IF there is _ANY uncaught exception_. This can happen if
  * an ~assert~ statement fails, which will _raise an ~Assertion;Error~
    exception_,
  * the test code calls ~pytest.fail()~, which will _raise an exception_, or
  * _any other exception is raised_

- In rare cases where ~assert~ is not suitable, use ~pytest.fail()~.
  * This kind of failure can't provide assert rewriting advices from _pytest_.

    However, there are reasonable times to use ~pytest.fail()~, such as in an
    assertion helper. =NEXT= see next subsection for examples.

*** DONE Writing Assertion Helper Functions - 20 - =TODO: See Also=
CLOSED: [2025-01-06 Mon 16:51]
#+file_name: ch2/test_helper.py
#+begin_src python
  from cards import card
  import pytest


  def assert_identical(c1: Card, c2: Card):
      __tracebackhide__ = True
      assert c1 == c2
      if c1.id != c2.id:
          pytest.fail(f"id's don't match. {c1.id} != {c2.id}")


  def test_identical():
      c1 = Card("foo", id=123)
      c2 = Card("foo", id=123)
      assert_identical(c1, c2)


  def test_identical_fail():
      c1 = Card("foo", id=123)
      c2 = Card("foo", id=456)
      assert_identical(c1, c2)
#+end_src
- The ~assert_identical~ function sets ~__tracebackhide__ = True~:
  1. This is optional.
  2. The effect will be that failing tests will NOT include this function in the
     traceback.

- =TODO: ??? conftest.py ???=
  Note that assert rewriting is only applied to conftest.py files and test
  files. =TODO= See the pytest documentation for more details:
  https://docs.pytest.org/en/stable/how-to/assert.html#assertion-introspection-details

*** DONE Testing for Expected Exceptions - 21
CLOSED: [2025-01-06 Mon 21:45]
#+file_name: ch2/test_exceptions.py
#+begin_src python
  import pytest
  import cards


  def test_no_path_raises():
      with pytest.raises(TypeError):
          cards.CardsDB()
#+end_src

- We just checked for the type of exception in ~test_no_path_raises()~. We can
  also check to make sure the message is correct, or any other aspect of the
  exception, like additional parameters:
  #+file_name: ch2/test_exceptions.py
  #+begin_src python
    import pytest
    import cards


    def test_raises_with_info():
        match_regex = "missing 1 .* positional argument"
        with pytest.raises(TypeError, match=match_regex):
            cards.CardsDB()

    def test_raises_with_info_alt():
        with pytest.raises(TypeError) as exc_info:
            cards.CardsDB()
        expected = "missing 1 required positional argument"
        assert expected in str(exc_info.value)
  #+end_src
  * =from Jian=
    Remember, ~with~ clause doesn't create a /scope/!

  * =TODO=
    See the _pytest documentation_ for full ~ExceptionInfo~ reference.

*** DONE Structuring Test Functions - 23
CLOSED: [2025-01-06 Mon 23:52]
- I recommend _making sure you keep assertions at the end of test functions._

  This is such a common recommendation that it has at least two names:
  _Arrange-Act-Assert_ and _Given-When-Then_.

- Bill Wake originally named the Arrange-Act-Assert pattern in 2001.
  * footnote 6 =TODO=

- Kent Beck later popularized the practice as part of test-driven development (TDD).
  * footnote 7 =TODO=

- /Behavior-driven development (BDD)/ uses the terms _Given-When-Then_, a
  pattern from Ivan Moore, popularized by Dan North.
  * footnote 8

- Regardless of the names of the steps, the goal is the same:
  *separate a test into stages*.

  * Benefits:
    Allows the test developer to focus attention on each part,
    + getting ready to do something
    + doing something
    + checking to see if it worked
    and be clear about what is really being tested.

- A common anti-pattern:
  interleaved stages
  * Example:
    "Arrange-Assert-Act-Assert-Act-Assert..."

- Stages:
  1. Given/Arrange
     A starting state. This is where you set up data or the environment to get
     ready for the action.

  2. When/Act
     Some action is performed. This is the focus of the test - the behavior we
     are trying to make sure is working right.

  3. Then/Assert
     Some expected result or end state should happen. At the end of the test, we
     make sure the action resulted in the expected behavior.

*** DONE Grouping Tests with Classes - 24
CLOSED: [2025-01-06 Mon 23:58]
So far so good.

However, _pytest_ also allows us to _group tests with /classes/._

- Example:
  #+file_name: ch2/test_classes.py
  #+begin_src python
    class TestEquality:
        def test_equality(self):
            c1 = Card("something", "brian", "todo", 123)
            c2 = Card("something", "brian", "todo", 123)
            assert c1 == c2

        def test_equality_with_diff_ids(self):
            c1 = Card("something", "brian", "todo", 123)
            c2 = Card("something", "brian", "todo", 4567)
            assert c1 == c2

        def test_inequality(self):
            c1 = Card("something", "brian", "todo", 123)
            c2 = Card("completely different", "okken", "done", 123)
            assert c1 != c2
  #+end_src

- =IMPORTANT=
  Though well-designed _test class inheritance_ can help to share helper
  functions/methods, getting fancy with _test class inheritance_ will certainly
  *confuse* someone, possibly yourself, in the future.

  Just use /test classes/ for grouping tests is a good, simple, and
  straightforward way. It is recommended.

*** DONE Running a Subset of Tests - 25
CLOSED: [2025-01-07 Tue 00:08]
- _pytest_ allows you to *run a subset of tests* in several ways:

  | Subset                        | Syntax                                               |
  |-------------------------------+------------------------------------------------------|
  | Single test method            | ~pytest path/test_module.py::TestClass::test_method~ |
  | All tests in a class          | ~pytest path/test_module.py::TestClass~              |
  | Single test function          | ~pytest path/test_module.py::test_function~          |
  | All tests in a module         | ~pytest path/test_module.py~                         |
  | All tests in a directory      | ~pytest path~                                        |
  | Tests matching a name pattern | ~pytest -k pattern~                                  |
  | Tests by marker               | Covered in Chapter 6, Markers, on page 73.           |

- The ~<pattern>~ in the ~pytest -k <pattern>~ is not a regex,
  but a pytes-specific pattern. Learn from examples:
  * ~pytest -v -k TestEquality~
  * ~pytest -v -k TestEq~
  * ~pytest -k equality~
  * ~pytest -k "equality and not equality_fail"~
    + keywords in pattern: ~and~, ~not~, ~or~
  * ~pytest -k "(dict or ids) and not TestEquality"~

*** DONE Review - 28
CLOSED: [2025-01-07 Tue 00:08]
*** DONE Exercises - 29
CLOSED: [2025-01-07 Tue 00:14]
*** DONE What's Next - 30
CLOSED: [2025-01-07 Tue 00:14]

** TODO 3. pytest Fixtures - 31
- fixtures :: _test helper functions_ that are essential to structuring test
  code for almost any non-trivial software system.

- fixtures :: functions that are run by _pytest_ *before* (and SOMETIMES
  *after*) the actual test functions.

  * The code in the fixture can do whatever you want it to.
    + You can use /fixtures/ to _get a data set_ for the tests to work on.
    + You can use /fixtures/ to _get a system into a known state_ before running
      a test.
    + /Fixtures/ are also used to get data ready for multiple tests.
    + etc.

- In this chapter, you'll learn _HOW TO_
  * create /fixtures/ and work with them.
  * structure /fixtures/ to hold both setup and teardown code.
  * use scope to allow /fixtures/ to run once over many tests, and
    tests can use MULTIPLE /fixtures/.
  * trace code execution through /fixtures/ and test code.

- First, let's look at
  * a small example /fixture/ and
  * how /fixtures/ and _test functions_ are *connected*.

*** DONE Getting Started with Fixtures - 31
CLOSED: [2025-01-07 Tue 10:29]
Here's a simple fixture that returns a number:
#+file_name: ch3/test_fixtures.py
#+begin_src python
  import pytest

  @pytest.fixture()
  def some_data():
      """Return answer to ultimate question."""
      return 42


  def test_some_data(some_data):
      """Use fixture return value in a test."""
      assert some_data == 42
#+end_src

- The term /fixture/ has many meanings in the programming and test community,
  and even in the Python community.

  In the context of _pytest_, /fixture/ is connected to functions / methods
  decorated by ~@pytest.fixture()~ and the mechanism _pytest_ provides to allow
  the separation of "getting ready for" and "cleaning up after" code from your
  test functions.

- _pytest_ *treats exceptions differently*
  during /fixtures/
  compared to
  during a test function:

  An exception (or /assert failure/ or call to ~pytest.fail()~) that happens
  * during the test code proper _results in a “Fail” result._
  * during a /fixture/, the test function is _reported as “Error.”_

  This distinction is helpful when debugging why a test didn't pass.

- pytest fixtures are one of the unique core features that make pytest stand out
  above other test frameworks, and are the reason why many people switch to and
  stay with pytest.
  =From Jian=, =TODO=
  I know /fixtures/ exist in many test frameworks in other languages. Not sure
  the frameworks in Python. Need a survey.

*** DONE Using Fixtures for Setup and Teardown - 33
CLOSED: [2025-01-07 Tue 12:29]
- Use a /fixture/ to improve a test:
  * No /fixture/ version:
    #+file_name: ch3/test_count_initial.py
    #+begin_src python
      from pathlib import Path
      from tempfile import TemporaryDirectory
      import cards

      def test_empty():
          with TemporaryDirectory() as db_dir:
              db_path = Path(db_dir)
              db = cards.CardsDB(db_path)

              count = db.count()
              db.close()

              assert count == 0
    #+end_src
    This test function really isn't too painful, but two problems exist:
    + It's better to move the set up out, and make it run before ~test_empty~.
    + It's better to place ~db.close()~ at the end of the function, but we have
      to call it before ~assert~, because if the ~assert~ statement fails, it
      won't be called.

  * Use /fixture/ (also thanks to the /context manager/):
    #+file_name: ch3/test_count.py
    #+begin_src python
      import pytest


      @pytest.fixture()
      def cards_db():
          with TemporaryDirectory() as db_dir:
              db_path = Path(db_dir)
              db = cards.CardsDB(db_path)
              yield db
              db.close()

      def test_empty(cards_db):
          assert cards_db.count() == 0
    #+end_src
    ~yield~ give the control to ~test_empy~.

    The /fixture/ resolves the first issue, and combined with the /context
    manager/, the second issue is also resolved: the teardown ~db.close()~ is
    moved into the /fixture/, but it is guaranteed to run after tests, no matter
    what happened during tests.

- =IMPORTANT=
  Remember:
  We never call /fixture/ functions directly - pytest looks at the specific name
  of the arguments to our test and then looks for a /fixture/ with the same name.

- One /fixture/ can be used in multiple tests.

- The /fixture/ and _test function_ are separate functions.

  Carefully naming your /fixtures/ to reflect
  _the work being done in the fixture_
  or
  _the object returned from the fixture_,
  or
  _both_,
  will help with readability.

*** DONE Tracing Fixture Execution with ~-–setup-show~ - 35
CLOSED: [2025-01-07 Tue 12:34]
Visualize when the _setup_ and _teardown_ portions of /fixtures/ run with
respect the tests using them. ~--setup-show~ can help to show this.

- ~pytest --setup-show test_count.py~
  #+begin_src text
    ======================== test session starts =========================
    collected 2 items

    test_count.py
      SETUP    F cards_db
      ch3/test_count.py::test_empty (fixtures used: cards_db).
      TEARDOWN F cards_db
      SETUP    F cards_db
      ch3/test_count.py::test_two (fixtures used: cards_db).
      TEARDOWN F cards_db

    ========================= 2 passed in 0.02s ==========================
  #+end_src
  The ~F~ in front of the _fixture name_ indicates that the /fixture/ is using
  /function scope/.

*** DONE Specifying Fixture Scope - 36
CLOSED: [2025-01-07 Tue 13:11]
- Each /fixture/ has a specific /scope/, which defines the order of when the
  _setup_ and _teardown_ run relative to running of all the test function using
  the /fixture/.

  * =IMPORTANT=
    The /scope/ dictates
    how often the setup and teardown get run when it's used by multiple test
    functions.

- The *DEFAULT scope* for /fixtures/ is /function scope/.
  That means
  1. the setup portion of the /fixture/ will run _BEFORE_ each test that needs
     it runs.
  2. the teardown portion runs _AFTER_ the test is done, for each test.

- However, there may be times when you don't want /function scope/:
  mostly you want to avoid /function scope/ for time-consuming operations.
  * Change the scope can be a solution if build the /fixture/ once is enough for
    multiple tests.

- It's a one-line change, adding scope="module" to the /fixture decorator/:
  #+file_name: ch3/test_mod_scope.py
  #+begin_src python
    @pytest.fixture(scope="module")
    def cards_db():
        with TemporaryDirectory() as db_dir:
            db_path = Path(db_dir)
            db = cards.CardsDB(db_path)
            yield db
            db.close()
  #+end_src
  You can check the /scope/ by running ~pytest --setup-show test_mod_scope.py~.

- Available /fixture scopes/:
  * ~scope='function'~
  * ~scope='class'~
  * ~scope='module'~
  * ~scope='package'~
  * ~scope='session'~ =TODO: ???=

- =CAUTION=:
  The /scope/ is set at the definition of a /fixture/, and _NOT_ at the place
  where it's called.

  The test functions that use a /fixture/ don't control how often a /fixture/ is
  set up and torn down.

- =TODO=
  With a /fixture/ defined within a test /module/, the /session scope/ and
  /package scope/ act just like /module scope/.

  * In order to make use of these OTHER /scopes/, we need to put them in a
    =conftest.py= file.

*** DONE Sharing Fixtures through =conftest.py= - 38
CLOSED: [2025-01-07 Tue 13:51]
- You can put fixtures into individual test files, but to share fixtures among
  multiple test files, you need to use a =conftest.py= file either in the same
  directory as the test file that's using it or in some parent directory.

- The =conftest.py= file is also optional. It is considered by _pytest_ as a
  “local plugin” and can contain /hook functions/ and /fixtures/.

- Let's start by moving the ~cards_db~ /fixture/ out of =test_count.py= and into
  a =conftest.py= file in the same directory:
  #+file_name: ch3/a/conftest.py
  #+begin_src python
    from pathlib import Path
    from tempfile import TemporaryDirectory
    import cards
    import pytest


    @pytest.fixture(scope="session")
    def cards_db():
        """CardsDB object connected to a temporary database"""
        with TemporaryDirectory() as db_dir:
            db_path = Path(db_dir)
            db = cards.CardsDB(db_path)
            yield db
            db.close()
  #+end_src

  #+file_name: ch3/a/test_count.py
  #+begin_src python
    import cards


    def test_empty(cards_db):
        assert cards_db.count() == 0


    def test_two(cards_db):
        cards_db.add_card(cards.Card("first"))
        cards_db.add_card(cards.Card("second"))
        assert cards_db.count() == 2
  #+end_src

  Run ~pytest --setup-show test_count.py~ to show how does the /fixture/ run.

- /Fixtures/ can _only depend on_ other /fixtures/ of their _SAME /scope/ or
  WIDER_.

- *Don’t Import conftest.py*
  Although =conftest.py= is a Python module, it should not be imported by test
  files. The =conftest.py= file *gets read by pytest automatically*, so you
  don't have import conftest anywhere.

*** DONE Finding Where Fixtures Are Defined - 39
CLOSED: [2025-01-07 Tue 14:17]
- _pytest_ shows us a list of all available /fixtures/ our test can use:
  ~pytest --fixtures -v~
  pytest 6.x need this ~-v~ to get the path and line numbers.
  pytest 7+ can show path and line numbers without ~-v~.

  * This list includes
    + a bunch of builtin fixtures that =TODO= we'll look at in the next chapter, as well as
    + those provided by plugins.
    + The /fixtures/ found in =conftest.py= files are at the bottom.

  * If you supply a directory,
    _pytest_ will list the /fixtures/ available to tests in that directory.

  * If you supply a _test file name_, pytest will include those defined in /test
    modules/ as well.

- _pytest_ also includes the first line of the docstring from the /fixture/,
  if you've defined one, and the file and line number where the /fixture/ is
  defined. It will also include the path if it's not in your current directory.
  =TODO= NEED EXAMPLES!

- You can also use ~--fixtures-per-test~ to see what /fixtures/ are used by each
  test and where the /fixtures/ are defined:
  ~pytest --fixtures-per-test test_count.py::test_empty~

*** DONE Using Multiple Fixture Levels - 40
CLOSED: [2025-01-07 Tue 14:51]

*** DONE Using Multiple Fixtures per Test or Fixture - 42
CLOSED: [2025-01-07 Tue 15:14]
Define multiple /fixtures/, and pass them to tests.

*** DONE Deciding Fixture Scope Dynamically - 43
CLOSED: [2025-01-07 Tue 16:13]
Just control the /fixture scope/ through some ways.

- An example about why do we need this:
  The ~cards_db~ /fixture/ is empty because it calls ~delete_all()~.
  If we don't completely trust that ~delete_all()~, we may want "run tests
  depend on it" can be turned off.

  For this kind of requirements, _deciding fixture scope dynamically_ is useful.

  * Code:
    #+file_name: ch3/d/conftest.py
    #+begin_src python
      @pytest.fixture(scope=db_scope)
      def db():
          """CardsDB object connected to a temporary database"""
          with TemporaryDirectory() as db_dir:
              db_path = Path(db_dir)
              db_ = cards.CardsDB(db_path)
              yield db_
              db_.close()
    #+end_src

    Here we use the /fixture scope/ ~db_scope~. Define the it:

    #+file_name: ch3/d/conftest.py
    #+begin_src python
      def db_scope(fixture_name, config):
          if config.getoption("--func-db", None):
              return "function"
          return "session"
    #+end_src

    * There are many ways tell _pytest_ which scope to use dynamically, but in
      this case, I chose to depend on a new command-line flag, ~--func-db~.
      + In order to tell _pytest_ to allow us to use this new flag, we need to
        write a /hook function/ (=TODO= which I'll cover in more depth in
        _Chapter 15, Building Plugins, on page 205_):
        #+file_name: ch3/d/conftest.py
        #+begin_src python
          def pytest_addoption(parser):
              parser.addoption(
                  "--func-db",
                  action="store_true",
                  default=False,
                  help="new db for each test",
              )
        #+end_src

        Test it with commands
        ~pytest --setup-show test_count.py~
        ~pytest --func-db --setup-show test_count.py~

*** DONE Using autouse for Fixtures That Always Get Used - 45
CLOSED: [2025-01-07 Tue 16:19]
- Example:
  Add test times after each /test/, and
  add the date and current time at the end of the /session/.
  #+file_name: ch3/test_autouse.py
  #+begin_src python
    import pytest
    import time


    @pytest.fixture(autouse=True, scope="session")
    def footer_session_scope():
            """Report the time at the end of a session."""
            yield
            now = time.time()
            print("--")
            print(
                "finished : {}".format(
                    time.strftime("%d %b %X", time.localtime(now))
                )
            )
            print("-----------------")


    @pytest.fixture(autouse=True)
    def footer_function_scope():
        """Report test durations after each function."""
        start = time.time()
        yield
        stop = time.time()
        delta = stop - start
        print("\ntest duration : {:0.3} seconds".format(delta))


    def test_1():
        """Simulate long-ish running test."""
        time.sleep(1)


    def test_2():
        """Simulate slightly longer test."""
        time.sleep(1.23)
  #+end_src
  Run this with the command ~pytest -v -s test_autouse.py~

  =IMPORTANT=
  Here ~-s~ is the shortcut flag for ~--capture=no~ that tells _pytest_ to turn
  off /output capture/ -- we need them to check how does fixture autouse work.

  =IMPORTANT=
  Without turning off /output capture/, _pytest_ only prints the output of tests
  that fail.

*** DONE Renaming Fixtures - 46
CLOSED: [2025-01-07 Tue 15:23]
#+file_name: ch3/test_rename_fixture.py
#+begin_src python
  import pytest


  @pytest.fixture(name="ultimate_answer")
  def ultimate_answer_fixture():
      return 42


  def test_everything(ultimate_answer):
      assert ultimate_answer == 42
#+end_src
People may want to add prefix or posfix like ~_fixture~ / ~fixture_~ to a
/fixture/, and rename them to make the shorter. Then the it is easy to identify
/fixtures/, the names at usage sites can keep shorter.

- One instance where renaming is useful is when the most obvious /fixture name/
  already exists as an existing variable or function name
  #+file_name: ch3/test_rename_2.py
  #+begin_src python
    import pytest
    from somewhere import app


    @pytest.fixture(scope="session", name="app")
    def _app():
        """The app object"""
        yield app()


    def test_that_uses_app(app):
        assert app.some_property == "something"
  #+end_src

- =from the author=
  * I usually only use /fixture renaming/ with a /fixture/ that lives in the
    same /module/ as the tests using it,

    as _renaming a /fixture/ can make it *harder to find* where it's defined._
    + However, remember that there is always ~--fixtures~, which can help you
      find where a /fixture/ lives.

*** DONE Review - 47
CLOSED: [2025-01-07 Tue 16:19]
*** TODO Exercises - 48
*** TODO What's Next - 48

** TODO 4. Builtin Fixtures - 49
*** Using ~tmp_path~ and ~tmp_path_factory~ - 49
*** Using capsys - 51
*** Using monkeypatch - 54
*** Remaining Builtin Fixtures - 58
*** Review - 59
*** Exercises - 59
*** What's Next - 60

** TODO 5. Parametrization - 61
*** Testing Without Parametrize - 62
*** Parametrizing Functions - 64
*** Parametrizing Fixtures - 66
*** Parametrizing with ~pytest_generate_tests~ - 67
*** Using Keywords to Select Test Cases - 69
*** Review - 71
*** Exercises - 71
*** What's Next - 72

** TODO 6. Markers - 73
*** Using Builtin Markers - 73
*** Skipping Tests with ~pytest.mark.skip~ - 74
*** Skipping Tests Conditionally with ~pytest.mark.skipif~ - 76
*** Expecting Tests to Fail with ~pytest.mark.xfail~ - 77
*** Selecting Tests with Custom Markers - 79
*** Marking Files, Classes, and Parameters - 82
*** Using “and,” “or,” “not,” and Parentheses with Markers - 85
*** Being Strict with Markers - 86
*** Combining Markers with Fixtures - 88
*** Listing Markers - 92
*** Review - 92
*** Exercises - 94
*** What's Next - 95

* Part II — Working with Projects
** 7. Strategy - 99
*** Determining Test Scope - 99
*** Considering Software Architecture - 101
*** Evaluating the Features to Test - 103
*** Creating Test Cases - 105
*** Writing a Test Strategy - 108
*** Review - 109
*** Exercises - 110
*** What's Next - 111

** 8. Configuration Files - 113
*** Understanding pytest Configuration Files - 113
*** Saving Settings and Flags in pytest.ini - 114
*** Using tox.ini, pyproject.toml, or setup.cfg in place of pytest.ini - 116
*** Determining a Root Directory and Config File - 118
*** Sharing Local Fixtures and Hook Functions with conftest.py - 119
*** Avoiding Test File Name Collision - 119
*** Review - 121
*** Exercises - 121
*** What's Next - 122

** 9. Coverage - 123
*** Using coverage.py with pytest-cov - 123
*** Generating HTML Reports - 127
*** Excluding Code from Coverage - 129
*** Running Coverage on Tests - 130
*** Running Coverage on a Directory - 131
*** Running Coverage on a Single File - 132
*** Review - 134
*** Exercises - 134
*** What’s Next - 135

** 10. Mocking - 137
*** Isolating the Command-Line Interface - 137
*** Testing with Typer - 139
*** Mocking an Attribute - 140
*** Mocking a Class and Methods - 141
*** Keeping Mock and Implementation in Sync with Autospec - 143
*** Making Sure Functions Are Called Correctly - 145
*** Creating Error Conditions - 146
*** Testing at Multiple Layers to Avoid Mocking - 147
*** Using Plugins to Assist Mocking - 148
*** Review - 149
*** Exercises - 149
*** What's Next - 150

** 11. tox and Continuous Integration - 151
*** What Is Continuous Integration? - 151
*** Introducing tox - 152
*** Setting Up tox - 153
*** Running tox - 154
*** Testing Multiple Python Versions - 155
*** Running tox Environments in Parallel - 156
*** Adding a Coverage Report to tox - 156
*** Specifying a Minimum Coverage Level - 157
*** Passing pytest Parameters Through tox - 158
*** Running tox with GitHub Actions - 159
*** Review - 162
*** Exercises - 162
*** What's Next - 163

** 12. Testing Scripts and Applications - 165
*** Testing a Simple Python Script - 166
*** Testing an Importable Python Script - 168
*** Separating Code into src and tests Directories - 170
*** Defining the Python Search Path - 171
*** Testing requirements.txt-Based Applications - 172
*** Review - 175
*** Exercises - 176
*** What's Next - 177

** 13. Debugging Test Failures - 179
*** Adding a New Feature to the Cards Project - 179
*** Installing Cards in Editable Mode - 182
*** Debugging with pytest Flags - 183
*** Re-Running Failed Tests - 184
*** Debugging with pdb - 186
*** Combining pdb and tox - 189
*** Review - 191
*** Exercises - 192
*** What's Next - 193

* Part III — Booster Rockets
** 14. Third-Party Plugins - 197
*** Finding Plugins - 197
*** Installing Plugins - 198
*** Exploring the Diversity of pytest Plugins - 198
*** Running Tests in Parallel - 201
*** Randomizing Test Order - 203
*** Review - 204
*** Exercises - 204
*** What's Next - 204

** 15. Building Plugins - 205
*** Starting with a Cool Idea - 205
*** Building a Local conftest Plugin - 207
*** Creating an Installable Plugin - 209
*** Testing Plugins with pytester - 214
*** Testing Multiple Python and pytest Versions with tox - 217
*** Publishing Plugins - 218
*** Review - 218
*** Exercises - 219
*** What's Next - 220

** 16. Advanced Parametrization - 221
*** Using Complex Values - 221
*** Creating Custom Identifiers - 223
*** Parametrizing with Dynamic Values - 227
*** Using Multiple Parameters - 227
*** Using Indirect Parametrization - 229
*** Review - 232
*** Exercises - 233
*** What's Next - 233

* A1. Virtual Environments - 235
* A2. pip - 237
* Index - 241
