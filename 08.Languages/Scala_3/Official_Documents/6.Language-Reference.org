#+TITLE: Scala 3 Reference
#+AUTHORS: Dotty Contributors
#+VERSION: 3.4.2-RC1-bin-20240219-bbedb45-NIGHTLY -> 3.6.4-RC1-bin-20241223-4d3f757-NIGHTLY
#+STARTUP: entitiespretty
#+STARTUP: indent
#+STARTUP: overview

=FIXME= Fix some title: capitalize each word that is not preposition

This website contains the developer documentation of the Scala 3 compiler. It
targets developers interested in contributing to the compiler, or learning its
internals. If you want to learn how to use Scala, go [[https://docs.scala-lang.org/][here]].

* Docs
** TODO Reference
*** DONE Overview
CLOSED: [2021-01-02 Sat 02:05]
**** DONE Goals - =RE-READ=
CLOSED: [2020-12-09 Wed 23:44]
- The language REDESIGN was guided by _THREE_ main goals:
  * Strengthen Scala's foundations.
    Make the full programming language compatible with the foundational work
    on the /DOT calculus/ and apply the lessons learned from that work.

  * Make Scala *easier* and *safer* to use.
    + Tame powerful constructs such as /implicits/ to provide a gentler
      learning curve.

    + Remove warts and puzzlers.

  * Further IMPROVE the *consistency* and *expressiveness* of Scala's language
    constructs.

- Corresponding to these goals, the language changes fall into _SEVEN_
  categories:
  1. Core constructs to strengthen foundations,

  2. simplifications and

  3. restrictions, to make the language easier and safer to use,

  4. dropped constructs to make the language smaller and more regular,

  5. changed constructs to remove warts, and increase consistency and usability,

  6. new constructs to fill gaps and increase expressiveness,

  7. a new, principled approach to metaprogramming that replaces today's
     experimental macros.

**** DONE Essential Foundations
CLOSED: [2020-12-09 Wed 00:34]
These new constructs directly *model*
core features of /DOT/,
/higher-kinded types/, and
the /SI calculus for implicit resolution/.

- /Intersection types/, replacing /compound types/,

- /Union types/,

- /Type lambdas/, replacing encodings using /structural types/ and
  /type projection/.
  * =from Jian= Learn more about this replaced Scala 2 way.

- /Context Functions/, offering abstraction over /given parameters/.

**** DONE Simplifications
CLOSED: [2020-12-09 Wed 00:34]
- These constructs replace existing constructs with the aim of making the
  language safer and simpler to use, and to promote uniformity in code style.

  * /Trait parameters/
    REPLACE
    /early initializers/ with a more generally useful construct.

  * /Given instances/
    REPLACE
    /implicit objects and defs/, focussing on intent over mechanism.

  * /Using clauses/
    REPLACE
    /implicit parameters/,
    AVOIDING
    their ambiguities.

  * /Extension methods/
    REPLACE
    /implicit classes/ with a clearer and simpler mechanism.

  * /Opaque type aliases/
    REPLACE
    _most uses_ of /value classes/
    while guaranteeing absence of /boxing/.

  * _Top-level definitions_
    REPLACE
    _package objects_,
    DROPPING
    syntactic boilerplate.

  * /Export clauses/
    provide a simple and general way to EXPRESS
    _aggregation_, which can replace the previous facade pattern of /package
    objects inheriting from classes/.

  * /Vararg patterns/
    =FIXME= /Vararg splices/
    NOW USE
    the form ~: _*~ instead of ~@ _*~,
    =FIXME= the form ~xs*~ instead of ~xs: _*~ in function arguments,
    =FIXME= and use the form ~xs*~ instead of ~xs @ _*~ in patterns,

  * /Creator applications/
    ALLOW USING
    _simple function call syntax_ instead of ~new~ expressions.
    + ~new~ expressions stay around as a fallback for the cases
      where creator applications cannot be used. =TODO= =Example???= =TODO=

- With the _EXCEPTION_ of /early initializers/ and /old-style vararg patterns/,
  all superseded constructs *continue to be available in Scala 3.0.*
  * The plan is to _deprecate and phase them out_ later.

- /Value classes/ (superseded by /opaque type aliases/) are a special case.
  There are *currently NO deprecation plans* for /value classes/, since we
  might bring them back in a more general form if they are supported
  natively by the JVM as is planned by project Valhalla.
  =FUTURE=
  * =from Jian=
    Don't use it in Scala 3 before project Valhalla is done.

**** DONE Restrictions
CLOSED: [2020-11-07 Sat 00:18]
- These constructs are restricted to make the language safer.
  * /Implicit Conversions/:
    there is only one way to define /implicit conversions/ instead of many,
    and potentially surprising /implicit conversions/ require a language
    /import/.

  * /Given Imports/:
    implicits now require a _special form_ of /import/,
    to _make the /import/ clearly visible_.

  * /Type Projection/:
    only /classes/ can be used as prefix ~C~ of a /type projection/ ~C#A~.
    /Type projection/ on /abstract types/ is *no longer supported* since it
    is unsound.
    =TODO= =LEARN MORE about this unsoundness=

  * /Multiversal Equality/:
    implements an "opt-in" scheme to rule out nonsensical comparisons with
    ~==~ and ~!=~.

  * ~infix~:
    makes method application syntax uniform *across* code bases.

- UNRESTRICTED /implicit conversions/ continue to be available in Scala 3.0,
  _BUT_ will *be deprecated and removed later*.
    Unrestricted versions of the other constructs in the list above are
  *available only under ~-source 3.0-migration~.* =from Jian= Avoid using it!

**** DONE Dropped Constructs - =RE-READ= =LEARN MORE=
CLOSED: [2020-12-10 Thu 00:07]
- These constructs are proposed to be dropped without a new construct replacing
  them. The motivation for dropping these constructs is to simplify the
  language and its implementation.
  * DelayedInit,
  * Existential types,
  * Procedure syntax,
  * Class shadowing,
  * XML literals,
  * Symbol literals,
  * Auto application,
  * Weak conformance,
  * Compound types,
  * Auto tupling (implemented, but not merged).
    + https://github.com/lampepfl/dotty/pull/4311
      At the end of this pull, Martin mentioned that "To be revived for 3.1".

- The date when these constructs are dropped *varies*.
  The current status is:
  * Not implemented at all:
    + DelayedInit =TODO=
    + existential types =TODO=
    + weak conformance

  * Supported under =-source 3.0-migration=:
    + procedure syntax
    + class shadowing =TODO=
    + symbol literals
    + auto application =TODO=
    + auto tupling in a restricted form =???= =TODO=

  * Supported in 3.0,
    to be deprecated and phased out later:
    + XML literals =TODO=
    + compound types =???= =TODO=

**** DONE Changes - =Read in Details= - =Change to Type Checking and Inference=
CLOSED: [2021-01-02 Sat 01:56]
- These constructs have undergone changes to make them more regular and useful.
  * /Structural Types/:
    They now allow pluggable implementations, which greatly increases their
    usefulness.
    =TODO= =???= Some usage patterns are restricted compared to the status quo.

  * /Name-based pattern matching/: =FIXME= =Use current name: Option-less pattern matching=
    The existing undocumented Scala 2 implementation has been codified in a
    slightly simplified form.

  * /Eta expansion/ =FIXME= 1. =use :=; 2. =--> Automatic Eta Expansion=
    is now performed universally also in the absence of an expected type.
    The postfix ~_~ operator is thus made redundant. It will be deprecated
    and dropped after Scala 3.0.

  * /Implicit Resolution/:
    The /implicit resolution rules/ have been *cleaned up* to make them
    *more useful and less surprising*.
    + /Implicit scope/ is restricted to *no longer include* /package prefixes/. =???= =TODO=

- Most aspects of _old-style_ /implicit resolution/ are still available under
  =-source 3.0-migration=.
  * The other changes in this list are *applied UNCONDITIONALLY*.

**** DONE New Constructs - =Read in Details=
CLOSED: [2021-01-02 Sat 02:05]
These are additions to the language that make it more powerful or pleasant to
use.
- /Enums/
  provide *concise syntax* for /enumerations/ and /algebraic data types/.

- /Parameter untupling/
  avoids having to use case for /tupled parameter destructuring/.

- /Dependent function types/ =TODO= =RE-READ=
  *generalize* /dependent methods/ to /dependent function values and types/.

- /Polymorphic function types/ =TODO= =RE-READ=
  *generalize* /polymorphic methods/ to /polymorphic function values and types/.
  * Current status:
    There is a proposal and a _merged PROTOTYPE implementation_,
    BUT the implementation _has *NOT* been finalized_ (it is notably *missing*
    type inference support).

- /Kind polymorphism/
  allows the definition of operators working equally on /types/ and /type
  constructors/.

- ~@targetName~ annotations
  make it easier to *interoperate* with code _written in other languages_ and
  give MORE FLEXIBILITY for _avoiding /name clashes/._

**** DONE Metaprogramming
CLOSED: [2020-12-10 Thu 00:25]
The following constructs together aim to put /metaprogramming/ in Scala on a
*new basis*.

- So far (=from Jian= Scala 2), /metaprogramming/ was achieved
  by _a *combination* of /macros/ and /libraries/ such as Shapeless_ that were
  in turn based on some _key_ /macros/.
  * Current Scala 2 macro mechanisms are a thin veneer on top the current
    Scala 2 compiler, which makes them fragile and in many cases impossible
    to port to Scala 3.
    + =from Jian=
      Both the desing of /Scala 2 macros/ and its FOUNDATION are considerd not
      good enough.

- However, Scala 2 macros are widely used!!!
  Under an =-experimental= flag.

- To enable porting most uses of /macros/, we are experimenting with the
  advanced language constructs listed below.
  * /Match Types/:
    ALLOW _computation_ on /types/.

  * ~inline~:
    + PROVIDES by itself
      a straightforward implementation of some _SIMPLE_ /macros/

    + IS at the same time
      an essential _building block_
      for the implementation of _COMPLEX_ /macros/.

  * /Quotes/ and /Splices/:
    PROVIDE
    a *principled way* to
    express /macros/ and /staging/ _with a UNIFIED SET of abstractions._

  * /Type class/ derivation:
    PROVIDES
    an in-language implementation of the ~Gen~ /macro/ in Shapeless and other
    foundational libraries.
    + The new implementation is *more robust, efficient and easier to use*
      than the /macro/.

  * /Implicit by-name parameters/:
    =FIXME= /By-name context parameters/
    =TODO= the line is contextual/by-name-context-parameters.md, and this
           title also should be the same: _by-name context parameters_.
    PROVIDE
    a _more robust_ _in-language_ implementation of the ~Lazy~ /macro/ in
    Shapeless.

- The designs above are
  _more *provisional* than the rest_ of the proposed language constructs for
  Scala 3.0.
  * There might still be some changes until the final release.

  * *Stabilizing* the feature set needed for metaprogramming is our
    *FIRST priority*.

**** DONE See Also - =IMPORTANT= =READ=
CLOSED: [2021-01-02 Sat 02:05]
A [[https://dotty.epfl.ch/docs/reference/features-classification.html][classification of proposed language features]] is an *expanded version* of
this page that
- _ADDS the status_ (i.e.
  * relative importance to be a part of Scala 3, and
  * relative urgency when to decide this)

    AND

- _EXPECTED migration cost_ of each language construct.

*** DONE New Types
CLOSED: [2020-03-08 Sun 21:34]
**** DONE Intersection Types
CLOSED: [2019-11-10 Sun 17:47]
The ~&~ operator creates an /intersection type/.

***** Type Checking
The type ~S & T~ represents values that are of the type ~S~ and ~T~ _at the
same time_.

- Example:
  #+begin_src scala
    trait Resettable:
      def reset(): Unit

    trait Growable[T]:
      def add(x: T): this.type

    def f(x: Resettable & Growable[String]) =
      x.reset()
      x.add("first")
  #+end_src

- If a /member/ appears in both ~A~ and ~B~, its type in ~A & B~ is the
  /intersection of its type/ in ~A~ and its type in ~B~.
    For instance, assume the definitions:
  #+begin_src scala
    trait A:
      def children: List[A]

    trait B:
      def children: List[B]

    val x: A & B = new C
    val ys: List[A & B] = x.children
  #+end_src
  ~ys~ is of type ~List[A] & List[B]~, _which can be FURTHER SIMPLIFIED
  to_ ~List[A & B]~ _because_ ~List~ is /convariant/.

- Q :: (One might wonder)
       How the compiler could come up with a definition for ~children~ of
       type ~List[A & B]~ since all its is given are ~children~ definitions
       of type ~List[A]~ and ~List[B]~.

- A :: The answer is it *does not need to*. TODO ??? ??? ??? TODO
         ~A & B~ is just a type that represents a set of requirements for
       values of the type.
         At the point where a value is constructed, one must make sure that
       all inherited members are correctly defined. So if one _defines a class
        ~C~ that inherits ~A~ and ~B~,_ one needs to give at that point a
       definition of a ~children~ method with the required type.
  #+begin_src scala
    class C extends A, B:
      def children: List[A & B] = ???
  #+end_src

***** More Details
****** Syntax
Syntactically, an /intersection type/ ~S & T~ is similar to an /infix
type/, where the _infix operator_ is ~&~.
- ~&~ is treated as a /soft keyword/.
  * it is a _NORMAL identifier_ with the usual precedence.

  * *BUT*
    a type of the form ~A & B~
    _is *ALWAYS* recognized as_ an /intersection type/,
    _WITHOUT_ trying to resolve ~&~.

- Syntax:
  #+begin_src text
    Type      ::=  ...| InfixType
    InfixType ::=  RefinedType {id [nl] RefinedType}
  #+end_src

****** Subtyping Rules
- Subtyping rules
  TODO

- It is can be proved that ~&~ is *commutative*.

- Derived:
  Given type constructor ~C~,
  * If ~C~ is /covariant/, ~C[A] & C[B] ~> C[A & B]~
  * If ~C~ is /contravariant/, ~C[A] & C[B] ~> C[A | B]~

****** TODO Erasure
TODO TODO TODO

****** Relationship with Compound Type (~with~)
- =from Jian=
  ~A & B~ is different from the ~A with B~ in Scala 2.
  The latter is not commutative!

- /Intersection types/ ~A & B~ *replace* /compound types/ ~A with B~ in
  Scala 2.
    For the moment, the syntax ~A with B~ is _still allowed_ and
  *interpreted as* ~A & B~, _but its usage as a type (as opposed to in a
  ~new~ or ~extends~ clause) will be *deprecated* and *removed* in the future._

**** DONE Union Types
CLOSED: [2019-07-01 Mon 15:49]
A ~A | B~ value can be _any value_ of type ~A~ _and_ also _any value_ of
type ~B~.

- Example:
  #+begin_src scala
    case class UserName(name: String)
    case class Password(hash: Hash)

    def help(id: UserName | Password) =
      val user = id match
        case UserName(name) => lookupName(name)
        case Password(hash) => lookupPassword(hash)
      // ...
  #+end_src

- /Union types/ are _DUALS of /intersection types/.

- ~|~ is *commutative*: ~A | B~ is the _SAME type_ as ~B | A~.

- The compiler will assign a /union type/ to an expression *only if such a
  type is _EXPLICITLY given_.*
  #+begin_src scala
    val password = Password(123)
    // val password: Password = Password(123)

    val name = UserName("Eve")
    // val name: UserName = UserName(Eve)

    if true then name else password
    // val res2: Object & Product = UserName(Eve)

    val either: Password | UserName = if true then name else password
      // val res2: Password | UserName = UserName(Eve)
  #+end_src
  * ~Object & Product~ is a /supertype/ of ~UserName~ and ~Password~,
    BUT NOT the /least supertype/ ~Password | UserName~
    + =from Jian= In the document, there is is a typo (not wrong, but not very
      meaningful): _Object & Product is a supertype of UserName and ~Product~._
      TODO Create a PR to correct this!

***** TODO More Details
****** Syntax
Syntactically, /union types/ follow the same rules as /intersection types/,
BUT have a _LOWER precedence_.

******* Intersection with pattern matching syntax - =IMPORTANT=
~|~ is also used in /pattern matching/ to _SEPARATE_ /pattern alternatives/ and
*has _LOWER PRECEDENCE than_ ~:~ as used in /typed patterns/,* this means that:
#+begin_src scala
  case _: A | B => ...

  // is still equivalent to:
  case (_: A) | B => ...

  // and NOT to:
  case _: (A | B) => ...
#+end_src

****** Subtyping Rules
- ~A~ is always a subtype of ~A | B~ for all ~A~, ~B~.

- If ~A <: C~ and ~B <: C~ then ~A | B <: C~.

- Like ~&~, ~|~ is /commutative/ and /associative/:
  #+begin_src text
    A | B       =:= B | A
    A | (B | C) =:= (A | B) | C
  #+end_src

- ~&~ _is distributive over ~|~:_
  #+begin_src text
    A & (B | C) =:= A & B | A & C
  #+end_src

- From these rules it follows that: TODO TODO TODO
  *the /least upper bound (lub)/ of a set of type is the union of these
  types.*

  * This *replaces* the definition of /least upper bound/ in the Scala 2
    specification. TODO

****** TODO Motivation - TODO NOTE, TODO Re-READ
****** TODO Join of a union type - TODO ???
******* Example
=FIXME= replace ~with~ with ~,~???

****** TODO Type inference
******* Example
=FIXME= Use ideal way:
#+begin_src scala
  import scala.collection.mutable

  val x = mutable.ListBuffer(Right("foo"), Left(0))
  val y: mutable.ListBuffer[Either[Int, String]] = x
#+end_src

****** TODO Members
******* Example
=FIXME= replace ~with~ with ~,~???

****** Exhaustivity checking
****** TODO Erasure

**** DONE Type Lambdas
CLOSED: [2019-07-01 Mon 15:55]
A /type lambda/ lets one express a /higher-kinded type/ directly, *WITHOUT*
a /type definition/.

- =from Jian=
  Scala 2 can do this with /type definition/ and /type projection/.

- Example:
  ~[+X, Y] =>> Map[Y, X]~

- /Type parameters/ of /type lambdas/ can have /variances/ and /bounds/.

- A /parameterized type definition or declaration/ such as ~type T[X] = (X, X)~
  is a shorthand for a PLAIN /type definition/ with a /type lambda/ as its RHS:
  ~type T = [X] =>> (X, X)~

- =TODO=
  _More details_ link

**** DONE Match Types - =TODO= _mechanism_ - =Keep Reading=
CLOSED: [2020-03-08 Sun 21:34]
- =from Jian=
  =IMPORTANT=
  =IMPORTANT=
  =IMPORTANT=
  Inspired by RockTheJVM's lecture: [[https://rockthejvm.com/courses/1769377/lectures/39882191][Match Types]]:
  * There is no concise way to do it in most industry OOP languages.
    + Do it quick and dirty:
      implement a function with type ~Any => Any~.
      - If the implementer and the user of this function are the same person,
        this is OK, BUT we
        _give up the type safety for BOTH input and output_ -- *WORST*, and
        the user need to know the implementation details of this function,
        and manually cast the output.

    + To make the users' work easier:
      implement a function with type ~Any => ReturnType~.
      - Create a super type ~ReturnType~ to box the actual return unrelated
        types, and the user can stop doing the manually cast -- type safety
        for the output can be guaranteed.

      - The user may provide illegal input -- the type safety for the input
        *CAN'T* be guaranteed. To use it properly, the user still need to know
        the implementation details -- still *BAD*.

    + To keep type safety for both input and output:
      implement a function with type ~InputType => ReturnType~.
      - Create
          a super type ~InputType~ to box the actual input values of
          unrelated types,

          AND

          a super type ~ReturnType~ to box the actual return values of
          unrelated types,

      - This works, and type safety can be guaranteed.
        _HOWEVER_,
          too much boilerplates are created!!!
          too many "boxes" are created -- unacceptable performance penalty can be introduced!!!

        Still *NOT a GOOD result*

  * In Scala, with /match types/, we can *abstract one more level* than
    /traditional generic functions/ and fulfill this requirement elegantly.
    + For /traditional generic functions/,
      ~def lastOf[A](list: List[A]): A = list.last~ can abstract out the element
      type of ~List~, and define a function for all ~List~ structure instances.

    + /Match types/ can also abstract out the structure info (or some other
      info which depends on the scenarios), and
      build _ARBITRARY but CLEAR relations (according to requirements)
      between INPUT TYPES and OUTPUT TYPES_.
        This can complement the functionalities of /traditional generic
      functions/, and do something conceptually we know it can be done, but
      the /traditional generic functions/ CAN'T do.
      - For instance,
        if we want to write a type safe function that can get the last
        element of ~List[_]~ and ~String~, though conceptually we know the
        both ~List[_]~ and ~String~ are collection types, these two
        types usually doesn't share one common ancestor collection trait.
          When this happens, of course, we can use the /type class way/, but
        the /match types/ can be more concise and elegant -- it deserve a
        specific syntax.

- A /match types/ reduces to one of a number of right hand sides, depending on
  a /scrutinee type/. Example:
  #+begin_src scala
    type Elem[X] = X match
      case String      => Char
      case Array[t]    => t
      case Iterable[t] => t
  #+end_src
  * An ~Elem~ with /CONCRETE type parameter/ ~X~ can be reduced _as_ (NOT legal
    code you want to write out explicitly):
    #+begin_src scala
      Elem[String]      =:= Char
      Elem[Array[Int]]  =:= Int
      Elem[List[Float]] =:= Float
      Elem[Nil.type]    =:= Nothing
    #+end_src
    Here ~=:=~ is understood to mean that left and right hand sides are
    *mutually subtypes* of each other.

- Syntax in general: ~S match { P1 => T1 .... Pn => Tn }~, where
  * ~S~, ~T1~, ..., ~Tn~ are types.
  * ~P1~, ..., ~Pn~ are patterns.
    + /Type variables/ in patterns start as usual with a lower case letter.
      =from Jian= because we want to bind them rather than match them.

- /Match types/ can form part of *RECURSIVE TYPE definitions*. Example:
  #+begin_src scala
    type LeafElem[X] = X match
      case String      => Char
      case Array[t]    => LeafElem[t]
      case Iterable[t] => LeafElem[t]
      case AnyVal      => X
  #+end_src

- _Recursive match type definitions_ can also be given an /upper bound/, like this:
  #+begin_src scala
    type Concat[+Xs <: Tuple, +Ys <: Tuple] <: Tuple = Xs match
      case EmptyTuple => Ys
      case x *: xs    => x *: Concat[xs, Ys]
  #+end_src
  * In this definition, every instance of ~Concat[A, B]~, whether reducible
    or not, is known to be a /subtype/ of ~Tuple~.

  * This is necessary to _make the recursive invocation ~x *: Concat[xs, Ys]~
    type check_, since ~*:~ demands a ~Tuple~ as its right operand.

***** TODO Dependent Typing - =TODO= =RE-READ=
     /Match types/ can be used to *define* /dependently typed methods/.

     - For instance,
       here is the value level counterpart to the ~LeafElem~ type defined above
       (note the use of the /match type/ as the /return type/):
       #+begin_src scala
         def leafElem[X](x: X): LeafElem[X] = x match
            case x: String      => x.charAt(0)
            case x: Array[t]    => leafElem(x(9))
            case x: Iterable[t] => leafElem(x.head)
            case x: AnyVal      => x
       #+end_src

     - This special mode of typing for match expressions is only used
       *when the following conditions are met:*
       1. The /match expression patterns/ do *not* have /guards/

       2. The /match expression scrutinee's type/ is a /subtype/ of the /match
          type scrutinee's type/

       3. The /match expression/ and the /match type/ have the *SAME number* of cases

       4. The /match expression patterns/ are all /Typed Patterns/, and these types
          are ~=:=~ to their corresponding /type patterns/ in the /match type/

***** DONE Representation of Match Types
     CLOSED: [2020-03-08 Sun 21:32]
     # =from Jian= Internal Representation of Match Types
     #+begin_src scala
       S match
         case P1 => T1
         case P2 => T2
         // ...
         case Pn => Tn
     #+end_src
     - It's _internal representation_ (=from Jian= Tasty???) is
       ~Match(S, C1, ..., Cn) <: B~
       * ~Ci~ is of the form ~[Xs] => P => T~
         + ~[Xs]~
           a /type parameter clause/ of the /variables bound/ in pattern ~Pi~.
           _It can be omitted if there is *NO* /bound/._

         + Each case (~Pi => Ti~) is either:
           - a /unary function type/ like ~String => Char~
             OR
           - a /type lambda over a unary function type/ like ~Array[t] => LeafElem[t]~.

         + ~B~ is the declared /upper bound/ of the /match type/, or ~Any~ if no
           such bound is given.

       * Scrutiny, /bound types/ and /pattern types/ must be /first-order types/.
         TODO =from Jian= ??? I don't quite understand this sentence!?!?

***** TODO Match Type Reduction
***** TODO Subtyping Rules for Match Types
***** TODO Termination
***** TODO Variance Laws for Match Types
***** TODO Related Work

**** DONE Dependent Function Types
CLOSED: [2020-12-08 Tue 22:49]
=from Jian=
This feature if a step to improve the support to /functions/.
  Scala defines itself as a language that mixes the functional programming and
object-oriented programming, but it was not always equally support these two.
After adding this feature, from the point of view of /dependent type/, the
status of /function/ is improved.

- A /dependent function type/ describes functions where the _result type_ may
  DEPEND ON the _function's parameter values_. Example:
  #+begin_src scala
    trait Entry { type Key; val key: Key }

    def extractKey(e: Entry): e.Key = e.key          // a dependent method

    val extractor: (e: Entry) => e.Key = extractKey  // a dependent function value
    //             ^^^^^^^^^^^^^^^^^^^
    //             a dependent function type
  #+end_src

  * Scala 2 _ALREADY_ has /dependent methods/.
    BUT so far (in Scala 2) it was _NOT possible_ to turn such /methods/ into
    /function values/, so that they can be passed as /parameters/ to other
    functions, or returned as results.
    + /Dependent methods/ COULD NOT be turned into /functions/ simply because
      there was no type that could describe them.

  * In dotty the /type/ of the ~extractor~ value above is ~(e: Entry) => e.Key~

- The /dependent function type/ above is just /syntactic sugar/ for
  #+begin_src scala
    Function1[Entry, Entry#Key]:
      def apply(e: Entry): e.Key
  #+end_src

***** More details

**** DONE Polymorphic Function Types
CLOSED: [2020-12-09 Wed 00:28]
=from Jian=
This feature if a step to improve the support to /functions/:
Scala defines itself as a language that *mixes* the /functional programming/
and /object-oriented programming/, _BUT_ it *was not always equally support*
these two.
  After adding this feature, from the point of view of /polymorphic type/,
the status of /function/ is improved.
=from Jian= ??? Still not equal? Any further improvement can be done?

- polymorphic function type :: a /function type/ which accepts /type parameters/.

- For example:
  #+begin_src scala
    // A polymorphic method:
    def foo[A](xs: List[A]): List[A] = xs.reverse

    // A polymorphic function value:
    val bar: [A] => List[A] => List[A]
    //       ^^^^^^^^^^^^^^^^^^^^^^^^^
    //       a polymorphic function type
           = [A] => (xs: List[A]) => foo[A](xs)
  #+end_src

- Scala 2 _ALREADY_ has /polymorphic methods/,
  i.e. /methods/ which accepts /type parameters/. Method ~foo~ above is an
  example, accepting a /type parameter/ ~A~.
  1. So far, it was not possible to turn such /methods/ into /polymorphic
     function values/ like ~bar~ above, which can be _passed as parameters_
     to other functions, or _returned as results_.

  2. In Dotty this is now possible.
     The type of the bar value above is
     #+begin_src scala
       [A] => List[A] => List[A]
     #+end_src
     This /type/ describes /function values/ which
     take a /type/ ~A~ as a parameter,
     then take a list of /type/ ~List[A]~, and
     return a list of the same type ~List[A]~.

***** DONE Example Usage
CLOSED: [2020-12-09 Wed 00:27]
/Polymorphic function type/ are _particularly useful_
WHEN callers of a /method/ are required to provide a function which has to
be polymorphic, meaning that it should accept arbitrary types as part of
its inputs.

- For instance,
  consider the situation where we have a data type to represent the
  expressions of a simple language (consisting only of variables and
  function application) in a strongly-typed way:
  #+begin_src scala
    enum Expr[A]:
      case Var(name: String)
      case Apply[A, B](fun: Expr[B => A], arg: Expr[B]) extends Expr[A]
  #+end_src
  * =from Jian=
    In the code below, add ~import Expr.*~ to make them workable.

  * *REQUIREMENT*
    Provide a way for users to _map a function over all immediate
    subexpressions of a given ~Expr~._
    + This requires the given function to be polymorphic.

  * *SOLUTION*
     using /polymorphic function types/:
    #+begin_src scala
      def mapSubexpressions[A](e: Expr[A])
                              (f: [B] => Expr[B] => Expr[B]): Expr[A] =
        e match
          case Apply(fun, arg) => Apply(f(fun), f(arg))
          case Var(n)          => Var(n)
    #+end_src
    + And here is how to use this function to _wrap each subexpression in a
      given expression_ with a call to some ~wrap~ function, defined as a
      variable:
      #+begin_src scala
        val e0 = Apply(Var("f"), Var("a"))

        val e1 = mapSubexpressions(e0)(
          [B] => (se: Expr[B]) => Apply(Var[B => B]("wrap"), se)
        )

        println(e1)  // Apply(Apply(Var(wrap), Var(f)), Apply(Var(wrap), Var(a)))
      #+end_src

***** DONE Relationship With Type Lambdas
CLOSED: [2020-12-08 Tue 23:58]
- /Polymorphic function types/ are NOT to be confused with /type lambdas/.
  * While the _FORMER_ describes the /type of a polymorphic value/,
  * the _LATTER_ is an actual /function value at the type level/.

- A good way of understanding the difference is to notice that /type lambdas/
  are applied in /types/, whereas /polymorphic functions/ are applied in
  /terms/:
    One would call the function ~bar~ above by passing it a /type argument/
  ~bar[Int]~ within a /method body/. On the other hand, given a /type lambda/
  such as ~type F = [A] =>> List[A]~, one would call ~F~ _withing a /type
  expression/,_ as in ~type Bar = F[Int]~.

*** DONE Enums
CLOSED: [2020-07-11 Sat 04:07]
**** DONE Enumerations
CLOSED: [2020-07-10 Fri 23:57]
An /enumeration/ is used to define a /type/ consisting of _a set of NAMED values._

- Example:
  #+begin_src scala
    enum Color:
      case Red, Green, Blue
  #+end_src
  Desugare to core Scala features are explained in the section _Translation_.
  * This defined a new ~sealed~ /class/ ~Color~ with 3 values:
    + ~Color.Red~
    + ~Color.Green~
    + ~Color.Blue~

  * The _color values_ are members of ~Color~'s /companion object/.

***** DONE Parameterized enums
CLOSED: [2020-07-10 Fri 19:08]
/Enums/ CAN BE _parameterized_:
#+begin_src scala
  enum Color(val rgb: Int):
    case Red   extends Color(0xFF0000)
    case Green extends Color(0x00FF00)
    case Blue  extends Color(0x0000FF)
#+end_src
As the example shows, you can _DEFINE_ the parameter value BY using an
_EXPLICIT_ ~extends~ /clause/.

***** DONE Methods defined for enums
CLOSED: [2020-07-10 Fri 19:15]
- The values of an /enum/ correspond to _UNIQUE integers_.
  The _integer_ associated with an /enum value/ is returned by its ~ordinal~
  /method/.

- Example:
  #+begin_src scala
    val red = Color.Red
    // val red: Color = Red

    red.ordinal
    // val res0: Int = 0
  #+end_src

- The /companion object/ of an /enum/ also defines *TWO* utility /methods/.
  * ~valueOf~: obtain an /enum value/ by its _name_:
    ~Color.valueOf("Blue")  // val res0: Color = Blue~

  * ~values~: returns _ALL_ /enum values/ defined in an enumeration in an
    ~Array~:
    ~Color.values  // val res1: Array[Color] = Array(Red, Green, Blue)~

***** DONE User-defined members of enums
CLOSED: [2020-07-10 Fri 19:23]
It is _possible_ to add your own definitions to an /enum/.

- Example:
  #+begin_src scala
    enum Planet(mass: Double, radius: Double):
      private final val G = 6.67300E-11
      def surfaceGravity = G * mass / (radius * radius)
      def surfaceWeight(otherMass: Double) =  otherMass * surfaceGravity

      case Mercury extends Planet(3.303e+23, 2.4397e6)
      case Venus   extends Planet(4.869e+24, 6.0518e6)
      case Earth   extends Planet(5.976e+24, 6.37814e6)
      case Mars    extends Planet(6.421e+23, 3.3972e6)
      case Jupiter extends Planet(1.9e+27,   7.1492e7)
      case Saturn  extends Planet(5.688e+26, 6.0268e7)
      case Uranus  extends Planet(8.686e+25, 2.5559e7)
      case Neptune extends Planet(1.024e+26, 2.4746e7)
  #+end_src

- It is also possible to define an *EXPLICIT* /companion object/ for an /enum/:
  #+begin_src scala
    object Planet:
      def main(args: Array[String]) =
        val earthWeight = args(0).toDouble
        val mass = earthWeight / Earth.surfaceGravity
        for p <- values do
          println(s"Your weight on $p is ${p.surfaceWeight(mass)}")
    end Planet
  #+end_src
  * =from Jian= ???
    Before compiling, will ~case~'s be merged into the generated /companion
    object/???

***** DONE Deprecation of Enum Cases
CLOSED: [2021-01-23 Sat 00:48]
- As a library author, you may want to
  1. *signal* that an enum case is no longer intended for use.
  2. However you could still want to gracefully *handle the removal* of a case
     from your _public API_, such as special casing _deprecated cases_.

- To illustrate, say that current ~Planet~ enum originally had an additional
  case ~Pluto~, and we want to DEPRECATED it.
  We can use ~scala.deprecated~:
  #+begin_src scala
    enum Planet(mass: Double, radius: Double):
       ...
       case Neptune extends Planet(1.024e+26, 2.4746e7)

       @deprecated("refer to IAU definition of planet")
       case Pluto extends Planet(1.309e+22, 1.1883e3)
    end Planet
  #+end_src

- *Outside* the /lexical scopes/ of ~enum Planet~ or ~object Planet~, references
  to ~Planet.Pluto~ will produce a _deprecation warning_,
  BUT *within* those scopes we can still reference it to implement introspection
  over the _deprecated cases_:
  #+begin_src scala
    trait Deprecations[T <: reflect.Enum] {
       extension (t: T) def isDeprecatedCase: Boolean
    }

    object Planet {
       given Deprecations[Planet] with {
          extension (p: Planet)
             def isDeprecatedCase = p == Pluto
       }
    }
  #+end_src
  * We could imagine that a library may use /type class derivation/ to
    AUTOMATICALLY provide an /instance/ for ~Deprecations~.

***** DONE Compatibility with Java Enums
CLOSED: [2020-08-22 Sat 22:10]
If you want to use the Scala-defined enums as Java enums, you can do so by
extending the class ~java.lang.Enum~, which is imported by default, as follows:

- Example
  #+begin_src scala
    enum Color extends Enum[Color] { case Red, Green, Blue }

    // Use `Color` as you would use a Java enum:
    Color.Red.compareTo(Color.Green)
    // val res15: Int = -1
  #+end_src
  * There is _NO need to provide_ /constructor arguments/ (as defined in the
    Java API docs) to ~java.lang.Enum~ when extending it – _the compiler will
    GENERATE them AUTOMATICALLY._

- For a more in-depth example of using Scala 3 /enums/ from Java, see
  [[https://github.com/lampepfl/dotty/tree/master/tests/run/enum-java][this test]]. In this test, the /enums/ are defined in the ~MainScala.scala~
  file and used from a Java source, ~Test.java~.

***** DONE Implementation
CLOSED: [2020-10-06 Tue 21:32]
/Enums/ are represented as ~sealed~ /abstract classes/ that extend the
~scala.reflect.Enum~ /trait/.

- =FIX=
- ~scala.reflect.Enum~ defines a _SINGLE_ /public method/ ~ordinal~:
  #+begin_src scala
    package scala.reflect

    /** A base trait of all Scala enum definitions */
    transparent trait Enum extends Any, Product, Serializable:

      /** A number uniquely identifying a case of an enum */
      def ordinal: Int
  #+end_src

- /Enum values/ *WITH* ~extends~ /clauses/ get *expanded* to /anonymous class
  instances/.
    For instance, the ~Venus~ value above (=from Jian= in Section _User-defined
  members of enums_) would be defined like this:
  #+begin_src scala
    val Venus: Planet =
      new Planet(4.869e24, 6.0518e6):
        def ordinal: Int = 1
        override def productPrefix: String = "Venus"
        override def toString: String = "Venus"
  #+end_src

- /Enum values/ *WITHOUT* ~extends~ /clauses/ all share a single implementation
  that can be instantiated using a /private method/ that takes _a tag (=from Jian=
  /ordinal/???)_ and _a name_ as /arguments/.
    For instance, ~Color.Red~ would expand to
    #+begin_src scala
      val Red: Color = $new(0, "Red")
    #+end_src

***** TODO Reference
For more info, see [[https://github.com/lampepfl/dotty/issues/1970][Issue #1970]] and [[https://github.com/lampepfl/dotty/pull/4003][PR #4003]].

**** DONE Algebraic Data Types - =Keep Reading=
CLOSED: [2020-07-11 Sat 01:28]
The ~enum~ concept is general enough to ALSO support ADTs and GADTs.

- Example:
  #+begin_src scala
    enum Option[+T]:
       case Some(x: T)
       case None
  #+end_src
  * ~case Some~ is a shorthand for writing a /case class/ that _extends_
    ~Option~.

  * ~None~ is NOT parameterized, it is treated as a _normal_ enum value.

  * The ~extends~ clauses can be given explicitly:
    #+begin_src scala
      enum Option[+T]:
         case Some(x: T) extends Option[T]
         case None       extends Option[Nothing]
    #+end_src

  * Note:
    The /parent type/ of the ~None~ value is inferred as ~Option[Nothing]~.
    Generally,
    + all /covariant/ /type parameters/ of the /enum class/ are *minimized* in
      a compiler-generated ~extends~ clause

    + whereas all /contravariant/ /type parameters/ are *maximized*.

    + If ~Option~ was /non-variant/, you would need to give the ~extends~
      /clause/ of ~None~ *EXPLICITLY*.

- If not directly ~new~ a enumeration, the /type/ is always its parent.
  For example,
  * ~Option.Some(2)~ is of /type/ ~Option[Int]~
  * ~Option.None~ is of /type/ ~Option[Nothing]~
  * ~new Option.Some(2)~ is of /type/ ~Option.Some[Int]~

- As all other enums, ADTs can define methods.
  #+begin_src scala
    enum Option[+T]:
       case Some(x: T)
       case None

       def isDefined: Boolean = this match
          case None => false
          case _    => true

    object Option:
      def apply[T >: Null](x: T): Option[T] =
        if x == null then None else Some(x)
    end Option
  #+end_src

- /Enumerations/ and /ADTs/ have been presented as two *DIFFERENT concepts*.
  _BUT_ since they _share the SAME /syntactic construct/,_
  1. they can be seen simply as two ends of a spectrum
     AND
  2. it is perfectly possible to construct *hybrids*.

- For instance, the code below gives an implementation of ~Color~ either with
  three /enum values/ or with a /parameterized case/ that takes an RGB value.
  #+begin_src scala
    enum Color(val rgb: Int):
      case Red           extends Color(0xFF0000)
      case Green         extends Color(0x00FF00)
      case Blue          extends Color(0x0000FF)
      case Mix(mix: int) extends Color(mix)
  #+end_src

***** TODO Parameter Variance of Enums
=New added in 2020-09-18=

***** DONE Syntax of Enums
CLOSED: [2019-07-02 Tue 13:27]
- TODO NOTE

***** TODO Reference
For more info, see [[https://github.com/lampepfl/dotty/issues/1970][Issue #1970]].

**** DONE Translation of Enums and ADTs
CLOSED: [2020-07-11 Sat 04:07]
- In Scala 3, /enums/ are CONVENIENT /syntactic sugar/,
  BUT they are *NOT* essential to understand _Scala's core_.

- We now explain the *expansion of enums* _in detail_.
  Here are some _terminology_ and _notational conventions_:
  * ~E~ as a NAME of an /enum/,
    ~C~ as a NAME of a /case/ that appears in ~E~.

  * We use ~<...>~ for /syntactic constructs/ that in some circumstances *might
    be empty*.
    + For instance, ~<value-params>~ represents one or more parameter lists
      ~(...)~ or nothing at all.

  * Enum cases fall into _THREE_ categories:
    + /Class cases/ are those /cases/ that are *parameterized*,
      - _EITHER_ with a /type parameter/ section ~[...]~
      - _OR_ with _one or more (possibly empty)_ /parameter sections/ ~(...)~.

    + /Simple cases/ are /cases/ of a *non-generic* /enum/ that have
      *NEITHER /parameters/ NOR an /extends clause/ or /body/.*
      That is, _they consist of a NAME only._

    + /Value cases/ are /cases/ that
      - do *NOT HAVE* a /parameter section/

      - BUT that do *HAVE* a (possibly generated) /extends clause/ and/or a
        /body/.

- There are _NINE_ *desugaring rules*.
  * Overview:
    + Rule (1) DESUGAR /enum/ definitions.

    + Rules (2) and (3) DESUGAR /simple cases/.

    + Rules (4) to (6) define /extends clauses/ for /cases/ that are MISSING
      them.

    + Rules (7) to (9) define how such /cases/ with /extends clauses/ map into
      /case classes/ or /vals/.

  * Details
    1. An ~enum~ definition
       + ~enum E ... { <defs> <cases> }~ expands to
         (=from Jian=
         Here ~...~ can be anything between the _NAME_ of /enum/ and _BODY_
         of /enum/)
         - a ~sealed abstract class~ that extends the ~scala.Enum~ /trait/
           AND
         - an associated /companion object/ that CONTAINS the _defined cases_,
           expanded according to rules (2 - 8).

       + The /enum trait/
         - _starts with_ a compiler-generated import that imports the names ~<caseIds>~
           of all cases _so that they can be used WITHOUT prefix *IN* the trait._
           #+begin_src scala
             sealed abstract class E ... extends <parents> with scala.reflect.Enum {
               import E.{ <caseIds> }
               <defs>
             }

             object E { <cases> }
           #+end_src

    2. A /simple case/ consisting of a comma-separated list of /enum NAMES/:
       ~case C_1, ..., C_n~ expands to ~case C_1; ...; case C_n~
       + Any /modifiers/ or /annotations/ on the ORIGINAL case _extend_ to ALL
         EXPANDED cases.

    3. For a /enum/ ~E~,
       its /simple case/ ~case C~ -----> ~val C = $new(n, "C")~.
       + Here, ~$new~ is a /private method/ that creates an instance of ~E~.

    4. For a /enum/ ~E[V1 T1 >: L1 <: U1, ..., Vn Tn >: Ln <: Un]~, where
       _n > 0_ and the /variances/ ~Vi~ is either ~+~ or ~\minus~,
       /simple case/ ~case C~ -----> ~case C extends E[B1, ..., Bn]~, where
       ~Bi~ is ~Li~ if ~Vi~ is ~+~ and ~Ui~ if ~Vi~ is ~\minus~.
       + =TODO= This result is then _further rewritten_ with *rule (8)*.

       + /Simple cases/ of /enums/ with /NON-VARIANT/ /type parameters/ are *not
         permitted* (however /value cases/ with *EXPLICIT* /extends clause/ are)
         * =from Jian=
           A /case/ with /NON-VARIANT/ /type parameters/ (compiler can't infer
           the /type parameters/ of EACH /cases/) *MUST* have an *EXPLICIT*
           /extends clause/ to specify the /type parameters/ of *EACH* /case/.

    5. For a ~enum E~,
       its /class case/ ~case C <type-params> <value-params>~  ----->
       ~case C <type-parmas> <value-parmas> extends E~.
       + This result is then further rewritten with *rule (9)*.

    6. For a ~enum E[Ts]~,
       its /class case/ with NEITHER /type parameters/ NOR an /extends clause/
       ~case C <value-params>~ -----> ~case C[Ts] <value-params> extends E[Ts]~.
       + This result is then _further rewritten_ with *rule (9)*.

       + For /class cases/ that have /type parameters/ themselves, an /extends
         clause/ needs to be GIVEN EXPLICITLY.

    7. For a ~enum E[Ts]~,
       its /class case/ ~case C <value-params> extends <parents>~ ----->
       ~case C[Ts] <value-parmas> extends <parents>~
       *provided* at least one of the /type parameters/ ~Ts~ is mentioned
       + in a /parameter type/ in ~<value-params>~
         OR
       + in a /type argument/ in ~<parents>~.

    8. For a ~enum E[Ts]~,
       it's /value case/ ~case C extends <parents>~ ----->
       ~val C = new <pareents> { <body>; def ordinal = n; $values.register(this) }~
       in ~E~'s /companion object/, and
       + ~n~ starting from ~0~.

       + The statement ~$values.register(this)~ registers the value as one of
         the ~values~ of the enumeration (see below).
           ~$values~ is a /compiler-defined _private_ value/ in the /companion
         object/.

       + The /anonymous class/ (the value referenced by ~C~) also implements the
         /abstract/ ~Product~ /methods/ that it inherits from ~Enum~.

       + It's an *error* =TODO= =???= =TODO=
         if a /value case/ referes to a /type parameter/ of the enclosing ~enum~
         in a /type argument/ of ~<parents>~.

    9. For ~enum E~,
       it's /class case/ ~case C <params> extends <parents>~ ----->
       ~final case class C <params> extends <parents>~ in ~E~'s /companion object/.
       + However, *unlike* for a REGULAR /case class/, the return type of the associated
         ~apply~ method is a /fully parameterized type instance/ of the /enum class/
         ~E~ itself instead of ~C~.

       + ~ordinal~ /method/ is defined as ~def ordinal = n~, where ~n~ the /ordinal
         number/ of the /case/ in the /companion object/, starting from ~0~.

       + It is an *error* =TODO= =???= =TODO=
         if a /value case/ refers to a /type parameter/ of the ENCLOSING ~enum~
         in a /parameter type/ in ~<params>~ or in a /type argument/ of ~<parents>~,
         unless that /parameter/ is already a /type parameter/ of the /case/,
         i.e. the parameter name is defined in ~<params>~.

***** DONE Translation of Enums with Singleton Cases - =TODO=
CLOSED: [2020-07-11 Sat 03:47]
- enumerations :: /non-generic enums/ that define one or more *singleton* cases.

- /Companion objects/ of /enumerations/ define the following additional
  /synthetic members/.
  * A /method/ ~valueOf(name: String): E~.
    It returns the /singleton case value/ whose identifier is ~name~.

  * A /method/ ~values~ which returns an ~Array[E]~ of *ALL* /singleton case/
    values in ~E~, _in the *ORDER* of their definitions._

- /Companion objects/ of /enumerations/ that contain _at least one_ /simple case/
  define in addtion:
  * A /private method/ ~$new~ which defines a new /simple case value/ with given
    /ordinal number/ and /name/.
    This /method/ can be thought as being defined as follows:
    #+begin_src scala
      private def $new(_$ordinal: Int, $name: String) = new E with runtime.EnumValue {
        def $ordinal = $_ordinal
        override def productPrefix = $name  // if not overridden in `E`
        override def toString = $name       // if not overridden in `E`
      }
    #+end_src

- The /anonymous class/ also implements the /abstract/ ~Product~ /methods/
  that it _inherits_ from ~Enum~.
  * The ~ordinal~ /method/ above is used to generate the ~ordinal~ /method/
    if the /enum/ does NOT /extend/ a ~java.lang.Enum~ *(as /Scala enums/ do
    NOT /extend/ ~java.lang.Enums~ UNLESS explicitly specified)*.
    In case it does, there is no need to generate ~ordinal~ as ~java.lang.Enum~
    defines it.
      Similarly there is no need to override ~toString~ as that is defined in
    terms of ~name~ in ~java.lang.Enum~. Finally, ~productPrefix~ will call
    ~this.name~ when ~E~ extends ~java.lang.Enum~.
    + =from Jian=
      This is the reason why NOT define ~ordinal~ directly instead.

***** DONE Scopes for Enum Cases
CLOSED: [2020-07-11 Sat 03:32]
- A /case/ in an /enum/ is treated similarly to a /secondary constructor/.
  It can access
  * *NEITHER* the enclosing ~enum~ using ~this~
  * *NOR* its /value parameters/ or /instance members/ using simple identifiers.

- Even though translated /enum cases/ are located in the /enum's companion
  object/, referencing this /object/ or its /members/ via ~this~ or a simple
  identifier is also *ILLEGAL*.
  * The compiler typechecks /enum cases/ in the scope of the enclosing
    /companion object/ BUT flags any such *illegal* accesses as errors.

***** DONE Translation of Java-compatible enums
CLOSED: [2020-07-11 Sat 04:06]
- A /Java-compatible enum/ is _an /enum/ that extends ~java.lang.Enum~._
  The translation rules are the same as above, with the reservations
  defined in this section.

- It is a /compile-time error/ for a /Java-compatible enum/ to have
  /class cases/.
  * =from Jian=
    This is the restriction from the design of /Java enum/.

- /Cases/ such as ~case C~ expand to a ~@static val~ as opposed to a ~val~.
  This allows them to be generated as /static fields/ of the /enum type/,
  thus _ENSURING they are represented the same way as /Java enums/._

***** DONE Other Rules
CLOSED: [2020-07-11 Sat 03:40]
- A normal /case class/ which is *NOT produced* from an /enum case/ is *NOT
  allowed* to /extend/ ~scala.Enum~.
    This _ENSURES_ that the *ONLY* /cases/ of an /enum/ are the ones that are
  EXPLICITLY declared in it (=from Jian= -- make sure *sealed*).

- If an /enum case/ has an /extends clause/, the /enum class/ *MUST* be one
  of the /classes/ that's extended.
  * =from Jian=
    For example,
    #+begin_src scala
      // Illegal
      enum E[T] {
        case E1[A, B] extends E[A] with F[B]
        case E2[B]    extends F[B]  // Illegal
      }

      // Legal
      enum E[T] {
        case E1[A, B] extends E[A] with F[B]
        case E2[A]    extends E[A]
      }
    #+end_src

*** DONE Contextual Abstractions
CLOSED: [2020-07-19 Sun 03:32]
**** DONE Overview
CLOSED: [2020-07-17 Fri 02:07]
***** DONE Critique of the Status Quo
CLOSED: [2020-07-17 Fri 02:07]
- Scala's /implicits/ are its most distinguished feature.
  They are the fundamental way to *ABSTRACT over context.*
  * They represent a unified paradigm with a great variety of use cases, among
    them:
    + *implementing* /type classes/
    + *establishing* /context/
    + /dependency injection/
    + *expressing* capabilities
    + *computing* NEW /types/ and *proving* _relationships_ between them.

- Following Haskell, Scala was the _SECOND popular_ language to have some form
  of /implicits/. Other languages have followed suit. E.g
  1. *Rust*'s /traits/
  2. *Swift*'s /protocol extensions/.
  3. Design proposals are also on the table for *Kotlin* as /compile time
     dependency resolution/,
  4. for *C#* as /Shapes/ and /Extensions/
  5. for *F#* as /Traits/.
  6. Implicits are also a common feature of theorem provers such as *Coq* or
     *Agda*.
- term inference :: GIVEN a /type/, the compiler *synthesizes* a "canonical"
  term that has that /type/

- Even though these designs use widely different terminology, they are all
  variants of the core idea of /term inference/.
  * Scala *embodies* the idea in a _PURER form_ than most other languages:
    + /implicit parameter/:
      _DIRECTLY_ leads to an /inferred argument term/ that could also be
      written down EXPLICITLY.

    + /type class/ based design:
      _LESS DIRECT_ since they *hide* /term inference/ behind some form of
      /type classification/ and do NOT offer the option of writing the
      inferred quantities (typically, dictionaries) EXPLICITLY.

- Q :: Given that /term inference/ is where the industry is heading, and
       given that Scala has it in a _VERY *pure* form_, how come /implicits/
       are *NOT* more popular?

- A :: In fact, it's fair to say that /implicits/ are at the same time
       _Scala's MOST DISTINGUISHED and MOST *Controversial* feature._
         I believe this is due to a number of aspects that together make
       /implicits/ *HARDER to learn THAN NECESSARY* and also make it *HARDER
       to PREVENT ABUSES*.
  * Particular criticisms are:
    1. _Being very powerful, /implicits/ are EASILY *over-used* and *mis-used*._
       + This observation holds in almost all cases when we talk about /implicit
         conversions/, which,
         EVEN THOUGH _conceptually different_,
         _SHARE the *SAME* syntax_ with other /implicit definitions/.
         - For instance, regarding the two definitions
           #+begin_src scala
             // conditional implicit value
             implicit def i1(impllicit x: T): C[T] = ...

             // implicit conversion
             implicit def i2(x: T): C[T] = ...
           #+end_src

         - /Conditional implicit values/ are a cornerstone for expressing
           /type classes/,
           whereas most applications of /implicit conversions/ have turned
           out to be of *DUBIOUS* value.

         - The problem is that many newcomers to the language start with defining
           /implicit conversions/ since they are easy to understand and seem
           powerful and convenient.
           + Scala 3 will put under a _language flag_ both definitions and
             applications of /"UNDISCIPLINED" implicit conversions/ between
             /types/ defined elsewhere.
               This is a useful step to *PUSH BACK against overuse* of /implicit
             conversions/.

       + But the problem remains that _syntactically_,
         /conversions/ and /values/ just look *TOO SIMILAR for comfort.*

    2. Another widespread abuse is over-reliance on /implicit imports/.
       + This often leads to INSCRUTABLE /type errors/ that go away with the
         right import incantation, leaving a feeling of frustration.

       + Conversely, it is hard to see what /implicits/ a program uses since
         /implicits/ can hide anywhere in a long list of /imports/.

    3. The syntax of /implicit definitions/ is *TOO minimal*.
       It consists of a single /modifier/, ~implicit~, that can be attached
       to a large number of language constructs.
       + A problem with this for newcomers is that _it conveys mechanism instead
         of intent._
         For instance, a /type class instance/ is an /implicit object or val/
         if UNCONDITIONAL and an ~implicit def~ with ~implicit parameters~
         referring to some class if CONDITIONAL. This describes precisely
         what the /implicit definitions/ translate to -- just drop the
         ~implicit~ /modifier/, and that's it! But the cues that define intent
         are rather indirect and can be easily misread, as demonstrated by
         the definitions of ~i1~ and ~i2~ above.

    4. The syntax of /implicit parameters/ also has shortcomings.
       While /implicit parameters/ are designated specifically, arguments are
       NOT. This leads to two issues:

       + Passing an argument to an /implicit parameter/ _looks like a regular
         application ~f(arg)~._ -- this is *problematic* because it means there
         can be confusion regarding what parameter gets instantiated in a call.
         * For instance,
           in ~def currentMap(implicit ctx: Context): Map[String, Int]~ one
           *CANNOT* write ~currentMap("abc")~ since the string ~"abc"~ is
           taken as /explicit argument/ to the ~implicit ctx~ parameter. One
           _has to_ write ~currentMap.apply("abc")~ instead, which is _AWKWARD_
           and _IRREGULAR_.

       + A /method definition/ can only have one /implicit parameter/ section
         and it _MUST always come LAST_ (=from Jian= if not, how can the compiler
         knows which one is /implicit/).
         * This restriction _NOT ONLY reduces orthogonality_, _BUT ALSO prevents
           some useful program constructs_, such as
           - a /method/ with a /regular parameter/ whose /type/ depends on an
             /implicit value/.

         * Finally, it's also a bit annoying that /implicit parameters/ must
           have a NAME, even though in many cases that name is never referenced.
           - =from Jian=
             in my expericen, the percentage is definitely greater than 50%.

    5. /Implicits/ pose challenges for tooling.
       The set of available /implicits/ depends on /context/, so command
       completion has to take /context/ into account. This is feasible in an
       IDE but docs like ScalaDoc that are based static web pages can only
       provide an approximation.

       Another problem is that *failed* _implicit searches_ often give _very
       unspecific error messages_, in particular if some _DEEPLY recursive
       implicit search_ has *failed*.
         Note that the Dotty compiler has already made a lot of progress in
       the error diagnostics area. If a /recursive search/ *fails* some levels
       down, it shows what was constructed and what is missing. Also, it
       suggests imports that can bring missing /implicits/ in scope.

- None of the shortcomings is fatal,
  after all /implicits/ are very widely used,
  and many libraries and applications rely on them.
  But together, they make code using /implicits/ a lot more *cumbersome* and
  *less clear than it could be.*

- Historically, many of these shortcomings come from the way /implicits/ were
  gradually "discovered" in Scala.
  1. Scala originally had only /implicit conversions/ with the intended use
     case of "extending" a /class/ or /trait/ after it was defined,
  2. 1. is what is expressed by /implicit classes/ in later versions of Scala.
  3. /Implicit parameters and instance definitions/ came later in 2006 and
     we picked similar syntax since it seemed convenient.
     * For the same reason, NO effort was made to *distinguish* /implicit
       imports or arguments/ *from* _normal ones_.

- Existing Scala programmers by and large have gotten used to the status quo
  and see little need for change.
  _BUT_ for newcomers this status quo presents a _big hurdle_.
  * I believe if we want to overcome that hurdle, we should take a step back
    and allow ourselves to consider a radically new design.

***** DONE The New Design
CLOSED: [2020-07-17 Fri 02:06]
- The following pages introduce a *REDESIGN* of /contextual abstractions/ in
  Scala. *They introduce _four_ fundamental CHANGES*:
  1. /Given Instances/ (use keyword ~given~):
     a new way to define basic terms that can be synthesized.
     * They _replace_ /implicit definitions/.

     * The core principle of the proposal:
       rather than mixing the ~implicit~ /modifier/ with a large number of
       features, we have a SINGLE WAY to define terms that can be synthesized
       for types.

  2. /Using Clauses/ (use keyword ~using~):
     a new syntax for _IMPLICIT parameters and their arguments_.
     * It *unambiguously* aligns /parameters/ and /arguments/, solving a number
       of language warts.

     * It also allows us to have _SEVERAL ~using~ clauses_ in a definition.
       + =from Jian=
         Scala 2 /implicit parameters and arguments/ can't do this -- if
         _not explicitly_ mark ~using~
         1. how can the compiler know if a parameter list is
            - a normal parameter list
              OR
            - a manually pass /context parameters/
         2. if the compiler doesn't know which is which,
            it doesn't know if some term inference need to be applied.

       + =from Jian=
         Here is an example of, if we don't need to mark ~using~ when manually
         pass the /context parameters/, what ambiguity can happen:
         #+begin_src scala
           def f(using a: T1, a2: T2)(c: T1, d: T2)(using e: T1, f: T2) = ...

           given x: T1 = ...
           given y: T2 = ...

           f(x, y)(x, y)
         #+end_src
         If we *ASSUME* Scala 3 doesn't require keyword ~using~ when explicitly
         passing /context parameters/, the meaning of ~f(x, y)~ can have ambiguity.
         Write down the possible interpretation in legal Scala 3 syntax:
         - ~f(using x, y)(x, y)~:
           LEGAL! The second /context parameter list/ will be inferred.

         - ~f(x, y)(using x, y)~:
           LEGAL! The first /context parameter list/ will be inferred.

         - ~f(using x, y)(using x, y)~:
           ILLEGAL! The /normal parameter list/ is not provided.

  3. /"Given" Imports/:
     a new class of /import selectors/ that _SPECIFICALLY import givens_
     and _NOTHING else_.
     * =from Jian=
       + Import /givens/ by their _names_ is like normal import sytax.
       + Import /givens/ by their _types_ need to use the keyword ~given~.

  4. /Implicit Conversions/:
     now expressed as /given instances/ of a standard ~Conversion~ class.
     All other forms of /implicit conversions/ WILL _be phased out_.

- This section also contains pages describing other language features that
  are _related to_ /context abstraction/. These are:
  * /Context Bounds/, which carry over *unchanged*.

  * /Extension Methods/ REPLACE /implicit classes/ in a way that _INTEGRATES
    BETTER with /type classes/._

  * /Implementing Type classes/ demonstrates how some common /type classes/
    can be implemented using the new constructs, e.g. /extension method/.

  * /Type class Derivation/ introduces constructs to AUTOMATICALLY *derive*
    /type class instances/ for ADTs.

  * /Multiversal Equality/ introduces a special type class to support /type
    safe equality/.

  * /Context Functions/ provide a way to abstract over /context parameters/.

  * /By-Name Context Parameters/ are an essential tool to DEFINE /recursive
    synthesized values/ WITHOUT looping.

  * _Relationship with Scala 2 Implicits_ discusses the relationship between
    old-style implicits and new-style givens and how to migrate from one to
    the other.

- Overall, the _new design_ achieves a BETTER *SEPARATION* of /term inference/
  *FROM* _the REST of the language_:
  * There is a *single way* to define /givens/ instead of a multitude of forms
    all taking an ~implicit~ /modifier/.

  * There is a *single way* to introduce /implicit parameters and arguments/
    _instead of_ conflating ~implicit~ with normal arguments.

  * There is a *separate way* to _import givens_ that does *NOT allow* them
    to *hide* in a sea of normal imports.

  * And there is a *single way* to define an /implicit conversion/ which is
    clearly marked as such and _does NOT require SPECIAL syntax._

- This design thus
  * *avoids* feature interactions
  * makes the language more *consistent* and *orthogonal*.
  * make /implicits/ _easier to learn_ and _harder to abuse_.
  * greatly improve the *clarity* of the 95% of Scala programs that use
    /implicits/.
  * fulfil the promise of /term inference/ in a principled way
    that is also _accessible_ and _friendly_.

- Q :: Could we achieve the same goals by tweaking existing implicits?

- A :: After having tried for a long time, I believe now that this is
       *impossible*.
  1. Some of the problems are clearly _syntactic_ and
     _require different syntax_ to solve them.
     =from Jian=
     * For example, mutiple /context parameter lists/ is impossible in Scala 2.
       Scala 3 enable this feature by introducing new syntax, and manually
       passing /context parameters/ must explicitly use ~using~.

     * Make the /imports/ to /implicits/ explicitly.

     * Distinguish _define_ /implicits/ and _use_ /implicits/.

  2. There is the problem how to migrate.
     * Requirement:
       We cannot change the rules in mid-flight. At some stage of language
       evolution we need to accommodate both the new and the old rules.

     * Solution candiates:
       + With a syntax change, this is easy:
         1. *Introduce* the _NEW syntax_ with new rules,
         2. *Support* the _OLD syntax_ for a while to *facilitate* _cross compilation_,
         3. *Deprecate* and *phase out* the _OLD syntax_ at some later time.

       + (NOT actually available)
         Keeping the same syntax does not offer this path, and in fact does
         not seem to offer any viable path for evolution

  3. Even if we would somehow succeed with migration, if we don't choose to
     use new syntax in the new design, we still have the problem how to
     teach this.
     * We cannot make existing tutorials go away.
       + Almost all existing tutorials start with /implicit conversions/, which
         is not encouraged and the Scala 2 syntax will go away in Scala 3.1+;

       + They use _normal imports_, which will go away, and they explain calls
         to methods with /implicit parameters/ by expanding them to plain
         applications, which will also go away.
         =from Jian= new syntax need ~using~

     * This means that we'd have to add modifications and qualifications to
       all existing literature and courseware, likely _causing more confusion
       with beginners instead of less_.

     * By contrast,
       with a _NEW syntax_ there is a clear criterion:
       Any book or courseware that mentions ~implicit~ is OUTDATED and SHOULD
       BE UPDATED.

**** DONE Given Instances -- =START= =Adjust unordered list=
CLOSED: [2020-11-09 Mon 11:54]
/Given instances/ (or, simply, "givens") define "canonical" values of certain
/types/ that serve for /synthesizing arguments/ to /context parameters/.

- =from Jian=
  The concepts of /context parameters/ and /using clauses/ will be introduced
  in the next section -- here what we need to know is /given instances/ and
  /context parameters/ (or /using clauses/) are _dual to each other_.

- Example:
  #+begin_src scala
    trait Ord[T]:
      def compare(x: T, y: T): Int
      extension (x: T) def < (y: T) = compare(x, y) < 0
      extension (x: T) def > (y: T) = compare(x, y) > 0

    given intOrd: Ord[Int] with
      def compare(x: Int, y: Int) =
        if x < y then -1 else if x > y then +1 else 0

    given listOrd[T](using ord: Ord[T]): Ord[List[T]] with
      def compare(xs: List[T], ys: List[T]): Int = (xs, ys) match
        case (Nil, Nil) => 0
        case (Nil, _)   => -1
        case (_, Nil)   => +1
        case (x :: xs1, y :: ys1) =>
          val fst = ord.compare(x, y)
          if fst != 0 then fst else compare(xs1, ys1)
  #+end_src
  This code defines a /trait/ ~Ord~ (type class) with two /given instances/.

***** DONE Anonymous Givens
CLOSED: [2020-07-17 Fri 02:28]
The name of a /given instance/ *can be left out*.
#+begin_src scala
  given Ord[Int] with
    ...

  given [T](using Ord[T]): Ord[List[T]] with
    ...
#+end_src
If the name of a /given/ is missing,
the compiler will _synthesize a name_ from the implemented type(s).

- Note: =FIX-DOC= Add :
  The _name synthesized by the compiler_ is chosen to be _readable_ and
  _reasonably concise_.
  * For instance, the two instances above would get the names:
    ~given_Ord_Int~ and ~given_Ord_List_T~

- The precise rules for synthesizing names are found in the subsection
  _Anonymous Given Instances_ of section _Relationship with Scala 2 Implicits_.
  + These rules *do not guarantee* absence of name conflicts between /given
    instances/ of /types/ that are "too similar".
    *To AVOID /conflicts/ one can use /named instances/.*

- Note: =FIX-DOC= Add :
  To ensure robust binary compatibility,
  _publicly available libraries_ *should prefer* /named instances/.
  =IMPORTANT= =!!!= =IMPORTANT=

***** DONE Alias Givens - =IMPROVE= =FIXME=
CLOSED: [2020-07-17 Fri 03:44]
An alias can be used to define a /given instance/ that is equal to some
expression. E.g.:
(=FIX-DOC= =IMPROVE-DOC= Here it's better to use the same example as below,
then people can compare their syntax)
#+begin_src scala
  given global: ExecutioinContext = ForkJoinPool()
  given factory(using config: Config): Factory = MemoizingFactory(config)
#+end_src
- When the first time ~global~ is accessed, the RHS is evaludated, which is
  then returned for _this and ALL subsequent_ accesses to ~global~.
  + =from Jian=
    More initialization rules see the "Given Instance Initialization" below.

- This operation is /thread-safe/.

- /Alias givens/ can be _anonymous_ as well, e.g.
  (=FIXME= =IMPROVE-DOC= Here it's better to use the same example as above,
  then people can compare their syntax)
  #+begin_src scala
    given ExecutioinContext = new ForkJoinPool()
    given (using config: Config): Factory = MemoizingFactory(config)
  #+end_src

- An /alias given/ can have /type parameters/ and /context parameters/ just
  like any other /given/, _but it can ONLY implement A SINGLE TYPE._
  + =from Jian= =TODO= =Re-visit= =NOT SURE=
    Here _A SINGLE TYPE_ means:
    #+begin_src scala
      // Here:
      // - `A` is a type parameter
      // - `Abc` and `Lmn` are concrete types
      // - `Bc` and `Mn` are type constructors

      // Legal:
      given [T](using config: Bc[T]): Lmn = ...

      // Illegal:
      given [T](using config: Abc): Mn[T] = ...
    #+end_src
    * RATIONALE (=from Jian= my understanding, may be not comprehensive):
      - _Given instance syntax_ is a kind of _definition syntax_,
        and its duty is /given instances/ creation, can be /generics/ or not.

      - /Alias givens/ is designed only for *aliasing*,
        and its is duty is to create a name that is considered as a /given/,
        and it is actually a /reference/ which points to another /instance/,
        which can be a /given instance/ or a /regular non-given instance/.
        * Allow an /alias given/ to be a /generics/ _is equaivalent to_ allow
          it pointing to multiple /instances/!
            If a _poit to_ is NOT deterministic, why do we need this feature?

        * Don't allow it to be /generics/ is also a design that can promise
          *orthogonality* between /given instances/ and /alias givens/
          - One benefit of /alias givens/ is, since it can _ONLY implement A
            SSINGLE TYPE_, every /alias given/ refer one /instance/ -- when
            using an /alias given/ you are sure that there is only one /instance/
            this alias refers, you *don't need to worry* about _multiple
            /instances/ creations_

***** DONE Given Macros
CLOSED: [2020-07-17 Fri 03:38]
/Given aliases/ can have the ~inline~ and ~transparent~ modifiers.
- Example:
  #+begin_src scala
    transparent inline given mkAnnotations[A, T]: Annotations[A, T] = ${
      // code producing a value of a subtype of Annotations
    }
  #+end_src
  Since ~mkAnnotations~ is ~transparent~, the /type/ of an application is
  the _type of its right hand side_, which can be a proper /subtype/ of the
  declared /result type/ ~Annotations[A, T]~.

***** DONE Pattern-Bound Given Instances
CLOSED: [2020-11-09 Mon 11:54]
/Given instances/ can also appear in patterns.

- Examples:
  * /Anonymous given instances/ for /class/ ~Context~ are established by
    enumerating over ~applicationContexts~:
    #+begin_src scala
      for given Context <- applicationContexts do
        ...
    #+end_src

  * A /given ~Context~ instance/ named ~ctx~ is established by matching
    against the first half of the pair selector.
    #+begin_src scala
      pair match
        case (ctx @ given Context, y) => ...
    #+end_src

  * In each case, a /pattern-bound given instance/ consists of /given/ and
    a /type/ ~T~. The /pattern matches/ exactly the same selectors as the
    /type ascription pattern/ ~_: T~.

***** DONE Negated Givens
Scala 2's somewhat puzzling behavior with respect to ambiguity has been
exploited to implement the analogue of a "negated" search in implicit
resolution, where _a query ~Q1~ fails if some other query ~Q2~ succeeds and
~Q1~ succeeds if ~Q2~ fails._
  With the new cleaned up behavior these techniques no longer work.
  BUT the new special type ~scala.util.NotGiven~ now implements negation
directly.

- For any query /type/ ~Q~, ~NotGiven[Q]~ *succeeds*
  iff the /implicit search/ for ~Q~ *fails*,
  for example:
  #+begin_src scala
    import scala.util.NotGiven

    trait Tagged[A]

    case class Foo[A](value: Boolean)
    object Foo:
        given fooTagged[A](using Tagged[A]): Foo[A] = Foo(true)
        given fooNotTagged[A](using NotGiven[Tagged[A]]): Foo[A] = Foo(false)

    @main def test(): Unit =
      given Tagged[Int] with {}
      assert(summon[Foo[Int]].value)      // fooTagged is found
      assert(!summon[Foo[String]].value)  // fooNotTagged is found
  #+end_src

***** DONE Given Instance Initialization
CLOSED: [2020-07-11 Sat 22:31]
- A /given instance/
  + without /type parameters/ or /context parameters/
    *is initialized on-demand, the first time it is accessed.*
    * =from Jian=
      this is /thread safe/, mentioned in the above _Alias Given_ section

  + has /type parameters/ or /context parameters/, a *FRESH* /instance/ is
    created _for EACH reference_. --- =from Jian= common sense

***** DONE Syntax
CLOSED: [2020-12-01 Tue 22:32]
#+begin_src text
  TmplDef             ::= ...
                       |  ‘given’ GivenDef

  GivenDef            ::=  [GivenSig] StructuralInstance
                       |   [GivenSig] AnnotType ‘=’ Expr
                       |   [GivenSig] AnnotType

  GivenSig            ::= [id] [DefTypeParamClause] {UsingParamClause} ‘:’

  StructuralInstance  ::= ConstrApp { ‘with’ ConstraApp} ‘with’ TemplateBody
#+end_src

**** DONE Using Clauses
CLOSED: [2021-05-29 Sat 03:47]
- Functional programming tends to _express most dependencies_ AS
  _simple function parameterization_.
  * Pros:
    clean and powerful,

  * Cons:
    sometimes leads to functions that take _MANY_ /parameters/
    where _the same value is passed over and over again_ in _LONG call chains_
    to _MANY_ functions.
    + Q :: What is a good way to get rid of this?

    + A :: /Context parameters/ can help here
           since they ENABLE
           the compiler to *synthesize* repetitive /arguments/
           INSTEAD OF the programmer having to write them EXPLICITLY.
      - =from Jian=
        /context parameters/ is a powerful solution but not the only solution.
        When exploit the more basic concepts /scopes/ and /class/, we know if
        we can try to put common variables in a /scope/ that can be access by
        functions (methods), then we don't need to pass those variables as
        parameters to functions.
        * Actually I can describe this as /term inferene by scope/ (I don't
          know if this name showed up in other literatures), whereas the /context
          parameters/ is /term inference by type/.
            Similarly, I can call /inheritence from supertype(s)/ as /term
          inference by subtyping relation/.
          + Summary:
            If consider in this way, I discover that /term inference/ is
            everywhere. Though they are based on different mechanisms, they
            are all /term inferences/.

- =from Jian=
  /Givens/ tell the compiler that when applicable (means *in scope* and *match
  type*) they can be used to *synthesize* /arguments/ when /Using clauses/ show
  up.

- Example:
  Assume required /givens/, here they are ~Ord[Int]~ and ~Ord[List[Int]]~, are
  *in scope* or can be *synthesize* with in scope /givens/.
  #+begin_src scala
    def max[T](x: T, y: T)(using ord: Ord[T]): T =
      if ord.compare(x, y) < 0 then y else x

    // The explicit way
    max(2, 3)(using intOrd)

    // The implicit way
    max(2, 3)
    max(List(1, 2, 3), Nil)
  #+end_src
  From the /givens/ defined in the last section,
  * ~intOrd~ is defined, it is in scope, and it can be used for ~max(2, 3)~
  * ~listOrd~ is defined, it is in scope, the /context parameter/ it need is
    ~intOrd~, which is also in scope, and thus the an instance of ~Ord[List[Int]]~
    can be *synthesized*.

***** DONE Anonymous Context Parameters
CLOSED: [2020-07-17 Fri 04:03]
In many situations,
the _NAME_ of a /context parameter/ _need *NOT* be mentioned EXPLICITLY
*AT ALL*,_ since it is used only in *synthesized arguments* for other
/context parameters/.
- Example:
  #+begin_src scala
    def maximum[T](xs: List[T])(using Ord[T]): T =
      xs.reduceLeft(max)
  #+end_src
  Here the /context parameter/ of type ~Ord[T]~ is *synthesized*
  + for ~max~,
  + *NOT* for EXPLICIT USE as inside ~max~.

- Generally, /context parameters/ may be defined either as
  =from Jian= NO mixture of the two ways below is allowed!!!
  + a FULL /parameter list/ ~(p_1: T_1, ..., p_n: T_n)~
    =from Jian= Here FULL means *BOTH* _names_ and /types/ ARE PROVIDED.
    OR
  + a sequence of /types/ ~T_1, ..., T_n~.

- Resaonable restriction:
  /Vararg parameters/ are *not* supported in /using clauses/.

***** DONE Class Context Parameters
CLOSED: [2021-05-29 Sat 03:47]
If a /class context parameter/ is made a member by adding a ~val~ or ~var~
modifier, then that member is available as a /given instance/.

- Compare the following examples, where the attempt to supply an _explicit_
  /given member/ induces an ambiguity:
  #+begin_src scala
    class GivenIntBox(using val givenInt: Int):
      def n = summon[Int]

    class GivenIntBox2(using givenInt: Int):
      given Int = givenInt
      // def n = summon[Int]  // ambiguous
  #+end_src

- The /given member/ is *importable*:
  #+begin_src scala
    val b = GivenIntBox(using 23)
    import b.given
    summon[Int]  // 23

    import b.*
    // givenInt  // Not found
  #+end_src

***** DONE Inferring Complex Arguments
CLOSED: [2020-07-17 Fri 04:06]
#+begin_src scala
  def descending[T](using asc: Ord[T]): Ord[T] = new Ord[T]:
    def compare(x: T, y: T) = asc.compare(y, x)

  def minimum[T](xs: List[T])(using Ord[T]) =
    maximum(xs)(using descending)

  // minimum(xs)
  //
  // EVALUATION by SUBSTITUTING a FUNCTON CALL with Its BODY:
  // maximum(xs)(using descending)
  //
  // CONTEXT ARGUMENTS INFERENCE:
  // maximum(xs)(using descending(using listOrd))
  // maximum(xs)(using descending(using listOrd(using intOrd)))
#+end_src

***** DONE Multiple ~using~ Clauses
CLOSED: [2020-07-17 Fri 04:15]
There can be SEVERAL /using clauses/ in a definition and /using clauses/ can be
freely mixed with normal parameter clauses.

Example:
#+begin_src scala
  def f(u: Universe)(using ctx: u.Context)(using s: ctx.Symbol, k: ctx.Kind) = ...
#+end_src

- *Multiple* /using clauses/ are matched left-to-right in applications.
  Example:
  #+begin_src scala
    object global extends Universe { type Context = ... }
    given ctx : global.Context with { type Symbol = ...; type Kind = ... }
    given sym : ctx.Symbol
    given kind: ctx.Kind
  #+end_src
  Then the following calls are all valid (and normalize to the last one)
  #+begin_src scala
    f(global)  // source code
    f(global)(using ctx)  // step 1
    f(global)(using ctx)(using sym, kind)  // step 2 -- Done
  #+end_src

- Invalid, for example:
  ~f(global)(using sym, kind)~
  + =from Jian=
    When the compiler search a function, if the function is a named function
    (like in this example), the compiler will try to match its whole signature,
    including names and parameter types. The compiler can't support this syntax.
    If it can, it doesn't do left to right match. If it doesn't do left to right
    match, I can create some ambiguity in a example:
    #+begin_src scala
      def g(u: Universe)(using s: ctx.Symbol, k: ctx.Kind)(using s1: ctx.Symbol, k1 ctx.Kind) = ...
      g(global)(using sym, kind)
    #+end_src
    We don't know the last parameter list ~(using sym, kind)~ is for the second one,
    or for the third one.

***** DONE Summoning Instances
CLOSED: [2020-07-17 Fri 04:18]
- =from Jian=
  ~sommon~ from ~Predef~ is a replacement and improved version of the
  ~implicitly~ in Scala 2. The difference between them is mentioned below.

- The ~summon~ is simply defined as /the (*non-widening*) identity function/
  over a /context parameter/:
  #+begin_src scala
    def sommon[T](using x: T): x.type = x
  #+end_src
  + =from Jian=
    The *non-widening* is the DIFFERENCE between ~summon~ and ~implicitly~.
    This is why we say ~summon~ can provide more concise result.
    =IMPORTANT=
    =TODO= example of when ~summon~ can work, but ~implicitly~ can't work.

***** DONE Syntax
CLOSED: [2020-07-17 Fri 04:19]
#+begin_src text
  ClsParamClause      ::=  ... | UsingClsParamClause
  DefParamClauses     ::=  ... | UsingParamClause
  UsingClsParamClause ::=  ‘(’ ‘using’ (ClsParams | Types) ‘)’
  UsingParamClause    ::=  ‘(’ ‘using’ (DefParams | Types) ‘)’
  ParArgumentExprs    ::=  ... | ‘(’ ‘using’ ExprsInParens ‘)’
#+end_src

**** DONE Context Bounds
CLOSED: [2021-02-15 Mon 23:16]
A /context bound/ is a *SHORTHAND* for expressing the common pattern (a.k.a
type class pattern) of an /context parameter/ that depends on *One* /type
parameter/.
#+begin_src scala
  def maximum[T: Ord](xs: List[T]): T = xs.reduceLeft(max)
#+end_src

- The /context parameter(s)/ *generated from* /context bounds/ come *LAST*
  in the definition of the containing /method/ or /class/. E.g.
  #+begin_src scala
    def f[T: C1 : C2, U: C3](x: T)(using y: U, z: V): R

    // would expand to

    def f[T, U](x: T)(using y: U, z: V)(using C1[T], C2[T], C3[U]): R
  #+end_src

 - /Context bounds/ can be combined with /subtype bounds/.
   _If both are present, /subtype bounds/ *come first*,_ e.g.
   ~def g[T <: B : C](x: T):R = ...~

***** DONE Migration
CLOSED: [2021-02-15 Mon 23:16]
- To ease migration, /context bounds/ in Dotty
  * in Scala 3.0
    /context bounds/ in Dotty _map to_ /OLD-STYLE implicit parameters/ for
    which /arguments/ can be passed
    + _EITHER_ with a ~(using ...)~
    + _OR_ with a normal application as in Scala 2.

  * From Scala 3.1 on,
    /context bounds/ in Dotty will _map to_ /context parameters/ instead,
    as is described above.

- If the _source version_ is ~future-migration~,
  any pairing of
    an /evidence context parameter/ stemming from
    a /context bound/ with a normal argument
  will give a _migration warning_. The warning indicates that a ~(using ...)~
  clause is needed instead.
  * The _REWRITE_ can be done AUTOMATICALLY under =-rewrite=.

***** Syntax
#+begin_src text
  TypeParamBounds ::= [SubtypeBounds] {ContextBound}
  ContextBound    ::= ‘:’ Type
#+end_src

**** TODO Dererred Givens - =new=
***** TODO Abstract Givens

**** DONE Importing Givens
CLOSED: [2020-07-18 Sat 21:33]
=from Jian= The /given imports syntax/ can be applied as syntax for ~export~.

A _special form_ of /import wildcard selector/ is used to *import /given
instances/.*
- Example:
  #+begin_src scala
    object A:
      class TC
      given tc: TC = ???
      def f(using TC) = ???

    object B:
      import A.*
      import A.given
      // ...
  #+end_src
  * In Dotty,
    + Import *EVERYTHING except givens* (this is _different from Scala 2_):
      ~import A.*~

    + Import *ALL givens*:
      ~import A.given~

    + Import *everything* in ~A~:
      ~import A.{given, *}~

- There are *TWO* main _benefits_ arising from these rules:
  * It is MADE CLEARER where /givens/ in scope are coming from.
    + =from Jian=
      This AMBIGUITY only appear when use wildcard import in Scala 2.
      - This is why you can still import /givens/ through their names if you
        don't use /wildcard import/ -- no ~given~ is required.
        For example, ~import A.tc~ is legal!

    + In particular,
      it is *NOT POSSIBLE to HIDE* imported /givens/ in a long list of
      /regular wildcard imports/.

  * It ENABLES importing ALL /givens/ WITHOUT importing anything else.
    This is _particularly important since /givens/ can be ANONYMOUS_, so the
    usual recourse of using /named imports/ is NOT practical --
    =from Jian= next subsection will introduce /importing (/givens/) by type/.

***** DONE Importing By Type
CLOSED: [2020-07-18 Sat 21:14]
Since /givens/ can be _anonymous_ it is _NOT always practical to import them
by their name_, and /wildcard imports/ are typically used instead.
- =from Jian=
  However, there is no reason when you want to import SOME /anonymous
  givens/ you must import ALL /anonymous givens/.
  * Avoid using /wildcard imports/:
    /By-type imports/ syntax is introduced.
    It provides a _MORE SPECIFIC alternative_ to /wildcard imports/, which
    makes it clearer what is imported.

- =from Jian=
  /Importing by type/ is actually /Importing givens by type/.
  /Importing non-givens by type/ is *NOT allowed*.
  * Actually,
    /Importing non-givens by type/ is allowed at least in Dotty 0.23,
    but this feature was removed from 0.24+ (when I write this sentence down,
    current doc version is 0.26.0)

- =from Jian=
  Check the last example below and you will notice
  * /by name imports/
    don't need ~given~ _no matter the imported IS /givens/ or NOT_

  * ONLY /by type imports/
    need ~given~.

- Examples:
  * ~import A.given TC~

  * ~import A.{given T1, given T2, ..., given Tn}~

  * Example code:
    #+begin_src scala
      object Instances:
        given intOrd: Ordering[Int] = ...
        given listOrd[T: Ordering]: Ordering[List[T]] = ...
        given ec: ExecutionContext = ...
        given im: Monoid[Int] = ...

      import A.{given Ordering[?], given ExecutionContext}
    #+end_src
    =IMPORTANT= easy to forget this usage
    This would import the ~intOrd~ (for ~listOrd~), ~listOrd~, and ~ec~
    instances but leave out the ~im~ instance, since it fits none of the
    specified bounds.

  * /By-type imports/ can be *mixed* with /by-name imports/.
    If BOTH are present in an import clause, *by-type imports come last*.
    ~import A.{im, given Ordering[?]}~

***** DONE Migration
CLOSED: [2020-07-18 Sat 21:20]
- The rules for /imports/ stated above have the consequence that a library
  would have to
  *MIGRATE* in lockstep with all its users
  *from* /old style implicits/ and /normal imports/
  *to* /givens/ and /given imports/.

- The following modifications avoid this hurdle to migration.
  * A /given import selector/ also brings /old style implicits/ into scope.
    So, in _Scala 3.0_ an /old-style implicit definition/ can be brought into
    scope
    + EITHER by a ~*~
    + OR by a ~given _~ /wildcard selector/.

  * In _Scala 3.1_,
    /old-style implicits/ ACCESSED THROUGH a ~*~ /wildcard import/ will give
    a *deprecation warning*.

  * In some version *AFTER* 3.1,
    /old-style implicits/ ACCESSED THROUGH a ~*~ /wildcard import/ will give a
    *compiler error*.

- These rules mean that library users
  * can use ~given~ /selectors/ to ACCESS /old-style implicits/ in _Scala 3.0_,
    AND
  * will be gently nudged and then forced to do so in later versions.
    Libraries can then *switch to* /given instances/ *once* their user base has
    migrated.

***** DONE Syntax
CLOSED: [2020-07-18 Sat 21:30]

**** TODO Other Forms of Givens - =new=
***** Simple Structural Givens
***** Conditional Givens with Parameters
***** By Name Givens
***** Given Macros
***** Pattern-Bound Given Instances
***** Negated Givens
***** Summary

**** DONE Extension Methods
CLOSED: [2020-03-10 Tue 00:59]
/Extension methods/ allow one to add /methods/ to a /type/ after the /type/
is defined.
- =from Jian=
  A way to extend a closed system (not own, or better not change source code).

- Example:
  * Definition:
    #+begin_src scala
      case class Circle(x: Double, y: Double, radius: Double)

      extension (c: Circle)
        def circumference: Double = c.radius * math.Pi * 2
    #+end_src

  * Invoke as regular /methods/:
    #+begin_src scala
      val circle = Circle(0, 0, 1)
      circle.circumference
    #+end_src

***** DONE Translation of Extension Methods
CLOSED: [2020-07-19 Sun 01:08]
- extension methods :: /methods/ that have a parameter clause in front of the
  defined identifier.

- An /extension method/ named ~f~ translates to /method/ named ~extension_f~
  that TAKES the _leading parameter_ section AS its _first argument list_.

- So, the definition of ~circumference~ above translates to the plain
  method, and can also be invoked as such:
  #+begin_src scala
    <extension> def circumference(c: Circle): Double = c.radius * math.Pi * 2

    assert(circle.circumference == circumference(circle))
  #+end_src

***** DONE Operators
CLOSED: [2020-07-19 Sun 01:12]
- Use /extension method syntax/ to define /operators/.
  * This case is indicated by *omitting the period* between the leading
    parameter list and the operator.

  * This syntax _mirrors_ the way the /operator/ is applied.

- Examples:
  #+begin_src scala
    extension (x: String)
      def < (y: String): Boolean = ...

    extension (x: Elem)
      def +: (xs: Seq[Elem]): Seq[Elem] = ...

    extension (x: Number)
      infix def min (y: Number): Number = ...

    "ab" < "c"
    1 +: List(2, 3)
    x min 3
  #+end_src
  * For /alphanumeric extension operators/, like ~min~, an ~infix~ is *implied*.

  * The translations:
    #+begin_src scala
      <extension> def < (x: String)(y: String): Boolean = ...
      <extension> def +: (xs: Seq[Elem])(x: Elem): Seq[Elem] = ...
      <extension> infix def min(x: Number)(y: Number): Number = ...
    #+end_src
    * =IMPORTANT= =!!!= =IMPORTANT=
      Remember that in Scala ~:~ suffixed operators are all /right associative/!!!
      This is why ~+:~ in the translation, the order of ~x~ and ~xs~ are swapped!
      - This is similar to the operator of ~Seq~.
        The Scala compiler *preprocesses* an _infix operation_ ~x \plus{}: xs~ *to*
        ~xs.\plus{}:(x)~.

***** DONE Generic Extensions
CLOSED: [2021-03-07 Sun 03:08]
It is also possible to extend /generic types/ by adding /type parameters/
to an /extension/.

- For instance:
  #+begin_src scala
    extension [T](xs: List[T])
      def second = xs.tail.head

    extension [T: Numeric](x: T)
      def + (y: T): T = summon[Numeric[T]].plus(x, y)
  #+end_src

- /Type parameters on extensions/ can also be _combined with_ /type parameters
  on the methods/ themselves:
  #+begin_src scala
    extension [T](xs: List[T])
       def sumBy[U: Numeric](f: T => U): U = ...
  #+end_src
  * Type arguments matching method type parameters are passed as usual:
    #+begin_src scala
      List("a", "bb", "ccc").sumBy[Int](_.length)
    #+end_src

  * By contrast, /type arguments/ matching /type parameters/
    FOLLOWING ~extension~ can be passed _only if_ the /method/ is referenced
    as a _non-extension method_:
    #+begin_src scala
      sumBy[String](List("a", "bb", "ccc"))[Int](_.length)
    #+end_src
    Or, when passing both type arguments:
    #+begin_src scala
      sumBy[String](List("a", "bb", "ccc"))(_.length)
    #+end_src

- /Extensions/ can also take /using clauses/.
  * For instance,
    the ~+~ extension above could equivalently be written with a /using clause/:
    #+begin_src scala
      extension [T](x: T)(using n: Numeric[T])
         def + (y: T): T = n.plus(x, y)
    #+end_src

***** DONE Collective Extensions
CLOSED: [2020-07-19 Sun 01:33]
Define several /extension methods/ that *SHARE the SAME left-hand parameter
type.*
=from Jian= I prefer to call it /left-hand parameter type/ the /receiver type/.

- In this case one can "pull out" the common parameters into a single /extension/
  and enclose all methods in the following braces or indented region followed
  by ~:~.
  + Examples:
    #+begin_src scala
      extension (ss: Seq[String])
        def longestStrings: Seq[String] =
          val maxLength = ss.map(_.length).max
          ss.filter(_.length == maxLength)

        def longestString: String = longestStrings.head
    #+end_src

- Note the right-hand side of ~longestString~: it calls ~longestStrings~
  directly, implicitly assuming the common extended value ~ss~ as receiver.

- /Collective extensions/ like these are a shorthand for individual extensions
  where each method is defined separately. For instance, the first extension
  above expands to
  #+begin_src scala
    extension (ss: Seq[String])
      def longestStrings: Seq[String] =
        val maxLength = ss.map(_.length).max
        ss.filter(_.length == maxLength)

    extension (ss: Seq[String])
      def longestString: String = ss.longestStrings.head
  #+end_src
  + *CAUTION*
    Now the ~longestStrings.head~ write down its /receiver/ *explicitly*.
    Since ~longestStrings~ and ~longestString~ are defined INDEPENDENTLY, and
    *NO assumption about the SHARED /receiver/ can be made!*
    * This is clear if we re-write the expansion as:
      #+begin_src scala
        // No change for `longestStrings`, receiver is `(ss: Seq[String])`

        extension (ss1: Seq[String])
          def longestString: String = ss1.longestStrings.head
      #+end_src

- /Collective extensions/ also can take /type parameters/ and
  have /using clauses/.
  + Example:
    #+begin_src scala
      extenson [T](xs: List[T])(using Ordering[T])
        def smallest(n: Int): List[T] = xs.sorted.take(n)

        def smallestIndices(n: Int): List[Int] =
          val limit = smallest(n).max
          xs.zipWithIndex.collect { case (x, i) if x <= limit => i }
    #+end_src

***** DONE Translation of Calls to Extension Methods - =RE-READ=
CLOSED: [2020-07-19 Sun 03:28]
- Prerequisite:
  To *convert* a /reference/ *to* an /extension method/,
  the compiler has to know about the /extension method/ -- we say in this
  case that the /extension method/ is applicable at the point of /reference/.

- There are _FOUR_ possible ways for an /extension method/ to be applicable
  (assume the /reference/ is in the form of ~r.m~):
  1. The /extension method/ is visible under a simple name,
     by being
     * *defined* or
     * *inherited* or
     * *imported* in a /scope/ *enclosing* the /reference/.

  2. The /extension method/ is a /member/ of some /given instance/ that is
     visible at the point of the _reference_.

  3. the /extension method/ _is *defined IN* the /implicit scope/
     of the /type/ of ~r~._

  4. the /extension method/ _is *defined IN* some /given instance/
     in the /implicit scope/ of the /type/ of ~r~._

- Examples of each rule
  * Example of rule 1 above:
    #+begin_src scala
      trait IntOps:
         extension (i: Int) def isZero: Boolean = i == 0

         extension (i: Int) def safeMod(x: Int): Option[Int] =
            // extension method defined in same scope IntOps
            if x.isZero
            then None
            else Some(i % x)

      object IntOpsEx extends IntOps:
         extension (i: Int) def safeDiv(x: Int): Option[Int] =
            // extension method brought into scope via inheritance from IntOps
            if x.isZero
            then None
            else Some(i / x)

      trait SafeDiv:
         import IntOpsEx.* // brings safeDiv and safeMod into scope

         extension (i: Int) def divide(d: Int): Option[(Int, Int)] =
            // extension methods imported and thus in scope
            (i.safeDiv(d), i.safeMod(d)) match
                case (Some(d), Some(r)) => Some((d, r))
                case _                  => None
    #+end_src

  * Example of rule 2 above:
    #+begin_src scala
      given ops1: IntOps with {}  // brings safeMod into scope

      1.safeMod(2)
    #+end_src

  * Example of rule 3 and 4 above:
    #+begin_src scala
      class List[T]:
         ...

      object List:
         ...
         extension [T](xs: List[List[T]])
            def flatten: List[T] = xs.foldLeft(List.empty[T])(_ ++ _)

         given [T: Ordering]: Ordering[List[T]] with
            extension (xs: List[T])
               def < (ys: List[T]): Boolean = ...
      end List

      // extension method available since it is in the implicit scope of List[List[Int]]
      List(List(1, 2), List(3, 4)).flatten

      // extension method available since it is in the given Ordering[List[T]],
      // which is itself in the implicit scope of List[Int]
      List(1, 2) < List(3)
    #+end_src

- The *precise* rules for *resolving* a selection to an /extension method/
  are as follows.
  Assume a selection ~e.m[Ts]~ where ~m~ is not a /member/ of ~e~, where
  the /type arguments/ ~[Ts]~ are _OPTIONAL_, and where ~T~ is the expected
  /type/.
  *The following TWO rewritings are tried _in order_:*
  1. The selection is rewritten to ~extension_m[Ts](e)~.

  2. If the first rewriting does _NOT_ typecheck with expected type ~T~, and
     there is an extension method ~m~ in some eligible object ~o~, the
     selection is rewritten to ~o.extension_m[Ts](e)~. An object ~o~ is
     eligible if
     * ~o~ forms part of the /implicit scope/ of ~T~, or

     * ~o~ is a /given instance/ that is visible at the point of the
       application, or

     * ~o~ is a /given instance/ in the /implicit scope/ of ~T~.

     This second rewriting is attempted at the time where the compiler also
     tries an /implicit conversion/ from ~T~ to a /type/ containing ~m~.
     *If there is more than one way of rewriting, an _ambiguity error_ results.*

- An /extension method/ can also be used as an /identifier/ by itself
  (=from Jian= without an explicit qualifier).
  * If an /identifier/ ~m~ does _NOT_ resolve,
    the /identifier/ is rewritten to:
    + ~x.m~ if the identifier appears in an /extension/ with /parameter/ ~x~
    + ~this.m~ otherwise

  * The rewritten term is again tried as an application of an /extension method/.
    Example:
    #+begin_src scala
      extension (s: String)
         def position(ch: Char, n: Int): Int =
            if n < s.length && s(n) != ch
            then position(ch, n + 1)
            else n
    #+end_src
    + The recursive call ~position(ch, n + 1)~ expands to ~s.position(ch, n + 1)~
      in this case.

    + The whole /extension method/ rewrites to
      #+begin_src scala
        def position(s: String)(ch: Char, n: Int): Int =
           if n < s.length && s(n) != ch
           then position(s)(ch, n + 1)
           else n
      #+end_src

***** DONE Syntax
CLOSED: [2020-07-19 Sun 03:31]
- ~extension~ is a /soft keyword/.
  * It is recognized as a /keyword/
    _ONLY_ if
    + it appears at the start of a statement
      AND
    + it is followed by ~[~ or ~(~.

  * In all other cases it is treated as an /identifier/.

**** TODO Right-Associative Extension Methods: Details
**** DONE Implementing Type classes
CLOSED: [2020-07-20 Mon 00:04]
- Type Class :: an /abstract/, /parameterized/ type that lets you add new
  behavior to any *closed* /data type/ *without* using /sub-typing/.
  * /extension methods/ is a technical way (new syntax) to enhance a *closed*
    /data type/

  * /type class/ is a *systematically strategy* of enhancing a *closed* /data
    type/, and it can exploit the /extension methods/ technique.

- Examples of use-cases:
  * expressing how a /type/ you don't own (from the standard or 3rd-party library)
    conforms to such behavior

  * expressing such a behavior for MULTIPLE /types/ *without* involving
    /sub-typing/ relationships (one extends another) between those /types/
    (see: /ad hoc polymorphism/ for /instance/)

- One concept can have multiple implementations. In Scala 3,
  * Type Classes :: /generic traits/ that are *NOT defined through* the ~extends~
    keyword, but by /given instances/.

- Some examples of common type classes are in the next subsections.

***** DONE Semigroups and monoids
CLOSED: [2020-12-20 Sun 18:58]
#+begin_src scala
  trait SemiGroup[T]:
    extension (x: T) def combine (y: T): T

  trait Monoid[T] extends SemiGroup[T]:
    def unit: T

  object Monoid:
    def apply[T](using m: Monoid[T]) = m

  // For `String`
  given Monoid[String] with
    extension (x: String) def combine (y: String): String = x.concat(y)
    def unit: String = ""

  // For `Int`
  given Monoid[Int] with
    extension (x: Int) def combine (y: Int): Int = x + y
    def unit: Int = 0

  //// If no `Monoid` companion object `apply` method
  // def combineAll[T: Monoid](xs: List[T]): T =
  //  xs.foldLeft(summon[Monoid[T]].unit)(_.combine(_))

  def combineAll[T: Monoid](xs: List[T]): T =
    xs.foldLeft(summon[Monoid[T]].unit)(_.combine(_))
#+end_src

***** DONE Functors
CLOSED: [2020-12-20 Sun 18:59]
- Functor :: a type provides the ability for its values to be "mapped over".

- We can represent all types that can be "mapped over" with ~F~ -- a /type
  constructor/ that need ONE /type argument/ to construct a /type/.
  * Therefore we write it ~F[_]~, hinting that the /type constructor/ ~F~
    takes another /type/ as argument.

- The instance of ~Functor~ for ~List~ now becomes:
  * WITHOUT /extension method/:
    #+begin_src scala
      trait Functor[F[_]]:
         def map[A, B](x: F[A], f: A => B): F[B]

      given Functor[List] with
         def map[A, B](x: List[A], f: A => B): List[B] =
            x.map(f)  // `List` already has a `map` method

      def assertTransformation[F[_]: Functor, A, B](expected: F[B], original: F[A], mapping: A => B): Unit =
         assert(expected == summon[Functor[F]].map(original, mapping))

      assertTransformation(List("a1", "b1"), List("a", "b"), elt => s"${elt}1")
    #+end_src
    + When define the /type class/, use ~F[_]~ to indicate ~F~ is an /kind-1
      type constructor/.

    + When implement the /given instance/, use ~List~ is enough to tell the
      compiler that it is a /kind-1 type constructor/.

  * WITH /extension method/:
    #+begin_src scala
      trait Functor[F[_]]:
        extension [A](x: F[A])
          def map[B](f: A => B): F[B]

      given Functor[List] with
        extension [A](xs: List[A])
          def map[B](f: A => B): List[B] =
            xs.map(f) // List already has a `map` method

      def assertTransformation[F[_]: Functor, A, B](expected: F[B], original: F[A], mapping: A => B): Unit =
        assert(expected == original.map(mapping))

      assertTransformation(List("a1", "b1"), List("a", "b"), elt => s"${elt}1")
    #+end_src

***** DONE Monads
CLOSED: [2020-07-20 Mon 00:04]
- A ~Monad~ for type ~F[_]~ is a ~Functor[F]~ with _TWO_ more operations:
  * ~flatMap~, which turns an ~F[A]~ into an ~F[B]~ when given a function of
    type ~A => F[B]~,

  * ~pure~, which creates an ~F[A]~ from a single value ~A~.

- Implementation:
  #+begin_src scala
    // "A `Monad` for type `F[_]` is a `Functor[F]`" => thus has the `map` ability
    trait Monad[F[_]] extends Functor[F]:

      /** The unit value for a monad */
      def pure[A](x: A): F[A]

      extension [A](x: F[A])
        /** The fundamental composition operation */
        def flatMap[B](f: A => F[B]): F[B]

        /** The `map` operation can now be defined in terms of `flatMap` */
        def map[B](f: A => B) = x.flatMap(f.andThen(pure))

    end Monad
  #+end_src

****** ~List~
#+begin_src scala
  given listMonad: Monad[List] with
     def pure[A](x: A): List[A] =
        List(x)

     extension [A](xs: List[A])
        def flatMap[B](f: A => List[B]): List[B] =
           xs.flatMap(f)  // rely on the existing `flatMap` method of `List`
#+end_src

****** ~Option~
#+begin_src scala
  given optionMonad: Monad[Option] with
     def pure[A](x: A): Option[A] =
        Option(x)

     extension [A](xo: Option[A])
        def flatMap[B](f: A => Option[B]): Option[B] = xo match
           case Some(x) => f(x)
           case None    => None
#+end_src

****** ~Reader~
- Reader Monad :: it is used to COMBINE /functions/ that ALL need the *same*
  /data/.
  * =from Jian=
    + If not using /reader monad/, _this *same* data_ will be encoded as a
       /parameter/ for each functions that need to be combined.

    + /Reader monad/ is the one that help us to access _this common data_
      _WITHOUT passing it EXPLICITLY_ to all functions that need to be combined.

  * This _common DATA_ is usually some _configuration_, _context_, _environment
    variables_, _etc_.

- Let's define a ~Config~ type, and two functions using it:
  #+begin_src scala
    trait Config
    // ...
    def compute(i: Int)(config: Config): String = ???
    def layout(str: String)(config: Config): Unit = ???
  #+end_src
  * =Fix-Doc=
    From the context, this ~layout~ should be named as ~show~.

  * Requirement:
    Combine ~compute~ and ~show~ into a single function.
    + Naive Solution (NO one will like this, especially when new use it frequently):
      ~show(compute(i)(config))(config)~

  * Addition requirement:
    Can we avoid passing ~config~ to both functions, and put ~config~ in
    /context/ that can be accessed by both functions.
    + Postulated Solution (if you know a /function/ can be a /monad/, it may
      be easy for you to guess we have a solution of this form):
      #+begin_src scala
        def computeAndShow(i: Int): Config => Unit =
          compute(i).flatMap(show)
      #+end_src
      Then let's try to implement this ~flatMap~.

- Let's define a /monad instance/ for functions that need a /context/ ~Config~.
  =from Jian=
  Here /context/ is more general than /context parameter/. Of course, it is
  possible to change the signature of ~compute~ and ~show~, and make their
  ~config: Config~ parameter a /context parameter/. However, this is need to
  change a existing and may be *closed* system, which is not always an
  acceptable solution. This is why we need a more flexible way to introduce
  the /context/ info through /reader monads/.

  1. Define a /type/ named ~ConfigDependent~ representing a function that
     when passed a ~Config~ produces a ~Result~.
     #+begin_src scala
       type ConfigDependent[Result] = Config => Result
     #+end_src

  2. The /monad instance/ will look like this:
     #+begin_src scala
       given configDependentMonad: Monad[ConfigDependent] with

          def pure[A](x: A): ConfigDependent[A] =
             config => x

          extension [A](x: ConfigDependent[A])
             def flatMap[B](f: A => ConfigDependent[B]): ConfigDependent[B] =
                config => f(x(config))(config)

       end configDependentMonad
     #+end_src

- =from Jian=
  Here is a better implementation -- /functions/ a often used as /reader
  monads/, we can give it a view that is similar to /functions/:
  The /type/ ~ConfigDependent~ can be written using /type lambdas/.
  Using this syntax would turn the previous ~configDependentMonad~ into:
  #+begin_src scala
    type ConfigDepdenent = [Result] =>> Config => Result  // from Jian

    given configDependentMonad: Monad[[Result] =>> Config => Result] with

       def pure[A](x: A): Config => A =
          config => x

       extension [A](x: Config => A)
          def flatMap[B](f: A => Config => B): Config => B =
             config => f(x(config))(config)

    end configDependentMonad
  #+end_src

- It is likely that we would like to use this pattern with other kinds of
  environments than our ~Config~ /trait/.
    The ~Reader~ /monad/ allows us to *abstract away* ~Config~ as a /type
  parameter/, named ~Ctx~ in the following definition:
  #+begin_src scala
    given readerMonad[Ctx]: Monad[[X] =>> Ctx => X] with

       def pure[A](x: A): Ctx => A =
          ctx => x

       extension [A](x: Ctx => A)
          def flatMap[B](f: A => Ctx => B): Ctx => B =
             ctx => f(x(ctx))(ctx)

    end readerMonad
  #+end_src
  + =from Jian=
    Here is a use case for /type lambda/.

***** DONE Summary
CLOSED: [2020-07-20 Mon 00:02]
- The definition of a /type class/ is expressed with _a /parameterised type/
  with /abstract members/,_ such as a /trait/.

- The main _DIFFERENCE_ between /subtype polymorphism/ and /ad-hoc polymorphism
  with type classes/ is how the definition of the /type class/ is implemented,
  in relation to the type it acts upon:
  * /Ad-hoc polymorphism with type classes/:
    the implementation for a /concrete type/, =from Jian= the TARGET type, is
    expressed through
    + a /given instance definition/, which is supplied as
      an /implicit argument/ alongside the value it acts upon.

  * /Subtype polymorphism/:
    the implementation is *mixed INTO* the /parents of a class/, and ONLY a
    SINGLE term is required to perform a polymorphic operation.

- Compare the application of the /subtype polymorphism/ and /ad-hoc polymorphism
  with type classes/:
  * /ad-hoc polymorphism with type classes/
    + take more effort to set up,
    + _BUT_ is more extensible.

  * /subtype polymorphism/:
    + add a new /interface/ to a /class/ requires *changing the source code
      of that /class/.* --
      =from Jian= usually we don't want to change the source code frequently!

- To conclude, we have seen that
  /traits/ and /given instances/, combined with other _constructs_ like
  /extension methods/, /context bounds/, and /type lambdas/ allow a *concise*
  and *natural* expression of /type classes/.
  * =from Jian=
    From the /reader monad/ example, you can see without /type lambdas/, its
    representation will be not *natural* -- let the type simulate the view
    of /function/.

**** DONE Type Class Derivation - =TODO=
CLOSED: [2020-07-12 Sun 23:07]
/Type class derivation/ is a way to *automatically* GENERATE /given instances/
for /type classes/ which satisfy some simple conditions.

- A /type class/ in this sense is *ANY* /trait/ or /class/ with *one* /type
  parameter/ determining the type being operated on.

- Common examples of /type class/ are ~Eq~, ~Ordering~, or ~Show~.

- For example, given the following ~Tree~ algebraic data type (ADT) with a
  ~dervies~ clause,
  #+begin_src scala
    enum Tree[T] derives Eq, Ordering, Show:
      case Branch(left: Tree[T], right: Tree[T])
      case Left(elem: T)
  #+end_src
  * _The ~derives~ clause_ *generates* the following /given instances/ for the
    ~Eq~, ~Ordering~ and ~Show~ /type classes/ _in the /companion object/ of ~Tree~,_
    #+begin_src scala
      given [T: Eq]      : Eq[Tree[T]]    = Eq.derived
      given [T: Ordering]: Ordering[Tree] = Ordering.derived
      given [T: Show]    : Show[Tree]     = Show.derived
    #+end_src

  * We say that
    + ~Tree~ is the /deriving type/
    + the ~Eq~, ~Ordering~ and ~Show~ /given instances/ are /derived instances/.

***** DONE Types supporting ~derives~ clauses - =TODO= _NOT stable in details_
CLOSED: [2020-07-12 Sun 22:25]
*ALL* data types CAN HAVE _a ~derives~ clause_.

- This document _FOCUSES PRIMARILY_ on data /types/ which also have a /given
  instance/ of the ~Mirror~ /type class/ available.
  * =from Jian=
    Reason of this document forcuses on the way of implementing ~derives~
    with ~Mirror~:
    ~Mirror~ is a structure, in the standard library, that is designed as an
    auxiliary to help implementing ~derives~
    + Use ~Mirror~ is *NOT the ONLY way* to implement ~derives~.

    + Use ~Mirror~ is considered the simplest and easist way to implement
      ~derives~. It uses less _advanced features_ of Scala 3.

- /Instances/ of the ~Mirror~ /type class/ are generated *AUTOMATICALLY* by
  the compiler for,
  * /enums/ and /enum cases/
  * /case classes/ and /case objects/
  * /sealed classes or traits/ _that have *ONLY* /case classes/ and /case
    objects/ as children_

- ~Mirror~ /type class instances/ provide
  * information at the _type level_ about the components and labelling of the /type/.
  * minimal _term level_ infrastructure
    to allow higher level libraries to provide comprehensive derivation support.
    =from Jian= Check libraries like _shapeless 3_.

- ~Mirror~ /type class/ definition
  #+begin_src scala
    sealed trait Mirror:

      /** The type being mirrored */
      type MirroredType

      /** The type of the elements of the mirrored type */
      type MirroredElemTypes

      /** The mirrored *-type */
      type MirroredMonoType

      /** The name of the type */
      type MirroredLabel <: String

      /** The names of the elements of the type */
      type MirroredElemLabels <: Tuple


    object Mirror:

      /** The Mirror for a product type */
      trait Product extends Mirror:

        /** Create a new instance of type `T` with elements taken from product `p`. */
        def fromProduct(p: scala.Product): MirroredMonoType

      trait Sum extends Mirror:
        /** The ordinal number of the case class of `x`. For enums, `ordinal(x) == x.ordinal`
         */
        def ordinal(x: MirroredMonoType): Int

    end Mirror
  #+end_src
  * ~Product~ types (i.e. /case classes and objects/, and /enum cases/) have
    /mirrors/ which are *subtypes* of ~Mirror.Product~.

  * ~Sum~ types (i.e. /sealed class/ or /traits with product children/, and
    /enums/) have /mirrors/ which are *subtypes* of ~Mirror.Sum~.

- For the ~Tree~ ADT from above the following ~Mirror~ /instances/ will be
  *AUTOMATICALLY* provided by the compiler,
  =from Jian=
  Since the generated ~Mirror~ /instances/ are put in the /companion object/
  of ~Tree~, and this is the reason why we don't need the ~Tree~ qualifier in
  the following example.
  #+begin_src scala
    // Mirror for `Tree`
    new Mirror.Sum:
      type MirroredType = Tree
      type MirroredElemTypes[T] = (Branch[T], Leaf[T])
      type MirroredMonoType = Tree[_]
      type MirroredLabel = "Tree"
      type MirroredElemLabels = ("Branch", "Leaf")

      def ordinal(x: MirroredMonoType): Int = x match
        case _: Branch[_] => 0
        case _: Leaf[_]   => 1

    // Mirror for `Branch`
    new Mirror.Product:
      type MirroredType = Branch
      type MirroredElemTypes[T] = (Tree[T], Tree[T])
      type MirroredMonoType = Branch[_]
      type MirroredLabel = "Branch"
      type MirroredElemLabels = ("left", "right")

      def fromProduct(p: Product): MirroredMonoType =
        new Branch(...)

    // Mirror for `Leaf`
    new Mirror.Product:
      type MirroredType = Leaf
      type MirroredElemTypes[T] = Tuple1[T]
      type MirroredMonoType = Leaf[_]
      type MirroredLabel = "Leaf"
      type MirroredElemLabels = Tuple1["elem"]

      def fromProduct(p: Product): MirroredMonoType =
        new Leaf(...)
  #+end_src

- Note the following properties of ~Mirror~ /types/,
  * Properties are encoded _using /types/ RATHER THAN /terms/._
    This means that
    + they have _no_ runtime footprint _unless_ used
    + they are a _compile time feature_ for use with Dotty's metaprogramming
      facilities.

  * The /kinds/ of ~MirroredType~ and ~MirroredElemTypes~ match the /kind/
    of the data type the /mirror/ is an /instance/ for.
    + This allows ~Mirror~'s to support /ADTs/ of *all* /kinds/.

  * There is NO DISTINCT /representation type/ for /sums/ or /products/
    (ie. there is no ~HList~ or ~Coproduct~ type as in Scala 2 versions of shapeless).
      Instead the collection of child types of a data type is represented by
    an ordinary, possibly parameterized, /tuple type/.
    + Dotty's metaprogramming facilities can be used to work with these /tuple
      types/ as-is, and _higher level libraries_ can be *built on top of them*.

    + =from Jian=
      It seems ~HList~ or ~Coproduct~ like structures are already partially
      (or minimalized) implemented and merged. Will see if the complete version
      of them can affect _type class derivation_!
      =TODO= =TODO= =TODO=

  * For both /product/ and /sum/ types, the elements of ~MirroredElemTypes~
    are arranged in *definition order* (i.e. ~Branch[T]~ precedes ~Leaf[T]~ in
    ~MirroredElemTypes~ for ~Tree~ because ~Branch~ is defined _BEFORE_ ~Leaf~
    in the source file).
    + This means that ~Mirror.Sum~ *differs* in this respect from /shapeless's
      generic representation/ for ADTs in Scala 2, where the constructors
      are *ordered alphabetically by name*.

  * The methods ~ordinal~ and ~fromProduct~ are defined in terms of
    ~MirroredMonoType~ which is the /type/ of /kind-*/ which is obtained from
    ~MirroredType~ by *wildcarding* its /type parameters/.

***** TODO Type classes supporting automatic deriving - =TODO=
- A /trait/ or /class/ can appear in a /derives clause/ if its /companion
  object/ defines a /method/ named ~derived~.

- The /signature/ and _implementation_ of a ~derived~ /method/ for a /type
  class/ ~TC[_]~ are arbitrary but it is typically of the following form,
  #+begin_src scala
    import scala.deriving.Mirror

    def derived[T](using Mirror.Of[T]): TC[T] = ...
  #+end_src

- That is, the ~derived~ /method/ takes a /context parameter/ of (some /subtype/
  of) type ~Mirror~ which
  * _DEFINES_ the shape of the /deriving type/ ~T~,
    AND
  * _COMPUTES_ the /type class/ _implementation_ according to that shape.

  This is all that the provider of an ADT with a ~derives~ _clause_ has to
  know about the _derivation_ of a /type class instance/.

- Note that ~derived~ /methods/ may
  * have /context ~Mirror~ parameters/ _INDIRECTLY_
    + e.g.
      by having a /context argument/ which in turn has a /context ~Mirror~
      parameter/

     OR  =TODO= =FIXME=

  * NOT have /context ~Mirror~ parameters/ AT ALL
    + e.g.
      they might use some completely different user-provided mechanism, for
      instance using Dotty /macros/ or /runtime reflection/.

- We expect that _(*direct* or *indirect*) ~Mirror~ based implementations_
  will be the most common and that is what this document emphasises.
  * _(*direct* or *indirect*) ~Mirror~ based implementations_ means ~derived~'s
    always have a ~Mirror~ /context parameter/ (*direct* or *indirect*).

- /Type class/ authors will most likely use /higher level derivation/ or
  /generic programming libraries/ to implement ~derived~ methods.
  * An example of how a ~derived~ /method/ might be implemented using only
    the low level facilities described above and Dotty's general
    metaprogramming features is _provided BELOW_.
    1. It is not anticipated that /type class/ authors would normally
       implement a ~derived~ method in this way,

    2. however this walkthrough can be taken as a guide for authors of the
       /higher level derivation libraries/ that we expect typical /type class/
       authors will use (for a fully worked out example of such a library,
       see _Shapeless 3_).

****** TODO How to write a type class ~derived~ method using low level mechanisms
- The low-level method we will use to implement a type class derived method
  in this example exploits three new type-level constructs in Dotty:
  inline methods, inline matches, and implicit searches via summonInline
  or summonFrom. Given this definition of the Eq type class,
  #+begin_src scala
    trait Eq[T]:
      def eqv(x: T, y: T): Boolean
  #+end_src
  we need to implement a method Eq.derived on the companion object of ~Eq~
  that produces a given instance for ~Eq[T]~ given a ~Mirror[T]~.

- Here is a possible implementation,
  #+begin_src scala
    import scala.deriving.Mirror

    inline given derived[T](using m: Mirror.Of[T]): Eq[T] =
      val elemInstances = summonAll[m.MirroredElemType]          // (1)
      inline m match                                             // (2)
        case s: Mirror.SumOf[T]     => eqSum(s, elemInstances)
        case p: Mirror.ProductOf[T] => eqProduct(p, elemInstances)
  #+end_src

- Note that derived is defined as an inline given. This means that the method
  will be expanded at call sites (for instance the compiler generated
  instance definitions in the companion objects of ADTs which have a
  derived Eq clause), and also that it can be used recursively if
  necessary, to compute instances for children.

- The body of this method (1) first materializes the Eq instances for all
  the child types of type the instance is being derived for. This is
  either all the branches of a sum type or all the fields of a product
  type. The implementation of summonAll is inline and uses Dotty's
  summonInline construct to collect the instances as a List,
  #+begin_src scala
    inline def summonAll[T <: Tuple]: List[Eq[_]] =
      inline erasedValue[T] match
        case _: EmptyTuple => Nil
        case _: (t *: ts)  => summonInline[Eq[t]] :: summonAll[ts]
  #+end_src
  with the instances for children in hand the derived method uses an
  inline match to dispatch to methods which can construct instances for
  either sums or products (2). Note that because derived is inline the
  match will be resolved at compile-time and only the left-hand side of
  the matching case will be inlined into the generated code with types
  refined as revealed by the match.

- In the sum case, eqSum, we use the runtime ordinal values of the arguments
  to eqv to first check if the two values are of the same subtype of the
  ADT (3) and then, if they are, to further test for equality based on the
  Eq instance for the appropriate ADT subtype using the auxiliary method
  check (4).
  #+begin_src scala
    import scala.deriving.Mirror

    def eqSum[T](s: Mirror.SumOf[T], elems: List[Eq[_]]): Eq[T] =
      new Eq[T]:
        def eqv(x: T, y: T): Boolean =
          val ordx = s.ordinal(x)                            // (3)
          (s.ordinal(y) == ordx) && check(elems(ordx))(x, y) // (4)
  #+end_src

- In the product case, ~eqProduct~ we test the runtime values of the arguments
  to ~eqv~ for equality as products based on the ~Eq~ instances for the fields
  of the data type (5),
  #+begin_src scala
    import scala.deriving.Mirror

    def eqProduct[T](p: Mirror.ProductOf[T], elems: List[Eq[_]]): Eq[T] =
      new Eq[T]:
        def eqv(x: T, y: T): Boolean =
          iterator(x).zip(iterator(y)).zip(elems.iterator).forall {  // (5)
            case ((x, y), elem) => check(elem)(x, y)
          }
  #+end_src

- Pulling this all together we have the following complete implementation,
  #+begin_src scala
    import scala.deriving.*
    import scala.compiletime.{erasedValue, summonInline}

    inline def summonAll[T <: Tuple]: List[Eq[_]] =
      inline erasedValue[T] match
        case _: EmptyTuple => Nil
        case _: (t *: ts)  => summonInline[Eq[t]] :: summonAll[ts]

    trait Eq[T]:
      def eqv(x: T, y: T): Boolean

    object Eq:
      given Eq[Int] with
        def eqv(x: Int, y: Int) = x == y

      def check(elem: Eq[_])(x: Any, y: Any): Boolean =
        elem.asInstanceOf[Eq[Any]].eqv(x, y)

      def iterator[T](p: T) = p.asInstanceOf[Product].productIterator

      def eqSum[T](s: Mirror.SumOf[T], elems: => List[Eq[_]]): Eq[T] =
        new Eq[T]:
          def eqv(x: T, y: T): Boolean =
            val ordx = s.ordinal(x)
            (s.ordinal(y) == ordx) && check(elems(ordx))(x, y)

      def eqProduct[T](p: Mirror.ProductOf[T], elems: => List[Eq[_]]): Eq[T] =
        new Eq[T]:
          def eqv(x: T, y: T): Boolean =
            iterator(x).zip(iterator(y)).zip(elems.iterator).forall {
              case ((x, y), elem) => check(elem)(x, y)
            }

      inline given derived[T](using m: Mirror.Of[T]): Eq[T] =
        lazy val elemInstances = summonAll[m.MirroredElemTypes]
        inline m match
          case s: Mirror.SumOf[T]     => eqSum(s, elemInstances)
          case p: Mirror.ProductOf[T] => eqProduct(p, elemInstances)
    end Eq
  #+end_src
  we can test this relative to a simple ADT like so,
  #+begin_src scala
    enum Opt[+T] derives Eq:
      case Sm(t: T)
      case Nn

    @main def test(): Unit =
      import Opt.*
      val eqoi = summon[Eq[Opt[Int]]]
      assert(eqoi.eqv(Sm(23), Sm(23)))
      assert(!eqoi.eqv(Sm(23), Sm(13)))
      assert(!eqoi.eqv(Sm(23), Nn))
  #+end_src

- In this case the code that is generated by the inline expansion for the
  derived Eq instance for Opt looks like the following, after a little
  polishing,
  #+begin_src scala
    given derived$Eq[T](using eqT: Eq[T]): Eq[Opt[T]] =
       eqSum(
          summon[Mirror[Opt[T]]],
          List(
             eqProduct(summon[Mirror[Sm[T]]], List(summon[Eq[T]])),
             eqProduct(summon[Mirror[Nn.type]], Nil)
          )
       )
  #+end_src

- Alternative approaches can be taken to the way that ~derived~ methods can
  be defined. For example, more aggressively inlined variants using Dotty
  macros, whilst being more involved for type class authors to write than
  the example above, can produce code for type classes like Eq which
  eliminate all the abstraction artefacts (eg. the ~Lists~ of child
  instances in the above) and generate code which is indistinguishable
  from what a programmer might write by hand. As a third example, using a
  higher level library such as shapeless the type class author could
  define an equivalent ~derived~ method as,

  #+begin_src scala
    given eqSum[A](using inst: => K0.CoproductInstances[Eq, A]): Eq[A] with
      def eqv(x: A, y: A): Boolean = inst.fold2(x, y)(false)(
        [t] => (eqt: Eq[t], t0: t, t1: t) => eqt.eqv(t0, t1)
      )

    given eqProduct[A](using inst: K0.ProductInstances[Eq, A]): Eq[A] with
      def eqv(x: A, y: A): Boolean = inst.foldLeft2(x, y)(true: Boolean)(
        [t] => (acc: Boolean, eqt: Eq[t], t0: t, t1: t) =>
          Complete(!eqt.eqv(t0, t1))(false)(true)
      )

    inline def derived[A](using gen: K0.Generic[A]): Eq[A] =
      gen.derive(eqSum, eqProduct)
  #+end_src

- The framework described here
  ENABLES _all three_ of these approaches
  WITHOUT MANDATING any of them.

- For a brief discussion on how to use /macros/ to write a /type class
  derived method/ please read more at
  [[https://dotty.epfl.ch/docs/reference/contextual/derivation-macro.html][How to write a type class derived method using macros]].

***** DONE Deriving instances elsewhere
CLOSED: [2020-07-12 Sun 22:47]
Sometimes one would like to
*derive* a /type class instance/ for an ADT *after the ADT is defined*,
WITHOUT being able to change the code of the ADT itself.

- To do this, simply define an /instance/ using the ~derived~ /method/ of
  the /type class/ as right-hand side.

- E.g, to implement ~Ordering~ for ~Option~ define,
  #+begin_src scala
    given [T: Ordering]: Ordering[Option[T]] = Ordering.derived
  #+end_src

- Assuming the ~Ordering.derived~ /method/ has a /context parameter/ of /type/
 ~Mirror[T]~, it will be satisfied by
 * the compiler generated ~Mirror~ /instance/ for ~Option~
   AND
 * the /derivation/ of the /instance/ will be _EXPANDED_ on the RHS of this
   definition in _the same way as_ an /instance/ DEFINED in ADT /companion
   objects/.

***** DONE Syntax
CLOSED: [2020-12-04 Fri 12:53]
- Note:
  To align ~extends~ clauses and ~derives~ clauses, Scala 3 also allows
  multiple extended types to be separated by commas. So the following is
  now legal:
  #+begin_src scala
    class A extends B, C { ... }
  #+end_src

  It is equivalent to the *OLD* form

  #+begin_src scala
    class A extends B with C { ... }
  #+end_src

***** DONE Discussion
CLOSED: [2020-07-12 Sun 23:06]
- This _/type class/ derivation framework_ is *INTENTIONALLY* very *small* and
  *low-level*.

- There are essentially *TWO* pieces of infrastructure in *compiler-generated
  ~Mirror~ instances*,
  * /type members/ encoding properties of the /mirrored types/.

  * a MINIMAL _value level_ mechanism for working generically with /terms/
    of the /mirrored types/.

- The ~Mirror~ infrastructure _can be seen as_ an /extension/ of the existing
  ~Product~ infrastructure for /case classes/:
  typically ~Mirror~ types will be implemented by the ADTs /companion object/,
  hence the /type members/ and the ~ordinal~ or ~fromProduct~ /methods/ will
  be members of that object.

  * The primary motivation for this design decision, and the decision to encode
    properties via /types/ rather than /terms/:
    to keep the /bytecode and runtime footprint/ of the feature *small enough*
    to make it possible to provide ~Mirror~ instances *unconditionally*.

- Whilst ~Mirrors~ encode properties precisely via /type members/, the _value
  level_ ~ordinal~ and ~fromProduct~ are somewhat _weakly typed_ (because they
  are defined in terms of ~MirroredMonoType~) just like the members of ~Product~.
  * This means that
    code for /generic type classes/ has to _ENSURE_ that
    1. /type exploration/ and /value selection/ PROCEED in lockstep
       AND
    2. has to assert this conformance in some places using /casts/.
       + If /generic type classes/ are *correctly* written these /casts/ will
         *never fail*.

- As mentioned, however,
  * the compiler-provided mechanism is _INTENTIONALLY very low level_
    AND
  * it is ANTICIPATED that
    /higher level type class derivation/ and /generic programming/
    _libraries_ will build on this and Dotty's other metaprogramming
    facilities
    + PURPOSE:
      to *hide* these low-level details *from* /type class/ authors and
      general users.

- _/Type class/ derivation_ in the style of both _shapeless_ and _Magnolia_
  are possible (a prototype of shapeless 3, which combines aspects of both
  shapeless 2 and Magnolia has been developed alongside this language feature)
  as is a _MORE AGGRESSIVELY /inlined style/,_ supported by Dotty's new
  _quote/splice macro_ and _inlining_ facilities.

**** TODO How to write a type class ~derived~ method using macros
***** TODO Calling the derived method inside the macro

**** DONE Multiversal Equality - =TODO= =RE-READ=
CLOSED: [2020-05-23 Sat 23:31]
- /Universal equality/ is *convenient*.
  _BUT_ it is also dangerous since it *undermines* /type safety/.

- /Multiversal equality/ is an _opt-in way_ to make /universal equality/ SAFER.
    It uses a /binary type class/ ~CanEqual~ to indicate that values of *two* given
  /types/ can be compared with each other.

- If we want to disable /universal equality/ check for ~T~, we can do
  #+begin_src scala
    class T derives CanEqual
  #+end_src
  Then if we compare an object of ~T~ with the other /types/, the error can
  be catched:
  #+begin_src scala
    val x = ...  // of type T
    val y = ...  // of type S, but should be T
    x == y       // can't typecheck because T drevies the type class Eql
  #+end_src

- Alternatively, one can also provide an ~CanEqual~ /given instance/ directly,
  like this:
  #+begin_src scala
    given CanEqual[T, T] = CanEqual.derived
  #+end_src
  This definition effectively says that values of /type/ ~T~ can (only) be compared
  to other values of type ~T~ when using ~==~ or ~!=~.
  + The definition
    * _affects_ /type checking/
    * BUT it has _no significance_ for /runtime/ behavior (=from Jian= GOOD!!!),
      since
      - ~==~ always maps to ~equals~
      - ~!=~ always maps to the negation of ~equals~

  + The right hand side ~CanEqual.derived~ of the definition is a value that has
    any ~CanEqual~ instance as its type.

  + Here is the definition of /class/ ~CanEqual~ and its /companion object/:
   #+begin_src scala
     package scala
     import annotation.implicitNotFound

     @implicitNotFound("Values of types ${L} and ${R} cannot be compared with == or !=")
     sealed trait CanEqual[-L, -R]

     object CanEqual:
       object derived extends CanEqual[Any, Any]
   #+end_src

- One can have *several* ~CanEqual~ /given instances/ for *one* /type/.
  + Example:
    If we define
    #+begin_src scala
      given CanEqual[A, A] = CanEqual.derived
      given CanEqual[B, B] = CanEqual.derived
      given CanEqual[A, B] = CanEqual.derived
      given CanEqual[B, A] = CanEqual.derived
    #+end_src
    , then only values of type ~A~ can be compared with values of type ~B~.

- The ~scala.CanEqual~ object defines a number of ~CanEqual~ /given instances/
  that together define a rule book for what /standard types/ can be compared.
  =from Jian= More details in the section "Predefined ~CanEqual~ Instances".

- For *backward compatibility*,
  There's also a *"FALLBACK"* /instance/ named ~canEqualAny~ that allows
  comparisons over *ALL* /types/ that do *NOT themselves have an ~CanEqual~
  /given/.*
  + The *primary motivation* for having ~canEqualAny~ is _backwards compatibility_.
    If no concern, on can disable ~canEqualAny~ by enabling the language feature
    *strictEquality* by:
    * Command line option: =-language:strictEquality=
    * imports: ~import scala.language.strictEquality~

  + ~canEqualAny~ is defined as follows:
    #+begin_src scala
      def canEqualAny[L, R]: CanEqual[L, R] = CanEqual.derived
    #+end_src

  + Even though ~canEqualAny~ is _NOT_ declared a ~given~,
    the compiler will *still* construct an ~canEqualAny~ instance as answer to an
    /implicit search/ for the type ~CanEqual[L, R]~, _UNLESS_:
    * ~L~ or ~R~ have ~CanEqual~ instances defined on them,
      OR
    * the language feature ~strictEquality~ is _enabled_

***** DONE Deriving ~CanEqual~ Instances
CLOSED: [2020-07-20 Mon 01:35]
#+begin_src scala
  class Box[T](x: T) derives CanEqual
#+end_src
- By the usual rules of /type class derivation/, this _generates_ the following
  ~CanEqual~ /instance/ in the /companion object/ of ~Box~:
  #+begin_src scala
    given [T, U](using CanEqual[T, U]): CanEqual[Box[T], Box[U]] =
      CanEqual.derived
  #+end_src

- Examples:
  #+begin_src scala
    new Box(1) == new Box(1L)   // ok since there is an instance for `Eql[Int, Long]`
    new Box(1) == new Box("a")  // error: can't compare
    new Box(1) == 1             // error: can't compare
  #+end_src
  =from Jian=
  See next subsection to know WHY "there is an instance for ~CanEqual[Int, Long]~"

***** DONE Precise Rules for Equality Checking - =TODO= _Verify my understanding to rule 2!!!_
CLOSED: [2020-07-20 Mon 01:53]
- If the ~strictEquality~ feature is enabled then a comparison using
  ~x \equal{}\equal{} y~ or ~x != y~ between values ~x: T~ and ~y: U~ is _legal iff there
  is a given of type ~CanEqual[T, U]~._
  * =from Jian=
    This doc use "if" in ths paragraph, and in this note I replace it with
    "iff", which I think is better because it's right and more strict!

- In the default case where the ~strictEquality~ feature is _NOT enabled_
  the comparison is also legal if
  1. ~T~ and ~U~ are the _same_
     OR
  2. one of ~T~, ~U~ is a /subtype/ of the /lifted version of the other type/,
     OR
  3. neither ~T~ nor ~U~ have a reflective ~CanEqual~ instance.

- Explanations:
  * /lifting/ a type ~S~ means
    + *replacing* ALL /references/ to /abstract types/ in /covariant positions/
      of ~S~ by _their /upper bound/,_

      AND

    + *replacing* ALL /refinement types/ in /covariant positions/ of ~S~ by
      _their parent_.

  * a /type/ ~T~ has a _reflexive_ ~CanEqual~ /instance/
    if the _implicit search_ for ~CanEqual[T, T]~ succeeds.

- =from Jian= =TODO= =TODO=
  * Why ~CanEqual[-T, -U]~ is /contravariant/ for ~T~ or ~U~.

  * I don't quite understand the rule 2.

  * My understanding to rule 2 is:
    ~S[+X]~ is the definition.
    ~U <: A~ and ~T <: S[A]~.
    ~U~ and ~T~ can be compared.

  * In the "Explanations" above:
    + Q :: WHY "covariant"? WHY NOT "contravariant" or "invariant"?

***** DONE Predefined ~CanEqual~ Instances
CLOSED: [2020-07-20 Mon 02:28]
- The ~CanEqual~ object defines instances for comparing
  * the /primitive types/
    + ~Byte~
    + ~Short~
    + ~Char~
    + ~Int~
    + ~Long~
    + ~Float~
    + ~Double~
    + ~Boolean~
    + ~Unit~,

  * ~java.lang.Number~
  * ~java.lang.Boolean~
  * ~java.lang.Character~

  * ~scala.collection.Seq~
  * ~scala.collection.Set~

- Instances are defined so that *every* one of the /types/ mentioned above
  has /a *reflexive* ~CanEqual~ instance/, and the following holds:
  * /Primitive numeric types/ can be compared with _each other_.

  * /Primitive numeric types/ can be compared with *subtypes* of
    ~java.lang.Number~ (and _vice versa_).

  * ~Boolean~ can be compared with ~java.lang.Boolean~ (and _vice versa_).

  + ~Char~ can be compared with ~java.lang.Character~ (and _vice versa_).

  * Two /sequences/ (of *arbitrary subtypes* of ~scala.collection.Seq~) can
    be compared with _each other_ *if their element types can be compared.*
    The two sequence types need not be the same.

  * Two /sets/ (of *arbitrary subtypes* of ~scala.collection.Set~) can be
    compared with _each other_ *if their element types can be compared.*
    The two set types need not be the same.

  * Any /subtype/ of ~AnyRef~ can be compared with ~Null~ (and _vice versa_).

- =from Jian=
  /a *reflexive* ~CanEqual~ instance/ for each /types/ mentioned above means
  any type ~A~ that is mentioned above *can't be compared* to any type ~B~
  if ~CanEqual[A, B]~ is *not* defined. This is true even when ~strictEquality~ is
  disabled. This is mentioned in the above subsection "Precise Rules for
  Equality Checking".
  * When ~strictEquality~ is *enabled*,
    if there is no ~CanEqual[A, B]~, values of ~A~ and ~B~ can't be compared.

  * When ~strictEquality~ is *turned off*,
    if there is NO ~CanEqual[A, B]~, because of the /*reflexive* ~CanEqual~
    instance/ and *rule 3*, ~A~ and ~B~ can't be compared.
    + *Note*:
      In this case, when there is no /*reflexive* ~CanEqual~ instance/, even
      without ~CanEqual[A, B]~, values of ~A~ and ~B~ can be compared because of
      ~canEqualAny~.

***** TODO Why Two Type Parameters? - =START= =RE-READ=
- One particular feature of the Eql type is that it takes two type parameters,
  representing the types of the two items to be compared. By contrast,
  conventional implementations of an equality type class take only a single
  type parameter which represents the common type of both operands. One
  type parameter is simpler than two, so why go through the additional
  complication? The reason has to do with the fact that, rather than coming
  up with a type class where no operation existed before, we are dealing
  with a refinement of pre-existing, universal equality. It is best
  illustrated through an example.

- Say you want to come up with a safe version of the ~contains~ /method/ on
  ~List[T]~. The original definition of ~contains~ in the standard library was:
  #+begin_src scala
    class List[+T]:
      // ...
      def contains(x: Any): Boolean
  #+end_src
  1. That uses /universal equality/ in an *unsafe* way
     since it permits arguments of *any* /type/ to be compared with the
     list's elements.

  2. The "obvious" alternative definition
     #+begin_src scala
       class List[+T]:
         // ...
         def contains(x: T): Boolean
     #+end_src
     *not* work, since it refers to the /covariant parameter/ ~T~ in a
     /nonvariant/ context.

  3. The only variance-correct way to use the /type parameter/ ~T~ in contains
     is as a /lower bound/:
     #+begin_src scala
       class List[+T]:
         // ...
         def contains[U >: T](x: U): Boolean
     #+end_src
     This /generic version/ of ~contains~ is the one used in the current
     (Scala 2.13) version of ~List~. It looks different but it admits exactly
     the same applications as the ~contains(x: Any)~ definition we started with.

  4. Make it _more useful (i.e. restrictive)_ by adding an ~CanEqual~ parameter:
     #+begin_src scala
       class List[+T]:
         // ...
         def contains[U >: T](x: U)(using CanEqual[T, U]): Boolean
     #+end_src
     This version of ~contains~ is *equality-safe*!
     More precisely, given ~x: T~, ~xs: List[T]~ and ~y: U~, then ~xs.contains(y)~
     is type-correct iff ~x == y~ is type-correct.

  5. Unfortunately, the crucial ability to "lift" equality type checking from
     simple equality and pattern matching to arbitrary user-defined
     operations gets lost if we restrict ourselves to an equality class
     with a single type parameter. Consider the following signature of
     contains with a hypothetical ~CanEqual1[T]~ /type class/:
     #+begin_src scala
       def contains[U >: T](x: U)(using CanEqual1[U]): Boolean
     #+end_src

  6. This version could be applied just as widely as the original ~contains(x: Any)~
     method, since the ~CanEqual1[Any]~ fallback is always available! So we
     have gained nothing. What got lost in the transition to a single parameter
     /type class/ was the original rule that ~CanEqual[A, B]~ is available only
     if neither ~A~ nor ~B~ have a reflexive ~CanEqual~ /instance/. That rule
     simply cannot be expressed if there is a single type parameter for ~CanEqual~.

  7. The situation is different under ~-language:strictEquality~.
     In that case, the ~CanEqual[Any, Any]~ or ~CanEqual1[Any]~ /instances/ would
     *never be available*, and both the single and two-parameter versions
     would indeed _coincide_ for most practical purposes.
     * =from Jian=
       Why only *most* practical purposes, not ALL???

  8. But assuming ~-language:strictEquality~ immediately and everywhere poses
     migration problems which might well be unsurmountable.
     Consider again ~contains~, which is in the standard library.
     * Parameterizing it with the ~CanEqual~ /type class/ as in 1) is an immediate
       win since it rules out non-sensical applications while still allowing
       all sensible ones. So it can be done almost at any time, modulo binary
       compatibility concerns.

     * On the other hand, parameterizing ~contains~ with ~CanEqual1~ as in
       would make ~contains~ unusable for all /types/ that have not yet
       declared an ~CanEqual1~ /instance/, including all types coming from
       Java. This is clearly unacceptable. It would lead to a situation
       where, rather than migrating existing libraries to use safe equality,
       the only upgrade path is to have parallel libraries, with the new
       version only catering to types deriving ~CanEqual1~ and the old version
       dealing with everything else. Such a split of the ecosystem would be
       very problematic, which means the cure is likely to be worse than the
       disease.

  9. For these reasons, it looks like a two-parameter type class is the only
     way forward because it can take the existing ecosystem where it is and
     migrate it towards a future where more and more code uses safe
     equality.

  10. In applications where ~-language:strictEquality~ is the default one could
      also introduce a *one-parameter type alias* such as
      #+begin_src scala
        type Eq[-T] = CanEqual[T, T]
      #+end_src
      Operations needing safe equality could then use this alias instead of
      the _two-parameter ~CanEqual~ class_. But it would *only work under
      ~-language:strictEquality~,* since otherwise the universal ~Eq[Any]~
      instance would be available everywhere.

  11. More on /multiversal equality/ is found in a [[https://www.scala-lang.org/blog/2016/05/06/multiversal-equality.html][blog post]] and a [[https://github.com/lampepfl/dotty/issues/1247][GitHub issue]].

**** DONE Context Functions - =TODO= =START= =HERE= =RE-READ=
CLOSED: [2020-07-14 Tue 02:39]
=from Jian= COPIED from the section "Polymorphic Function Types"
This feature if a step to improve the support to /functions/:
Scala defines itself as a language that *mixes* the /functional programming/
and /object-oriented programming/, _BUT_ it *was not always equally support*
these two.
  After adding this feature, from the point of view of /abstraction from the
context/, the status of /function/ is improved.
=from Jian= ??? Still not equal? Any further improvement can be done?

- Context functions :: functions with *ONLY* /context parameters/.
  * Their /types/ are /context function types/.
  * /Context functions/ are written using ~?=>~ as the "arrow" sign, which is
    different from /Non-context functions/.
  * Example:
    #+begin_src scala
      type Executable[T] = ExecutionContext ?=> T

      given ec: ExecutionContext = ...

      def f(x: Int): ExecutionContext ?=> Int = ...
      // could be written as follows with the type alias from above
      // def f(x: Int): Executable[Int] = ...

      f(2)(using ec)  // explicit argument
      f(2)            // argument is inferred
    #+end_src

- Conversely,
  * IF ::
    + An expression ~e~ show up in a position that the *EXPECTED* /type/ should
      be a /context function type/ ~(T_1, ..., T_n) ?=> U~

    + ~e~ *is NOT ALREADY* an /context function literal/ with the /context type/
      ~(T_1, ..., T_n) ?=> U~

  * THEN ::
    ~e~ *is converted to* a /context function literal/ by *rewriting it to*
    #+begin_src scala
      (x_1: T1, ..., x_n: Tn) ?=> E
    #+end_src
    where the NAMES ~x_1, ..., x_n~ are ARBITRARY.
    + This expansion is performed *before* the expression ~e~ is typechecked,
      which means _that ~x_1, ..., x_n~ are available as /givens/ that ~e~
      can use._

    + =from Jian= CAUTION:
      ~e~ itself doesn't need be of type ~U~.
      HOWEVER, ~e~ combine with ~x_1, ..., x_n~ must be of type ~U~.
      - For example, _continuing_ with the previous definitions:
        #+begin_src scala
          def g(arg: Executable[Int]) =  // ...

          g(22)    // is expanded to g((ev: ExecutionContext) ?=> 22)
          g(f(2))  // is expanded to g((ev: ExecutionContext) ?=> f(2)(using ev))

          g((ctx: ExecutionContext) ?=> f(3))  // is expanded to g((using ev: ExecutionContext) => f(3)(using ev))
          g((ctx: ExecutionContext) ?=> f(22)(using ctx))  // is left as it is
        #+end_src

***** DONE Example: Builder Pattern - =TODO= RE-READ
CLOSED: [2020-07-14 Tue 00:02]
/Context function types/ have considerable *EXPRESSIVE power*.

- For instance,
  here is how they can _support the "builder pattern",_ where the aim is to
  construct tables like this:
  #+begin_src scala
    table {
      row {
        cell("top left")
        cell("top right")
      }
      row {
        cell("bottom left")
        cell("bottom right")
      }
    }
  #+end_src

- The idea is to define /classes/ for ~Table~ and ~Row~ that allow the addition
  of elements via ~add~:
  #+begin_src scala
    class Table:
      val rows = new ArrayBuffer[Row]
      def add(r: Row): Unit = rows += r
      override def toString = rows.mkString(start = "Table(", sep = ", ", end = ")")

    class Row:
      val cells = new ArrayBuffer[Cell]
      def add(c: Cell): Unit = cells += c
      override def toString = cells.mkString(start = "Row(", sep = ", ", end = ")")

    case class Cell(elem: String)
  #+end_src

- Then, the ~table~, ~row~ and ~cell~ /constructor methods/ can be defined
  _with /context function types/ as parameters_ to *AVOID* the plumbing
  boilerplate that would otherwise be necessary.
  #+begin_src scala
    def table(init: Table ?=> Unit) =
      given t: Table = new Table
      init
      t

    def row(init: Row ?=> Unit)(using t: Table) =
      given r: Row = new Row
      init
      t.add(r)

    def cell(str: String)(using r: Row) =
      r.add(new Cell(str))
  #+end_src

- With that setup, the _table construction_ code above compiles and _expands to_:
  #+begin_src scala
    table { (using $t: Table) ?=>

      row { (using $r: Row) ?=>
        cell("top left")(using $r)
        cell("top right")(using $r)
      }(using $t)

      row { (using $r: Row) ?=>
        cell("bottom left")(using $r)
        cell("bottom right")(using $r)
      }(using $t)
    }
  #+end_src

***** DONE Example: Postconditions - =TODO= RE-READ
CLOSED: [2020-07-14 Tue 02:39]
Define constructs for _checking arbitrary postconditions_ using an /extension
method/ *ensuring* so that the checked result can be referred to simply by
~result~.
#+begin_src scala
  object PostConditions:
    opaque type WrappedResult[T] = T

    def result[T](using r: WrappedResult[T]): T = r

    extension [T](x: T)
      def ensuring(condition: WrappedResult[T] ?=> Boolean): T =
        assert(condition(using x))
        x
  end PostConditions

  import PostConditions.{ensuring, result}

  val s = List(1, 2, 3).sum.ensuring(result == 6)
#+end_src
- The example combines
  * /opaque type aliases/
  * /context function types/
  * /extension methods/

- Combine the structures above can create a *zero-overhead abstraction*.

- Explanations:
  * We use a /context function type/ ~WrappedResult[T] ?=> Boolean~ as the
    /type/ of the ~condition~ of ~ensuring~.

  * An argument to ~ensuring~ such as (~result == 6~) will therefore have a
    /given/ of /type/ ~WrappedResult[T]~ _in scope_ to pass along to the
    ~result~ /method/.

  * ~WrappedResult~ is a *FRESH* /type/,
    to make sure that we do *NOT* get _unwanted /givens/ in scope_ (this is
    good practice in all cases where /context parameters/ are involved).

  * Since ~WrappedResult~ is an /opaque type alias/, its values _need NOT be
    boxed_,
    AND
    since ~ensuring~ is added as an /extension method/, its argument does *not*
    need boxing either.

  * Hence, the implementation of ~ensuring~ is as about _as *efficient* as the
    best possible code one could write by hand_:
    #+begin_src scala
      val s =
        val result = List(1, 2, 3).sum
        assert(result == 6)
        result
    #+end_src
    + =from Jian= =TODO= =Verify=
      Inspect the function calls to ~result~ and ~condition~ (after inserting
      required /using clauses/) that _can't be inlined_, comparing to this write
      by hand code, there are *two extra function call cost* in the /context
      function/ implementation.

***** TODO Reference

**** DONE Implicit Conversions
CLOSED: [2020-03-11 Wed 00:14]
/Implicit conversions/ are defined by /given instances/ of the
~scala.Conversion~ class.

- ~scala.Conversion~ class is defined in package scala as follows:
  #+begin_src scala
    abstract class Conversion[-T, +U] extends (T => U):
      def apply(x: T): U
  #+end_src

- Example:
  #+begin_src scala
    given Conversion[String, Token] with
      def apply(str: String): Token = new KeyWord(str)
  #+end_src
  * Express more concisely as:
    #+begin_src scala
      given Conversion[String, Token] = new KeyWord(_)
    #+end_src

- An /implicit conversion/ is applied automatically by the compiler in _THREE_
  situations:
  * _Type_ doesn't match, but an after an /implicit conversion/, type can match.

  * _Method Name_ doesn't match, but an after an /implicit conversion/, method
    can be found.

  * _Method Name matches, but Method Signature doesn't match_, but an after
    an /implicit conversion/, /method signature/ can match.

***** Examples
1. In ~Predef~
   #+begin_src scala
     given int2Integer: Conversion[Int, java.lang.Integer] =
       java.lang.Integer.valueOf(_)
   #+end_src

2. /Magnet pattern/ that use /implicit conversion/:
   #+begin_src scala
     object Completions:

       // The argument "magnet" type
       enum CompletionArg:
         case Error(s: String)
         case Response(f: Future[HttpResponse])
         case Status(code: Future[StatusCode])

       object CompletionArg:

         // conversions defining the possible arguments to pass to `complete`
         // these always come with CompletionArg
         // They can be invoked explicitly, e.g.
         //
         //   CompletionArg.fromStatusCode(statusCode)

         given fromString    : Conversion[String, CompletionArg]               = Error(_)
         given fromFuture    : Conversion[Future[HttpResponse], CompletionArg] = Response(_)
         given fromStatusCode: Conversion[Future[StatusCode], CompletionArg]   = Status(_)
       end CompletionArg

       import CompletionArg.*

       def complete[T](arg: CompletionArg) = arg match
         case Error(s)     => ...
         case Response(f)  => ...
         case Status(code) => ...

     end Completions
   #+end_src
   * =from Jian= Why does ~complete~ have a /type parameter/ ~T~.

   * This setup is more complicated than simple overloading of ~complete~ (the
     traditional way of implementing the /magnet pattern/),
     BUT it can still be useful
     + *if normal /overloading/ is not available* (as in the case above, since
       we cannot have two overloaded methods that take ~Future[...]~ arguments),
       =from Jian= ??? /Type erasure/ ???
       _OR_
     + if normal overloading would lead to a _combinatorial explosion of variants_.

**** DONE By-Name Context Parameters - =TODO= =RE-READ=
CLOSED: [2020-05-23 Sat 00:01]
=from Jian= This section discussion the /LAZY context parameters/.

- /Context parameters/ can be DECLARED /by-name/ to *avoid* a /divergent inferred
  expansion/.

- Example:
  #+begin_src scala
    trait Codec[T]:
      def write(x: T): Unit

    given intCodec: Codec[Int] = ???

    given optionCodec[T](using ev: => Codec[T]): Codec[Option[T]] with
      def write(xo: Option[T]) = xo match
        case Some(x) => ev.while(x)
        case None    =>

      // TODO: from Jian: can this work for "by-name context parameters"
      // def write(xo: Option[T]) =
      //  xo.map(ev.write)

    val s = summon[Codec[Option[Int]]]

    s.write(Some(33))
    s.write(None)
  #+end_src
  * As is the case for a normal (non-context parameter) /by-name parameter/,
    the argument for the /context parameter/ ~ev~ is evaluated on demand.
      In the example above, if the ~xo~ is ~None~, it is *NOT* evaluated at all.

- TODO ??? TODO -- =Try to understand this=
  The /synthesized argument/ for a /context parameter/
  is backed by a _LOCAL_ ~val~
  if this is necessary to prevent an otherwise /diverging expansion/.

- The precise steps for /synthesizing an argument/ for a /by-name context
  parameter/ of type ~=> T~ are as follows: TODO ??? TODO
  1. Create a new /given/ of type ~T~:
     #+begin_src scala
       given lv: T = ???
     #+end_src
     where ~lv~ is an arbitrary fresh name.

  2. This /given/ is not immediately available as candidate for argument
     inference (making it immediately available could result in a loop in
     the synthesized computation). But it becomes available in all nested
     contexts that look again for an argument to a /by-name context parameter/.

  3. If this search succeeds with expression ~E~, and ~E~ contains references
     to ~lv~, replace ~E~ by
     #+begin_src scala
       { given lv: T = E; lv }
     #+end_src
     Otherwise, return ~E~ unchanged.

- In the example above, the definition of s would be *EXPANDED* as follows.
  #+begin_src scala
    val s = summon[Test.Codec[Option[Int]]](
      optionCodec[Int](using intCodec)
    )
  #+end_src
  /No local given instance/ was generated because _the /synthesized argument/
  is *not* /recursive/._

***** TODO Reference
For more info, see
- Issue _#1998: Let by-name implicit parameters have lazy semantics_
  and the associated
- _SIP-NN - BYNAME IMPLICIT ARGUMENTS_.

**** DONE Relationship with Scala 2 Implicits
CLOSED: [2020-07-14 Tue 03:52]
Many, but *NOT all*, of the _Scala 3's NEW /contextual abstraction/ features_
can be mapped to _Scala 2's /implicits/._

This page gives a rundown on the relationships between new and old features.

***** DONE Simulating Scala 3 Contextual Abstraction Concepts with Scala 2 Implicits
CLOSED: [2020-07-14 Tue 03:50]
****** DONE Given Intances
CLOSED: [2020-07-14 Tue 02:58]
- /Given instances/ can be mapped to _COMBINATIONS_ of /implicit objects/,
  /classes/ and /implicit methods/.
  1. /Given instances without parameters/ ---> /implicit objects/.
     #+begin_src scala
       // Dotty
       given intOrd: Ord[Int] with { ... }

       // Scala 2
       implicit object intOrd extends Ord[Int] { ... }
     #+end_src

  2. /Parameterized givens/ ---> COMBINATIONS of /classes/ and /implicit
     methods/.
     #+begin_src scala
       // Dotty
       given listOrd[T](using ord: Ord[T]): Ord[List[T]] with { ... }

       // Scala 2
       class listOrd[T](implicit ord: Ord[T]) extends Ord[List[T]] { ... }
       final implicit def listOrd[T](implicit ord: Ord[T]): listOrd[T] = new listOrd[T]
     #+end_src

  3. /Alias givens/ map to /implicit methods/ OR /implicit lazy vals/.
     =from Jian= Remember! /Alias givens/ won't eagerly evaluate its RHS value.
     =from Jian= Remember! Here the "alias" means assignment.
     #+begin_src scala
       // Dotty
       given global: ExecutionContext = new ForkJoinContext()

       val ctx: Context = ...
       given Context = ctx
     #+end_src

     would map to

     #+begin_src scala
       // Scala 2
       final implicit lazy val global: ExecutionContext = new ForkJoinContext()

       val ctx: Context = ...
       final implicit def given_Context = ctx
     #+end_src
     * If an alias has _NEITHER /type parameters/ NOR /context parameters/,_
       it is treated as a ~lazy val~,
       + unless the right hand side is a simple reference, in which case we
         can use a forwarder to that reference *WITHOUT CACHING it*.

****** DONE Anonymous Given Intances
CLOSED: [2020-07-14 Tue 03:07]
/Anonymous given instances/ get *compiler synthesized* NAMES, which are
generated _in a reproducible way FROM the implemented type(s)._
- =from Jian=
  The overview above actually means Scala 2 doesn't have this feature,
  BUT Scala 2 to can _SIMULATE_ dotc work, and _MANUALLY write down_ the
  same code.

- Examples:
  #+begin_src scala
    given Ord[Int] with { ... }
    //// dotc generate:
    // given given_Ord_Int: Ord[Int] with { ... }

    given [T](using ord: Ord[T]): Ord[List[T]] with { ... }
    //// dotc generate:
    // given given_Ord_List_T[T](using ord: Ord[T]): Ord[List[T]] with { ... }
  #+end_src

- The SYNTHESIZED _type names_ are formed from =TODO= =FIX-DOC=
  =from Jian= I don't think rule 3 is clear enough to explain the above 2nd example
  1. the prefix ~given_~,
  2. the simple name(s) of the implemented type(s), leaving out any prefixes,
  3. the simple name(s) of the toplevel argument type constructors to these types.

- /Tuples/ are treated _as transparent_,
  i.e. a type ~F[(X, Y)]~ would get the synthesized name ~F_X_Y~.

- *Directly implemented* /function types/ ~A => B~ are represented as ~A_to_B~.

- /Function types/ used as arguments to OTHER /type constructors/ are
  represented as ~Function~.
  =TODO= Example??? =TODO=

****** DONE Using Clauses
CLOSED: [2020-07-14 Tue 03:22]
- /Using clauses/ correspond largely to Scala-2's /implicit parameter clauses/.
  E.g.
  #+begin_src scala
    // Dotty
    def max[T](x: T, y: T)(using ord: Ord[T]): T

    // Scala 2
    def max[T](x: T, y: T)(implicit ord: Ord[T]): T
  #+end_src

- _The main difference concerns applications of such parameters._
  + Dotty:
    /Explicit arguments (not synthesized, manually written down)/ to parameters
    of /using clauses/ *must* be written as ~(using ...)~, *mirroring the
    definition syntax*.
    E.g, ~max(2, 3)(using IntOrd)~.

  + Scala 2:
    uses normal applications ~max(2, 3)(IntOrd)~ instead.

  + SUMMARY:
    The /Scala 2 syntax/ has some _inherent ambiguities_ and _restrictions_
    which are *overcome by the NEW (Dotty) syntax*. For instance,
    * /multiple implicit parameter lists/ are _NOT available in the *old*
      syntax_,
      - =TODO= =TODO= =TODO=
        EVEN THOUGH they can be _simulated using /auxiliary objects/ in
        the "Aux" pattern -- check /Shapeless/._

- The ~summon~ method corresponds to ~implicitly~ in Scala 2.
  *It is _PRECISELY_ the SAME as the the method in Shapeless.*
  The difference between ~summon~ (or ~the~) and ~implicitly~ is that
  ~summon~ can return a *MORE _PRECISE_ type* than the type that was asked for.
  + =from Jian=
    Check the source code, API doc, or the _Using Clauses_ section, you'll see
    why -- *no widening*:
    #+begin_src scala
      def impicitly[T](implicit x: T): T = x

      inline def summon[T](implicit x: T): x.type = x
    #+end_src
    * I guess the ~summon~ will final replace ~implicit~ with ~using~ for
      its /context parameter/ prefix since a future version (Scala 3.1+).

****** DONE Context Bounds
CLOSED: [2020-07-14 Tue 03:23]
/Context bounds/ are the *same* in both language versions.
They *expand* to the respective forms of /implicit parameters/.

- Note:
  To ease migration,
  /context bounds/ in Dotty map for a limited time to /old-style implicit
  parameters/ for which arguments can be passed either in a /using clause/
  or in a /normal argument list/.
  + Once old-style implicits are deprecated,
    /context bounds/ will map to /using clauses/ instead.

****** DONE Extension Methods
CLOSED: [2020-07-14 Tue 03:31]
- /Extension methods/ have *NO DIRECT counterpart* in Scala 2,
  BUT they can be _SIMULATED_ with /implicit classes/. For instance, the
  /extension method/
  #+begin_src scala
    extension (c: Circle)
      def circumference: Double = c.radius * math.Pi * 2
  #+end_src
  could be _SIMULATED_ to some degree by
  #+begin_src scala
    implicit class CircumDecorator(c: Circle) extends AnyVal {
      def circumference: Double = c.radius * math.Pi * 2
    }
  #+end_src

- /ABSTRACT extension methods/ in /traits/ that are implemented in /given
  instances/ have *NO DIRECT counterpart* in Scala-2.
  + The ONLY way to _SIMULATE_ these is to make /implicit classes/ available
    through /imports/.

  + =TODO=
    The _Simulacrum macro library_ can automate this process in some cases.

****** DONE Type class Derivation
CLOSED: [2020-07-14 Tue 03:33]
/Type class derivation/ has *NO DIRECT counterpart* in the Scala 2 language.

- Comparable functionality can be achieved by _macro-based libraries_ such as
  + _Shapeless_
  + _Magnolia_
  + _scalaz-deriving_

****** DONE Context Function Types
CLOSED: [2020-07-14 Tue 03:33]
/Context function types/ have *NO analogue* in Scala 2.

****** DONE Implicit By-Name Parameters
CLOSED: [2020-07-14 Tue 03:36]
/Implicit by-name parameters/ are *NOT supported* in Scala 2,
but can be _EMULATED to some degree_ by the ~Lazy~ type in _Shapeless_.

***** DONE Simulating Scala 2 Implicits in Scala 3
CLOSED: [2020-07-14 Tue 03:51]
****** DONE Implicit Conversions
CLOSED: [2020-07-14 Tue 03:51]
/Implicit conversion/ methods in Scala 2 can be expressed as /given instances/
of the ~scala.Conversion~ /class/ in Dotty.
- E.g.
  instead of ~implicit def stringToToken(str: String): Token = new Keyword(str)~
   one can write
   #+begin_src scala
     given stringToToken: Conversion[String, Token] with
       def apply(str: String): Token = KeyWord(str)

     // OR

     given stringToToken: Conversion[String, Token] = KeyWord(_)
   #+end_src

****** DONE Implicit Classes
CLOSED: [2020-07-14 Tue 03:50]
- /Implicit classes/ in Scala 2 are often used to define /extension methods/,
  which are *DIRECTLY supported* in Dotty.

- OTHER uses of /implicit classes/ can be _SIMULATED_ by a pair of
  =from Jian= Examples for "OTHER uses"???
  * a REGULAR /class/
    and
  * a /given ~Conversion~ instance/.

****** DONE Implicit Values
CLOSED: [2020-07-14 Tue 03:45]
- /Implicit ~val~ definitions/ in Scala 2 can be expressed in Dotty using a
  * regular ~val~ definition
    AND
  * an /alias given/.

- E.g.,
  Scala 2's ~lazy implicit val pos: Position = tree.sourcePos~ can be
  expressed in Dotty as
  #+begin_src scala
    lazy val pos: Position = tree.sourcePos
    given Position = pos
  #+end_src

****** DONE Abstract Implicits
CLOSED: [2020-07-14 Tue 03:48]
- An _ABSTRACT IMPLICIT ~val~ or ~def~ in Scala 2_ can be expressed in Dotty
  using
  * a REGULAR /abstract definition/
    AND
  * an /alias given/.

- E.g.,
  Scala 2's ~implicit def symDecorator: SymDecorator~ can be expressed in
  Dotty as
  #+begin_src scala
    def symDecorator: SymDecorator
    given SymDecorator = symDecorator
  #+end_src

***** DONE Implementation Status and Timeline
CLOSED: [2020-07-14 Tue 03:43]
- The Dotty implementation implements BOTH
  * Scala-2's /implicits/
  * the new abstractions.

- In fact, support for Scala-2's implicits is an _essential part_ of the common
  language subset between 2.13/2.14 and Dotty.

- *Migration to the new abstractions* will be supported
  by making _AUTOMATIC rewritings_ available.

- Depending on adoption patterns,
  /old style implicits/ might start to be *deprecated* in a _version
  *FOLLOWING* Scala 3.0_.

*** DONE Metaprogramming
CLOSED: [2021-03-17 Wed 01:42]
**** DONE Overview
CLOSED: [2021-04-28 Wed 03:25]
The following pages introduce the *redesign* of /metaprogramming/ in Scala.
The following fundamental facilities:
1. /Inline/
   ~inline~ is a new /soft modifier/ that *guarantees* that a definition will
   be inlined at the point of use.

   - The primary motivation:
     *reduce the overhead* behind
     * _function calls_
     * _access to values_.

   - The _expansion_ will be performed by the Scala compiler _during the *Typer*
     /compiler phase/._

   - ~inline~ is a *COMMAND* (*MUST DO*) to the *compiler*.
       This is _DIFFERENT_ from some other ecosystems, in which /inline/ is a
     request that _might be_ satisfied by the compiler.
     * The _REASON_:
       /inlining/ in Scala can drive other _compile-time operations_, like
       + /inline pattern matching/ (enabling /type-level programming/)

       + /macros/ (enabling /compile-time, generative, metaprogramming/)

       + /runtime code generation/ (/multi-stage programming/)
         - =from Jian=
           WHY this is considered as one kind of drive othe _compile-time
           operations_.

2. /Compile-time ops/ are helper definitions in the standard library that
   provide support for _compile-time operations_ over /values/ and /types/.

3. /Macros/ construct code at /compile-time/
   - /Macros/ are built on _TWO_ well-known fundamental operations:
     * quotation :: *convert program code to data*, specifically,
                    a (tree-like) representation of this code.
       + It is expressed as
         - ~'{...}~ for /expressions/
         - ~'[...]~ for /types/

     * splicing :: *convert a program's representation to program code*
       + expressed as ~${ ... }~.

   - Together with ~inline~, _these two abstractions_ allow to construct
     program code programmatically.

4. =REDO=
   /Runtime Staging/ construct new code at /runtime/.
   That way, code generation can depend NOT ONLY on _static data_ BUT ALSO on
   _data available at runtime_.
   * This splits the evaluation of the program in two or more phases or
     =FIXME= /stages/.

   * Consequently,
     this method generative programming is called /"Multi-Stage Programming"/.
     /Staging/ is built on the _SAME_ foundations as /macros/.
     It uses /quotes/ and /splices/, but *LEAVES OUT* /inline/.
     =from Jian=
     /inline/ can only be done at /compile time/.

5. /Reflection/
   * /Quotations/ are a "black-box" representation of code.
     They can be parameterized and composed using /splices/ but their
     structure cannot be analyzed from the outside.
   * /Tasty reflection/ gives a way to analyze code structure by partly
     revealing the representation type of a piece of code in a standard API.
     =TODO=
     The _representation type_ is a form of /typed abstract syntax tree/,
     which gives rise to the ~TASTy~ moniker.
     =from Jian=

6. /TASTy Inspection/
   * /Typed abstract syntax trees/ are serialized in a custom compressed
     binary format in =.tasty= files.

   * /TASTy inspection/ allows to *load* these files and *analyze* their
     content's tree structure.

**** DONE Inline
CLOSED: [2021-02-15 Mon 18:00]
***** DONE Inline Definitions
CLOSED: [2020-11-24 Tue 01:27]
- ~inline~ :: a new /soft modifier/ that *guarantees* that a definition will
              be /inlined/ at the point of use.
- Example:
  #+begin_src scala
    object Config:
      inline val logging = false

    object Logger:
      private var indent = 0

      inline def log[T](msg: String, indentMargin: => Int)(op: => T): T =
        if Config.logging
        then
          println(s"${"  " * indent}start $msg")
          indent += indentMargin
          val result = op
          indent -= indentMargin
          println(s"${"  " * indent}$msg = $result")
          result
        else op
    end Logger
  #+end_src

  =from Jian=
  #+begin_src scala
    import scala.util.chaining.given

    object Config:
      inline val logging = false

    object Logger:
      private var indent = 0

      inline def log[T](msg: String, indentMargin: => Int)(op: => T): T =
        if !Config.logging
        then op
        else
          op.tap { _ =>
            println(s"${"  " * indent}start $msg")
            indent += indentMargin
            indent -= indentMargin
            println(s"${"  " * indent}$msg = $result")
          }
    end Logger
  #+end_src
  * The ~Config~ object contains a definition of the /inline value/ ~logging~.
    This means that ~logging~ is treated as a _constant value_, equivalent to
    its RHS ~false~. The RHS of such an ~inline val~ *must itself be a /constant
    expression/.*
    + _Used in this way_, ~inline~ is *equivalent to* Java and Scala 2's ~final~.
      =IMPORTANT= (=from Jian= Only when being used in this way, the equivalence exists)

    + Note:
      ~final~, meaning /inlined constant/,
      1. is still supported in Scala 3,
      2. BUT *will be Phased Out*.

  * The ~Logger~ object contains a definition of the /inline method/ ~log~.
    This method will *ALWAYS be inlined* _at the point of call._

  * Usage and re-write:
    #+begin_src scala
      var indentSetting = 2

      def factorial(n: BigInt): BigInt =
        log(s"factorial($n)", indentSetting) {
          if n == 0
          then 1
          else n * factorial(n - 1)
        }
    #+end_src
    + IF ~inline val logging = false~, as being given above,
      the usage code will be re-written as
      #+begin_src scala
        def factorial(n: BigInt): BigInt =
          if n == 0
          then 1
          else n * factorial(n - 1)
      #+end_src
      1. Since _NEITHER_ ~msg~ _OR_ ~indentMargin~ were used, they do *NOT*
         appear in the _generated code_ for ~factorial~.

      2. The ~else~- part reduces to just an ~op~.
         In the _generated code_ we do *NOT* generate any /closures/
         because we _ONLY refer to a /by-name parameter/ ONCE._

      3. *CONSEQUENTLY*, the code was /inlined/ directly and the call was
         /beta-reduced/.

    + IF ~inline val logging = true~, the usage code will be re-written as
      #+begin_src scala
        def factorial(n: BigInt): BigInt =
          val msg = s"factorial($n)"
          println(s"${"  " * indent}start $msg")
          Logger.inline$indent_=(indent.+(indentSetting))
          val result =
            if n == 0
            then 1
            else n * factorial(n - 1)
          Logger.inline$indent_=(indent.-(indentSetting))
          println(s"${"  " * indent}$msg = $result")
          result
      #+end_src

      =from Jian=
      #+begin_src scala
        import scala.util.chaining.given

        def factorial(n: BigInt): BigInt =
          {
            if n == 0
            then 1
            else n * factorial(n - 1)
          }.tap { _ =>
           val msg = s"factorial($n)"
           println(s"${"  " * indent}start $msg")
           Logger.inline$indent_=(indent.+(indentSetting))
           Logger.inline$indent_=(indent.-(indentSetting))
           println(s"${"  " * indent}$msg = $result")
          }
      #+end_src

      - The /by-value parameter/ ~msg~ is _evaluated ONLY ONCE_,
        per the usual Scala semantics, by binding the value and reusing the
        ~msg~ through the body of ~factorial~.

      - The special handling of the assignment to the ~private var indent~:
        It is achieved by *generating* a /setter method/ ~def inline$indent_=~
        and calling it instead.

****** DONE Recursive Inline Methods
      CLOSED: [2020-11-25 Wed 15:57]
      /Inline methods/ can be *recursive*.

      - For instance,
        when called with a *constant* exponent ~n~, the following /method/ for
        ~power~ will be implemented by straight _inline code_ *WITHOUT ANY /loop/
        or /recursion/.*
        #+begin_src scala
          inline def power(x: Double, n: Int): Double =
            if n == 0 then s.0
            else if n == 1 then x
            else
              val y = power(x, n / 2)
              if n % 2 == 0 then y * y else y * y * x

          power(expr, 10)
          // translates to
          //
          //    val x = expr
          //    val y1 = x * x   // ^2
          //    val y2 = y1 * y1 // ^4
          //    val y3 = y2 * x  // ^5
          //    y3 * y3          // ^10
        #+end_src
        =from Jian=
        If the second parameter is not a constant, the inlinement will fail!
        =???= Is there way to mark this in code???

      - *Parameters of inline methods* can have an ~inline~ modifier as well.
        * Atual arguments to these /inline parameters/ will be *inlined* in the
          body of the ~inline def~.

        * /inline parameters/ have _call semantics_ *EQUIVALENT TO* /by-name
          parameters/
          BUT ALLOW for DUPLICATION of the code in the argument.

        * It is usually useful when /constant values/ need to be propagated to
          allow further optimizations/reductions.
          =TODO= =TODO= =???= =TODO= =TODO=

      - The difference in translation between /by-value/, /by-name/, and ~inline~
        parameters:
        #+begin_src scala
          inline def funkyAssertEquals(actual: Double,
                                       expected: =>Double,
                                       inline delta: Double): Unit =
            if (actual - expected).abs > delta then
              throw new AssertionError(s"difference between ${expected} and ${actual} was larger than ${delta}")

          funkyAssertEquals(computeActual(), computeExpected(), computeDelta())
          // translates to
          //
          //    val actual = computeActual()
          //    def expected = computeExpected()
          //    if (actual - expected).abs > computeDelta() then
          //      throw new AssertionError(s"difference between ${expected} and ${actual} was larger than ${computeDelta()}")
        #+end_src

****** DONE Rules for Overriding
      CLOSED: [2020-11-24 Tue 01:41]
      /Inline methods/ can *override* other /non-inline methods/.

      The rules are as follows:
      1. If an /inline method/ ~f~ *implements* or *overrides* another, /non-inline
         method/, the /inline method/ *CAN ALSO be invoked at /runtime/.*
         For instance, consider the scenario:
         #+begin_src scala
           abstract class A:
             def f: Int
             def g: Int = f

           class B extends A:
             inline def f = 22
             override inline def g = f + 11

           val b = B
           val a: A = b

           // inlined invocations
           assert(b.f == 22)
           assert(b.g == 33)

           // dynamic invocations
           assert(a.f == 22)
           assert(a.g == 33)
         #+end_src
         The /inlined invocations/ and the /dynamically dispatched invocations/
         give the _SAME_ results.

      2. /Inline methods/ are _effectively_ ~final~.
         =TODO= =???= =FROM JIAN=

      3. /Inline methods/ can also be ~abstract~.
           An /abstract inline method/ can be _implemented_ ONLY by other /inline
         methods/. *It cannot be invoked directly*:
         #+begin_src scala
           abstract class A:
             inline def f: Int

           object B extends A:
             inline def f: Int = 22

           B.f  // OK
           val a: A = B
           a.f  // error: cannot inline `f` in `A`.
         #+end_src

****** DONE Relationship to ~@inline~
      CLOSED: [2021-03-17 Wed 01:42]
      - Scala 2 also defines a ~@inline~ annotation which is used as _a *hint* for
        the BACKEND to inline code._

      - The ~inline~ modifier is a _MORE POWERFUL_ than the ~@inline~ annotation.
        Here is a comparison:
        * ~@inline~ annotation ::
          + A _hint_
            - _Hint_ here means _try with *BEST EFFORT*, *but NOTHING guaranteed*!_

          + The _hint_ is for the *backend*


        * ~inline~ /modifier/ ::
          + A _command_
            - _Command_ here means _GUARANTEED!_

          + The _command_ is for the *frontend*

          + it also applies to /recursive methods/.
            =from Jian= =TODO= =???=
            Does this mean ~@inline~ can't inline /recursive methods/???
            Annotate a /recursive method/ with ~@inline~ is legal, which I tried.

******* The definition of constant expression
       Scala Language Specification 2.13 - _6.24 Constant Expressions_, including
       _platform-specific extensions_ such as /constant folding/ of pure numeric
       computations.

       - An /inline value/ *must* have a /literal type/ such as ~1~ or ~true~.
         #+begin_src scala
           inline val four = 4

           // Equivalent to

           inline val four: 4 = 4
         #+end_src

       - It is also possible to have _inline vals_ of /types/ that do not have a
         specific syntax, such as ~Short(4)~.
         #+begin_src scala
           trait InlineConstant:
             inline val myShort: Short

           object Constants extends InlineConstants:
             inline val myShort/*: Short(4)*/ = 4
         #+end_src
         =from Jian=
         * ~inline val myShort: Short = 4~ is illegal

         * ~inline val myShort: Short(4) = 4~ is legal, but the /term-dependent types/
           must be enabled with a ~experimental.dependent~ language ~import~ or setting.

***** DONE Transparent Inline Methods
CLOSED: [2020-11-24 Tue 02:13]
/Inline methods/ can additionally be declared ~transparent~.
  This means that the /return type/ of the /inline method/ can be
*SPECIALIZED to a more precise type* upon expansion.

- Example:
  #+begin_src scala
    class A

    class B extnds A:
      def m = true

    transparent inline def choose(b: Boolean): A =
      if b then (new A) else (new B)

    val obj1 = choose(true)  // static type is A
    val obj2 = choose(false) // static type is B

    // obj1.m // compile-time error: `m` is not defined on `A`
    obj2.m    // OK
  #+end_src

- A *non-transparent* /inline method/ is a *"blackbox"* in the sense that
  details of its implementation do *not leak out.*

- =from Jian= =IMPORTANT=
  When a non-constant expression is passed to ~choose~,
  it likes the ~transparent~ in the definition is dropped!
  * This means the ~transparent inline~ means this ~inline~ *CAN BE ~transparent~ (or NOT)*.

- /Transparent inline methods/ are *"whitebox"* in the sense that the type
  of an application of such a method can be _more specialized than its
  DECLARED /return type/,_ depending on how the method expands.

- Example:
  we see how the return type of zero is *specialized* to the /singleton
  type/ ~0~ permitting the addition to be ascribed with the correct
  /singleton type/ ~1~.
  #+begin_src scala
    transparent inline def zero: Int = 0
    val one: 1 = zero + 1
  #+end_src

****** DONE Transparent vs. non-transparent inline
CLOSED: [2021-02-15 Mon 17:55]
- As we already discussed, /transparent inline methods/ may *influence* /type
  checking/ at call site. Technically this implies that
  1. /transparent inline methods/ must be *expanded DURING* /type checking/
     of the program.

  2. Other /inline methods/ are inlined later *after* the program is *fully typed*.

- For example,
  the following two functions
  will be _typed the SAME way_
  _BUT_ will *be inlined at DIFFERENT times*.
  #+begin_src scala
    inline def f1: T = ...
    transparent inline def f2: T = (...): T
  #+end_src

- A noteworthy difference is the behavior of ~transparent inline given~.
  * If there is an error reported when inlining that definition,
    1. it will be considered as an *implicit search mismatch* and
    2. the search will *continue*.

  * A ~transparent inline given~ can add a /type ascription/ in its RHS (as
    in ~f2~ from the previous example) to
    + *AVOID* the _precise type_
    + BUT *KEEP* the _search behavior_

- On the other hand, an ~inline given~ is
  1. taken as an implicit and
  2. then inlined after typing.
  Any error will be emitted as usual.

***** DONE Inline Conditionals
CLOSED: [2021-02-15 Mon 17:59]
=FIXME= =ADD THIS TO DOCS= =START=
A /if-then-else expression/ _in the body_ of an /inline method definition/
_may be_ prefixed by the ~inline~ modifier.

(*THIS SHOULD BE EMPHASIZED*:
 Even if /inline if-then-else expression/ is stupid outside of an /inline
 method definition/, it may still exist. This document should clearly tell
 its readers that "you can't use /inline if-then-else expression/ outside
 of an /inline method definition/")
=FIXME= =ADD THIS TO DOCS= =END=

#+begin_src scala
  inline def update(delta: Int) =
    inline if delta >= 0
           then increaseBy(delta)
           else decreaseBy(-delta)
#+end_src
- If the /condition/ of an /if-then-else expressions/ is a /constant expression/
  then _it *SIMPLIFIES* to the selected branch._ -- *NOT guaranteed*.

- An ~inline~ prefixed /if-then-else expression/ *enforces* that the
  /condition/ has to be a /constant expression/, and thus *guarantees* that
  the conditional _will *always* simplify_.

- Use ~inline~ means, for legal code, in the call site ~delta~ _MUST be_ a
  /compile-time constant/.

- A call ~update(22)~ would re-write to ~increaseBy(22)~.

- A call with a value of *not* /compile-time constant/ will trigger a
  /compile error/:
  #+begin_src text
       |  inline if (delta >= 0) ???
       |  ^
       |  cannot reduce inline if
       |   its condition
       |     delta >= 0
       |   is not a constant value
       | This location is in code that was inlined at ...
  #+end_src

- In a ~transparent inline~,
  an ~inline if~ will *force* the inlining of ANY inline definition *in its
  condition* _during_ /type checking/.

***** DONE Inline Matches
CLOSED: [2020-11-24 Tue 02:23]
- A /match expression/ _in the body_ of an /inline method definition/ _may be_
  prefixed by the ~inline~ modifier.
  * If there is *ENOUGH* _STATIC information_ to _unambiguously take a branch_,
    the expression is *reduced* to that branch and the type of the result
    is taken.

  * If not, a /compile-time error/ is raised that reports that the match cannot
    be reduced.

- The example below defines an /inline method/ with a single /inline match
  expression/ that picks a case based on its /static type/:
  #+begin_src scala
    transparent inline def g(x: Any): Any =
      inline x match
        case x: String => (x, x)  // Tuple2[String, String](x, x)
        case x: Double => x

    g(1.0d)    // Has type `1.0d` which is a subtype of `Double`
    g("test")  // Has type `(String, String)`
  #+end_src

- The scrutinee ~x~ is *examined statically* and the /inline match/ is
  *reduced* accordingly returning the corresponding value (with the /type
  specialized/ because ~g~ is declared ~transparent~).

- The /type/ can have a RICHER structure like the _simple_ /ADT/ below.
  ~toInt~
  1. _matches_ the structure of a number in /Church-encoding/
  2. _computes_ the corresponding integer.
  #+begin_src scala
    enum Nat
      case Zero
      case Succ[N <: Nat](n: N)

    transparent inline def toInt(n: Nat): Int =
      inline n match
        case Nat.Zero     => 0
        case Nat.Succ(n1) => toInt(n1) + 1

    inline val natTwo = toInt(Nat.Succ(Nat.Succ(Nat.Zero)))
    val intTwo: 2 = natTwo
  #+end_src
  ~natTwo~ can be inferred to have the /singleton type/ ~2~ because of ~transparent~.
  =IMPORTANT= =GOOD EXAMPLE=

***** DONE Reference - =READ=
CLOSED: [2021-04-28 Wed 03:29]
=FIXME= Fix the heading level of this section both in docs and in the content.
        https://docs.scala-lang.org/scala3/reference/metaprogramming/compiletime-ops.html

For more information about the semantics of ~inline~, see the
Scala 2020: Semantics-preserving inlining for metaprogramming]] paper.

**** DONE Compile-time operations
CLOSED: [2022-04-10 Sun 20:19]
***** DONE The ~scala.compiletime~ Package
CLOSED: [2022-04-10 Sun 20:19]
The ~scala.compiletime~ package contains _helper definitions_ that
provide support for /compile-time operations/ over _values_. They are
described in the following.

****** DONE ~constValue~ and ~constValueOpt~
CLOSED: [2022-04-10 Sun 15:15]
~constValue~ is a function that produces *the _constant value_ represented
by a /type/.*

- ~constValue[T]~ generate a _constant value_ of the /singleton type/ ~T~
  #+begin_src scala
    import scala.compiletime.constValue
    import scala.compiletime.opt.int.S

    transparent inline def toIntC[N]: Int =
      inline constValue[N] match
        case 0        => 0
        case _: S[n1] => 1 + toIntC[n1]

    inline val ctwo = toIntC[2]
  #+end_src

- ~constValueOpt[T]~ is similar to ~constValue[T]~, and it generates a
  _constant value_ of type ~Option[T]~.

- ~S~ is the type of the *successor* of some /singleton type/.
  For example, ~S[1]~ is the /singleton type/ ~2~.
  * =from Jian=
    =IMPORTANT= =TODO=
    How can we make a type of values that can have /successor/, and
    how do these successors generate???
    =IMPORTANT= =TODO=

****** DONE ~erasedValue~
CLOSED: [2022-04-10 Sun 15:15]
#+begin_src scala
  def erasedValue[T]: T
#+end_src
- The ~erasedValue[T]~ function _pretends_ to return a value of its type
  argument ~T~. Calling this function will always result in a compile-time
  error unless the call is removed from the code while /inlining/.

- Example:
  #+begin_src scala
    import scala.comiletime.erasedValue

    inline def defaultValue[T] =
      inline erasedValue[T] match
        case _: Byte    => Some(0: Byte)
        case _: Char    => Some(0: Char)
        case _: Short   => Some(0: Short)
        case _: Int     => Some(0)
        case _: Long    => Some(0L)
        case _: Float   => Some(0.0f)
        case _: Double  => Some(0.0d)
        case _: Boolean => Some(false)
        case _: Unit    => Some(())
        case _          => None

    val dInt:     Some[Int]     = defaultValue[Int]
    val dDouble:  Some[Double]  = defaultValue[Double]
    val dBoolean: Some[Boolean] = defaultValue[Boolean]
    val dAny:     None.type     = defaultValue[Any]
  #+end_src

- Another example:
  #+begin_src scala
    transparent inline def toIntT[N <: Nat]: Int =
      inline erasedValue[N] match
        case _: Zero.type => 0
        case _: Succ[n]   => toIntT[n] + 1

    inline val two = toIntT[Succ[Succ[Zero.type]]]
  #+end_src

- ~erasedValue~ is /an ~erased~ method/ so *it _CANNOT be used_ and _has NO_
  /runtime behavior/.*
    Since ~toIntT~ performs /static checks/ over the /static type/ of ~N~
  we can safely use it to scrutinize its return type (~S[S[Z]]~ in this case).

****** DONE ~error~
CLOSED: [2022-04-10 Sun 15:15]
The ~error~ /method/ is used to produce _user-defined_ /compile errors/
*DURING /inline expansion/.* It has the following signature:
#+begin_src scala
  inline def error(inline msg: String): Nothing
#+end_src

- Imports:
  #+begin_src scala
    import scala.compiletime.{error, code}
  #+end_src

- If an /inline expansion/ results in a call ~error(msgStr)~ the compiler
  produces an _error message_ containing the given ~msgStr~.
  * Example 1:
    #+begin_src scala
      inline def fail() =
        error("failed for a reason")

      fail()  // error: failed for a reason
    #+end_src

    OR

  * Example 2:
    #+begin_src scala
      inline def fail(p1: => Any) =
        error(code"failed on: $p1")

      fail(indentity("foo"))  // error: failed on: indentity("foo")
    #+end_src
    + ~error~ expects a string literal.
      If you want to do some string interpolation, you need to import ~code~.
      - *CAUTION*: ~p1~ *MUST BE* a _literal_!

  * =From Jian=
    Example 3:
    #+begin_src scala
      inline def conditionalFail(cond: Boolean, p1: => Any) =
        inline if cond then 1 else error(code"failed on: $p1")
    #+end_src

****** DONE The ~scala.compiletime.ops~ package
CLOSED: [2020-11-24 Tue 03:07]
The ~scala.compiletime.ops~ package contains types that provide support for
*primitive operations on /singleton types/.*

- When all arguments to a type in ~scala.compiletime.ops~ are /singleton types/,
  the compiler can *evaluate* the result of the operation.

- For example,
  #+begin_src scala
    import scala.compiletime.ops.int.*
    import scala.compiletime.ops.boolean.*

    val conjunction: true && true = true
    val multiplication: 3 * 5 = 15
  #+end_src
  * ~scala.compiletime.ops.int.*~ provides support for _multiplying TWO
    /singleton ~Int~ types/,_
    + =from Jian=
      =TODO= =???=
      Here the ~*~ is not an on purpose "import all".
      Is there a way to import the _multiply operation (~*~)_, instead of import all?
      =TODO= =???=

  * ~scala.compiletime.ops.boolean.&&~ for the _conjunction of TWO ~Boolean~
    types._

- Many of these /singleton operation types/ are meant to be used _infix_
  (as in SLS § 3.2.8).

- =IMPORTANT= =NO SURPRISE=
  *Since /type aliases/ have the SAME /precedence/ rules as their term-level
  equivalents,* the operations _COMPOSE with the EXPECTED /precedence/ rules_:
  #+begin_src scala
    import scala.compiletime.ops.int._
    val x: 1 + 2 * 3 = 7
  #+end_src

- The /operation types/ are *located in* /packages/ named after the /type/
  of the *left-hand side* parameter.
  * ~scala.compiletime.ops.int.+~ represents _addition of two numbers_,
  * ~scala.compiletime.ops.string.+~ represents _string concatenation_.

- To _use both_ and _distinguish the two types from each other_,
  a /match type/ can dispatch to the correct implementation:
  #+begin_src scala
    import scala.compiletime.ops.*

    import scala.annotation.infix

    type +[X <: Int | String, Y <: Int | String] = (X, Y) match
      case (Int, Int)       => int.+[X, Y]
      case (String, String) => string.+[X, Y]

    val concat: "a" + "b" = "ab"
    val addition: 1 + 1 = 2
  #+end_src
  =from Jian=
  The operations here are for /types/;

  This is NO PROBLEM for /values/, based on the receiver type, the compiler know
  how to do the dispatch.

***** DONE Summoning Implicits Selectively
CLOSED: [2022-04-10 Sun 20:19]
It is foreseen that *many areas* of /typelevel programming/ *can be* done
with _REWRITE_ methods *instead of* /implicits/.
*BUT* _sometimes /implicits/ are *UNAVOIDABLE*._

- The problem so far was that the /Prolog-like programming style/ of /implicit
  search/ becomes *viral*:
  *Once some construct depends on implicit search it has to be written as a
  logic program itself.*

- Consider for instance the problem of creating a ~TreeSet[T]~ or a ~HashSet[T]~
  depending on whether ~T~ _has an ~Ordering~ or not._
  We can create a set of /given definitions/ like this:
  =TODO=
  =TODO=
  =TODO=
  #+begin_src scala
    trait SetFor[T, S <: Set[T]]

    class LowPriority:
      implicit def hashSetFor[T]: SetFor[T, HashSet[T]] = ...

    object SetFor extends LowPriority:
      implicit def treeSetFor[T: Ordering]: SetFor[T, TreeSet[T]] = ...
  #+end_src
  + =from Jian=
    I don't know the complete form of this example.
    I try to complete it (Of course, this is too verbose!!!):
    #+begin_src scala
      trait SetFor[T, S <: Set[T]] {
        val set: S
      }

      class LowPriority {
        given hashSetFor[T]: SetFor[T, HashSet[T]] with {
          val set =  new HashSet
        }
      }

      object SetFor extends LowPriority {
        given treeSetFor[T: Ordering]: SetFor[T, TreeSet[T]] with {
          val set =  new TreeSet
        }
      }

      case class Person(name: String)

      println(summon[SetFor[Person, _]].set)  //  HashSet()
      println(summon[SetFor[String, _]].set)  //  TreeSet()
    #+end_src
    * =from Jian=
      TODO Can I find a conciser way to eliminate the ~.set~ part???

  + *Clearly, this is _NOT_ pretty.*
    * Besides all the usual indirection of /implicit search/,

    * we face the problem of rule *prioritization* where we have to
      _ensure that ~treeSetFor~ takes /priority/ over ~hashSetFor~ if the
      element type has an ordering._
        This is solved (clumsily) by putting ~hashSetFor~ in a /superclass/
      ~LowPriority~ of the object ~SetsFor~ where ~treeSetFor~ is defined.

    * Maybe the boilerplate would still be acceptable if the crufty code
      could be contained.
      _However_, this is not the case:
      Every user of the abstraction *has to be PARAMETERIZED itself with a
      ~SetFor~ implicit.* Considering the simple task "I want a ~TreeSet[T]~
      if ~T~ has an /ordering/ and a ~HashSet[T]~ otherwise", this seems
      like a lot of ceremony.

  + There are some proposals to improve the situation _in specific areas,_
    for instance by allowing _MORE ELABORATE schemes to SPECIFY /priorities/._
      But they all keep the viral nature of /implicit search/ programs based
    on logic programming. -- =from Jian= _and they are NOT adopted._

- _By contrast_,
  the NEW ~scala.compiletime.summonFrom~ construct makes /implicit search/
  available _in a functional context_.
  #+begin_src scala
    import scala.compiletime.summonFrom

    inline def setFor[T]: Set[T] = summonFrom {
      case ord: Ordering[T] => new TreeSet[T](using ord)
      case _                => new HashSet[T]
    }
  #+end_src
  + A ~summonFrom~ /call/ takes a /pattern matching closure/ as argument.
      *All* patterns in the /closure/ are /type ascriptions/ of the form
    ~identifier : Type~.

  + Patterns are tried *in sequence* (=from Jian= This help us avoiding using
    inheritance to solve the _implicit search priority issue_).
    * The first case with a pattern ~x: T~ such that an /given value/ of type
      ~T~ can be *summoned* is chosen.

    * If the pattern is _PREFIXED_ with ~given~, the variable ~x~ is bound to
      the /given value/ *for the remainder of the case.*
      #+begin_src scala
        import scala.compiletime.summonFrom

        inline def setFor[T]: Set[T] = summonFrom {
          case given ord: Ordering[T] => new TreeSet[T]
          case _                      => new HashSet[T]
        }
      #+end_src

  + ~summonFrom~ application *MUST BE reduced at /compile time/.*

- Example:
  #+begin_src scala
    summon[Ordering[String]]

    println(setFor[String].getClass)  // prints class scala.collection.immutable.TreeSet
  #+end_src

- Of course, when there is /contextual abstractions/, /ambiguity errors/ can
  happen:
  #+begin_src scala
    class A
    given a1: A = new A
    given a2: A = new A

    inline def f: Any = summonFrom {
      case given _: A => ???  // error: ambiguous implicits
    }
  #+end_src

***** DONE ~summonInline~
CLOSED: [2022-04-10 Sun 20:19]
The shorthand ~summonInline~ provides a _simple way_ to write a ~summon~ that is
*delayed* _until the call is inlined_.

- *Unlike* ~summonFrom~, ~summonInline~ also yields the /implicit-not-found error/,
  if a given instance of the summoned type is not found.

- Example:
  #+begin_src scala
    import scala.compiletime.summonInline
    import scala.annotation.implicitNotFound

    @implicitNotFound("Missing One")
    trait Missing1

    @implicitNotFound("Missing Two")
    trait Missing2

    trait NotMissing
    given NotMissing = ???

    transparent inline def summonInlineCheck[T <: Int](inline t : T) : Any =
      inline t match
        case 1 => summonInline[Missing1]
        case 2 => summonInline[Missing2]
        case _ => summonInline[NotMissing]

    val missing1 = summonInlineCheck(1) // error: Missing One
    val missing2 = summonInlineCheck(2) // error: Missing Two
    val notMissing : NotMissing = summonInlineCheck(3)
  #+end_src

***** DONE Reference - =TODO= =READ=
CLOSED: [2022-04-10 Sun 20:19]
For more information about /compile-time operations/, see
- =PR #4768=, which explains how
  ~summonFrom~'s _predecessor_ (/implicit matches/)
  can be used for /typelevel programming/ and /code specialization/

- =PR #7201=, which explains the _NEW ~summonFrom~ syntax._

**** DONE Macros
CLOSED: [2022-04-10 Sun 20:21]
- When developing macros
  ENABLE ~-Xcheck-macros~ _scalac option flag_ to have _EXTRA runtime checks_.

***** DONE Macros: Quotes and Splices
CLOSED: [2020-11-30 Mon 02:31]
- Macros are built on _TWO_ well-known fundamental operations:
  * quotation :: ~'{...}~ for /expressions/
  * splicing :: ~${ ... }~

- Additionally, *within* a /quote/ or a /splice/
  we can /quote/ or /splice/ _identifiers_ *directly* (i.e. ~'e~ and ~$e~).

- Readers may notice the _RESEMBLANCE_ of the two aforementioned syntactic
  schemes with the familiar /string interpolation syntax/.
  #+begin_src scala
    println(s"Hello, $name, here is the result of 1 + 1 = ${1 + 1}")
  #+end_src
  /Quotes/ and /splices/ in this section allow us to treat code in a similar
  way, effectively supporting /macros/.

  In /string interpolation/ we /quoted/ a string and then we /spliced/ into
  it, two others.
  1. ~name~, is a reference to a value of type ~String~,
  2. an _arithmetic expression_ that will be evaluated followed by the /splicing/
    of its string representation.

- The *entry point* for /macros/: an /inline method/ with a *top-level* /splice/.
  * *Top-level* here means
    it is the *ONLY* OCCASION where we encounter
    a /splice/ *outside* a /quote/ (consider as a /quote/ the compilation-unit
    at the call-site).

- For example, the code below presents an ~inline~ /method/ ~assert~ which
  calls at compile-time a method ~assertImpl~ with a /boolean expression tree/
  as argument. ~assertImpl~ evaluates the expression and prints it again in
  an error message if it evaluates to ~false~.
  #+begin_src scala
    import sala.quoted.*

    inline def assert(inline expr: Boolean): Unit =
      ${ assertImpl('expr) }

    def assertImpl(expr: Expr[Boolean])(using Quotes) = '{
      if !$expr then
        throw new AssertionError(s"failed assertion: ${${ showExpr(expr) }}")
    }

    def showExpr(expr: Expr[Boolean])(using Quotes): Expr[String] =
      '{ "[actual implementation later in this document]" }  // Place holder
  #+end_src
  * =IMPORTANT= =IMPORTANT= =IMPORTANT=
    =from Jian=
    The ~inline~ method with /top level splice/
    can provide a /given ~Quotes~ instance/, which, in syntax, is NOT
    be written out explicitly! This is why the signature of the above ~asset~
    does *NOT* have a ~(using Quotes)~ parameter list.

- If ~e~ is an expression, then ~'{e}~ represents the /typed abstract syntax
  tree/ representing ~e~.
- If ~T~ is a type, then ~Type.of[T]~ represents the /type structure/
  representing ~T~.

- The precise definitions of "typed abstract syntax tree" or "type-structure"
  do not matter for now, the terms are used only to give some intuition.

- Conversely, ~${e}~ evaluates the expression ~e~, which *MUST* yield a /typed
  abstract syntax tree/ or /type structure/, and embeds the result as an
  /expression/ (respectively, /type/) in the enclosing program.

- /Quotations/ can have _spliced_ parts in them; in this case the embedded /splices/
  _are evaluated and embedded as part of_ the formation of the /quotation/.

  * /Quotes/ and /splices/ can also be applied *DIRECTLY* to _identifiers_.
    + An /identifier/ ~$x~ starting with a ~$~ that appears _INSIDE_ a /quoted
      expression or type/ is _treated as_ a /splice/ ~${x}~.

    + Analogously, an /quoted identifier/ ~'x~ that appears _INSIDE_ a /splice/
      is _treated as_ a /quote/ ~'{x}~.

- /Quotes/ and /splices/ are *DUALS of each other*.
  For arbitrary /expressions/ ~e~ we have:
  #+begin_src scala
    ${'{e}} = e
    '{${e}} = e
  #+end_src

***** DONE Types for Quotations
CLOSED: [2020-11-30 Mon 02:33]
- The /type signatures/ of /quotes/ and /splices/ can be described using
  _TWO_ _FUNDAMENTAL /types/:_
  + ~Expr[T]~: /abstract syntax trees/ representing /expressions/ of /type/ ~T~

  + ~Type[T]~: /non erased representation of type/ ~T~.

- /Quoting/ and /splicing/ are dual to each other
  + /Quoting/
    * /expressions/ of /type/ ~T~ ---> /expressions/ of /type/ ~Expr[T]~
    * /types/ ~T~ ---> /expressions/ of /type/ ~Type[T]~.

  + /Splicing/
    - expressions of /type/ ~Expr[T]~ ---> /expressions/ of /type/ ~T~
    - expressions of /type/ ~Type[T]~ ---> /types/ ~T~.

- The two types can be defined in package ~scala.quoted~ as follows:
  #+begin_src scala
    package scala.quoted

    sealed trait calss Expr[+T]
    sealed trait calss Type[T]
  #+end_src
  Both ~Expr~ and ~Type~ are ~abstract~ and ~sealed~, so _ALL /constructors/
  for these types are PROVIDED BY THE SYSTEM._

- *TWO* ways to construct values of type ~Expr[T]~ or ~Type[T]~:
  + by /quoting/,
  + =TODO= by /type-specific lifting operations/ that will be discussed later on.

***** DONE The Phase Consistency Principle
CLOSED: [2020-12-01 Tue 03:03]
- A fundamental /phase consistency principle (PCP)/ regulates accesses to
  /free variables/ in /quoted/ and /spliced/ code:
  #+begin_quote
  For any /free variable reference/ ~x~,
  the _number_ of /quoted scopes/ and the _number_ of /spliced scopes/
  between the reference to ~x~ and the definition of ~x~ *must be equal*.
  #+end_quote
  + ~this~-reference count as /free variables/.

  + We assume
    * ALL _imports_ are fully expanded
    * ~_root_~ is *NOT* a /free variable/.
    So /references/ to /global definitions/ are *allowed everywhere*.

- The /phase consistency principle/ can _be motivated as follows_:
  1. Suppose the result of a program _P_ is some /quoted text/ ~'{ ... x ... }~
    that refers to a /free variable/ ~x~ in _P_. This can be represented only
    by referring to the original variable ~x~.

  2. Hence, the result of the program will need to persist the program state
    itself as one of its parts. We don't want to do this, hence this situation
    should be made illegal.

    Dually, suppose a top-level part of a program is a /spliced text/
    ~${ ... x ... }~ that refers to a /free variable/ ~x~ in _P_. This would
    mean that we refer during construction of _P_ to a value that is
    _available ONLY during execution of P._
    *This is of course impossible and therefore needs to be ruled out.*

  Now, the small-step evaluation of a program will reduce /quotes/ and
  /splices/ in equal measure using the cancellation rules above. But it will
  neither create nor remove /quotes/ or /splices/ individually. So the PCP
  ensures that program elaboration will lead to neither of the two unwanted
  situations described above.

- In what concerns the range of features it covers, this form of macros (Scala 3
  macro) introduces a principled metaprogramming framework that is quite
  close to the /MetaML family of languages/.
  + One difference is that MetaML does NOT have an equivalent of the PCP.
      quoted code in MetaML can access variables in its immediately
    enclosing environment, with some restrictions and caveats since such
    accesses involve serialization. _However, this does not constitute a
    fundamental gain in expressiveness._

***** DONE From ~Expr~'s to Functions and Back
CLOSED: [2020-12-01 Tue 03:03]
It is possible to
CONVERT _back and forth_ between ~Expr[T => R]~ and ~Expr[T] => Expr[R]~!

- The conversions can be implemented as follows:
  #+begin_src scala
    def to[T: Type, R: Type](f: Expr[T] => Expr[R])(using Quotes): Expr[T => R] =
      '{ (x: T) => ${ f('x) } }

    def from[T: Type, R: Type](f: Expr[T => R])(using Quotes): Expr[T] => Expr[R] =
      (x: Expr[T]) => '{ $f($x) }
  #+end_src
  * This /decorator/ gives ~Expr~ the ~apply~ operation of an /applicative functor/.

  * Note how the fundamental /phase consistency principle/ works in two different
    directions here for ~f~ and ~x~.
    + For example,
      in the method ~to~,
      - the reference to ~f~ is legal because it is /quoted/, then /spliced/,
      - the reference to ~x~ is legal because it is /spliced/, then /quoted/.

- Example:
  #+begin_src scala
    // '{ (x: Int) => x.toString }
    val f1: Expr[Int => String] = to((x: Expr[Int]) => '{ $x.toString })

    // (x: Expr[Int]) => '{ ((x: Int) => x.toString)($x) }
    val f2: Expr[Int] => Expr[String] = from('{ (x: Int) => x.toString })
    f2('{2})  // '{ ((x: Int) => x.toString)(2) }
  #+end_src
  * =from Jian=
    To make the code above runnable, they must be used in a scope with a
    given ~Quotes~ instance. To satisfy this, there are two ways:
    + Macro (All operations happens in /compile time/):
      #+begin_src scala
        import scala.quoted.*

        inline def runf1: Int => String = ${ mcrImpl1 }
        def mcrImpl1(using Quotes): Expr[Int => String] =
          to((x: Expr[Int]) => '{ $x.toString })

        inline def runf2: String = ${ mcrImpl2 }
        def mcrImpl2(using Quotes): Expr[String] =
          val f2: Expr[Int] => Expr[String] = from('{ (x: Int) => x.toString })
          f2('{2})
      #+end_src

  + Multi-Stage Programming (inlucdes /runtime/ evaluation, see next section
      for details):
      1. Include dependency (this was inside dotty before, and they are now
        separated) ~"ch.epfl.lamp" %% "scala3-staging" % scalaVersion.value~.

      2. Then,
        #+begin_src scala
          import scala.quoted.*
          import scala.quoted.staging.*

          given Toolbox = Toolbox.make(getClass.getClassLoader)

          //// '{ (x: Int) => x.toString }
          val runf1: Int => String = run {
            to((x: Expr[Int]) => '{ $x.toString })
          }

          //// (x: Expr[Int]) => '{ ((x: Int) => x.toString)($x) }
          val runf2: String = run {
            val f2: Expr[Int] => Expr[String] = from('{ (x: Int) => x.toString })
            f2('{2})
          }
        #+end_src

- One *LIMITATION* of ~from~ ::
  it does _NOT_ \beta{}-reduce when a lambda is called immediately
  * =from Jian=
    Example that shows the immediate result which is not the result of automatic \beta{}-reduce:
    #+begin_src scala
      inline def resultOfFrom: String = ${ resultOfFromImpl }

      def resultOfFromImpl(using Quotes): Expr[String] = {
        val f: Expr[Int] => Expr[String] = from('{ (x: Int) => x.toString })
        Expr(f('{2}).show)
      }
      // ((x: scala.Int) => x.toString()).apply(2)
    #+end_src

  * In some cases we _want to *REMOVE* the lambda from the code_,
    for this we provide the method ~Expr.betaReduce~ that turns a /TREE
    describing a function/ into a /FUNCTION mapping trees to trees/.
    #+begin_src scala
      inline def forBetaReduceExample: String = ${ forBetaReduceExampleImpl }

      def forBetaReduceExampleImpl(using Quotes): Expr[String] = {
        val afterBetaReduction = Expr.betaReduce('{ (x: Int) => x.toString })('{2})
        Expr(afterBetaReduction.show)
      }
      // 2.toString()
    #+end_src

  * ~Expr.betaReduce~ _IMPLEMENTATION_:
    The definition of ~Expr.betaReduce(f)(x)~ is *assumed* to be functionally the
    same as ~'{($f)($x)}~, however _it SHOULD *optimize* this call by returning
    the result of beta-reducing ~f(x)~ if ~f~ is a *KNOWN* lambda expression._
    ~Expr.betaReduce~ DISTRIBUTES applications of ~Expr~ over function arrows:
    #+begin_src scala
      Expr.betaReduce(_): Expr[(T1, ..., Tn) => R] => ((Expr[T1], ..., Expr[Tn]) => Expr[R])
    #+end_src

***** DONE Lifting Types - =TODO= - =RE-READ= because of docs update
CLOSED: [2021-04-23 Fri 10:08]
- */Types/ are _NOT directly_ affected by the /phase consistency principle/.*
  * *It is possible to use /types/ defined at any level in any other level.*
    *But*, if a /type/ is used in a SUBSEQUENT /stage/ it will need to be _lifted_
    to a ~Type~.

    + The resulting value of ~Type~ will be subject to /PCP/.
      Indeed, the definition of ~to~ above uses ~T~ in the NEXT /stage/,
      there is a /quote/ but NO /splice/ between the parameter binding of
      ~T~ and its usage. But the code can be rewritten by adding an explicit
      binding of a ~Type[T]~:
      #+begin_src scala
        def to[T, R](f: Expr[T] => Expr[R])
                    (using t: Type[T])
                    (using Type[R], Quotes): Expr[T => R] =
          '{ (x: t.Underlying) => ${ f('x) } }
      #+end_src
      - In this version of ~to~, the /type/ of ~x~ is now the result of
        /splicing/ the ~Type[T]~ and selecting its ~Underlying~.
        =NEW ADDED=

- *To _AVOID_ clutter* (=MOTIVATION= of /lifting types/), the compiler
  converts any type reference to a type ~T~ in subsequent phases to
  ~summon[Type[T]].Underlying~.
    And to avoid duplication it does it once per type, and creates an alias
  for that type at the start of the /quote/.
  * For instance, the user-level definition of ~to~:
    #+begin_src scala
      def to[T, R](f: Expr[T] => Expr[R])
                  (using t: Type[T], r: Type[R])
                  (using Quotes): Expr[T => R] =
        '{ (x: T) => ${ f('x) } }
    #+end_src

    would be rewritten to

    #+begin_src scala
      def to[T, R](f: Expr[T] => Expr[R])
                  (using t: Type[T], r: Type[R])
                  (using Quotes): Expr[T => R] =
        '{
          type T = t.Underlying
            (x: T) => ${ f('x) }
        }
    #+end_src
    * The ~summon~ query succeeds because
      - there is a /given instance/ of type ~Type[T]~ available
      - the reference to that value is *phase-correct*.

    * If that was NOT the case,
      the phase inconsistency for ~T~ would be _reported_ as an error.

***** DONE Lifting Expressions
CLOSED: [2020-12-01 Tue 03:04]
- Consider the following implementation of a /staged interpreter/ that implements
  a compiler through staging.
  #+begin_src scala
    import scala.quoted.*

    enum Exp:
      case Num(n: Int)
      case Plus(e1: Exp, e2: Exp)
      case Var(x: String)
      case Let(x: String, e: Exp, in: Exp)

    import Exp.*
  #+end_src
  * The interpreted language consists of numbers ~Num~, addition ~Plus~, and
    variables ~Var~ which are bound by ~Let~.

- Here are two sample expressions in the language:
  #+begin_src scala
    val exp    = Plus(Plus(Num(2), Var("x")), Num(4))
    val letExp = Let("x", Num(3), exp)
  #+end_src

- Here's a compiler that maps an expression given in the interpreted language
  to /quoted/ Scala code of type ~Expr[Int]~.
  #+begin_src scala
    import scala.quoted.*

    def compile(e: Exp, env: Map[String, Expr[Int]])(using Quotes): Expr[Int] =
      e match
        case Num(n)          => Expr(n)
        case Plus(e1, e2)    => '{ ${ compile(e1, env) } + ${ compile(e2, env) } }
        case Var(x)          => env(x)
        case Let(x, e, body) => '{ val y = ${ compile(e, env) }; ${ compile(body, env + (x -> 'y)) } }
  #+end_src

- Running ~compile(letExp, Map.empty)~ would yield the following Scala code:
  #+begin_src scala
    '{ val y = 3; (2 + y) + 4 }
  #+end_src
  =from Jian=
  You can check this representation with the help of ~showExpr~ mentioned below.

- The body of the first clause, ~case Num(n) => Expr(n)~, *looks SUSPICIOUS*.
  ~n~ is declared as an ~Int~, yet it is converted to an ~Expr[Int]~ with
  ~Expr.apply~.
  * Q :: Shouldn't ~n~ be /quoted/ (=from Jian= Use ~'n~ instead of ~Expr(n)~)?

  * A :: In fact this would _NOT_ work since replacing ~n~ by ~'n~ in the
        clause would *NOT* be /phase correct/ (=from Jian= violate PCP).

- =from Jian=
  From the Q&A above we know it's better to find an easy way to _lift a value
  of ~T~ to ~Expr[T]~ with enough information hiding_. A good API for this is
  already hinted above -- use ~Expr.apply[T: ToExpr](v: T)~ to do this.
  We'll talk about the knowledge about ~Expr.apply~ below.

- The ~Expr.apply~ method is defined in package ~quoted~:
  #+begin_src scala
    package quoted

    object Expr:
      /** Lift a value into an expression containing the construction of that value */
      def apply[T: ToExpr](x: T)(using Quotes): Expr[T] =
        summon[ToExpr[T]].toExpr(x)

      // ...
  #+end_src
  * This method says that values of types implementing the ~ToExpr~ /type
    class/ can be converted ("lifted") to ~Expr~ values using ~Expr.apply~.

- Dotty comes with /given instances/ of ~ToExpr~ for several types including
  ~Boolean~, ~String~, and /ALL primitive number types/.
  * For example,
    ~Int~ values can be converted to ~Expr[Int]~ values by wrapping the value
    in a ~Literal~ /tree node/ (=from Jian= actually ~Literal(Constant(n))~).
      This makes use of the underlying /tree representation/ in the compiler
    *for efficiency*.
    + _BUT_ the ~ToExpr~ instances are nevertheless NOT magic in the sense
      that they could all be defined in a user program *without knowing
      anything about the representation of ~Expr~ trees* (=from Jian= this
      can be done is because the fundamental types /given ~ToExpr~ instances/
      are provided by Scala).
      - For instance, here is a possible instance of ~ToExpr[Boolean]~:
        #+begin_src scala
          given ToExpr[Boolean] with
            def toExpr(b: Boolean) =
              if b then '{ true } else '{ false }
        #+end_src

- Once we can lift bits, we can work our way up.
  For instance, here is a possible implementation (=from Jian= of course,
  not the best way!) of ~ToExpr[Int]~ that _does *NOT* use the underlying
  tree machinery_:
  #+begin_src scala
    given ToExpr[Int] with
      def toExpr(n: Int): Expr[Int] = n match
        case Int.MinValue    => '{ Int.MinValue }
        case _ if n < 0      => '{ - ${ toExpr(-n) } }
        case 0               => '{ 0 }
        case _ if n % 2 == 0 => '{ ${ toExpr(n / 2) } * 2 }
        case _               => '{ ${ toExpr(n / 2) } * 2 + 1 }
  #+end_src
  * =from Jian=
    Since the PCP is only for /free variables/, and ~'{ Int.MinValue }~ and
    ~'{ 0 }~ don't include any /free variables/, they are legal and no
    violation to PCP. We can see they other 3 branches includes /free
    variables/ and follow PCP!

- Since ~ToExpr~ is a /type class/, its instances can be conditional.
  For example, a ~List~ is /liftable/ _if its element type is_:
  #+begin_src scala
    given [T: ToExpr : Type]: ToExpr[List[T]] with
      def toExpr(xs: List[T]) = xs match {
        case head :: tail => '{ ${ Expr(head) } :: ${ Expr(tail) } }
        case Nil          => '{ Nil: List[T] }
      }
  #+end_src

- *In the end, ~ToExpr~ _RESEMBLES_ very much a serialization framework.*
  Like the latter it can be derived systematically for all /collections/,
  /case classes/ and /enums/.

- =TODO= =???= =TODO=
  Note also that the synthesis of type-tag values of type ~Type[T]~ is
  essentially the type-level analogue of /lifting/.

- Using /lifting/, we can now give the missing definition of ~showExpr~ in
  the introductory example:
  #+begin_src scala
    def showExpr[T](expr: Expr[T])(using Quotes): Expr[String] =
      val code: String = expr.show
      Expr(code)
  #+end_src
  * That is, the ~showExpr~ /method/ _converts_ its ~Expr~ argument to a
    string (~code~), and *lifts* the result back to an ~Expr[String]~ using
    ~Expr.apply~.

***** DONE Lifting Types
CLOSED: [2020-11-30 Mon 21:07]
The previous section has shown that the metaprogramming framework has to
be able to take a /type/ ~T~ and convert it to a /type tree of type/ ~Type[T]~
that can be reified.
  This means that all /free variables/ of the /type tree/ refer to /types/
and /values/ defined in the _current /stage/._

- For a /reference/ to a _GLOBAL_ /class/, this is easy:
  Just issue the _FULLY QUALIFIED NAME of the /class/._

- /Members of reifiable types/ are handled
  by just reifying the CONTAINING /type/ together with the /member name/.

- Q :: But what to do for references to /type parameters/ or /local type
      definitions/ that are not defined in the _CURRENT /stage/?_

- A :: Here, we *cannot* construct the ~Type[T]~ tree DIRECTLY, so we need to
      get it from a _RECURSIVE implicit search._ For instance, to implement
  #+begin_src scala
    summon[Type[List[T]]]
  #+end_src
  where ~T~ is not defined in the _CURRENT /stage/,_ we construct the /type
  constructor/ of ~List~ applied to the /splice/ of the result of searching
  for a /given instance/ for ~Type[T]~:
  #+begin_src scala
    Type.of[ List[ summon[Type[T]].Underlying ] ]
  #+end_src
  * This is exactly the algorithm that _Scala 2_ uses to search for /type tags/.

  * In fact /Scala 2's type tag/ feature can be understood as a more ad-hoc
    version of ~quoted.Type~.
      As was the case for /type tags/, the _implicit search_ for a ~quoted.Type~
    is handled by the compiler, using the algorithm sketched above.

***** DONE Relationship with ~inline~ - =RE-READ=
CLOSED: [2020-11-30 Mon 21:38]
- Seen by itself, principled metaprogramming in Dotty looks
  _MORE like_ a framework for /runtime metaprogramming/
  _THAN_ one for /compile-time metaprogramming/ with /macros/.
  * But combined with Dotty's ~inline~ feature
    it can be _turned into_ a compile-time system.
      The idea is that /macro elaboration/ can be understood as a *combination*
    of a /macro library/ and a /quoted program/.

- Example used to illustrate the above discussion,
  here's the ~assert~ /macro/ again together with a program that CALLS
  ~assert~.
  #+begin_src scala
    object Macros:

      inline def assert(inline expr: Boolean): Unit =
        ${ assertImpl('expr) }

      def assertImpl(expr: Expr[Boolean])(using Quotes) =
        val failMsg: Expr[String] = Expr(s"failed assertion: ${expr.show}")
        '{ if !($expr) then throw new AssertionError($failMsg) }

    @main def program =
      val x = 1
      Macros.assert(x != 0)
  #+end_src
  * The example is only /phase correct/ because ~Macros~ is a /global value/
    and as such *NOT subject to* _phase consistency checking_.
    + *Conceptually that's a bit unsatisfactory.*
      - If the PCP is so fundamental,
        it should be applicable without the /global value/ *exception*.

      - _BUT_ in the example as given this does not hold since both ~assert~
        and program call ~assertImpl~ *with a* /splice/ but *no* /quote/.

  * However, one could argue that the example is really missing an important
    aspect:
    The /macro library/ has to be compiled in a phase *prior to* the program
    using it, _BUT_ in the code above, /macro/ and /program/ are _defined
    together_.
    + A more accurate view of /macros/ would be to have the _user program_
      be in a /phase/ *after* the /macro definitions/, reflecting the fact
      that /macros/ have to be defined and compiled before they are used.
      Hence, conceptually the program part should be treated by the
      compiler *as if* (=from Jian= not real legal code?) it was quoted:
      #+begin_src scala
        @main def program = '{
          val x = 1
          ${ Macros.assertImpl('{ x != 0 }) }
        }
      #+end_src
      If program is treated as a /quoted expression/, the call to
      ~Macro.assertImpl~ becomes /phase correct/ even if _macro library_
      and _program_ are conceptualized as local definitions.

- Q :: But what about the call from ~assert~ to ~assertImpl~?
- A :: Here, *we need a _tweak_ of the /typing rules/.*
  * Macro :: an ~inline~ function such as ~assert~ that contains a /splice/
            operation *outside* an ENCLOSING /quote/.

  * /Macros/ are supposed to be expanded in a SUBSEQUENT /phase/, i.e. in a
    /quoted context/. Therefore, they are also type checked *as if* they were
    in a /quoted context/.

- For instance, the definition of ~assert~ is typechecked *as if* it
  appeared INSIDE /quotes/.
    _This makes the call from ~assert~ to ~assertImpl~ phase-correct,_
  even if we assume that both definitions are *local*.

- The ~inline~ modifier is used to declare a ~val~ that is
  * either a constant
  * or a parameter that will be a constant when instantiated.
    =FIX= =remove a "is"=
  This aspect is also important for /macro expansion/.

- To get values out of expressions containing constants ~Expr~ provides the
  /methods/
  + ~value[T]~: return a value of ~Option[T]~
  + ~valueOrError[T]~: return a value of ~T~

- Wanted: avoid having incidental ~val~ bindings generated by the /inlining/
          of the ~def~
  Solution: it is *RECOMMENDED* to use /an ~inline~ parameter/.
  + To illustrate this, consider an implementation of the ~power~ function that
    makes use of a statically known exponent:
    #+begin_src scala
      inline def power(x: Double, inline n: Int) =
        ${ powerCode('x, 'n) }

      private def powerCode(x: Expr[Double], n: Expr[Int])(using Quotes): Expr[Double] =
        n.value match
          case Some(m) => powerCode(x, m)
          case None    => '{ Math.pow($x, $y) }

      private def powerCode(x: Expr[Double], n: Int)(using Quotes): Expr[Double] =
        if      n == 0     then '{ 1.0 }
        else if n == 1     then x
        else if n % 2 == 0 then '{ val y = $x * $x; ${ powerCode('y, n / 2) } }
        else                    '{ $x * ${ powerCode(x, n - 1) } }
    #+end_src

***** DONE Scope Extrusion
CLOSED: [2020-11-30 Mon 22:49]
- /Quotes/ and /splices/ are duals _as far as_ the PCP is concerned.
  _BUT_ there is an *additional RESTRICTION* that needs to be imposed on
  /splices/ to guarantee /soundness/:
  code in /splices/ *must be _FREE_ of /side effects/.*
  * The restriction prevents code like this:
    #+begin_src scala
      var x: Expr[T] = ...
      '{ (y: T) => ${ x = 'y; 1 } }
    #+end_src
    This code, IF it was accepted, would *extrude* a reference to a /quoted
    variable/ ~y~ from its /scope/.
      This would subsequently allow access to a variable outside the scope
    where it is defined, which is LIKELY (=TODO= =???=) problematic.
    1. The code is clearly /phase consistent/, so we CANNOT use PCP to rule
      it out.

    2. Instead, we postulate a FUTURE /effect system/ that can guarantee
      that /splices/ are pure.
      - In the absence of such a system we simply demand that /spliced
        expressions/ are pure *by convention*, and allow for *undefined
        compiler behavior* if they are not.

      - This is analogous to the status of /pattern guards/ in Scala,
        which are also _required, but NOT VERIFIED, to be pure._

- /Multi-Stage Programming/ (=from Jian= next section) introduces one
  additional /method/ where you can *expand code at runtime* with a
  /method/ ~scala.quoted.staging.run~.
  * =from Jian=
    /Staging/ is *not* a part of the standard libary. Need to includes the
    dependency: ~"ch.epfl.lamp" %% "scala3-staging" % scalaVersion.value~

- Call ~scala.quoted.staging.run~ in /splices/ is forbidden!
  This is a little bit tricky.
  * Use this example code to illustrate this trickiness:
    #+begin_src scala
      '{ (x: Int) => ${ run('x); 1 } }  // Not legal code
    #+end_src
    + This is /phase correct/, _BUT_ WILL lead us into *TROUBLE*:
      Evaluate the /splice/ will reduce the expression ~run('x)~ to ~x~.
      But then the result is *no longer* /phase correct/.
      #+begin_src scala
        '{ (x: Int) => ${ x; 1 } }
      #+end_src

  * To *prevent* this /soundness hole/ it seems easiest to classify ~run~ as
    a /side-effecting operation/. It would thus be *prevented from appearing
    in /splices/.*
      In a base language with /side effects/ we would have to do this anyway:
    Since ~run~ runs _ARBITRARY_ code it can ALWAYS produce a /side effect/
    if the code it runs produces one.

***** DONE Example Expansion - =RE-DO= =???= =Try Code Example=
CLOSED: [2020-11-30 Mon 23:18]
Assume we have _two_ /methods/,
one ~map~ that takes an ~Expr[Array[T]]~ and a function ~f~,
=FIX= =COMMA=
and one ~sum~ that performs a sum by delegating to ~map~.
=from Jian= I prefer to use ~var acc = 0~ instead of ~var sum = 0~ to avoid same names.
#+begin_src scala
  object Macros:

    def map[T](arr: Expr[Array[T]], f: Expr[T] => Expr[Unit])
              (using Type[T], Quotes): Expr[Unit] = '{
      var i: Int = 0
      while i < ($arr).length do
        val element: T = ($arr)(i)
        ${f('element)}
        i += 1
    }

    def sum(arr: Expr[Array[Int]])(using Quotes): Expr[Int] = '{
      var sum = 0
      ${ map(arr, x => '{sum += $x}) }
      sum
    }

    inline def sum_m(arr: Array[Int]): Int = ${sum('arr)}

  end Macros
#+end_src

Expand the call to ~sum_m(Array(1, 2, 3))~:
1. Inline ~sum_m~:
  #+begin_src scala
    val arr: Array[Int] = Array.apply(1, [2, 3: Int]: Int*)
    ${ _root_.Macros.sum('arr) }
  #+end_src

2. Splice ~sum~:
  #+begin_src scala
    val arr: Array[Int] = Array.apply(1, [2, 3: Int]: Int*)

    var sum = 0
    ${ map('arr, x => '{ sum += $x }) }
    sum
  #+end_src

3. Inline ~map~:
  #+begin_src scala
    val arr: Array[Int] = Array.apply(1, [2, 3: Int]: Int*)

    var sum = 0
    val f = x => '{ sum += $x }
    ${ _root_.Macros.map('arr, 'f)(Type.of[Int]) }
    sum
  #+end_src

4. Expand and /splice/ inside quotes ~map~:
  #+begin_src scala
    val arr: Array[Int] = Array.apply(1, [2, 3: Int]: Int*)

    var sum = 0
    val f = x => '{ sum += $x }
    var i: Int = 0
    while i < (arr).length do
      val element: Int = (arr)(i)
      sum += element
      i += 1

    sum
  #+end_src

5. Cleanups and dead code elimination:
  #+begin_src scala
    val arr: Array[Int] = Array.apply(1, [2, 3: Int]: Int*)
    var sum = 0
    var i: Int = 0
    while i < arr.length do
      val element: Int = arr(i)
      sum += element
      i += 1

    sum
  #+end_src

***** DONE Find implicits within a macro
CLOSED: [2020-11-30 Mon 23:27]
Similarly to the ~summonFrom~ construct, it is possible to make _implicit
search_ available in a /quote context/. For this we simply provide
~scala.quoted.Expr.summon~:
#+begin_src scala
  import scala.collection.immutable.{ TreeSet, HashSet }
  import scala.quoted.*

  inline def setFor[T]: Set[T] = ${ setForExpr[T] }

  def setForExpr[T: Type](using Quotes): Expr[Set[T]] =
    Expr.summon[Ordering[T]] match
      case Some(ord) => '{ TreeSet.empty[T](using $ord) }
      case _         => '{ HashSet.empty[T] }
#+end_src

***** DONE Relationship with Transparent ~inline~
CLOSED: [2021-02-14 Sun 02:26]
The code below introduces a /transparent inline method/ that can calculate
either a value of /type/ ~Int~ or a value of /type/ ~String~:
#+begin_src scala
  transparent inline def defaultOf(inline str: String) =
    ${ defaultOfImpl('str) }

  def defaultOfImpl(strExpr: Expr[String])(using Quotes): Expr[Any] =
    strExpr.valueOrError match
      case "int"    => '{1}
      case "string" => '{"a"}

  // in a separate file
  val a: Int    = defaultOf("int")
  val b: String = defaultOf("string")
#+end_src

***** DONE Defining a macro and using it in a single project
CLOSED: [2020-11-30 Mon 23:36]
- =from Jian=
  Of course, if the /macros/ project is *different* from the project use
  /macros/, the compilation is much simpler, and this doc does discuss.

- It is possible to define /macros/ and use them in the *same project* as
  long as the implementation of the /macros/ does NOT have /runtime
  dependencies/ on code in the file where it is used.
  + It might still have /compile-time dependencies/ on
    /types/ and /quoted code/ that refers to the use-site file.

- To provide the functionality of a project inlcudes both /macros/ and the
  code use them, Dotty provides a /transparent compilation mode/ where
  1. Files that try to expand a /macro/ but fail because the /macro/ has NOT
    been compiled yet are *suspended*.

  2. If there are any suspended files when the compilation ends,
    the compiler will *AUTOMATICALLY* RESTART compilation of the suspended
    files using the output of the previous (partial) compilation as /macro/
    classpath.

  3. In case *ALL* files are *suspended* due to /cyclic dependencies/ the
    compilation will *FAIL* with an error.

***** DONE Pattern matching on quoted expressions
CLOSED: [2020-12-07 Mon 11:18]
It is possible to deconstruct or extract values out of Expr using pattern matching.

- ~scala.quoted~ contains objects that can help extracting values from ~Expr~:
  * ~scala.quoted.Expr~ / ~scala.quoted.Exprs~:
    matches an expression of a value (or list of values) and returns the
    value (or list of values).

  * ~scala.quoted.Const~ / ~scala.quoted.Consts~:
    Same as ~Expr~ / ~Exprs~ but only works on primitive values.

  * ~scala.quoted.Varargs~:
    matches an explicit sequence of expressions and returns them. These
    sequences are useful to get individual ~Expr[T]~ out of a varargs
    expression of type ~Expr[Seq[T]]~.

- These could be used in the following way to optimize any call to sum that
  has statically known values.
  #+begin_src scala
    inline def sum(inline args: Int*): Int = ${ sumExpr('args) }

    private def sumExpr(argsExpr: Expr[Seq[Int]])
                      (using Quotes): Expr[Int] =
      argsExpr match
        case Varargs(args @ Exprs(argValues)) =>
          // args is of type Seq[Expr[Int]]
          // argValues is of type Seq[Int]
          Expr(argValues.sum) // precompute result of sum

        case Varargs(argExprs) => // argExprs is of type Seq[Expr[Int]]
          val staticSum: Int = argExprs.map(_.value.getOrElse(0)).sum
          val dynamicSum: Seq[Expr[Int]] = argExprs.filter(_.value.isEmpty)
          dynamicSum.foldLeft(Expr(staticSum))((acc, arg) => '{ $acc + $arg })

        case _ =>
          '{ $argsExpr.sum }
  #+end_src

****** DONE Quoted patterns
CLOSED: [2020-12-06 Sun 16:43]
  /Quoted pattens/ allow deconstructing complex code that contains a precise
  structure, types or methods.

  - Patterns ~'{ ... }~ can be placed in any location where Scala expects a
    pattern.
    * For example,
      #+begin_src scala
        optimize {
          sum(sum(1, a, 2), 3, b)
        } // should be optimized to 6 + a + b
      #+end_src

      #+begin_src scala
        def sum(args: Int*): Int = args.sum

        inline def optimize(inline arg: Int): Int = ${ optimizeExpr('arg) }

        private def optimizeExpr(body: Expr[Int])(using Quotes): Expr[Int] =
          body match
            // Match a call to sum without any arguments
            case '{ sum() }                     => Expr(0)
            // Match a call to sum with an argument $n of type Int. n will be the Expr[Int] representing the argument.
            case '{ sum($n) }                   => n
            // Match a call to sum and extracts all its args in an `Expr[Seq[Int]]`
            case '{ sum(${Varargs(args)}: _*) } => sumExpr(args)
            case body                           => body

        private def sumExpr(args1: Seq[Expr[Int]])(using Quotes): Expr[Int] =
            def flatSumArgs(arg: Expr[Int]): Seq[Expr[Int]] = arg match
              case '{ sum(${Varargs(subArgs)}: _*) } => subArgs.flatMap(flatSumArgs)
              case arg                               => Seq(arg)

            val args2 = args1.flatMap(flatSumArgs)

            val staticSum: Int = args2.map(_.value.getOrElse(0)).sum
            val dynamicSum: Seq[Expr[Int]] = args2.filter(_.value.isEmpty)
            dynamicSum.foldLeft(Expr(staticSum))((acc, arg) => '{ $acc + $arg })
      #+end_src

****** DONE Recovering precise types using patterns
CLOSED: [2020-12-07 Mon 10:07]
Sometimes it is necessary to get a more _precise type_ for an expression.
This can be achieved using the following pattern match.
#+begin_src scala
  def f(expr: Expr[Any])(using Quotes) = expr match
    case '{ $x: t } =>
      // If the pattern match succeeds, then there is some type `t` such that
      // - `x` is bound to a variable of type `Expr[t]`
      // - `t` is bound to a new type `t` and a given instance `Type[t]` is provided for it
      // That is, we have `x: Expr[t]` and `given Type[t]`, for some (unknown) type `t`.
#+end_src

This might be used to then perform an implicit search as in:

#+begin_src scala
  extension (inline sc: StringContext)
    inline def showMe(inline args: Any*): String =
      ${ showMeExpr('sc, 'args) }

  private def showMeExpr(sc: Expr[StringContext], argsExpr: Expr[Seq[Any]])(using Quotes): Expr[String] =
    argsExpr match {
      sase Varargs(argExprs) =>
        val argShowedExprs = argExprs.map {
          case '{ $arg: tp } =>
            val showTp = Type.of[]
            Expr.summon[Show[tp]] match
              case Some(showExpr) => '{ $showExpr.show($arg) }
              case None           => report.error(s"could not find implicit for ${Type.show[Show[tp]]}", arg); '{???}
        }
        val newArgsExpr = Varargs(argShowedExprs)
        '{ $sc.s($newArgsExpr: _*) }

      case _ =>
        // `new StringContext(...).showMeExpr(args: _*)` not an explicit `showMeExpr"..."`
        report.error(s"Args must be explicit", argsExpr)
        '{???}
    }

  trait Show[-T]:
    def show(x: T): String

  // in a different file
  given Show[Boolean] with
    def show(b: Boolean) = "boolean!"

  println(showMe"${true}")
#+end_src

****** DONE Open code patterns
CLOSED: [2020-12-07 Mon 11:18]
/Quote pattern matching/ also provides higher-order patterns to match _open
terms_.
  If a quoted term contains a definition, then the rest of the quote can
refer to this definition.
#+begin_src scala
  '{
    val x: Int = 4
    x * x
  }
#+end_src

- To match such a term we need to match the definition and the rest of the
  code, but we need to explicitly state that the rest of the code may
  refer to this definition.
  ~case '{ val y: Int = $x; $body(y): Int } =>~

  * Here
    ~$x~ will match any closed expression while
    ~$body(y)~ will match an expression that is closed under ~y~.
    Then the subexpression of type ~Expr[Int]~ is bound to ~body~ as an
    ~Expr[Int => Int]~.
    The extra
    argument represents the references to ~y~. Usually this expression is
    used in combination with ~Expr.betaReduce~ to replace the extra argument.
    #+begin_src scala
      inline def eval(inline e: Int): Int = ${ evalExpr('e) }

      private def evalExpr(e: Expr[Int])(using Quotes): Expr[Int] =
        e match
          case '{ val y: Int = $x; $body(y): Int } =>
            // body: Expr[Int => Int] where the argument represents references to y
            evalExpr(Expr.betaReduce('{$body(${evalExpr(x)})}))

          case '{ ($x: Int) * ($y: Int) } =>
            (x.value, y.value) match
              case (Some(a), Some(b)) => Expr(a * b)
              case _                  => e

          case _ => e

      eval {  // expands to the code: (16: Int)
        val x: Int = 4
        x * x
      }
    #+end_src
    We can also close over several bindings using ~$b(a1, a2, ..., an)~. To
    match an actual application we can use braces on the function part
    ~${b}(a1, a2, ..., an)~.

***** TODO More details

**** TODO The Meta-theory of Symmetric Metaprogramming
**** DONE Run-Time Multi-Stage Programming - =RE-READ=
CLOSED: [2020-12-27 Sun 13:25]
The framework expresses at the same time /compile-time metaprogramming/ and
/multi-stage programming/.

- We can think of /compile-time metaprogramming/ as a _two stage compilation
  process_: one that we write the code _in top-level /splices/,_ that will be
  used for /code generation (macros)/ and one that will perform all
  necessary evaluations at /compile-time/ and an object program that we will
  run as usual.

- Q :: What if we could *synthesize* code at /run-time/ and offer one extra
        /stage/ to the programmer?
- A :: Then we can have a value of type ~Expr[T]~ at /run-time/ that we can
        essentially treat as a /typed-syntax tree/ that we can either show as
        a string (pretty-print) or compile and run.
  * If the NUMBER of /quotes/ *exceeds* the NUMBER of /splices/ _by more than
    one_ (effectively handling at /run-time values/ of /type/ ~Expr[Expr[T]]~,
    ~Expr[Expr[Expr[T]]]~, ...) then we talk about /Multi-Stage Programming/.

- The motivation behind this paradigm is to let _runtime information_
  *affect* or *guide* /code-generation/.

- Intuition:
  The phase in which code is run is determined
  by THE DIFFERENCE BETWEEN THE NUMBER OF /splice scopes/ and /quote scopes/
  in which it is embedded.
  * If there are *more /splices/ than /quotes/,*
    the code is run at /compile-time/ i.e. as a /macro/.
        In the general case, this means running an interpreter that evaluates
    the code, which is represented as a /typed abstract syntax tree/. The
    interpreter can _fall back_ to _reflective calls_ when evaluating an
    application of a _PREVIOUSLY *compiled* /method/._

      If the /splice/ *excess is MORE THAN ONE*, it would mean that a _macro's
    implementation code_ (as opposed to the code it expands to) invokes other
    /macros/.

      If /macros/ are realized by interpretation, this would lead to _towers of
    interpreters_, where the first interpreter would itself interpret an
    interpreter code that possibly interprets another interpreter and so on.

  * If the NUMBER of /splices/ *equals* the NUMBER of /quotes/,
    the code is compiled and run as usual.

  * If the NUMBER of /quotes/ *exceeds* the NUMBER of /splices/, the code is /staged/.
    That is, it produces a /typed abstract syntax tree/ or /type structure at run-time/.
    + A /quote/ *excess of more than one* corresponds to /multi-staged programming/.

- Providing an interpreter for the full language is quite difficult, and
  it is even more difficult to make that interpreter run efficiently.
    So we currently impose the following *RESTRICTIONS* on the use of /splices/.
  1. A _top-level_ /splice/ _MUST_ appear in an /inline method/
      (TURNING that /method/ INTO a /macro/)

  2. The /splice/ _MUST_ call a previously /compiled method/
      passing /quoted arguments/, /constant arguments/ or /inline arguments/.

  3. /Splices/ inside /splices/ (but NO intervening quotes) are *not allowed*.

***** DONE API - =TODO= =???=
CLOSED: [2020-12-20 Sun 22:27]
The framework as discussed so far allows code to be /staged/, i.e. be prepared
to be executed at a LATER /stage/.

- To run that code, there is another method in class ~Expr~ called ~run~.
  * Note that ~$~ and ~run~ both map from ~Expr[T]~ to ~T~
    BUT only ~$~ is subject to the /PCP/, whereas ~run~ is just a NORMAL
    /method/.

  * ~scala.quoted.staging.run~ provides a ~Quotes~ that can be used to *show*
    the expression in its scope.

  * On the other hand ~scala.quoted.staging.withQuotes~ provides a ~Quotes~
    WITHOUT *evaluating* the expression.
    #+begin_src scala
      pakcage scala.quoted.staging

      def run[T](expr: Quotes ?=> Expr[T])(using Compiler): T = ...

      def withQuotes[T](thunk: Quotes ?=> T)(using Compiler): T = ...
    #+end_src

***** DONE Create a new Scala 3 project with staging enabled
CLOSED: [2020-12-20 Sun 22:16]
#+begin_src bash
  sbt new scala/scala3-staging.g8
#+end_src
It will create a project with the necessary dependencies and some examples.

- In case you prefer to create a project on your own, make sure to define
  the following dependency in your =build.sbt=.
  #+begin_src scala
    libraryDependencies += "org.scala-lang" %% "scala3-staging" % scalaVersion.value
  #+end_src
  * in case you use scalac/scala directly,
    then use the =-with-compiler= FLAG for both:
    #+begin_src bash
      scalac -with-compiler -d out Test.scala
      scala -with-compiler -classpath out Test
    #+end_src
    =TODO= =TODO= =TODO=
    =check!!!=

***** DONE Example
CLOSED: [2020-12-20 Sun 22:10]
Now take exactly the same example as in Macros.
- Assumption:
  we do *NOT* want to *pass* an array STATICALLY
  BUT *generate* code at /run-time/
      and
      *pass* the value, also at /run-time/.

- Note,
  how we make a future-stage function of type ~Expr[Array[Int] => Int]~ in
  line 6 below.

- Using ~staging.run { ... }~ we can *evaluate* an expression at /runtime/.

- Within the scope of ~staging.run~ we can also invoke ~show~ on an expression
  to get a source-like representation of the expression.
  #+begin_src scala
    import scala.quoted.*

    // make available the necessary compiler for runtime code generation
    given staging.Compiler = staging.Compiler.make(getClass.getClassLoader)

    val f: Array[Int] => Int = staging.run {
      val stagedSum: Expr[Array[Int] => Int] = '{ (arr: Array[Int]) => ${sum('arr)} }
      println(stagedSum.show)  // Prints "(arr: Array[Int]) => { var sum = 0; ... }"
      stagedSum
    }

    f.apply(Array(1, 2, 3))  // Return 6
  #+end_src

**** DONE Reflection
CLOSED: [2020-12-28 Mon 01:37]
/Reflection/ ENABLES *inspection* and *construction* of /Typed Abstract
Syntax Trees (Typed-AST)/.

- /Reflection/ may be used ON
  /quoted expressions/ (~quoted.Expr~) and /quoted types/ (~quoted.Type~)
  FROM /Macros/ or ON _full TASTy files_.

- =IMPORTANT=
  If you are writing /macros/, please first read /Macros/.
  You may find all you need without using /quote reflection/.

***** API: From quotes and splices to TASTy reflect trees and back
- With ~quoted.Expr~ and ~quoted.Type~ we can compute code but also analyze
  code by inspecting the ASTs.
  * /Macros/ provide the *GUARANTEE* that the generation of code will be
    /type-correct/.

  * Using /quote reflection/ will *BREAK* these guarantees and may fail
    _at macro expansion time_, hence _additional explicit checks *must be
    done*._

- To provide _reflection capabilities_ in /macros/
  we need to
  *add* an /implicit parameter/ of type ~scala.quoted.Quotes~ and
  *import* ~quotes.reflect.*~ from it in the scope where it is used.
  #+begin_src scala
    import scala.quoted.*

    inline def natConst(inline x: Int): Int = ${ natConstImpl('{x}) }

    def natConstImpl(x: Expr[Int])(using Quotes): Expr[Int] =
      import quotes.reflect.*
      ...
  #+end_src

****** Extractors
- ~import quotes.reflect.*~ will provide _ALL_ /extractors/ and /methods/
  on ~quotes.reflect.Tree~'s. For example the ~Literal(_)~ /extractor/
  used below.
  #+begin_src scala
    def natConstImpl(x: Expr[Int])(using Quotes): Expr[Int] =
      import quotes.reflect.*
      val tree: Term = x.asTerm

      tree match
        case Inlined(_, _, Literal(IntConstant(n))) =>
          if n <= 0 then
            report.error("Parameter must be natural number")
            '{0}
          else
            tree.asExprOf[Int]

        case _ =>
          report.error("Parameter must be a known constant")
          '{0}
  #+end_src

- We can easily know which /extractors/ are needed using
  ~Printer.TreeStructure.show~, which returns the _STRING REPRESENTATION
  the structure of the tree_. Other /printers/ can also be found in the
  ~Printer~ /module/.
  #+begin_src scala
    tree.show(using Printer.TreeStructure)
    // or
    Printer.TreeStructure.show(tree)
  #+end_src

- The /methods/ ~quotes.reflect.Term.{asExpr, asExprOf}~ provide a way to go
  back to a ~quoted.Expr~.
  * Note
    + ~asExpr~ returns a ~Expr[Any]~.
    + On the other hand ~asExprOf[T]~ returns a ~Expr[T]~,
        _if the /type/ does NOT conform to it an exception will be thrown at
      /runtime/._

****** Positions
_The ~Position~ in the context_ provides a ~ofMacroExpansion~ value. It
corresponds to the /expansion site/ for /macros/. The /macro/ authors can
obtain various information about that /expansion site/.

- The example below shows how we can obtain _position information_ such as
  the start line,
  the end line,
  or even the source code at the expansion point.
  #+begin_src scala
    def macroImpl()(quotes: Quotes): Expr[Unit] =
      import quotes.reflect.*
      val pos = Position.ofMacroExpansion

      val path = pos.sourceFile.jpath.toString
      val start = pos.start
      val end = pos.end
      val startLine = pos.startLine
      val endLine = pos.endLine
      val startColumn = pos.startColumn
      val endColumn = pos.endColumn
      val sourceCode = pos.sourceCode
      ...
  #+end_src
  =FIXME - not this doc=
  https://scalacenter.github.io/scala-3-migration-guide/docs/compatibility.html

****** TODO Tree Utilities
~quotes.reflect~ contains _THREE_ facilities for /tree traversal and
transformation/.

- ~TreeAccumulator~ ties the knot of a traversal.
  By calling ~foldOver(x, tree)(owner)~ we can dive into the ~tree~ node
  and start accumulating values of type ~X~ (e.g., of type ~List[Symbol]~
  if we want to collect symbols). The code below, for example, collects
  the ~val~ definitions in the tree.
  #+begin_src scala
    def collectPatternVariables(tree: Tree)(using ctx: Context): List[Symbol] =
      val acc = new TreeAccumulator[List[Symbol]]:
        def foldTree(syms: List[Symbol], tree: Tree)
                    (owner: Symbol): List[Symbol] = tree match
          case ValDef(_, _, rhs) =>
            val newSyms = tree.symbol :: syms
            foldTree(newSyms, body)(tree.symbol)

          case _ =>
            foldOverTree(syms, tree)(owner)

      acc(Nil, tree)
  #+end_src
  A ~TreeTraverser~ extends a ~TreeAccumulator~ and performs the same
  traversal but without returning any value. Finally, a ~TreeMap~ performs
  a transformation.

******* TODO ~ValDef.let~
~quotes.reflect.ValDef~ also offers a /method/ ~let~ that allows us to
bind the ~rhs~ (right-hand side) to a ~val~ and use it in ~body~.
  Additionally, ~lets~ binds the given ~terms~ to names and allows to use
them in the ~body~. Their type definitions are shown below:
#+begin_src scala
  def let(rhs: Term)(body: Ident => Term): Term = ...

  def lets(terms: List[Term])(body: List[Term] => Term): Term = ...
#+end_src

**** DONE TASTy Inspection
CLOSED: [2022-05-29 Sun 02:09]
#+begin_src scala
  libraryDependencies += "org.scala-lang" %% "scala3-tasty-inspector" % scalaVersion.value
#+end_src

_TASTy files_ contain the FULL /typed tree/ of a /class/ including _source
positions_ and _documentation_. This is ideal for tools that analyze or
extract semantic information from the code. To avoid the hassle of working
directly with the TASTy file we provide the ~TastyInspector~ which loads the
contents and exposes it through the TASTy reflect API.

***** Inspecting TASTy files
To inspect the /trees/ of a _TASTy file_ a /consumer/
can be defined in the following way:
#+begin_src scala
  import scala.quoted.*
  import scala.tasty.inspector.*

  class MyInspector extends Inspector:
    def inspect(using Quotes)(tastys: List[Tasty[quotes.type]]): Unit =
        import quotes.reflect.*
        for tasty <- tastys do
          val tree = tasty.ast
          // Do something with the tree
#+end_src

- Then the consumer can be instantiated with the following code to get the
  /tree/ of the ~foo/Bar.tasty~ file.
  #+begin_src scala
    object Test:
      def main(args: Array[String]): Unit =
          val tastyFiles = List("foo/Bar.tasty")
          TastyInspector.inspectTastyFiles(tastyFiles)(new MyInspector)
  #+end_src

- Note that if we need to run the ~main~ (in the example below defined in an
  object called ~Test~) after compilation we need to make the compiler
  available to the /runtime/:
  #+begin_src shell
    scalac -d out Test.scala
    scala -with-compiler -classpath out Test
  #+end_src

***** Template project =TRY=
Using sbt version 1.1.5+, do:
#+begin_src shell
  sbt new scala/scala3-tasty-inspector.g8
#+end_src
in the folder where you want to clone the template.

*** TODO Other New Features
**** DONE Trait Parameters
CLOSED: [2021-02-15 Mon 23:07]
Dotty allows /traits/ to have /parameters/, just like /classes/ have /parameters/.

- Example:
  #+begin_src scala
    trait Greeting(val name: String):
      def msg = s"How are you, $name"

    class C extends Greeting("Bob"):
      println(msg)
  #+end_src

- =IMPORTANT= Initialization Rule:
  /Arguments/ to a /trait/ are *evaluated immediately _BEFORE_ the /trait/ is
  initialized.*

- One potential issue with /trait parameters/:
  *how to prevent ambiguities.*
  For instance, you might try to _extend ~Greeting~ TWICE, with DIFFERENT
  parameters._
  #+begin_src scala
    class D extends C, Greeting("Bill")  // error: parameter passed twice
  #+end_src
  Should this print ~"Bob"~ or ~"Bill"~? In fact this program is *ILLEGAL*,
  because it _VIOLATES the SECOND rule of the following for /trait parameters/:_
  1. IF a /class/ ~C~ _extends_ a /parameterized trait/ ~T~, and
      IF its /superclass/ does NOT,
      ~C~ *must* pass arguments to ~T~.

  2. IF a /class/ ~C~ _extends_ a /parameterized trait/ ~T~, and
      IF its /superclass/ does as well,
      ~C~ *must not* pass arguments to ~T~.

  3. /Traits/ *must NEVER* PASS arguments to /parent traits/.

- Here's /trait/ extending the /parameterized trait/ ~Greeting~.
  #+begin_src scala
    trait FormalGreeting extends Greeting:
      override def msg = s"How do you do, $name"
  #+end_src
  * As is required, no arguments are passed to ~Greeting~.
    However, this poses an *ISSUE* when defining a /class/ that extends
    ~FormalGreeting~:
    #+begin_src scala
      class E extends FormalGreeting  // error: missing arguments for `Greeting`.
    #+end_src
    The correct way to write ~E~ is to extend both ~Greeting~ and ~FormalGreeting~
    (in either order):
    #+begin_src scala
      class E extends Greeting("Bob"), FormalGreeting
    #+end_src

****** DONE Traits With Context Parameters
  CLOSED: [2021-03-24 Wed 00:37]
  This "explicit extension required" rule is *relaxed* if the missing /trait/
  contains *ONLY* /context parameters/.
    In that case
  the /trait reference/ *is implicitly inserted* as an additional parent with
  inferred arguments.

  - For instance,
    here's a variant of greetings where the addressee is a /context parameter/
    of type ~ImpliedName~:
    #+begin_src scala
      case class ImpliedName(name: String):
          override def toString = name

      trait ImpliedGreeting(using val iname: ImpliedName):
          def msg = s"How are you, $iname"

      trait ImpliedFormalGreeting extends ImpliedformalGreeting

      class F(using iname: ImpliedName) extends ImpliedFormalGreeting
    #+end_src

    The definition of ~F~ in the last line is implicitly expanded to

    #+begin_src scala
      class F(using iname: ImpliedName) extends
          Object,
          ImpliedGreeting(using iname),
          ImpliedFormalGreeting(using iname)
    #+end_src
    * Note:
      The inserted reference to the /super trait/ ~ImpliedGreeting~, which was
      *NOT* mentioned explicitly.

***** TODO Reference
  For more info, see _Scala SIP 25_.

**** DONE Transparent Traits and Classes
CLOSED: [2020-11-27 Fri 02:42]
- /Traits/ are used in _TWO_ roles:
  * As *mixins* for other /classes/ and /traits/
  * As *types* of ~vals~, ~defs~, or ~parameters~

- Some /traits/ are used primarily in the first role, and we usually *do not
  want to see* them in /inferred types/.
  * Example:
    The ~Product~ /trait/ that the compiler adds as a /mixin trait/ to every
    /case class/ or /case object/.
      In Scala 2, this /parent trait/ sometimes makes /inferred types/ more
    complicated than they should be.

  * Example:
    #+begin_src scala
      trait Kind
      case object Var extends Kind
      case object Val extends Kind
      val x = Set(if condition then Val else Var)
    #+end_src
    The /inferred type/ of ~x~ in Scala 2 is ~Set[Kind & Product & Serializable]~
    whereas one would have hoped it to be ~Set[Kind]~.
    + The reasoning for this particular type to be inferred is as follows:
      1. The /type/ of the conditional above is the /union type/ ~Val | Var~
          (this is just in concept -- we don't actually have the /union type/
          syntax in Scala 2).

      2. A /union type/ is widened in /type inference/ to the *least supertype*
          that is _NOT_ a /union type/.
            In the example, this type is ~Kind & Product & Serializable~
          since *ALL THREE* /traits/ are /supertraits/ of both ~Val~ and ~Var~.
          So that /type/ becomes the /inferred element type/ of the /set/.

- Scala 3 allows one to mark a /trait/ as a ~transparent~, which means it can
  be suppressed in /type inference/.
  #+begin_src scala
    // In Scala 3
    transparent trait S
    trait Kind
    case object Var extends Kind, S
    case object Val extends Kind, S
    val x = Set(if condition then Val else Var)
  #+end_src
  Now ~x~ has /inferred type/ ~Set[Kind]~ -- the common /mixin trait/ ~S~ does
  _NOT_ appear in the /inferred type/.

***** Transparent Traits
  - The /traits/ ~scala.Product~, ~java.lang.Serializable~ and ~java.lang.Comparable~
    are *treated _AUTOMATICALLY_ as ~transparent~.*
    * /Scala 2 traits/ can also be made /transparent/ by adding a
      ~@transparentTrait~ annotation, which is defined in ~scala.annotation~.
      + It _WILL BE_ /deprecated/ and phased out once Scala 2/3 interopability
        is no longer needed.

  - Typically, ~transparent trait~'s are /traits/
    that influence the implementation of inheriting /classes/ and /traits/
    AND
    that are _NOT usually used as types by themselves._
    * Two examples from the standard collection library:
      + ~IterableOps~,
        which provides method implementations for an ~Iterable~

      + ~StrictOptimizedSeqOps~,
        which optimises some of these implementations for sequences with
        efficient indexing.

  - =IMPORTANT=
    Generally, _ANY_ /trait/ that is _extended RECURSIVELY_ is a good candidate
    to be declared /transparent/.

***** Rules for Inference - =TODO= =RE-READ=
  - /Transparent traits/ *can be* given as /explicit types/ as usual.
    But they are often ELIDED when types are inferred.
      Roughly, the rules for /type inference/ say that /transparent traits/
    _are DROPPED from intersections *WHERE POSSIBLE*._

  - The precise rules are as follows: =TODO= =???= =TODO=
    * When *inferring* a /type/ of
      a /type variable/, or
      the /type/ of a ~val~, or
      the /return type/ of a ~def~,

    * where that /type/ is *NOT* /higher-kinded/,

    * and where ~B~ is its known /upper bound/ or ~Any~ if none exists: (=FIX= this : ???)

    * If the /type inferred/ so far is of the form ~T1 & ... & Tn~ where n >= 1,
      replace the maximal number of ~Ti~'s by ~Any~, while ensuring that the
      resulting type is still a /subtype/ of the bound ~B~.

    * However, do NOT perform this /widening/ if all /transparent traits/ ~Ti~
      can get replaced in that way.

  - The _last clause_ *ensures* that
    a single ~transparent trait~ instance such as ~Product~ is not widened to
    ~Any~.
    * =IMPORTANT= =SUMMARY=
      ~transparent trait~ instances are _ONLY dropped_
      WHEN they appear _in conjunction with some other /type/._

**** DONE Universal Apply Methods
CLOSED: [2020-07-14 Tue 13:33]
Scala /case classes/ *generate* ~apply~ /methods/, so that values of /case
classes/ can be created using simple /function application/, *WITHOUT*
needing to write ~new~.
  Scala 3 *generalizes* this scheme to *all* *concrete* /classes/.

- Example:
  #+begin_src scala
    class StringBuilder(s: String):
      def this() = this("")

    StringBuilder("abc")  // old: new StringBuilder("abc")
    StringBuilder()       // old: new StringBuilder()
  #+end_src
  This works since a /companion object/ with TWO ~apply~ /methods/ are
  _generated together with_ the /class/. The /companion object/ looks like:
  #+begin_src scala
    object StringBuilder:
      inline def apply(s: String): StringBuilder = new StringBuilder(s)
      inline def apply(): StringBuilder = new StringBuilder()
  #+end_src
  The _synthetic object_ ~StringBuilder~ and its ~apply~ /methods/ are called
  /constructor proxies/.

- /Constructor proxies/ are generated _even for_ /Java classes/ and /classes/
  comming from Scala 2.
  * The precise rules are as follows:
    1. A /constructor proxy/ /companion object/ ~object C~ is created for a
        _concrete_ /class/ ~C~, provided
        + the /class/ does *not* have already a companion
        + there is also *no* other /value/ or /method/ named ~C~
          _defined_ or _inherited_ in the scope where ~C~ is defined.

    2. /Constructor proxy/ ~apply~ /methods/ are *generated* for a _concrete_
        /class/ provided
        + the /class/ has a /companion object/ (which might have been generated in
          step 1), and
        + that /companion object/ does *NOT already* define a member named ~apply~.

- Each generated ~apply~ /method/ *forwards* to *one* /constructor/ of the
  /class/.
  * It has the *same* /type/ and /value parameters/ as the /constructor/.

- /Constructor proxy companions/ *cannot* be used as values by themselves.
  A /proxy companion object/ must be selected with ~apply~ (or be applied to
  arguments, in which case the ~apply~ is implicitly inserted).

- /Constructor proxies/ are also *NOT allowed to shadow* NORMAL definitions.
  * That is, if
    an identifier resolves to a /constructor proxy/, and
    the same identifier is also defined or imported in some other scope,
    _an ambiguity is reported._

***** Motivation
  - Leave out ~new~ *hides* an implementation detail _and_
    makes code more pleasant to *read*

  - Q :: What's the cost of this change?
  - A :: _Add a new rule_ (a fallback rule) to the interpretation of the
        /function call syntax/.

  - Q :: Why this cost is valuable?
  - A :: It increase the perceived regularity of the language, since /case classes/
        already provide /function call creation syntax/ (and are often defined for
        this reason alone).
        + =from Jian=
          though define a /case class/ only for its ~apply~ is not the right
          way to use /case classes/ -- /case classes/ are HEAVY because of
          tens of generated methods. However, people keep doing this.

**** TODO Export Clauses -- =TODO= _Elaboration of Export Clauses_
    *An ~export~ clause defines aliases for selected members of an object.*

    - NOTE:
      Unless otherwise stated, _the term "class"_ in this discussion also
      _includes_ /object/ and /trait/ definitions.

    - Example:
      #+begin_src scala
        class BitMap
        class InkJet

        class Printer:
          type PrinterType
          def print(bits: BitMap): Unit = ???
          def status: List[String] = ???

        class Scanner:
          def scan(): BitMap = ???
          def status: List[String] = ???

        class Copier:
          private val printUnit = new Printer { type PrinterType = InkJet }
          private val scanUnit = new Scanner

          export scanUnit.scan
          export printUnit.{status => _, *}

          def status: List[String] = printUnit.status ++ scanUnit.status
      #+end_src
      * Here the two ~export~ clauses define the following /export aliases/ in
        class ~Copier~:
        #+begin_src scala
          final def scan(): BitMap            = scanUnit.scan()
          final def print(bits: BitMap): Unit = printUnit.print(bits)
          final type PrinterType              = printUnit.PrinterType
        #+end_src

      * The exported members can be accessed inside ~Copier~ as well as from
        outside (=from Jian= in the scope the ~export~ clause resides, ~export~
        is like ~import~, while for the outside of this scope ~export~ make this
        exported members accessible from the outside):
        #+begin_src scala
          val copier = new Copier
          copier.print(copier.scan())
        #+end_src

      * Syntax (similar to ~import~):
        #+begin_src scala
          export path . { sel_1, ..., sel_n }
        #+end_src
        + ~path~ here must be a /stable identifier/.

        + ~export~ is like ~import~.
          Synthetic members generated by compiler can't be exported.

        + Selectors can be of one of the following forms: =TODO= simplify this part of note
          * A simple selector x creates aliases for all eligible members of path
              that are named x.

          * A renaming selector x => y creates aliases for all eligible members
            of path that are named x, but the alias is named y instead of x.

          * An omitting selector x => _ prevents x from being aliased by a
              subsequent wildcard selector.

          * A given selector given x has an optional type bound x. It creates
            aliases for all eligible given instances that conform to either x,
            or Any if x is omitted, except for members that are named by a
          previous simple, renaming, or omitting selector.

            * A wildcard selector ~*~ creates aliases for all eligible members of path
            except for given instances, synthetic members generated by the
            compiler and those members that are named by a previous simple,
            renaming, or omitting selector.

      * A member is *eligible for being exported* if all of the following holds:
      + The _owner of the being exported member_ is *NOT* the /base class/ of
          /class/ (includes /object/) that conttains the /export clause/.

        + The member does *NOT* /override a concrete definition/ that has as owner
        a /base class/ of the /class/ containing the /export clause/.

          + it is _accessible_ at the /export clause/ -- =from Jian= with proper
          modifier,

        + it is
            * *NOT* a /constructor/,
          * *NOT* the (*synthetic*) class part of an object,

        + it is a /given instance/ (declared with ~given~)
            iff the ~export~ is from a /given selector/.

    * It is a /compile-time error/ if a simple or renaming selector does *not*
        identify any _eligible members_.

      * _Code generation_ triggered by ~export~'s:
      + /Type members/ are aliased by _type definitions_;
        + /Term members/ are aliased by _method definitions_;
          + Export aliases _copy_ the /type and value parameters/ of the members
          they refer to.
      + /Export aliases/ are always ~final~.
        + Aliases of /given instances/ are again defined as /givens/.
          + Aliases of /inline methods/ or values are again defined ~inline~.
        + There are *NO* OTHER /modifiers/ that can be given to an alias.

      * The _Code generation_ rule above has the following *CONSEQUENCES* for
          /overriding/:
        + Export aliases *cannot* be overridden, since they are ~final~.

        + Export aliases *cannot* override /concrete members/ in /base classes/,
            since they are not marked ~override~.

      + However, export aliases *can* _IMPLEMENT_ /deferred members/ (=from Jian=
          I think this term is the same as /abstract members/) of /base classes/.

      * TODO =RE-READ= TODO
      /Export aliases/ for /public value/ definitions that are accessed *WITHOUT
        referring to* /private values/ in the qualifier path are marked by the
          compiler as "stable" and their result types are the /singleton types/ of
        the aliased definitions.
        This means that they can be used as parts of /stable identifier paths/,
        even though they are _technically_ /methods/. For instance, the
          following is OK (_technically_, the consequence of ~export O.c~ generate
        a ~c~ /method/ -- when this is not a /export alias/, it can't be marked
        as stable):
        #+begin_src scala
          class C { type T }
          object O { val c: C = ... }
        export O.c
            def f: c.T = ...
        #+end_src

    * /Export clauses/ *can* appear in /classes/
        /Export clauses/ *can* appear _at the /top-level/._
          /Export clauses/ *CANNOT* appear _as a statement IN A BLOCK_.

    * If an /export clause/ contains a /wildcard/ or /given selector/, it is
        *forbidden* for its /qualifier path/ to *refer* to a /package/.
          - This is because it is *not yet known*
          how to safely track /wildcard dependencies/ to a /package/ for the
        purposes of incremental compilation.
          =TODO= =NEW-ADDED= =TRY-TO-UNDERSTAND=

      * =from Jian=
      A real world example:
        Sometimes we know something should be /static/, but make it /static/ can
          make the code looks WIERD! Before adding ~export~, we don't have a perfect
        solution. After adding the ~export~ feature, we can get a solution, though
        it is limited, can apply to most of the real world cases with this
        requirement.

        + In Scala 2, if we want to keep /static/ things /static/, we need to
          write like
          #+begin_src scala
            trait Calculator {
              val calculatorName: String
          }

            class AbcCalculator extends Calculator {
              override val calculatorName = AbcCalculator.calculatorName
          }

            object AbcCalculator {
              val calculatorName = "Abc"
          }
            #+end_src

        + In Scala 3, we still keep /static/ things /static/, but we can write
        #+begin_src scala
            trait Calculator:
                val calculatorName: String

          final class AbcCalculator extends Calculator:
              export AbcCalculator.calculatorName

            object AbcCalculator:
            val calculatorName = "Abc"
          #+end_src
            - Of course, for providing a perfect solution like this with ~export~,
            One requirement is satisfied:
          - The being overridden field is /abstract/.

            - Another limitation is that we can't do similar thing to the /subclasses/
            of ~AbcCalculator~ -- the compiler will synthesize /final members/ for
          ~export~ clauses! However, this is not a real limitation -- a good design
              should avoid creating a long inheritance chain. Mostly, none level is
            enough.
            * However, if in future this limitation can be removed or not that strict,
            it is of course better for using. The only thing I doubt is that if this
              will be limited in theory and remove the limitation can create an unsound
                system.

  - *Restrictions*:
      1. /Export clauses/ can appear
            * in /classes/
            OR
        * at the top-level.
          An /export clause/ *cannot* appear as a statement in a block.

      2. If an /export clause/ contains a /wildcard/ or /given selector/,
        it is *forbidden* for its qualifier path to refer to a /package/.
          =TODO= =from Jian= _I don't quite understand this. Need an example._
              This is because it is not yet known how to safely track wildcard
          dependencies to a package for the purposes of incremental compilation.

      3. Simple renaming exports like =TO BE REMOVED Restriction=
            #+begin_src scala
            export status as stat
        #+end_src
          are not supported yet.
            They would run afoul of the restriction that the exported ~a~ cannot
          be already a member of the /object/ containing the ~export~. *This
        restriction might be lifted in the future.*

***** DONE Motivation
  CLOSED: [2020-05-18 Mon 02:35]
  - It is a standard recommendation to *prefer composition over inheritance*.
    + This is really an application of /the principle of least power/:
      * /Composition/ treats components as _BLACKBOXES_
        _WHEREAS_
      * /Inheritance/ can _AFFECT the internal workings_ of components through
        /overriding/

    + Sometimes the _close coupling_ implied by /inheritance/ is the best solution
      for a problem, but where this is not necessary the looser coupling of composition
      is better.

  - So far, OO Language including Scala made it much easier to use /inheritance/
    than /composition/, which pushing programmers to a solution that is often
    too powerful (=from Jian= "too powerful" is not a good word in /the principle
    of least power/) as well as complicated (=from Jian= hard to verify in the
    concept of math).
    + For example, in Scala,
      * /inheritance/: Use ~extends~ clause

      * /composition/: Require a verbose elaboration of a sequence of forwarders.
        - =from Jian=
          Introduce ~export~ can mostly reduce one level of forwarders --
          + before: ~def mth = c.mth~
          + now: ~export c.mth~

    + ~export~ clauses redress the balance, and
      make /composition relationships/ *as CONCISE and EASY to* express as
      /inheritance relationships/.
      * Actually, ~export~ clauses is MORE FLEXIBLE than ~extends~ clauses --
        members can be _renamed_ or _ommited_.

      * =from Jian=
        ~export~ has some limitations.
        I'm not sure if the limitations must be there for soundness, but one of
        the reason of their existence that I can guess is with them, the system
        eliminate most of the potential interference between composition (~export~)
        and inheritance (~extends~).

  - /Export clauses/ also fill a gap opened by _the shift from /package objects/
    (DEPRECATED in Scala 3) to /toplevel definitions/._
    + In Scala 2, sometimes /package objects/ is created also with ~extends~ clauses.

    + /Toplevel definitions/ doesn't reside in semantics in a user-defined object,
      so they _can't inherit anyting_. However, ~export~ can be applied in
      toplevel, and make a similar result to the /package object/ _inheritance_ way.

***** DONE Syntax changes
  CLOSED: [2020-05-18 Mon 02:35]
***** TODO Elaboration of Export Clauses
  - Q :: How does the order of elaboration affect type checking?

  - Example:
    #+begin_src scala
      class B { val c: Int }
      object a { val b = new B }
      export a.*
      export b.*
    #+end_src
    + Q :: Is the ~export b.*~ clause legal?
    + Q :: If yes, what does it export?
    + Q :: Is it equivalent to export ~a.b.*~?
    + Q :: What about if we swap the last two clauses?
          #+begin_src scala
            export b.*
            export a.*
          #+end_src

  - A :: To avoid tricky questions like these,
        we _FIX the elaboration order of exports_ as follows.

  - Export clauses are processed when the type information of the enclosing
    object or class is completed. Completion *SO FAR* consisted of the
    following steps: TODO TODO TODO TODO TODO TODO
    1. Elaborate any annotations of the class.

    2. Elaborate the parameters of the class.

    3. Elaborate the self type of the class, if one is given.

    4. Enter all definitions of the class as class members, with types to be
      completed on demand.

    5. Determine the types of all parents of the class.

      *With export clauses, the following steps are added*

    6. Compute the types of all paths in export clauses in a context logically
      inside the class but not considering any imports or exports in that class.

    7. Enter export aliases for the eligible members of all paths in export clauses.

  - Conclusion :: a path of an /export clause/ *cannot* _refer to_ an alias
                  made available by _ANOTHER_ /export clause/ of the _SAME_
                  /class/.

**** DONE Opaque Type Alias
CLOSED: [2021-03-13 Sat 23:11]
/Opaque types aliases/ provide type abstraction without any runtime overhead.

- Example:
  #+begin_src scala
    object MyMath:

      opaque type Logarithm = Double

      object Logarithm:
        // These are the ways to lift to the Logarithm type

        def apply(d: Double): Logarithm = math.log(d)

        def safe(d: Double): Option[Logarithm] =
          if (d > 0.0) Some(math.log(d)) else None
      end Logarithm

      // Extension methods define opaque type aliases' public APIs
      extension (x: Logarithm)
        def toDouble: Double = math.exp(x)
        def + (y: Logarithm): Logarithm = Logarithm(math.exp(x) + math.exp(y))
        def * (y: Logarithm): Logarithm = Logarithm(x + y)

    end MyMath
  #+end_src
  * ~Logarithm~ is the same as ~Double~ is *only known in the scope where
    ~Logarithm~ is defined* which in the above example corresponds to the
    object ~MyMath~.
    + This in scope knowledge of their equivalence is very important!
        Without this knowledge, type-check will say functions ~apply~, ~safe~,
      ~toDouble~, ~+~, and ~*~ have wrong type signature, there there will
      be no simple way to override it.

  * Outside ~MyMath~, ~Logarithm~ is treated as a _NEW abstract type_.
    + Legal operations example:
      #+begin_src scala
        import MyMath.Logarithm

        val l = Logarithm(1.0)
        val l2 = Logarithm(2.0)
        val l3 = l * l2
        val l4 = l + l2
      #+end_src
      - =IMPORTANT=
        =TODO= Try in 3.0.0-RC1, RC2, and the release version
        The ~import Predef.{any2stringadd => _}~ is necessary!!!
          Without this import clause, the universal ~+~ in ~Predef~ would
        take precedence over the ~+~ /extension method/ of ~Logarithm~.
        * Solution: eliminate ~any2stringadd~ -- this is already in DEPRECATED
                    status.

    + Illegal operations example:
      #+begin_src scala
        val d: Double = l        // error: found: Logarithm, required: Double
        val l2: Logarithm = 1.0  // error: found: Double, required: Logarithm
        l * 2                    // error: found: Int(2), required: Logarithm
        l / l2                   // error: `/` is not a member fo Logarithm
      #+end_src

***** Bounds For Opaque Type Alias
  /Opaque type aliases/ can also come with /bounds/.
  Example:
  #+begin_src scala
    object Access:

      opaque type Permissions = Int
      opaque type PermissionChoice = Int
      opaque type Permission <: Permissions & PermissionChoice = Int

      extension (x: Permissions)
        def & (y: Permissions): Permissions = x | y

      extension (x: PermissionChoice)
        def | (y: PermissionChoice): PermissionChoice = x | y

      extension (granted: Permissions)
        def is(required: Permissions): Boolean = (granted & required) == required

      extension (granted: Permissions)
        def isOneOf(required: PermissionChoice): Boolean = (granted & required) != 0

      val NoPermission: Permission = 0
      val Read: Permission = 1
      val Write: Permission = 2
      val ReadWrite: Permissions = Read | Write
      val ReadOrWrite: PermissionChoice = Read | Write

    end Access
  #+end_src
  - The ~Access~ object defines THREE /opaque type aliases/:
    * ~Permission~,       representing a single permission,
    * ~Permissions~,      representing a conjunction (logical "and") of permissions,
    * ~PermissionChoice~, representing a disjunction (logical "or") of permissions.

  - /Type bound/ of ~Permission~ makes it known outside the ~Access~ object that
    ~Permission~ is a /subtype/ of the other two types. Hence, the following
    usage scenario type-checks:
    #+begin_src scala
      object User:
        import Access.*

        case class Item(rights: Permissions)

        val roItem = Item(Read)  // OK, since Permission <: Permissions
        val rwItem = Item(ReadWrite)
        val noItem = Item(NoPermission)

        assert(!roItem.rights.is(ReadWrite))
        assert(roItem.rights.isOneOf(ReadOrWrite))

        assert(rwItem.rights.is(ReadWrite))
        assert(rwItem.rights.isOneOf(ReadOrWrite))

        assert(!noItem.rights.is(ReadWrite))
        assert(!noItem.rights.isOneOf(ReadOrWrite))
      end User
    #+end_src
    * On the other hand, ~roItem.rights.isOneOf(ReadWrite)~ can't pass the type check.

***** DONE Opaque Type Members on Classes
  CLOSED: [2021-03-13 Sat 23:10]
  While typically, /opaque types/ are used together with objects to hide
  implementation details of a /module/,
  they can also be used with /classes/.

  - For example,
    #+begin_src scala
      class Logarithms:
        opaque type Logarithm = Double

        def apply(d: Double): Logarithm =
            math.log(d)

        def safe(d: Double): Option[Logarithm] =
            if d > 0.0 then Some(math.log(d)) else None

        def mul(x: Logarithm, y: Logarithm): Logarithm =
            x + y
    #+end_src

  - /Opaque type members/ of *different* /instances/
    are *treated as different*:
    #+begin_src scala
      val l1 = new Logarithms
      val l1 = new Logarithms

      val x = l1(1.5)
      val y = l1(2.6)
      val z = l2(3.1)

      l1.mul(x, y)  // type checks
      l1.mul(x, z)  // error: found l2.Logarithm, required l1.Logarithm
    #+end_src
    * =from Jian=
      + This is just a pedagogical example -- usually we define this
        ~Logarithms~ as an ~object~, not a ~class~.

      + Is there any practical example(s) for this kind of usage --
        combine ~class~ with /opaque types/???
        =TODO= =TODO= =TODO=

  - =FIXME=
    Rephrase the last senctence to eliminate reference to ~private[this]~.
    * _REASON_:
      We should avoid explaining a Scala 3 new feature with
      a deprecated Scala 2 feature.

***** TODO More details
****** Syntax
****** Type Checking
****** Realtionship to SIP 35

**** TODO Opaque Type Alias: More Details
**** DONE Open Classes
CLOSED: [2020-05-14 Thu 01:29]
An ~open~ /modifier/ on a class signals that the class _is planned for
extensions_.
- Example:
  #+begin_src scala
    // File Writer.scala
    package p

    open class Writer[T]:

      /** Sends to stdout, can be overridden */
      def send(x: T) = println(x)

      /** Sends all arguments using `send` */
      def sendAll(xs: T*) = xs.foreach(send)
    end Writer

    // File EncryptedWriter.scala
    package p

    class EncryptedWriter[T: Encryptable] extends Writer[T]:
      override def send(x: T) = super.send(encrypt(x))
  #+end_src

- An /open class/ typically comes with
  *some documentation that describes the internal calling patterns between
  methods of the class as well as hooks that can be overridden.*
  * We call this the /extension contract/ of the /class/.
    It is DIFFERENT FROM the /external contract/ between a /class/ and its
    users.

- /Classes/ that are _not open_ *can still be extended*, *but only if* at least
  one of two alternative conditions is met:
  * The /extending class/ is in the *same source file as* the /extended class/.
    In this case, the extension is usually an _internal implementation matter_.

  * The language feature ~adhocExtensions~ is enabled for the extending class.
    If not enabled, the compiler will issue a "feature" warning when it see an
    extension with no ~open~ and not in the same source file.
    + ~import scala.language.adhocExtensions~
    + command line option ~-language:adhocExtensions~

***** DONE Motivation
  CLOSED: [2020-05-14 Thu 01:28]
  - When writing a class, there are _THREE possible expectations_ of
    /extensibility/:
    1. The class is intended to allow extensions.
      This means one should expect
      * a *carefully* worked out (=from Jian= this kind of class is like a public API)
      * *documented* /extension contract/ for the class. (=IMPORTANT=)

    2. Extensions of the class are _forbidden_,
      for instance to make correctness or security guarantees.

    3. There is no firm decision either way.
      The class is not a priori intended for extensions, but if others find
      it useful to extend on an ad-hoc basis, let them go ahead. However,
      they are on their own in this case.
      * Possible issue:
        There is _NO documented /extension contract/,_ and future versions of
        the class might break the extensions (by rearranging internal call
        patterns, for instance =from Jian= this happens in my everyday work).

  - The three cases are clearly distinguished by using
    * ~open~ for 1
    * ~final~ for 2
    * _no modifier_ for 3

  - _It is GOOD PRACTICE to *avoid* ad-hoc extensions in a code base,_
    since they tend to lead to fragile systems that are hard to evolve.

  - But there are _still some situations_ where these extensions are *USEFUL*.
      That's why /ad-hoc extensions/ are permitted, but only if there is an
    explicit opt-in via a language feature import.
    * for instance,
      + to _mock_ classes in tests,
      + to _apply temporary patches_ that add features or fix bugs in library classes.

***** DONE Details
  CLOSED: [2020-05-14 Thu 01:14]
  - ~open~ is a /soft modifier/.
    It is treated as a normal identifier _unless it is in modifier position._

  - An ~open~ /class/ *CANNOT BE* ~final~ or ~sealed~.

  - /Traits/ or /abstract classes/ are *always ~open~,* so ~open~ is redundant
    for them.

***** DONE Relationship with ~sealed~
  CLOSED: [2020-05-14 Thu 01:20]
  - A class that is NEITHER ~abstract~ NOR ~open~ is SIMILAR TO a ~sealed class~:
    it can still be extended, but ONLY _in the same source file_.

  - The _DIFFERENCE_ is what happens
    if an extension of the class is attempted _in another source file_.
    * For a /sealed class/, this is an *error*

    * for a /simple non-open class/, this is still permitted provided
      + the ~adhocExtensions~ feature is enabled
      + otherwise, it gives a *warning*.

***** DONE Migration
  CLOSED: [2020-05-14 Thu 01:16]
  - ~open~ is a NEW modifier in Scala 3.

  - _To allow /cross compilation/ between Scala 2.13 and Scala 3.0 WITHOUT /warnings/,_
    the /feature warning/ for /ad-hoc extensions/ is produced only under ~-strict~.
    * It will be produced by default from Scala 3.1 on.

**** DONE Parameter Untupling
CLOSED: [2019-12-31 Tue 00:56]
For data like ~val xs: List[(Int, Int)]~,
- In Scala 2.x,
  use _EXPLICIT_ /pattern matching/ (partial function) decomposition:
  #+BEGIN_SRC scala
    xs map {
      case (x, y) => x + y
    }
  #+END_SRC

- Dotty allows the syntax:
  #+BEGIN_SRC scala
    xs map {
      (x, y) => x + y
    }

    // OR, EQUIVALENTLY:
    xs.map(_ + _)
  #+END_SRC

- Generally, a /function value/ with *n > 1 parameters* is _converted to_ a
  /pattern-matching closure/ using ~case~ if the expected type is a /unary
  function type/ of the form ~((T_1, ..., T_n)) => U~.

***** Reference

**** DONE Kind Polymorphism
CLOSED: [2020-07-24 Fri 23:48]
- Normally /type parameters/ in Scala are _partitioned into_ /kinds/.
  * /First-level types/ are /types/ of /values/.
  * /Higher-kinded types/ are /type constructors/ such as ~List~ or ~Map~.

- The /kind/ of a /type/ is indicated by the /TOP type/ of which it is a
  /subtype/.
  * /First-level types/ are /subtypes/ of ~Any~.

  * /Higher-kinded types/:
    + /Covariant/ SINGLE argument /type constructors/, such as ~List~, are
      /subtypes/ of ~[+X] =>> Any~;

    + The ~Map~ /type constructor/ is a /subtype/ of ~[X, +Y] =>> Any~.

- =from Jian=
  I remember when learning Haskell (long ago, need verify this memory by
  checking the book I read), we call types /kind-0 type/, /kind-1 type/,
  etc. When /kind/ is greater than 0, we call them /higher-kinded types/.

- A /type/ can be used ONLY as prescribed by its /kind/.
  * /Subtypes/ of ~Any~ *cannot* be applied to type arguments
  * whereas /subtypes/ of ~[X] =>> Any~ *must* be applied to a /type argument/,
    unless they are passed to /type parameters/ of the SAME /kind/.

- Sometimes we would like to have /type parameters/ that can have _more than one_
  /kind/, for instance to define an /implicit value/ that works for _parameters
  of *ANY* /kind/._
  * This is now possible through a form of (subtype) kind polymorphism. Kind
    polymorphism relies on the special type ~scala.AnyKind~ that can be used
    as an upper bound of a type. ~def f[T <: AnyKind] = ...~

- The actual /type arguments/ of ~f~ can then be /types/ of ARBITRARY /kinds/.
  So the following would all be legal:
  #+begin_src scala
    f[Int]
    f[List]
    f[Map]
    f[[X] =>> String]
  #+end_src

- We call /type parameters/ and /abstract types/ with an ~AnyKind~ /upper bound/
  /any-kinded types/.

- Since the ACTUAL /kind/ of an /any-kinded type/ is unknown, its usage must
  be heavily restricted:
  An /any-kinded type/ can be neither the type of a value, nor can it be
  instantiated with /type parameters/. So about the only thing one can do with
  an /any-kinded type/ is to pass it to another /any-kinded type argument/.
  Nevertheless, this is enough to achieve some interesting generalizations
  that work across /kinds/, typically through advanced uses of /implicits/.

- (todo: insert good concise example)
  =from Jian= Official =TODO= :-)

- Some technical details:
  ~AnyKind~ is a /synthesized class/ just like ~Any~, but *WITHOUT* any /members/.
  * It _extends NO other /class/._

  * It is declared ~abstract~ and ~final~,
    so it can be *NEITHER /instantiated/ NOR /extended/.*

- ~AnyKind~ plays a special role in /Scala's subtype system/:
  * It is a /supertype/ of *ALL other* /types/ no matter what their /kind/ is.

  * It is also assumed to be /kind-compatible/ with *ALL other* /types/.

  * Furthermore,
    + ~AnyKind~ is *treated as* a /higher-kinded type/ (so it CANNOT be used
      as a /type/ of values),

    + _BUT_ at the SAME TIME it has *NO /type parameters/* (so it cannot be
      instantiated).

- *NOTE*:
  This feature is considered _EXPERIMENTAL but STABLE_
  AND
  it can be disabled under /compiler flag/ (i.e. =-Yno-kind-polymorphism=).

**** DONE The ~Matchable~ Trait
CLOSED: [2020-12-15 Tue 20:57]
A new /trait/ ~Matchable~ controls the ability to /pattern match/.

***** The Problem
  The _Scala 3 standard library_ has a type ~IArray~ for /immutable arrays/
  that is defined like this:
  #+begin_src scala
    opaque type IArray[+T] = Array[_ <: T]
  #+end_src
  The ~IArray~ type offers /extension methods/ for ~length~ and ~apply~,
  BUT _not_ for ~update~; hence it _SEEMS_ values of type ~IArray~ *cannot be
  updated*.

  - "SEEMS" is not enough -- for /immutable arrays/, /update/ *should be
    forbidden*.

  - However, there is a _potential hole_ due to /pattern matching/.
    Consider:
    #+begin_src scala
      val imm: IArray[Int] = ...
      imm match
        case a: Array[Int] => a(0) = 1
    #+end_src
    1. The test will _SUCCEED at runtime_
      SINCE ~IArray~'s are represented as ~Array~'s at runtime.

    2. But if we allowed it,
      it would *break* the fundamental abstractn of immutable arrays.

    3. *Aside*:
      One could also achieve the same by casting:
      ~imm.asInstanceOf[Array[Int]](0) = 1~
      But that is not as much of a problem since in Scala ~asInstanceOf~ is
      understood to be _low-level_ and _unsafe_.
        By contrast, a /pattern match/ that compiles _without warning or error_
      *should NOT break abstractions.*

  - Note also that the problem is *NOT tied to* /opaque types/ as /match
    selectors/.
      The following slight variant with a value of /parametric type/ ~T~ as
    /match selector/ leads to the same problem:
    #+begin_src scala
      def f[T](x: T) = x match
        case a: Array[Int] => a(0) = 0

      f(imm)
    #+end_src

***** The Solution
  - There is a *new* /type/ ~scala.Matchable~ that controls /pattern matching/.

    1. When typing a /pattern match/ of a /constructor pattern/ ~C(...)~ or a
      /type pattern/ ~_: C~ it is required that the /selector type/ conforms
      to ~Matchable~.

    2. If that's NOT the case a WARNING is issued.

  - For instance when compiling the example at the start of this section we
    get:
    #+begin_src bash
      sc ../new/test.scala -source 3.1
      # -- Warning: ../new/test.scala:4:12 ---------------------------------------------
      # 4 |    case a: Array[Int] => a(0) = 0
      #   |            ^^^^^^^^^^
      #   |            pattern selector should be an instance of Matchable,
      #   |            but it has unmatchable type IArray[Int] instead
    #+end_src
    * To allow
      _migration from_ Scala 2 and cross-compiling _between_ Scala 2 and 3
      the warning is _turned on *only* for =-source 3.1-migration= or higher_.

  - ~Matchable~ is a ~universal trait~ with ~Any~ as its /parent class/.
    * It is extended by both ~AnyVal~ and ~AnyRef~.

    * Since ~Matchable~ is a /supertype/ of _EVERY concrete value_ or /reference
      class/
      it means that /instances/ of such /classes/ _can be matched_ *as before*.

    * However, /match selectors/ of the following types will produce a *warning*:
      + Type ~Any~:
        if pattern matching is required one should use Matchable instead.

      + Unbounded type parameters and abstract types:
        If pattern matching is required they should have an upper bound Matchable.

      + /Type parameters/ and /abstract types/ that are ONLY bounded by some
        /universal trait/:
        Again, ~Matchable~ should be added as a /bound/.

  - Here is the hierarchy of _toplevel_ /classes/ and /traits/ with their
    /defined methods/:
    #+begin_src scala
      abstract class Any:
        def getClass
        def isInstanceOf
        def asInstanceOf
        def ==
        def !=
        def ##
        def equals
        def hashCode
        def toString

      trait Matchable extends Any

      class AnyVal extends Any, Matchable
      class Object extends Any, Matchable
    #+end_src
    1. ~Matchable~ is currently a /marker trait/ _WITHOUT any methods_.

    2. Over time we might migrate /methods/ ~getClass~ and ~isInstanceOf~ to
      it, since these are closely related to pattern-matching.

***** TODO Matchable and Universal Equality - =NEW=

**** DONE The ~@threadUnsafe~ Annotation
CLOSED: [2019-12-31 Tue 04:24]

=FIXME= current title: The ~threadUnsafe~ annotation -- should be capitalized as the other titles

When the compiler see a ~@threadUnsafe lazy val~, it can pick a faster
mechanism to do the initialization.

- =from Jian= TODO TODO TODO
  Does this mean before introducing the ~threadUnsafe~ annotation, we only
  have one mechanism that initialize all ~lazy val~ in a /thread safe/
  way???

***** Examples
  #+begin_src scala
    import scala.annotation.threadUnsafe

    class Hello:
      @threadUnsafe lazy val x: Int = 1
  #+end_src

**** DONE The ~@targetName~ Annotation
CLOSED: [2020-11-22 Sun 04:16]
=FIXME= current title: The ~targetName~ annotation -- should be capitalized as the other titles

- ~@targetName~ annotation :: it is applied on a /method definition/ defines
  an _alternate name_ for the implementation of that /method/.

- Example:
  #+begin_src scala
    import scala.annotation.targetName

    object VecOps:
      extension [T](xs: Vec[T])
        @targetName("append")
        def ++= [T] (ys: Vec[T]): Vec[T] =  // ...
  #+end_src
  1. The ~++=~ operation is
      implemented (in /bytecode/ or /native code/) _under the name_ ~append~.

  2. We call the name mentioned in the ~@targetName~ /implementation name/.
      * A /implementation name (external name)/ affects the code that is generated

      * A /implementation name (external name)/ is the _NAME_ under which code
        _from OTHER languages_ can call the /method/.
        + For instance,
          ~++=~ could be invoked from Java like this (use its /implementation
          name (external name)/):
        #+begin_src scala
          VecOps.append(vec1, vec2)
        #+end_src
        =IMPORTANT=
        *ONLY* from _OTHER_ languages! You *can't* use the /implementation
        name/ _in Scala_.

****** Details
  1. ~scala.annotation.targetName~ takes a _SINGLE argument_ of /type/ ~String~.
      That string is called the /external name/ of the definition that's annotated.
      #+begin_src scala
        import scala.annotation.targetName

        targetName(externalName)
        // method definition
      #+end_src

  2. An ~@targetName~ annotation can be given for *ALL kinds* of definitions.
      =from Jian=
      TO BE VERIFIED:
      *NOT ONLY* for symbolic name; not only /methods/ or /funcitons/.

  3. The given /external name/ *must* be a _legal name_ for the defined
      entities on the _host platform_.
      =TODO= =???= =???= =???= =TODO=
      TO BE VERIFIED:
      * Legal JVM name for (JVM based) Scala???
      * Legal (???) name for (Native) Scala???
      * etc. ???

  4. It is *RECOMMENDED* that definitions with /symbolic names/ have a
      ~@targetName~ annotation.
      * This will establish an _alternate name_ that
        + is *EASIER* (than symbolic name) TO *SEARCH for*
        + will *avoid* cryptic encodings in _runtime diagnostics_

  5. Definitions with _names in backticks_ that are *NOT legal* _host platform
      names_ *should* also have a ~@targetName~ annotation.

****** Relationship with Overriding
  - ~@targetName~ annotations are SIGNIFICANT for matching _TWO_ /method
    definitions/ to decide whether they _conflict_ or /override/ each other:
    TWO /method dfinitions/ *match* _IF they have the SAME /name/, /signature/,
    and /erased name/._ Here,
    * The /signature/ of a definition consists of the _names_ of
      + the /erased types/ of all (value-) parameters
          [ =TODO= what does this "(value-)" mean??? ]
        AND
      + the /method/'s /result type/.

    * The _erased name_ of a /method definition/ is
      IF a ~@targetName~ annotation is give
      THEN /target name/
      ELSE its _defined name_

  - *CAN*
    This (the second point above) means that ~@targetName~ annotations can be
    used to *disambiguate* two /method definitions/ that would otherwise clash.
    For instance,
    #+begin_src scala
      def f(x: => String): Int = x.length

      def f(x: => Int): Int = x + 1  // error: double definition
    #+end_src
    The two definitions above clash since their _erased parameter types_ are
    both ~Function0~, which is the /type/ of the translation of a
    /by-name-parameter/.
      Hence they have the _SAME names and signatures_. *But we can _AVOID_ the
    clash* BY adding a ~@targetName~ annotation to either /method/ or to both
    of them. E.g.
    #+begin_src scala
      @targetName("f_string")
      def f(x: => String): Int = x.length

      def f(x: => Int): Int = x + 1  // OK
    #+end_src
    * This will produce /methods/ ~f_string~ and ~f~ in the generated code.

    * =from Jian=
      + This is not very useful if the Scala code that is NOT written for being
        called by other languages:
        - Use different names will be a better solution.
        - No one want to, IN PUER SCALA, use methods designed for different
            purposes with same name and indistinguishable if no /external name/.

      + The only exception is machine generated code.
        If the code is not written by human, this kind of issue may happen.
          However, generate proper distinguishable names is already resolved in
        all /hygienic macro systems/, and the solution can be borrowed to there.
        This makes this distinguish functions by /external names/ are by no means
        a good solution, except the scenarios that =Jian= I can't imagine by now.

  - *CAN'T*
    However, ~@targetName~ annotations are *NOT allowed* to BREAK /overriding
    relationships/ between two definitions that have otherwise the _SAME names
    and types_. So the following would be in error (=from Jian= modified by me):
    #+begin_src scala
      import annotation.targetName

      class A:
        def f: Int = 1

      class B extends A:
        @targetName("g") def f: Int = 2
    #+end_src
    The compiler reports here (=from Jian= modified by me):
    #+begin_src text
      -- Error: test.scala:6:23 ------------------------------------------------------
      6 |  @targetName("g") def f: Int = 2
        |                       ^
        |              error overriding method f in class A of type => Int;
        |                method f of type => Int should not have a @targetName annotation since the overridden member hasn't one either
    #+end_src
    * =IMPORTANT= =NEED FIX???= =FIXME= =???=
      =from Jian= I don't quite understand "the same /types/" at the end of each points. =TODO=
      The relevant _overriding rules_ can be summarized as follows:
      + Two members can *override* each other if their /names/ and /signatures/
        are the same, and they either have the same /erased names/ or the same
        /types/.

      + If two members *override*, then both their _erased names_ and their /types/
        *must* be the same.

    * =from Jian=
      =Re-Write=
      The relevant _overriding rules_ can be summarized as follows:
      #+begin_quote
      Two /memebers/ *CAN* /override/ each other if their /names/ and
      /signatures/ are the _SAME_. When this is guaranteed, there are two
      scenarios:
      + If two members *override* and both don't have ~@targetName~'s, no other
        requirement, and this is just like before, before we introduce
        ~@targetName~ into Scala 3.

      + If two members *override* and both have ~@targetName~'s, their /erased
        names/ must be the same.
      #+end_quote

    * =from Jian=
      By the rules above, we know the error in the above not compilable code
      example. Since ~f~ in ~B~ have the same /name/ and /signature/ as the
      ~f~ in ~A~, ~f~ in ~B~ *SHOULD* /override/ the one in ~A~, but two things
      are wrong (assume we don't change the name ~f~ that can be invoked in
      Scala):
      1. ~override~ is missing.
        We can first ignore ~@targetName~, only consider the code can be used in Scala.
        This is easy to be found out.
        Since this is Scala code, the requirements in Scala must be first guaranteed.

      2. (This should be considerd after adding ~override~ mentioned in 1.),
          ~@targetName("g")~ is missing for the ~f~ in ~A~.
          #+begin_src scala
            import annotation.targetName

            class A:
              def f: Int = 1

            class B extends A:
              @targetName("g") override def f: Int = 2
          #+end_src
          If this code is legal, one unreasonable thing will happen:
          The /override relationships/ are different in Scala and in other languages.
          This is not acceptable.

    * As usual, any /overriding relationship/ in the _generated code_ *must also be
      present* in the _original code_. So the following example would also be in error:
      #+begin_src scala
        import annotation.targetName

        class A:
          def f: Int = 1

        class B extends A:
          @targetName("f") def g: Int = 2
      #+end_src
      Here, the ORIGINAL methods ~g~ and ~f~ _do NOT *override* each other_
      since they have _DIFFERENT names_. BUT once we switch to /target names/,
      there is a clash that is reported by the compiler:
      #+begin_src text
        -- [E120] Naming Error: test.scala:4:6 -----------------------------------------
        4 |class B extends A:
          |      ^
          |      Name clash between defined and inherited member:
          |      def f: Int in class A at line 3 and
          |      def g: Int in class B at line 5
          |      have the same name and type after erasure.
        1 error found
      #+end_src

**** DONE New Control Syntax
CLOSED: [2020-12-04 Fri 13:03]
#+begin_src scala
  if x < 0 then
    "negative"
  else if x == 0 then
    "zero"
  else
    "positive"

  if x < 0 then -x else x

  while x >= 0 do x = f(x)

  for x <- xs if x > 0
  yield x * x

  for
    x <- xs
    y <- ys
  do
    println(x + y)

  try body
  catch case ex: IOException => handle
#+end_src
- =from Jian= The rules in details are listed in the docs.

- The rules in details:
  (=from Jian=
    proper INDENTATION is always required for the _new control syntax_, and
    we won't repeat here).
  * New ~if~ syntax:
    + with a ~then~ that FOLLOWS the ~if~-condition

  * ~while~-loop with ~do~ following the ~while~-condition
    =from Jian=
    Remember:
    *No* ~do ... while~ syntax is Scala 3.
    In Scala 3, ~do~ will only show up in the _new control syntax_.

  * For the enumerators of ~for~-expression,
    + /comprehensions/ still use ~yield~
    + /side effect loops/ use ~do~

  * New ~catch~ syntax:
    + _SINGLE_ case
      can be on the _same line_ as ~catch~.

    + _MULTIPLE_ cases
      these have to be appear within braces (just like in Scala-2) or an
      indented block.

***** Rewrites
  The Dotty compiler _can rewrite_ source code bidirectionally
  - old to new: option =-rewrite -new-syntax=
  - new to old: option =-rewrite -old-syntax=

**** DONE Optional Braces - =TODO= =Update Notes because of docs changes= =READ "Settings and Rewrites"=
CLOSED: [2020-12-30 Wed 02:00]
*As an /experimental feature/,*
Scala 3 _enforces some rules on indentation_ and _allows some occurrences
of braces {...} to be OPTIONAL_.

=FIXME= =RePhrase=
- It can be *turned off* with the /compiler flag/ =-no-indent=.
- Benefits:
  1. Some badly indented programs are *ruled out*,
      which means they are _flagged with WARNINGS._

  2. Some occurrences of braces ~{...}~ are *made optional*.
        Generally, the rule is that adding a pair of optional braces will NOT
      change the meaning of a well-indented program.

***** DONE Indentation Rules
  CLOSED: [2020-07-22 Wed 03:18]
  - The compiler
    * enforces *TWO* rules for well-indented programs,
    * flagging violations as _WARNINGS_. =from Jian= WHY *NOT* Errors???

  - The TWO rules are:
    1. In a brace-delimited region,
      no statement is allowed to start to the left of the first statement
      after the opening brace that starts a new line.

      * This rule is helpful for finding missing closing braces.
        It prevents errors like:
        #+begin_src scala
          if (x < 0) {
            println(1)
            println(2)

          println("done")  // error: indented too far to the left
        #+end_src

    2. If /significant indentation/ is _turned off_ (i.e. under Scala-2 mode OR
      under ~-no-indent~) and we are at the start of an indented sub-part of an
      expression, and the indented part ends in a newline, the next statement
      must start at an indentation width less than the sub-part.
      * This prevents errors where an opening brace was forgotten, as in
        #+begin_src scala
          if (x < 0)
            println(1)
            println(2)   // error: missing `{`
        #+end_src

  - These rules still leave _a lot of leeway_ how programs should be indented.
    For instance, they do *NOT impose* any restrictions on
    * indentation within expressions,

    * all statements of an indentation block line up exactly.
      =from Jian= I think this SHOULD be enforced

  - =IMPORTANT=
    The rules are _generally helpful in *pinpointing* the root cause of errors_
    related to _MISSING opening or closing braces_.

***** DONE Optinal Braces
  CLOSED: [2020-12-29 Tue 21:07]
  - The *compiler will insert* <indent> or <outdent> tokens at certain /line
    breaks/.
    * Grammatically, pairs of <indent> and <outdent> tokens have the _SAME_
      effect as pairs of braces ~{~ and ~}~.

  - The algorithm makes use of a stack ~IW~ of previously encountered
    indentation widths.
    * The stack initially holds a single element with a zero indentation width.
    * The current indentation width is the indentation width of the top of the
      stack.

  - There are TWO rules:
    1. An <indent> is inserted at a line break, if
      * An indentation region can start at the current position in the source,
        and
      * the first token on the next line has an indentation width *strictly
        greater than* (=from Jian= but no rule about HOW MUCH) the current
        indentation width

      An indentation region can start
      * after the leading parameters of an ~extension~, or
      * after a ~with~ in a /given instance/, or
      * after a "~:~ at end of line" token (see below)
      * after one of the following tokens:
        + ~=~
        + ~=>~
        + ~<-~
        + ~catch~
        + ~do~
        + ~else~
        + ~finally~
        + ~for~
        + ~if~
        + ~match~
        + ~return~
        + ~then~
        + ~try~
        + ~while~
        + ~yield~

      If an <indent> is inserted, the indentation width of the token on the
      next line is pushed onto IW, which makes it the NEW _current
      indentation width_.

    2. An <outdent> is inserted at a line break, if
      * the _first token_ on the _NEXT line_ has an indentation width
        *strictly less than* the _current indentation width_, and

      * the _last token_ on the _PREVIOUS line_ is *not* one of the following
        tokens which indicate that the previous statement continues:
        + ~then~
        + ~else~
        + ~do~
        + ~catch~
        + ~finally~
        + ~yield~
        + ~match~

      * the _first token_ on the _NEXT line_ is *not* a leading /infix operator/.

      If an <outdent> is inserted, the top element is popped from IW. If the
      indentation width of the token on the next line is still less than the
      new current indentation width, step (2) repeats. Therefore, several
      <outdent> tokens may be inserted in a row.

      An <outdent> is also inserted if the next token following a statement
      sequence starting with an <indent> closes an indentation region, i.e.
      is one of ~then~, ~else~, ~do~, ~catch~, ~finally~, ~yield~, ~}~, ~)~,
      ~]~ or ~case~.

      An <outdent> is finally inserted in front of a comma that follows a
      statement sequence starting with an <indent> if the indented region is
      itself enclosed in parentheses

  - It is an error if the indentation width of the token following an <outdent>
    does not match the indentation of some previous line in the enclosing
    indentation region. For instance, the following would be rejected.
    #+begin_src scala
      if x < 0 then
          -x
        else  // error: `else` does not align correctly
          x
    #+end_src

  - Indentation tokens are only inserted in regions where newline statement
    separators are also inferred: at the top-level, inside braces ~{...}~, but
    not inside parentheses ~(...)~, /patterns/ or /types/.

***** DONE Optinal Braces Around Template Bodies
  CLOSED: [2020-12-29 Tue 21:17]
  The Scala grammar uses the term /template body/ for the definitions of a
  class, trait, or object that are normally enclosed in braces. The braces
  around a template body can also be omitted by means of the following rule.

  - If at the point where a /template body/ can start there is a ~:~ that
    occurs at the end of a line, and that is followed by _at least one_
    indented statement, the recognized token is changed from _":"_ to
    _": at end of line"_. The latter token is one of the tokens that can
    start an indentation region.
    * The Scala grammar is changed so an optional ": at end of line" is allowed
      in front of a /template body/.

  - Analogous rules apply for
    * _enum bodies_
    * _local packages containing nested definitions_.

  - With these new rules, the following constructs are all valid:
    #+begin_src scala
      trait A:
        def f: Int

      class C(x: Int) extends A:
        def f = x

      object O:
        def f = 3

      new A:
        def f = 3

      package p:
        def a = 1

      package q:
        def b = 2
    #+end_src

  - In each case, the ~:~ at the end of line can be replaced without change of
    meaning by a pair of braces that enclose the following indented definition(s).

  - The syntax changes allowing this are as follows:
    #+begin_src text
      Template  ::= InheritClauses [colonEol] [TemplateBody]
      EnumDef   ::= id ClassConstr InheritClauses [colonEol] EnumBody
      Packaging ::= ‘package’ QualId [nl | colonEol] ‘{’ TopStatSeq ‘}’
      SimpleExpr::= ‘new’ ConstrApp {‘with’ ConstrApp} [[colonEol] TemplateBody]
    #+end_src
    Here, ~colonEol~ stands for _": at end of line"_, as described above.
    The lexical analyzer is modified so that a ~:~ at the end of a line is
    reported as ~colonEol~ if the parser is at a point where a ~colonEol~ is
    valid as next token.

***** DONE Optional Braces for Method Arguments
     CLOSED: [2022-12-07 Wed 01:36]
     *Starting with Scala 3.3*, a ~<colon>~ tokken is also recognized where a
     function argument would be expected.

     - Exmaples:
       #+begin_src scala
         times(10):
           println("ah")
           println("ha")


         credentials `++`:
           val file = Path.userHome / ".credentials"
           if file.exists
           then Seq(Credentials(file))
           else Seq.empty


         xs.map:
           x =>
             val y = x - 1
             y * y
       #+end_src

     - _What's more_,
       a ~:~ in these settings can ALSO be followed on the *SAME line* by
       * the *parameter part* and
       * the *arrow of a lambda*.
       So the last example could be compressed to this:
       #+begin_src scala
         xs.map: x =>
           val y = x - 1
           y * y
       #+end_src

     - Another legal example:
       #+begin_src scala
         xs.foldLeft(0): (x, y) =>
           x + y
       #+end_src

***** DONE Spaces vs Tabs
  CLOSED: [2019-12-29 Sun 03:29]
  - _Mix SPACES and TABS is legal._
    However, there is no rule defined about how many SPACES equals to a TAB, or
    vice versa. This means
    * "2 tabs, fllowed by 4 spaces" is strictly less than "2 tabs, followed by
      5 spaces",

    * BUT "2 tabs, followed by 4 spaces" is *incomparable*
      + to "6 tabs"
        or
      + to "4 spaces, followed by 2 tabs".

  - *CAUTION*:
    NOT all the legal ways are recommended!!!
    *Do NOT MIX Spaces and Tabs!!!*

***** DONE Indentation and Braces
  CLOSED: [2020-12-29 Tue 21:30]
  _Indentation can BE MIXED FREELY with braces._

  - For interpreting indentation inside braces,
    the following rules apply.
    1. The assumed indentation width of a multiline region enclosed in braces
      is _the indentation width of the *first token* that_ starts a new line
      after the opening brace.

    2. On encountering a closing brace ~}~, _as many <outdent> tokens as necessary_
      are inserted to close all open indentation regions inside the pair of
      braces.

***** DONE Special Treatment of Case Clauses
  CLOSED: [2020-07-22 Wed 03:36]
  - The _INDENTATION RULES_ for
    ~match~ expressions
    AND
    ~catch~ clauses
    are refined as follows:
    * An _indentation region_ is *OPENED*
      after a ~match~ or ~catch~ ALSO if the following ~case~ appears at the
      _indentation width that's current_ for the ~match~ (or ~catch~) itself.

    * In that case, the _indentation region_ *CLOSES*
      + at the _first token_ at that *SAME* _indentation width_ that is *not*
        a ~case~, or

      + at _ANY token_ with a *SMALLER* _indentation width_, whichever comes
        first.

  - Legal form (the ~println~ in example do not belong to ~match~ block)
    * Next leval indentation:
      #+begin_src scala
        x match
          case 1 => print("I")
          case 2 => print("II")
          case 3 => print("III")
          case 4 => print("IV")
          case 5 => print("V")

        println(".")
      #+end_src

    * Same level indentation:
      #+begin_src scala
        x match
        case 1 => print("I")
        case 2 => print("II")
        case 3 => print("III")
        case 4 => print("IV")
        case 5 => print("V")

        println(".")
      #+end_src

***** TODO Using Indentation to Signal Statement Continuation
***** DONE The End Marker
  CLOSED: [2020-12-30 Wed 01:33]
  Identation-based syntax has many advantages over other conventions,
  BUT it hard to discern when a large indentation region ends.

  - Braces are not much better
    since a brace by itself also contains NO information about what region is
    closed.

  - Solution ::
    Scala 3 offers an _optional_ ~end~ marker.

  - Example:
    #+begin_src scala
      def largeMethod(...) =
        ...
        if ... then ...
        else
          ...  // a large block
        end if
        ...  // more code
      end largeMethod
    #+end_src

  - An ~end~ marker consists of the /identifier/ ~end~ and a follow-on specifier
    token that together constitute all the tokens of a line.
    * Possible specifier tokens are identifiers or one of the following keywords
      + ~if~
      + ~while~
      + ~for~
      + ~match~
      + ~try~
      + ~new~
      + ~this~
      + ~val~
      + ~given~

  - /End markers/ are allowed in statement sequences.
    The specifier token ~s~ of an /end marker/ must correspond to the
    statement that precedes it. This means:
    * If the statement defines a /member/ ~x~ then ~s~ must be the same
      identifier ~x~.

    * If the statement defines a /constructor/ then ~s~ must be ~this~.

    * If the statement defines an /anonymous given/, then ~s~ must be ~given~.

    * If the statement defines an /anonymous extension/, then ~s~ must be
      ~extension~.

    * If the statement defines an /anonymous class/, then ~s~ must be ~new~.

    * If the statement is a ~val~ definition binding a /pattern/, then ~s~
      must be ~val~.

    * If the statement is a /package clause/ that refers to /package/ ~p~,
      then ~s~ must be the same identifier ~p~.

    * If the statement is an ~if~, ~while~, ~for~, ~try~, or ~match~ statement,
      then ~s~ must be that same token.

  - For instance, the following /end markers/ are ALL *legal*:
    #+begin_src scala
      package p1.p2:

        abstract class C:

          def this(x: Int) =
            this()
            if x > 0 then
              val a :: b =
                x :: Nil
              end val
              var y =
                x
              end y
              while y > 0 do
                println(y)
                y -= 1
              end while
              try
                x match
                  case 0 => println("0")
                  case _ =>
                end match
              finally
                println("done")
              end try
            end if
          end this

          def f: String
        end C

        object C:
          given C =
            new C:
              def f = "!"
              end f
            end new
          end given
        end C

        extension (x: C)
          def ff: String = x.f ++ x.f
        end extension

      end p2
    #+end_src

    * =from Jian=
      Though they are all legal,
      the next subsection will explain why they are *NOT GOOD*.

****** DONE When to Use End Markers
  CLOSED: [2020-07-22 Wed 03:43]
  It is recommended that /end markers/ are used _FOR_ CODE
  where
  the extent of an indentation region is *NOT* immediately apparent "at a
  glance".

  - People will have different preferences what this means,
    BUT one can _nevertheless_ give some guidelines that stem from experience.

  - An /end marker/ makes sense if
    * the construct *contains blank lines*, or
    * the construct is *long*, say _15-20 lines or more_,
    * the construct ends *heavily indented*, say _4 indentation levels or more_.

  - If none of these above criteria apply,
    it's often better to *not* use an /end marker/
    since the code will be just as clear and more concise.

  - If there are _SEVERAL ending regions_ that _SATISFY one of the criteria
    above_,
    we usually need an /end marker/ *ONLY for the _outermost_ closed region*.
    * Usually *better avoid* /CASCADES of end markers/ like the example above.

****** TODO Syntax

***** DONE Example
  CLOSED: [2020-12-30 Wed 01:57]
  =FIXME= =IMPROVE= =???=
  ~def Run~ ---> ~def run~
  #+begin_src scala
    enum IndentWidth:
      case Run(ch: Char, n: Int)
      case Conc(l: IndentWidth, r: Run)

      def <= (that: IndentWidth): Boolean = this match
          case Run(ch1, n1) =>
            that match
                case Run(ch2, n2) => n1 <= n2 && (ch1 == ch2 || n1 == 0)
                case Conc(l, r)   => this <= l
          case Conc(l1, r1) =>
            that match
                case Conc(l2, r2) => l1 == l2 && r1 <= r2
                case _            => false

      def < (that: IndentWidth): Boolean =
          this <= that && !(that <= this)

      override def toString: String =
          this match
          case Run(ch, n) =>
            val kind = ch match
                case ' '  => "space"
                case '\t' => "tab"
                case _    => s"'$ch'-character"
            val suffix = if n == 1 then "" else "s"
            s"$n $kind$suffix"
          case Conc(l, r) =>
            s"$l, $r"

    object IndentWidth:
      private inline val MaxCached = 40

      private val spaces = IArray.tabulate(MaxCached + 1)(new Run(' ', _))
      private val tabs = IArray.tabulate(MaxCached + 1)(new Run('\t', _))

      def run(ch: Char, n: Int): Run =
          if n <= MaxCached && ch == ' ' then
            spaces(n)
          else if n <= MaxCached && ch == '\t' then
            tabs(n)
          else
            new Run(ch, n)
      end run

      val Zero = run(' ', 0)
    end IndentWidth
  #+end_src

***** TODO Settings and Rewrites
  - =READ= and =NOTE=

**** TODO Safe Initialization - =TODO= =START=
Dotty implements *experimental* /safe initialization check/, which can be
enabled by the compiler option ~-Ysafe-init~.

***** DONE A Quick Glance
  CLOSED: [2020-07-25 Sat 00:58]
  To get a feel of how it works, we first show several examples below.

****** DONE Parent-Child Interaction
  CLOSED: [2020-07-25 Sat 00:52]
  #+begin_src scala
    abstract class AbstractFile:
      def name: String
      val extension: String = name.substring(4)

    class RemoteFile(url: String) extends AbstractFile
      val localFile: String = s"${url.##}.tmp"  // error: usage of `localFile` before it's initialized
      def name: String = localFile
  #+end_src
  The checker will report:
  #+begin_src text
    -- Warning: tests/init/neg/AbstractFile.scala:7:4 ------------------------------
    7 |	    val localFile: String = url.hashCode + ".tmp"  // error
      |	        ^
      |    Access non-initialized field value localFile. Calling trace:
      |     -> val extension: String = name.substring(4)	[ AbstractFile.scala:3 ]
      |      -> def name: String = localFile            	[ AbstractFile.scala:8 ]
  #+end_src
  + _FIX_:
    =from Jian=
    * Make ~localFile~ a ~lazy val~.
    * I'm not sure this fix is a fundamental fix, OR just hide a possible defect?

****** DONE Inner-Outer Interaction
  CLOSED: [2020-07-25 Sat 00:54]
  #+begin_src scala
    object Trees:
      class ValDef { counter += 1 }
      class EmptyValDef extends ValDef
      val theEmptyValDef = new EmptyValDef
      private var counter = 0  // error
  #+end_src
  The checker will report:
  #+begin_src text
    -- Warning: tests/init/neg/trees.scala:5:14 ------------------------------------
    5 |  private var counter = 0  // error
      |              ^
      |             Access non-initialized field variable counter. Calling trace:
      |              -> val theEmptyValDef = new EmptyValDef    [ trees.scala:4 ]
      |               -> class EmptyValDef extends ValDef       [ trees.scala:3 ]
      |                -> class ValDef { counter += 1 }	        [ trees.scala:2 ]
  #+end_src
  + _FIX_: =from Jian=
    Move the ~private var counter = 0~, and make it the first line in ~Trees~
    can

****** DONE Functions
  CLOSED: [2020-07-25 Sat 00:58]
  #+begin_src scala
    abstract class Parent:
      val f: () => String = () => this.message
      def message: String

    class Child extends Parent:
      val a = f()
      val b = "hello"           // error
      def message: String = b
  #+end_src
  The checker reports:
  #+begin_src text
    -- Warning: tests/init/neg/features-high-order.scala:7:6 -----------------------
    7 |  val b = "hello"           // error
      |      ^
      |Access non-initialized field value b. Calling trace:
      | -> val a = f()                              	[ features-high-order.scala:6 ]
      |   -> val f: () => String = () => this.message	[ features-high-order.scala:2 ]
      |    -> def message: String = b	                [ features-high-order.scala:8 ]
  #+end_src

***** DONE Design Goals
  CLOSED: [2020-07-25 Sat 03:25]
  - We establish the following design goals:
    + Sound ::
      checking _ALWAYS_ terminates,
      and is /sound/ for common and reasonable usage (over-approximation =???=)

    + Expressive ::
      support common and reasonable initialization patterns

    + Friendly ::
      * simple rules
      * minimal syntactic overhead
      * informative error messages

    + Modular ::
      modular checking, *NO* analysis *beyond* _project boundary_

    + Fast ::
      instant feedback

    + Simple ::
      no changes to core type system, explainable by a simple theory

  - By reasonable usage, we _INCLUDE_ the following use cases (but *not restricted
    to* them):
    *During initialization*
    + *Access* /fields/ on *this* and _outer_ *this*
    + *Call* /methods/ on *this* and _outer_ *this*
    + *Instantiate* /inner class/ and *call* /methods/ on such /instances/
    + *Capture* /fields/ in /functions/

***** TODO Principles
  - To achieve the goals, we uphold _THREE_ *fundamental principles*:
    * stackability
    * monotonicity
    * scopability

  - Stackability ::
    objects are initialized in /stack order/:
    if the /object/ ~b~ is created during the initialization of /object/ ~a~,
    then all /fields/ of ~b~ should become *initialized BEFORE* OR *at the same
    time* as ~a~.
    * Scala enforces this property _in syntax_ by demanding that all /fields/
      are *initialized at the end* of the /primary constructor/,
      *EXCEPT* for the language feature below:
      #+begin_src scala
        var x: T = _
      #+end_src

    * /Control effects/ such as /exceptions/ may *break* this property, as the
      following example shows:
      #+begin_src scala
        class MyException(val b: B) extends Exception("")

        class A:
          val b = try { new B } catch { case myEx: MyException => myEx.b }
          println(b.a)

        class B:
          throw new MyException(this)
          val a: Int = 1
      #+end_src
      + In the code above, the _control effect_ *teleport* the _uninitialized
        value_ wrapped in an /exception/.
          In the implementation, we avoid the problem by ensuring that the
        values that are thrown *MUST BE* /transitively initialized/.

        - transitively initialized :: =TODO= ??? =TODO= NO in the Docs

      + =from Jian= not in the official doc
        *WARNING* message:
        #+begin_src text
          [warn]  2 |  throw new MyException(this)
          [warn]    |                        ^^^^
          [warn]    |Promote the value under initialization to fully-initialized. Calling trace:
          [warn]    | -> throw new MyException(this)      [ SafeInitialization.scala:2 ]
          [warn] one warning found
        #+end_src

  - Monotonicity ::
    The _initialization status_ of an /object/ *should _NOT_ go backward*:
    /initialized fields/ continue to be initialized, a /field/ points to an
    /initialized object/ may *not* later point to an object _UNDER initialization_.
    As an example, the following code will be rejected:
    #+begin_src scala
      trait Reporter:
        def report(msg: String): Unit

      class FileReporter(ctx: Context) extends Reporter:
        ctx.typer.reporter = this  // `ctx` now reaches an uninitialized object
        val file: File = new File("report.txt")
        def report(msg: String) = file.write(msg)
    #+end_src
    * In the code above,
      *SUPPOSE* ~ctx~ points to a /transitively initialized object/.
      + Now the assignment at line 3 makes ~this~, which is *not* _fully
        initialized_, reachable from ~ctx~.
          This makes /field/ usage *DANGEROUS*, as it may INDIRECTLY reach
        /uninitialized fields/.

    * /Monotonicity/ is based on a well-known technique called /heap monotonic
      typestate/ to *ensure* /soundness/ in the presence of aliasing [1].
        Otherwise, either /soundness/ will be compromised or we have to *disallow*
      the usage of /ALREADY initialized fields/.

  - Scopability :: =TODO= =START=
    access to /partially constructed objects/ should be *controlled by* /static
    scoping/.
    * _Control effects_ like /coroutines/, /delimited control/, /resumable
      exceptions/ may *break* the property, as they can transport a value upper
      in the stack (not in scope) to be reachable from the current scope.

    * /Static fields/ can also serve as a teleport thus *breaks* this property.
      In the implementation, we need to _enforce_ that teleported values are
      /transitively initialized/.

  - The principles enable /local reasoning/ of initialization,
    which means _An INITIALIZED ENVIRONMENT can *only* produce INITIALIZED VALUES._

    * For example,
      + if the arguments to an ~new~-expression are /transitively initialized/,
        so is the result.

      + if the receiver and arguments in a /method call/ are /transitively
        initialized/, so is the result.

***** TODO Rules
  With the established principles and design goals, following rules are imposed:
  1. In an /assignment/ ~o.x = e~, the expression ~e~ may only point to
    /transitively initialized objects/.
    - This is how /monotonicity/ is enforced in the system.
      Note that in an /initialization/ ~val f: T = e~, the expression ~e~ may
      point to an /object/ _under initialization_.
        This requires a _DISTINCTION_ between /mutation/ and /initialization/
      in order to enforce different rules.
      * Scala has different syntax for them, it thus is not an issue.

  2. /Objects/ under /initialization/ may *NOT* be passed as /arguments/ to
    /method calls/.
    - *Escape of ~this~ in the /constructor/ is commonly regarded as an
      anti-pattern.* _HOWEVER_, escape of ~this~ as constructor arguments
      are are allowed, to support creation of cyclic data structures.
      The checker will ensure that the escaped non-initialized object is not
      used.
      * i.e.
        calling methods or accessing fields on the escaped object is NOT allowed.

  3. /Local definitions/ may *ONLY* refer to /transitively initialized/ /objects/.
      It means that in a /local definition/ ~val x: T = e~, the expression ~e~
    may *only* evaluate to /transitively initialized objects/.
    - The same goes for /local lazy variables and methods/.

    - This rule is again motivated for simplicity in reasoning about
      /initialization/:
      programmers may safely assume that all /local definitions/ *only* point to
      /transitively initialized objects/.

***** TODO Modularity - =RE-READ=
  - The analysis takes the /primary constructor/ of /CONCRETE classes/ as
    _entry points_. It follows _the /constructors/ of /super classes/,_ which
    might be defined in another project. The analysis takes advantage of
    /TASTy/ for analyzing /super classes/ defined in another project.

  - The *crossing of project boundary* raises a concern about /modularity/.
    It is well-known in _object-oriented programming_ that /superclass/ and
    /subclass/ are tightly coupled. For example, adding a /method/ in the
    /superclass/ requires recompiling the /child class/ for checking *safe
    overriding*.

    * /Initialization/ is no exception in this respect.
      The /initialization/ of an object essentially invovles close interaction
      between /subclass/ and /superclass/.
        If the /superclass/ is defined in another project, the *crossing of
      project boundary* _CANNOT_ be avoided for /soundness/ of the analysis.

    * Meanwhile, /inheritance/ across _project boundary_ has been under
      scrutiny and the introduction of /open classes/ mitigate the concern
      here.
        For example, the /initialization/ check could enforce that the
      /constructors/ of /open classes/ may not contain /method/ calls on ~this~
      or introduce annotations as a contract.

***** DONE Back Doors
  CLOSED: [2020-11-14 Sat 02:23]
  - Requirement:
    Occasionally you may want to *suppress warnings* reported by the checker.

  - Solution:
    * Either write ~e: @unchecked~ to tell the checker to *skip* checking for
      the expression ~e~, or

    * Use the old trick: mark some /fields/ as ~lazy~.

***** DONE Caveats
  CLOSED: [2020-11-14 Sat 02:24]
  - The system *CANNOT* provide _safety guarantee_
    when extending Java or Scala 2 classes.

  - /Safe initialization/ of _global objects_ is only partially checked.
    =TODO= =???=

***** TODO References
  1. Fähndrich, M. and Leino, K.R.M., 2003, July. [[https://www.microsoft.com/en-us/research/publication/heap-monotonic-typestate/][Heap monotonic typestates]].
    In International Workshop on Aliasing, Confinement and Ownership in
    object-oriented programming (IWACO).

  2. Fengyun Liu, Ondřej Lhoták, Aggelos Biboudis, Paolo G. Giarrusso, and
    Martin Odersky. 2020.
    [[https://dl.acm.org/doi/10.1145/3428243][A type-and-effect system for object initialization]]. OOPSLA, 2020.

**** TODO TypeTest
***** ~TypeTest~
  - When /pattern matching/ there are *TWO* situations where a /runtime type/
    test *MUST* be performed.
    * _an /explicit type/ test_ using the /ascription pattern notation/.
      #+begin_src scala
        (x: X) match
          case y: Y =>
      #+end_src

    * When an /extractor/ takes an /argument/ that is _NOT a /subtype/ of the
      /scrutinee type/._
      #+begin_src scala
        (x: X) match
          case y @ Y(n) =>

        object Y:
          def unapply(x: Y): Some[Int] = ...
      #+end_src

  - In both cases, _a /class/ test_ will be performed at /runtime/.
    BUT when _the /type/ test_ is on an /abstract type/ (/type parameter/ or
    /type member/), the test CANNOT be performed because the /type/ is *erased*
    at /runtime/.

  - A ~TypeTest~ can be provided to make this test possible.
    #+begin_src scala
      package scala.reflect

      trait TypeTest[-S, T]:
        def unapply(s: S): Option[s.type & T]
    #+end_src
    It provides an /extractor/ that returns its /argument typed/ as a ~T~ if
    the argument is a ~T~. It can be used to encode _a /type/ test_.
    #+begin_src scala
      def f[X, Y](x: X)(using tt: TypeTest[X, Y]): Option[Y] =
        x match
          case tt(x @ Y(1)) => Some(x)
          case tt(x)        => Some(x)
          case _            => None
    #+end_src

  - To avoid the /syntactic overhead/ the compiler will look for a /type test/
    *automatically* if it detects that the /type test/ is on /abstract types/.
    This means that
    * ~x: Y~ is transformed to ~tt(x)~
      and
    * ~x @ Y(_)~ to ~tt(x @ Y(_))~
    if there is a contextual ~TypeTest[X, Y]~ in scope. The previous code is
    equivalent to
    #+begin_src scala
      def f[X, Y](x: X)(using TypeTest[X, Y]): Option[Y] =
        x match
          case x @ Y(1) => Some(x)
          case x: Y     => Some(x)
          case _        => None
    #+end_src

  - We could create a /type test/ at call site where the /type test/ can be
    performed with /runtime class tests/ directly as follows
    #+begin_src scala
      val tt: TypeTest[Any, String] =
        new TypeTest[Any, String]
          def unapply(s: Any): Option[s.type & String] =
            s match
              case s: String => Some(s)
              case _         => None

      f[AnyRef, String]("acb")(using tt)
    #+end_src

  - The compiler will synthesize a new /instance/ of a /type test/ if none is
    found _in scope_ as:
    #+begin_src scala
      new TypeTest[A, B]:
        def unapply(s: A): Option[s.type & B] =
          s match
            case s: B => Some(s)
            case _    => None
    #+end_src
    If the /type tests/ *CANNOT* be done there will be an /unchecked warning/
    that will be raised on the case ~s: B => test~.

  - The most common ~TypeTest~ /instances/ are the ones that take ANY /parameters/
    (i.e. ~TypeTest[Any, T]~). To make it possible to use such /instances/ directly
    in /context bounds/ we provide the alias
    #+begin_src scala
      package scala.reflect

      type Typeable[T] = TypeTest[Any, T]
    #+end_src

    This alias can be used as

    #+begin_src scala
      def f[T: Typeable]: Boolean =
        "abc" match
          case x: T => true
          case _    => false

      f[String]  // true
      f[Int]     // false
    #+end_src

***** ~TypeTest~ and ~ClassTag~
  ~TypeTest~ is a replacement for functionality provided previously by
  ~ClassTag.unapply~.
  * Using ~ClassTag~ /instances/ was /unsound/ since /classtags/ can check
    *only* the /class component/ of a /type/.

  * ~TypeTest~ fixes that /unsoundness/.

  * ~ClassTag~ _type tests_ are _still supported_
    BUT a /warning/ will be emitted after 3.0.

***** Example
  Given the following abstract definition of ~Peano~ numbers that provides two
  /given instances/ of types ~TypeTest[Nat, Zero]~ and ~TypeTest[Nat, Succ]~
  #+begin_src scala
    import scala.refelct.*

    trait Peano:
      type Nat
      type Zero <: Nat
      type Succ <: Nat

      def safeDiv(m: Nat, n: Succ): (Nat, Nat)

      val Zero: Zero

      val Succ: SuccExtractor
      trait SuccExtractor {
        def apply(nat: Nat): Succ
        def unapply(succ: Succ): Some[Nat]
      }

      given typeTestOfZero: TypeTest[Nat, Zero]
      given typeTestOfSucc: TypeTest[Nat, Succ]
  #+end_src

  together with an implementation of ~Peano~ numbers based on type ~Int~

  #+begin_src scala
    object PeanoInt extends Peano:
      type Nat = Int
      type Zero = Int
      type Succ = Int

      def safeDiv(m: Nat, n: Nat): (Nat, Nat) = (m / n, m % n)

      val Zero: Zero = 0

      val Succ: SuccExtractor = new:
        def apply(nat: Nat): Succ = nat + 1
        def unapply(succ: Succ): Some(Nat) = Some(succ - 1)

      def typeTestOfZero: TypeTest[Nat, Zero] = new:
        def unapply(x: Nat): Option[x.type & Zero] =
          if x == 0 then Some(x) else None


      def typeTestOfSucc: TypeTest[Nat, Succ] = new:
        def unapply(x: Nat): Option[x.type & Succ] =
          if x > 0 then Some(x) else None
  #+end_src

  it is possible to write the following program

  #+begin_src scala
    @main def test =
      import PeanoInt.*

      def divOpt(m: Nat, n: Nat): Option[(Nat, Nat)] =
        n match
          case Zero        => None
          case s @ Succ(_) => Some(safeDiv(m, s))

      val two = Succ(Succ(Zero))
      val five = Succ(Succ(Succ(two)))

      println(divOpt(five, two))  // prints "Some((2, 1))"
      println(divOpt(two, five))  // prints "Some((0, 2))"
      println(divOpt(two, Zero))  // prints "None"
  #+end_src
  Note that without the ~TypeTest[Nat, Succ]~ the pattern ~Succ.unapply(nat: Succ)~
  would be unchecked.

**** TODO Experimental Definitions
***** Referrences to experimental definitions
***** Experimental inheritance
***** Experimental overriding
***** Test frameworks

**** TODO Binary Integer Literals
*** TODO Other Changed Features
**** TODO Programmatic Structural Types
***** TODO Motivation - =NEW=
     - Some usecases are more awkward in statically typed languages than in
       dynamically typed languages

     - Example: modelling database access
       1. With dynamically typed languages, it's quite natural to _model a /row/ as
         a /record/ or /object/_, and to select entries with simple dot notation
         (e.g. ~row.columnName~).

       2. Achieving the same experience in /statically typed language/ requires
         * defining a class for every possible row arising from database manipulation
           (including rows arising from joins and projections)
         * setting up a scheme to map between a row and the class representing it.

       3. This requires a large amount of boilerplate, which leads developers
         to trade the advantages of static typing for simpler schemes where
         colum names are represented as strings and passed to other operators
         (e.g. ~row.select("columnName")~). _This approach is unatural in both
         sides_
         * forgoes the advantages of static typing,
         * is still not as natural as the dynamically typed version.

     - Structural types help in situations where we would like to support simple
       dot notation in dynamic contexts without losing the advantages of static
       typing.
         They allow developers to use dot notation and configure how fields and
       methods should be resolved.

***** Example
     #+begin_src scala
       class Record(elems: (String, Any)*) extends Selectable:
         private val fields = elems.toMap
         def selectDynamic(name: String): Any = fields(name)

       type Person = Record {
         val name: String
         val age: Int
       }

       @main def main(args: Array[String]): Unit = {
         val person = Record("name" -> "Emma", "age" -> 42).asInstanceOf[Person]
         println(s"${person.name} is ${person.age} years old.")
         // Prints: Emma is 42 years old.
       }
     #+end_src

***** Using Java Reflection - =NEW=
***** Extensibility
     New instances of ~Selectable~ can be defined to *support means of access*
     _othr than_ /Java reflection/, which would enable usages such as the
     database access example given at the beginning of this document.

***** TODO Local Selectable Instances
***** TODO Relation with ~scala.Dynamic~
     TODO =from Jian= I need to learn more about ~scala.Dynamic~

**** DONE Rules for Operators
    CLOSED: [2020-11-30 Mon 02:18]
    - The rules for /infix operators/ have changed in some parts:
      1. a _method with alphanumeric named_ can be used as an /infix operator/
          *ONLY if* its definition carries an ~infix~ /modifier/.

      2. it is recommended (but not enforced) to augment definitions of /symbolic
          operators/ with ~@targetName~ /annotations/.

      3. Finally, a syntax change allows /infix operators/ to be written on the
          left in a multi-line expression.

***** DONE The ~infix~ Modifier
     CLOSED: [2020-11-30 Mon 02:07]
     - An ~infix~ modifier on a /method definition/ allows using the method as an
       _infix operation_.

     - Example:
       #+begin_src scala
         import scala.annotation.targetName

         trait MultiSet[T]:
           infix def union(other: MultiSet[T]): MultiSet[T]

           def difference(other: MultiSet[T]): MultiSet[T]

           @targetName("intersection")
           def *(other: MultiSet[T]): MultiSet[T]
         end MultiSet

         val s1, s2: MultiSet[Int]

         s1 union s2     // OK
         s1 `union` s2   // also OK, but unusual
         s1.union(s2)    // also OK

         s1.difference(s2)   // OK
         s1 `difference` s2  // also OK, but unusual
         s1 difference s2    // gives a deprecation warning

         s1 * s2    // OK
         s1 `*` s2  // also OK, but unusual
         s1.*(s2)   // also OK, but unusual
       #+end_src
       * *Infix operations involving alphanumeric operators are deprecated*,
         unless one of the following conditions holds:
         + the operator definition carries an ~infix~ /modifier/, or
         + the operator was compiled with Scala 2, or
         + the operator is followed by an opening brace. =TODO= =???= =TODO=

     - alphanumeric operator :: an operator *consisting ENTIRELY* of
       * letters
       * digits
       * ~$~
       * ~_~
       * any unicode character for which ~java.lang.Character.isIdentifierPart(c)~
         returns ~true~.

     - /Infix operations/ involving /symbolic operators/ are *ALWAYS* allowed, so
       ~infix~ is *redundant* for methods with _symbolic names_.

     - The ~infix~ /modifier/ can also _be given to a /type/:_
       #+begin_src scala
         infix type or[X, Y]
         val x: String or Int
       #+end_src

****** Motivation
      The purpose of the ~infix~ /modifier/ is to achieve consistency across a
      code base in how a method or type is applied. The idea is that the author
      of a method decides whether that method should be applied as an infix
      operator or in a regular application. Use sites then implement that
      decision consistently.

****** Details
      1. ~infix~ is a /soft modifier/.

      2. If a method override another, their ~infix~ /modifiers/ must agree --
          EITHER both or NONE

      3. ~infix~ can be given to a /method defintions/.
          The *first* /non-receiver parameter list/ of an ~infix~ method *must* define
          *exactly one* parameter. For example,
          #+begin_src scala
            infix def op(x: S): R                  // OK
            infix def op[T](x: T)(y: S): R         // OK
            infix def op[T](x: T, y: S): R         // error: two parameters

            extension (x: A)
              infix def op4(y: B): R          // OK
              infix def op5(y1: B, y2: B): R  // error: two parameters
          #+end_src

      4. ~infix~ can also be given to /type, trait or class definitions/
          that have *exactly two* /type parameters/. An /infix type/ like
          #+begin_src scala
            infix type op[X, Y]
          #+end_src
          can be applied using infix syntax, i.e. ~A op B~

      5. To smooth migration to Scala 3.0, alphanumeric operations will only be
          deprecated from Scala 3.1 onwards, or if the ~-source 3.1~ option is
          given in Dotty/Scala 3.

***** DONE The ~@targetName~ Annotation
     CLOSED: [2020-11-30 Mon 02:18]
     - It is *RECOMMENDED* that
       definitions of /symbolic operators/ carry a ~@targetName~ annotation (there
       is an independent "~@targetName~ annotation" entry in this document) that
       provides an encoding of the _operator with an ALPHANUMERIC NAME._

     - This has several benefits:
       * It helps *interoperability* between Scala and other languages.
         One can CALL a /Scala-defined symbolic operator/ FROM another language
         using its /target name/, which avoids having to remember the low-level
         encoding of the /symbolic name/.
         + If an _ALPHANUMERIC NAME_ is not provided, the compiler will use its
           own rule to create an _ALPHANUMERIC NAME_ -- then you need to remember
           this naming details when calling this function/method in other languages.

         + If you provide an _ALPHANUMERIC NAME_, you don't need to remember this
           _translation rule_.

       * It helps legibility of /stacktraces/ and OTHER /runtime diagnostics/, where
         the /user-defined alphanumeric name/ will be shown instead of the low-level
         encoding.

       * It serves *as a documentation tool* by providing an _alternative regular
         name_ as an alias of a /symbolic operator/.
         + This makes the definition also *easier to find in a search*.

***** DONE Syntax Change
     CLOSED: [2020-11-30 Mon 02:18]
     /Infix operators/ can now APPEAR *at the START OF LINES in a multi-line expression.*

     Examples:
     #+begin_src scala
       val str = "hello"
         ++ " world"
         ++ "!"

       def condition =
         x > 0
         || xs.exists(_ > 0)
         || xs.isEmpty
     #+end_src

     - Thanks to the *change* of /semicolon inference/.
       If NOT, lines in the example that start with /infix operators/ will be
       considered as SEPARATE sentence.
       * Previously, those expression would have been rejected,
         since the compiler's semicolon inference would have treated the
         continuations ~++ " world"~ or ~|| xs.isEmpty~ as separate statements.

     - To make this syntax work, the rules are modified to not infer semicolons
       in front of leading /infix operators/ (Scala 2 infers this).
       A *leading infix operator* is
       * a symbolic identifier such as ~+~, or ~approx_==~, or an identifier in
         backticks that

       * STARTS a new line, and

       * is NOT following a blank line, and

       * is followed by
         AT LEAST ONE whitespace character
         and
         a token that can start an expression.

       * Furthermore, if the operator appears on its own line, the next line must
         have at least the same indentation width as the operator.

     - Illustrate by examples:
       * The leading /infix operator/ should be followed by at least one space
         character (=from Jian= and then another operand).
         #+begin_src scala
             freezing
           | boiling
         #+end_src

       * No space, no infix operation
         #+begin_src scala
           freezing
           !boiling
         #+end_src

       * No following legal operand
         #+begin_src scala
           println("hello")
           ???
           ??? match { case 0 => 1 }
         #+end_src
         + The second line ~???~ doesn't have a following operand.

         + The thrid line ~???~ doesn't have a legal following operand -- ~match~
           is not a token that can start an expression.

**** DONE Wildcard Arguments in Types - =IMPORTANT= =Migration is COMPLICATED=
    CLOSED: [2020-11-07 Sat 00:44]
    - The syntax of /wildcard arguments in types/ has *changed* FROM ~_~ TO ~?~.

    - Examples:
      * ~List[?]~
      * ~Map[? <: AnyRef, ? >: Null]~

***** Motivation
  =from Jian=
  Give ~_~ syntax another semantics, and make semantics more consistent and
  flexible. One of the reason that Scala want to do this is that there exists
  a better synbol can convey the current ~_~ semantics -- ~?~. After doing this
  ~?~ in both Java and Scala has the same semantics.

  - We would like to use the underscore syntax ~_~ to stand for an /anonymous
    type parameter/, *aligning* it with its meaning in /value parameter lists/.
    So, just as ~f(\under{})~ is a shorthand for the lambda ~x => f(x)~ (we current
    have this in Scala 2), _in the future_ ~C[_]~ will be _a shorthand for the
    /type lambda/ ~[X] =>> C[X]~._
    * This makes /higher-kinded types/ easier to use.

  - The new ~_~ semantics also *removes the wart* that,
    * used AS a /type parameter/, ~F[_]~ means ~F~ is a /type constructor/

    * WHEREAS used AS a /type/, ~F[_]~ means it is a /wildcard (i.e. existential)
      type/.

  - In the future, ~F[_]~ will always mean the one thing,
    no matter where it is used.

  - We pick ~?~ as a _REPLACEMENT syntax_ for /wildcard types/, since it
    _ALIGNS WITH Java's syntax._

***** Migration Strategy
  - The migration to the new scheme is *complicated*,
    in particular since the /kind projector compiler plugin/ still uses the
    _reverse convention_, with ~?~ meaning /parameter placeholder/ _INSTEAD
    OF_ /wildcard/.
    * Fortunately, kind projector has added ~*~ as an *ALTERNATIVE syntax* for
      ~?~.

  - A step-by-step migration is made possible with the following measures:
    * _In Scala 3.0_,
      both ~_~ and ~?~ are legal names for /wildcards/.

    * _In Scala 3.1_,
      ~_~ is deprecated in favor of ~?~ as a name for a /wildcard/.
      A ~-rewrite~ option is available to rewrite one to the other.

    * _In Scala 3.2_,
      the meaning of ~_~ changes _FROM_ /wildcard/ _TO_ /placeholder for type
      parameter/.

    * The _Scala 3.1_ behavior is already available today under the ~-strict~
      setting.

  - To smooth the transition for codebases that use *kind-projector*, we adopt
    the following measures under the command line option ~-Ykind-projector~:
    * In Scala 3.0,
      ~*~ is _available_ as a /type parameter placeholder/.

    * In Scala 3.2,
      ~*~ is *DEPRECATED* in favor of ~_~.
      A ~-rewrite~ option is available to rewrite one to the other.

    * In Scala 3.3,
      ~*~ is *REMOVED* again, and all /type parameter placeholders/ will be
      expressed with ~_~.

  - These rules make it possible to cross build between Scala 2 using the
    /kind projector/ plugin and Scala 3.0 - 3.2 using the _compiler option_
    ~-Ykind-projector~.

  - There is also a migration path for users that want a _one-time transition_
    to syntax with ~_~ as a /type parameter placeholder/.
    With option ~-Ykind-projector:underscores~ Scala 3 will
    * regard ~_~ as a /type parameter placeholder/,
    * leaving ~?~ as the only syntax for wildcards.

  - To cross-compile with old Scala 2 sources, while using ~_~ a /placeholder/,
    you must use options ~-Xsource:3 -P:kind-projector:underscore-placeholders~
    together with a recent version of _kind-projector (0.13 and higher)_ and
    most recent versions of _Scala 2 (2.13.5 and higher and 2.12.14 and
    higher)_.

**** DONE Imports
    CLOSED: [2021-02-15 Mon 18:30]
    The syntax of /wildcard imports/ and /renaming imports/ has changed.
    The same change happens to the new added ~export~.

    - =from Jian=
      There is some restrictions in /renaming exports/, read the "Restrictions"
      part point 3.

***** DONE Wildcard Imports
  CLOSED: [2021-02-15 Mon 18:25]
  Use ~*~ insteand of ~_~.

  - Example:
    #+begin_src scala
      import scala.annotation.*  // imports everything in the annotation package
    #+end_src

  - If you want to import a member named ~*~ specifically,
    you can use backticks around it.
    #+begin_src scala
      object A:
        def * = ...
        def min = ...

      object B:
        import A.`*`  // imports just `*`

      object C:
        import A.`*`  // imports everything in A
    #+end_src

***** DONE Renaming Imports
  CLOSED: [2021-02-15 Mon 18:27]
  Use ~as~ instead of ~=>~.

  - A single renaming import no longer needs to be enclosed in braces.

  - Example:
    #+begin_src scala
      import A.{min as minimum, `*` as multiply}
      import Predef.{augmentString as _, *}
      import scala.annotation as ann
      import java as j
    #+end_src

****** DONE Migration
  CLOSED: [2021-02-15 Mon 18:30]
  - To support cross-building,
    Scala 3.0 supports the old import syntax that uses ~_~ and ~=>~ as well.

  - The old syntax will be dropped in a future versions.

  - Automatic rewritings from old to new syntax are offered under
    ~-source 3.1-migration -rewrite~.

****** TODO Syntax

**** TODO Changes in Type Inference - =TODO: WATCH=
    See
    - https://www.youtube.com/watch?v=lMvOykNQ4zs
    - https://www.youtube.com/watch?v=VV9lPg3fNl8

**** TODO Changes in Implicit Resolution
    This page describes *changes* to the /implicit resolution/ that apply both to
    the new ~given~'s and to the old-style ~implicit~'s in Dotty.
      /Implicit resolution/ uses a new algorithm which *caches* implicit results
    *more aggressively* for performance. There are also some changes that affect
    implicits on the language level.

    1. *EXPLICIT types* of /implicits/:
        #+begin_src scala
          class C {
            val ctx: Context = ...  // ok

            /*!*/ implicit val x = ...  // error: type must be given explicitly

            /*!*/ implicit def y = ...  // error: type must be given explicitly
          }

          val y = {
            implicit val ctx = this.ctx  // ok
            // ...
          }
        #+end_src
        + Scala 3:
          /Types/ of /implicit values/ and /implicit methods (_result types_)/
          *MUST be explicitly declared* -- no inferred types.
          * *EXCEPTION*:
            ONLY values in /local blocks/ where the /type/ may still be inferred.

        + Scala 2:
          *NO* /EXPLICIT types/ required!

    2. _Nesting_ is NOW _taken into account_ for selecting an /implicit/:
        #+begin_src scala
          def f(implicit i: C) = {
            def g(implicit j: C) = {
              implicitly[C]
            }
          }
        #+end_src
        + Scala 3:
          _Select ~j~, because ~j~ is in the immediate scope that is accessible by
          ~implicitly[C]~._
          * _Nesting_ is NOW _taken into account_ for selecting an /implicit/.
            This is different from Scala 2.

        + Scala 2:
          _This would have resulted in an *ambiguity error*._
          The previous possibility of an implicit search failure due to shadowing
            (where an implicit is hidden by a nested definition) no longer applies.

    3. /Package prefixes/ no longer contribute to the /implicit search scope/ of
          a /type/. Example:
        #+begin_src scala
          package p
            given a: A = A()

            object o:
            given b: B = B()
              type C
      #+end_src
            + Both ~a~ and ~b~ are visible as /impicits/ at the point of the definition
        of /type/ ~C~.
                However, a reference to ~p.o.C~ _OUTSIDE of package_ ~p~ will have *ONLY*
        ~b~ in its /implicit search scope/ but NOT ~a~.

      + In more detail, here are the rules for what contributes the /implicit
            scope/ of a /type/:
        * Definition:
            A reference is an anchor if it refers to an object, a class, a trait,
            an abstract type, an opaque type alias, or a match type alias.
                References to packages and package objects are anchors only under
            =-source:3.0-migration=.

        + Definition:
            The anchors of a type ~T~ is a set of references defined as follows:
        1. If ~T~ is a reference to an anchor, ~T~ itself plus, if ~T~ is of the
            form ~P#A~, the anchors of ~P~.

          2. If ~T~ is an alias of ~U~, the anchors of ~U~.

            3. If ~T~ is a reference to a type parameter, the union of the anchors of
          both of its bounds.

            4. If ~T~ is a singleton reference, the anchors of its underlying type,
          plus, if ~T~ is of the form (~P#x~).type, the anchors of ~P~.

          5. If ~T~ is the this-type ~o.this~ of a /static object/ ~o~, the anchors
          of a term reference ~o.type~ to that object.

          6. If ~T~ is some other type, the union of the anchors of each constituent
          type of ~T~.

        + Definition:
        The implicit scope of a type T is the smallest set S of term references
            such that
          1. If T is a reference to a class, S includes a reference to the /companion
          object/ of the class, if it exists, as well as the implicit scopes of all
              of T's parent classes.

        2. If T is a reference to an object, S includes T itself as well as the
              implicit scopes of all of T's parent classes.

        3. If T is a reference to an opaque type alias named A, S includes a
            reference to an object A defined in the same scope as the type, if
              it exists, as well as the implicit scope of T's underlying type or
          bounds.

            4. If T is a reference to an abstract type or match type alias named
          A, S includes a reference to an object A defined in the same scope
            as the type, if it exists, as well as the implicit scopes of T's
              given bounds.

          5. If T is a reference to an anchor of the form p.A then S also includes
              all term references on the path p.

          6. If T is some other type, S includes the implicit scopes of all anchors
            of T.

      4. The treatment of ambiguity errors has changed.
        If an ambiguity is encountered in some recursive step of an implicit
      search, the ambiguity is propagated to the caller.
        + Example:
            Say you have the following definitions:
        #+begin_src scala
            class A
            class B extends C
            class C
            implicit def a1: A
            implicit def a2: A
            implicit def b(implicit a: A): B
            implicit def c: C
          #+end_src
          and the query ~implicitly[C]~.

          + This query would now be classified as ambiguous. This makes sense, after
        all there are two possible solutions, ~b(a1)~ and ~b(a2)~, neither of
          which is better than the other and both of which are better than the
          third solution, ~c~. By contrast, Scala 2 would have rejected the
          search for ~A~ as ambiguous, and subsequently have classified the query
            ~b(implicitly[A])~ as a normal fail, which means that the alternative
          ~c~ would be chosen as solution!

        + Scala 2's somewhat puzzling behavior with respect to ambiguity has been
            exploited to implement the analogue of a "negated" search in implicit
        resolution, where a query ~Q1~ fails if some other query ~Q2~ succeeds
          and ~Q1~ succeeds if ~Q2~ fails. With the new cleaned up behavior these
            techniques no longer work. But there is now a new special type
        ~scala.util.NotGiven~ which implements negation directly. For any query
          type ~Q~, ~NotGiven[Q]~ succeeds if and only if the implicit search for
          ~Q~ fails.

    5. The treatment of /divergence errors/ has also changed.
          A _divergent_ implicit is treated as a *normal* failure, after which
      alternatives are still tried. This also makes sense:
          Encountering a /divergent implicit/ means that we assume that no finite
          solution can be found on the corresponding path, but another path can still
      be tried. By contrast, *most (but not all)* /divergence errors/ in Scala 2
        would terminate the /implicit search/ as a whole.

  6. In Scala-2
        /implicit conversions/ with /call-by-name parameters/
          *has a lower level of priority* relative to
      /implicit conversions/ with /call-by-value parameters/.
          Dotty *drops* this distinction. So the following code snippet would be
          _ambiguous in Dotty_:
      #+begin_src scala
          implicit def conv1(x: Int): A = new A(x)
            implicit def conv2(x: => Int): A = new A(x)
        def buzz(y: A) = ???
          buzz(1)  // error: ambiguous
        #+end_src

    7. The rule for picking a *most specific* alternative among a set of /overloaded/
        or /implicit alternatives/ is refined to take /context parameters/ into account.
          All else being equal, an alternative that takes some /context parameters/
        is taken to be less specific than an alternative that takes none.
          If both alternatives take /context parameters/, we try to choose between
        them as if they were methods with _regular parameters_. The following
        paragraph in the SLS is affected by this change:
          + Original version:
        #+begin_quote
          An alternative ~A~ is more specific than an alternative ~B~ if the relative
            weight of ~A~ over ~B~ is greater than the relative weight of ~B~ over ~A~.
        #+end_quote

          + Modified version:
        An alternative ~A~ is more specific than an alternative ~B~ if
          * the relative weight of ~A~ over ~B~ is greater than the relative weight
              of ~B~ over ~A~, or

          * the relative weights are the same, and ~A~ takes NO /implicit parameters/
              but ~B~ does, or

          * the relative weights are the same, both ~A~ and ~B~ take /implicit
            parameters/, and ~A~ is more specific than ~B~ if all /implicit parameters/
            in either alternative are replaced by _regular parameters_.

      8. The previous disambiguation of _implicits based on inheritance depth_ is
      *refined* to make it /transitive/.
          /Transitivity/ is important to _GUARANTEE_ that *search outcomes are
        compilation-order independent*.
        + Here's a scenario where the *previous rules* VIOLATED /transitivity/:
          #+begin_src scala
            class A extends B
            object A { given a ... }

            class B
            object B extends C { given b ... }

            class C { given c }
        #+end_src
          1. ~a~ is *more specific* than ~b~
              SINCE the /companion class/ ~A~ is a /subclass/ of the /companion
          class/ ~B~.

            2. ~b~ is *more specific* than ~c~
          SINCE /object/ ~B~ /extends/ /class/ ~C~.

          3. But ~a~ is *NOT more specific* than ~c~.
            This means if ~a~, ~b~, ~c~ are all applicable /implicits/, *it makes
            a difference in what order they are compared.*
              If we compare ~b~ and ~c~ first, we keep ~b~ and drop ~c~. Then,
            comparing ~a~ with ~b~ we keep ~a~. But if we compare ~a~ with ~c~
            first, we fail with an ambiguity error.

      + The new rules are as follows:
          An _implicit_ ~a~ defined in ~A~
          is *more specific* than
        an _implicit_ ~b~ defined in ~B~ if
          * ~A~ /extends/ ~B~, or

        * ~A~ is an /object/ and the /companion class/ of ~A~ /extends/ ~B~, or

          * ~A~ and ~B~ are /objects/, =TODO= =???= =TODO=
          - ~B~ does *not inherit* any /implicit members/ from base /classes/ (*),
              AND
            - the /companion class/ of ~A~ /extends/ the /companion class/ of ~B~.
            + Condition (*) is new.
                It is necessary to ensure that the defined relation is transitive.

  9. [//]: #todo: expand with precise rules

**** DONE Implicit Conversions
    CLOSED: [2020-11-07 Sat 02:25]
    - An /implicit conversion/, also called /view/, is a conversion that is applied
      by the compiler in several situations:
      1. When an expression ~e~ of type ~T~ is encountered, but the compiler needs
          an expression of type ~S~.

      2. When an expression ~e.m~ where ~e~ has type ~T~ but ~T~ defines no member
          ~m~ is encountered.

    - In those cases, the compiler LOOKS in the /implicit scope/ FOR a conversion
      (declared as ~given~ in Scala 3 or ~implicit~ in Scala 2 or Scala 3.0)
      that can convert an expression of type ~T~
      * to an expression of /type/ ~S~ to the first case above
        OR
      * to a /type/ that defines a /member/ ~m~ in the second case above.

    - This conversion can be either:
      1. An ~implicit def~ of type ~T => S~ or ~(=> T) => S~
      2. An /implicit value/ of type ~scala.Conversion[T, S]~

    - Defining an implicit conversion will emit a warning unless
      * the ~import scala.language.implicitConversions~ is _in scope_, =FIX=
        OR
      * the _flag_ ~-language:implicitConversions~ is given to the compiler.

    - =from Jian=
      Like other features that are considered should be restricted, and can be
      switched on by _flag_ or _import_, *use _import_ is always the preferred
      way* because of its *flexibility* -- limit the usage to a single file, or
      even a smaller scope.

***** Examples
  - The first example is taken from ~scala.Predef~. Thanks to this /implicit
    conversion/, it is possible to pass a ~scala.Int~ to a /Java method/ that
    expects a ~java.lang.Integer~
    #+begin_src scala
      import scala.language.implicitConversions

      implicit def int2Integer(x: Int): java.lang.Integer =
        x.asInstanceOf[java.lang.Integer]
    #+end_src
    * =from Jian=
      The above code use the legacy syntax because it tries to only emphasise
      the ~import scala.language.implicitConversions~ and the ~Conversion~.
      If re-write it in the new syntax, we have:
      #+begin_src scala
        import scala.language.implicitConversions

        given int2Integer: Conversion[Int, java.lang.Integer] =
          java.lang.Integer.valueOf(_)
      #+end_src

  - The second example shows how to use ~Conversion~ to define an ~Ordering~
    for an _ARBITRARY_ /type/, given existing ~Ordering~'s for other /types/:
    #+begin_src scala
      import scala.language.implicitConversions

      implicit def ordT[T, S](
        implicit conv: Conversion[T, S],
                ordS: Ordering[S]
      ): Ordering[T] =
        // `ordS` compares values of type `S`, but we can convert from `T` to `S`
        (x: T, y: T) => ordS.compare(x, y)

      class A(val x: Int)  // The type for which wewant an `Ordering`

      // Convert `A` to a type for which an `Ordering` is available:
      implicit val AToInt: Conversion[A, Int] = _.x

      implicitly[Ordering[Int]]  // Ok, exists in the standard library
      implicitly[Ordering[A]]    // Ok, will use the implicit conversion from
                                // `A` to `Int` and the `Ordering` for `Int`.
    #+end_src
    * =from Jian=
      The above code use the legacy syntax because it tries to only emphasise
      the ~import scala.language.implicitConversions~ and the ~Conversion~.
      If re-write it in the new syntax, we have:
      #+begin_src scala
        import scala.language.implicitConversions

        given ordT[T, S](
          using conv: Conversion[T, S],
                ordS: Ordering[S]
        ): Ordering[T] =
          // `ordS` compares values of type `S`, but we can convert from `T` to `S`
          (x: T, y: T) => ordS.compare(x, y)

        class A(val x: Int)  // The type for which wewant an `Ordering`

        // Convert `A` to a type for which an `Ordering` is available:
        given AToInt: Conversion[A, Int] = _.x

        summon[Ordering[Int]]  // Ok, exists in the standard library
        summon[Ordering[A]]    // Ok, will use the implicit conversion from
                              // `A` to `Int` and the `Ordering` for `Int`.
      #+end_src

**** TODO Changes in Overload Resolution - =TODO= =READING=
    /Overload resolution/ in Dotty *improves* on Scala 2 in _TWO_ ways.
    - it takes *ALL* /argument lists/ into account
      _instead of_
      just the *first* /argument list/.

    - it can *infer* /parameter types/ of /function values/ *even if they are in
      the _FIRST_ /argument list/.*

***** Looking Beyond the First Argument List
     - Example:
       Code legal in Scala 3, while it results in an ambiguous overload error in Scala 2:
       + Example 1:
         #+begin_src scala
           def f(x: Int)(y: String): Int = 0
           def f(x: Int)(y: Int): Int = 0

           f(3)("")
         #+end_src

       + Example 2:
         #+begin_src scala
           def g(x: Int)(y: Int)(z: Int): Int = 0
           def g(x: Int)(y: Int)(z: String): Int = 0

           g(2)(3)(4)     // ok
           g(2)(3)("")    // ok
         #+end_src

***** Parameter Types of Function Values
***** Default Arguments Are No longer Relevant for Prioritization

**** DONE Match Expressions
    CLOSED: [2020-05-24 Sun 22:53]
    The /syntactical precedence/ of /match/ expressions has been *changed*.

    - ~match~ is still a keyword,
      but it is used like an /alphabetical operator/.

    - This has several consequences:
      1. ~match~ expressions can be chained:
          #+begin_src scala
            xs match
              case Nil => "empty"
              case _   => "nonempty"
            match
              case "empty"    => 0
              case "nonempty" => 1
          #+end_src

      2. ~match~ may follow a /period/:
          #+begin_src scala
            if xs.match
              case Nil => false
              case _   => true
            then "nonempty"
            else "empty"
          #+end_src

      3. The scrutinee of a ~match~ expression must be an ~InfixExpr~.
          * Previously the scrutinee could be _followed by_ a type ascription ~: T~,
            but this is *no longer supported*.

          * So ~x : T match { ... }~ in Scala 3 now has to be written
            ~(x: T) match { ... }~.

***** Syntax

**** DONE Vararg Splices
    CLOSED: [2023-05-25 Thu 18:56]
    The syntax of /vararg splices/ in _patterns_ and _function arguments_ has
    changed!

    - The *new syntax* uses a _postfix ~*~,_
      ANALOGOUSLY TO
      how a /vararg parameter/ is declared.
      * NEW:
        #+begin_src scala
          val arr = Array(0, 1, 2, 3)
          val lst = List(arr*)                   // vararg splice argument
          lst match
            case List(0, 1, xs*) => println(xs)  // binds xs to Seq(2, 3)
            case List(1, _*)     =>              // wildcard pattern
        #+end_src

      * OLD:
        this will be phased out.
        #+begin_src scala
          val lst = List(arr: _*)    // syntax error
          lst match
            case List(0, 1, xs @ _*) // ok, equivalent

        #+end_src

***** Syntax
***** Compatibility considerations
     To enable /cross compilation/ between Scala 2 and Scala 3, the compiler will
     accept both the old and the new syntax.

     - Under the ~-source future~ setting,
       an error will be emitted when the old syntax is encountered.

     - An *automatic rewrite* from old to new syntax is offered under
       ~-source future-migration~.

**** DONE Pattern Bindings
    CLOSED: [2020-05-25 Mon 11:03]
    - In Scala 2, /pattern bindings/ in ~val~ definitions and ~for~ expressions are
      *LOOSELY typed*.
      * Potentially failing matches are still _ACCEPTED at /compile-time/,_
        but may influence the program's /runtime/ behavior.

    - From Scala 3.2 on, /type checking/ rules will be tightened so that _warnings
      are *REPORTED* at /compile-time/ instead._

***** Bindings in Pattern Definitions
     - Exmaple 1:
       _Code that can pass Scala 2 /type checking/ but fail at /runtime/_
       #+begin_src scala
         val xs: List[Any] = List(1, 2, 3)
         val (x: String) :: _ = xs
       #+end_src
       * This code gives a compile-time warning in Scala 3.2 (and also earlier Scala 3.x under the ~-strict~
         setting or Scala 3.1 by default.

       * It will fail at runtime with a ~ClassCastException~ in Scala 2.

     - In Scala 3.1, a /pattern binding/ is *ONLY allowed* if the pattern is
       /irrefutable/, that is, if the right-hand side's type CONFORMS TO the
       pattern's type.
       + For instance, the following is OK:
         #+begin_src scala
           val pair = (1, true)
           val (x, y) = pair
         #+end_src

     - Exmaple 2:
       Sometimes one wants to decompose data anyway, even though the pattern is
       /refutable/.

       For instance, if at some point one knows that a list elems is non-empty
       one might want to decompose it like this:
       #+begin_src scala
         val first :: rest = elems  // error in Scala 3.1; work in Scala 2
       #+end_src
       * Use ~@unchecked~ to avoid the error:
         #+begin_src scala
           val first :: rest = elems: @unchecked  // OK
         #+end_src

***** Pattern Bindings in ~for~ Expressions
     - In Scala 2, /pattern bindings/ in ~for~ expressions do _implicit filtering_,
       and filter out data that are not matched.
       * In Scala 3, apply this _implicit filtering_ *ONLY when* a ~case~ shows up
         before the pattern -- this is a new syntax! Scala 2 syntax no longer has
         the implicit filtering semantics.

     - Example (in Scala 3.1):
       * Usage in Scala 2 can fail becuase of the semantics change.
         #+begin_src scala
           val elems: List[Any] = List((1, 2), "hello", (3, 4))
           for ((x, y) <- elems) yield (y, x) // error: pattern's type (Any, Any) is more specialized
                                             // than the right hand side expression's type Any
         #+end_src

       * Make implicit filtering available by using the ~case~:
         #+begin_src scala
           for (case (x, y) <- elems) yield (y, x)  // returns List((2, 1), (4, 3))
         #+end_src

***** Syntax Changes
     There are *TWO syntax CHANGES* relative to Scala 2:
     - /pattern definitions/ can carry ascriptions such as ~: @unchecked~.
     - /generators/ in ~for~ expressions may be prefixed with ~case~.

***** Migration
     - The new syntax is supported in Dotty and Scala 3.0.

     - However, to enable smooth cross compilation between Scala 2 and Scala 3,
       * In Scala 3.0, the changed behavior and additional type checks are *only
         enabled under the ~-strict~ setting*.

       * In Scala 3.1+, they will be enabled by default.

**** DONE Option-less Pattern Matching - =FIX TITLE= =RE-READ= - =Further simplification will come, no need to read now=
    CLOSED: [2020-09-25 Fri 00:37]
    =FIXME= current title: Option-less pattern matching -- should be capitalized as the other titles

    - Dotty implementation of /pattern matching/ was GREATLY *simplified* compared
      to Scala 2.
        From a user perspective, this means that Scala 3 generated patterns are a
      lot easier to debug as
      * _variables_ all show up in debug modes
      * _positions_ are correctly preserved

    - Dotty supports a *superset* of Scala 2 /extractors/.

    - CAUTION:
      *There are plans for further simplification*,
      in particular to factor out /product match/ and /name-based match/ into a
      SINGLE type of /extractor/.

***** DONE Extractors
     CLOSED: [2020-09-25 Fri 00:37]
     /Extractors/ are objects that expose a /method/ ~unapply~ or ~unapplySeq~:
     - fixed-arity extractors :: /extractor/ for /patterns of fixed arity/:
       #+begin_src scala
         def unapply[A](x: T)(using x: B): U
       #+end_src

     - variadic extractors :: /extractor/ for /variadic patterns/:
       #+begin_src scala
         def unapplySeq[A](x: T)(using x: B): U
       #+end_src

****** Fixed-Arity Extractors
      /Fixed-arity extractors/ expose the following signature:
      #+begin_src scala
        def unapply[A](x: T)(using x: B): U
      #+end_src
      - The type ~U~ conforms to
        * one of the following matches:
          + /Boolean match/
          + /Product match/

          OR

        * the type ~R~:
          #+begin_src scala
            type R = {
              def isEmpty: Boolean

              def get: S
            }
          #+end_src
          Here ~S~ conforms to one of the following matches:
          + single match
          + name-based match

      - *Precedence* of these forms:
        ~unapply~ form > /single match/ > /name-based match/

      - A usage of a /fixed-arity extractor/ is irrefutable if one of the following
        condition holds:
        * ~U~ = ~true~
        * the /extractor/ is used as a /product match/
        * ~U~ = ~Some[T]~ *(for Scala 2 compatibility)*
        * ~U <: R~ and ~U <: { def isEmpty: false }~

****** Variadic Extractors
      Variadic extractors expose the following signature:
      #+begin_src scala
        def unapplySeq[A](x: T)(using x: B): U
      #+end_src
      - The type U conforms to one of the following matches:
        * /sequence match/
        * /product-sequence match/

      - Or ~U~ conforms to the /type/ ~R~:
        #+begin_src scala
          type R = {
            def isEmpty: Boolean
            def get: S
          }
        #+end_src
        Here ~S~ conforms to one of the _TWO_ /matches/ above.

      - *Precedence* of these forms:
        ~unapplySeq~ form > /sequence match/ > /product-sequence match/

      - A usage of a /variadic extractor/ is irrefutable if one of the following
        conditions holds:
        * the /extractor/ is used directly as a
          + /sequence match/
            OR
          + /product-sequence match/
        * ~U~ = ~Some[T]~ *(for Scala 2 compatibility)*
        * ~U <: R~ and ~U <: { def isEmpty: false }~

***** DONE Boolean Match
     CLOSED: [2020-09-24 Thu 23:44]
     - Criterion:
       * ~U =:= Boolean~
       * Pattern-matching on exactly *0* patterns

     - Example:
       #+begin_src scala
         object Even {
           def unapply(s: String): Boolean = s.size % 2 == 0
         }

         "even" match {
           case s @ Even() => println(s"$s has an even number of characters")
           case s          => println(s"$s has an odd number of characters")
         }
         // even has an even number of characters
       #+end_src

***** DONE Product Match
     CLOSED: [2020-09-24 Thu 23:44]
     - Criterion:
       * ~U <: Product~

       * N > 0 is the maximum number of consecutive (parameterless ~def~ or ~val~)
         ~_1: P1~ ... ~_N: PN~ members in ~U~

       * Pattern-matching on EXACTLY *N* patterns with types P1, P2, ..., PN

     - Example:
       #+begin_src scala
         class FirstChars(s: String) extends Product {
           def _1 = s.charAt(0)
           def _2 = s.charAt(1)

           // Not used by pattern matching: Product is only used as a marker trait.
           def canEqual(that: Any): Boolean = ???
           def productArity: Int = ???
           def productElement(n: Int): Any = ???
         }

         object FirstChars {
           def unapply(s: String): FirstChars = new FirstChars(s)
         }

         "Hi!" match {
           case FirstChars(char1, char2) =>
             println(s"First: $char1; Second: $char2")
         }
         // First: H; Second: i
       #+end_src

***** DONE Single Match
     CLOSED: [2020-09-24 Thu 23:46]
     - Criterion:
       If there is exactly *1* pattern, pattern-matching on 1 pattern with type ~U~

     - Example:
       #+begin_src scala
         class Nat(val x: Int) {
           def get: Int = x
           def isEmpty = x < 0
         }

         object Nat {
           def unapply(x: Int): Nat = new Nat(x)
         }

         5 match {
           case Nat(n) => println(s"$n is a natural number")
           case _      => ()
         }
         // 5 is a natural number
       #+end_src

***** DONE Name-based Match
     CLOSED: [2020-09-24 Thu 23:51]
     - Criterion:
       * N > 1 is the maximum number of consecutive (parameterless ~def~ or ~val~)
         ~_1: P1~ ... ~_N: PN~ members in ~U~

       * Pattern-matching on EXACTLY ~N~ patterns with types P1, P2, ..., PN

     - Example:
       #+begin_src scala
         object ProdEmpty {
           def _1: Int = ???

           def _2: String = ???

           def isEmpty = true
           def get = this

           def unapply(s: String): this.type = this
         }

         "" match {
           case ProdEmpty(_, _) => ???
           case _               => ()
         }
       #+end_src

***** DONE Sequence Match
     CLOSED: [2020-09-25 Fri 00:30]
     - Criterion:
       * ~U <: X~, ~T2~ and ~T3~ conform to ~T1~
         #+begin_src scala
           type X = {
             def lengthCompare(len: Int): Int // or, `def length: Int`
             def apply(i: Int): T1
             def drop(n: Int): scala.Seq[T2]
             def toSeq: scala.Seq[T3]
           }
         #+end_src

       * Pattern-matching on EXACTLY *N* simple patterns with types ~T1~, ~T1~, ...,
         ~T1~, where *N* is the _runtime size_ of the sequence, or

       * Pattern-matching on >= N simple patterns and a /vararg pattern/ (e.g.,
         ~xs: _*~) with types ~T1~, ~T1~, ..., ~T1~, ~Seq[T1]~, where *N* is the
         _minimum size_ of the sequence.

     - Example:
       #+begin_src scala
         object CharList {
           def unapplySeq(s: String): Option[Seq[Char]] = Some(s.toList)
         }

         "example" match {
           case CharList(c1, c2, c3, c4, _, _, _) =>
             println(s"$c1,$c2,$c3,$c4")

           case _ =>
             println("Expected *exactly* 7 characters!")
         }
         // e,x,a,m
       #+end_src

***** DONE Product-Sequence Match
     CLOSED: [2020-09-25 Fri 00:36]
     - Criterion:
       * ~U <: Product~

       * N > 0 is the _maximum number_ of consecutive (parameterless def or val)
         ~_1: P1~ ... ~_N: PN~ members in ~U~

       * ~PN~ conforms to the signature ~X~ defined in /Seq Pattern/

       * Pattern-matching on EXACTLY *>= N* patterns, the first *N - 1* patterns
         have types P1, P2, ... P(N-1), the type of the remaining patterns are
         determined as in /Seq Pattern/.

     - Example:
       #+begin_src scala
         class Foo(val name: String, val children: Int*)
         object Foo {
           def unapplySeq(f: Foo): Option[(String, Seq[Int])] =
             Some((f.name, f.children))
         }

         def foo(f: Foo) = f match {
           case Foo(name, ns : _*)       => ...
           case Foo(name, x, y, ns : _*) => ...
         }
       #+end_src

***** TODO Type testing
     /Abstract type/ testing with ~ClassTag~ is replaced with ~TypeTest~ or the
     alias ~Typeable~.
     - /pattern/ ~_: X~ for an /abstract type/ requires a ~TypeTest~ _in scope_

     - /pattern/ ~x @ X()~ for an unapply that takes an /abstract type/ requires a
       ~TypeTest~ _in scope_

**** DONE Automatic Eta Expansion
    CLOSED: [2020-05-25 Mon 10:20]
    The _conversion of METHODS into FUNCTIONS_ has been improved and happens
    *automatically* for /methods/ with one or more parameters.
    - Example:
      #+begin_src scala
        def m(x: Boolean, y: String)(z: Int): List[Int]
        // automatically create a function value of type
        // `(Boolean, String) => Int => List[Int]`
        // without explicit type annotation.
        val f1 = m

        // automatically create a function value of type
        // `Int => List[Int]`
        // without explicit type annotation.
        val f2 = m(true, "abc")
      #+end_src

    - The syntax ~m \under{}~ *is _NO LONGER_ needed* and *will be _DEPRECATED_ in the future.*

***** Automatic eta-expansion and nullary methods
     /Automatic eta expansion/ does *NOT apply* to /"nullary" methods/ that take
     an empty parameter list.
     - Given a simple reference to ~next~ does *NOT auto-convert* to a function.
       One has to write explicitly ~() => next()~ to achieve that.
       * Once again since the ~_~ _is going to be DEPRECATED_ it's better to write
         it this way rather than ~next _~.

     - The _REASON_ for *excluding* /nullary methods/ from /automatic eta expansion/:
       that Scala implicitly inserts the ~()~ argument, which would *conflict* with
       /eta expansion/.
       * _Automatic ~()~ insertion_ is _limited_ (see "Dropped: Auto-Application)
         in Dotty, but the fundamental ambiguity remains.

**** TODO Changes in Compiler Plugins
***** Using Compiler Plugins
***** Writing a Standard Compiler Plugin
***** Writing a Research Compiler Plugin

**** TODO Lazy Vals Initialization - =FIX TITLE=
    =FIXME= current title: Lazy Vals initialization -- should be capitalized as the other titles

***** Motivation
***** Implementation
***** Note on recursive lazy vals
***** Reference
     - SIP-20

**** DONE Main Methods
    CLOSED: [2020-05-24 Sun 22:31]
    Scala 3 offers a new way to define programs that can be invoked from the command line:
    _A ~@main~ /annotation/ on a /method/ turns this /method/ into an executable program._

    - Example:
      #+begin_src scala
        @main def happyBirthday(age: Int, name: String, others: String*): Unit =
          val suffix =
            age % 100 match
              case 11 | 12 | 13 => "th"
              case _ =>
                age % 10 match
                  case 1 => "st"
                  case 2 => "nd"
                  case 3 => "rd"
                  case _ => "th"

          // =FIXME= Add ! after $name
          val bldr = new StringBuilder(s"Happy $age$suffix birthday, $name")
          for other <- others do bldr.append(" and ").append(other)
          bldr.toString
      #+end_src
      This would generate a main program ~happyBirthday~ that could be called like this
      =FIXME=
      #+begin_src bash
        scala happyBirthday 23 Lisa Peter
        # Happy 23rd birthday, Lisa and Peter!
      #+end_src

    - A ~@main~ annotated method can be written either
      * at the top-level
        OR
      * in a statically accessible object.

    - Parameters of the ~@main~ method:
      * the ~@main~ method can have an _ARBITRARY number_ of parameters.

      * For each parameter type there *must be* an instance of the
          ~scala.util.FromString~ /type class/ that is used to
      _convert_ an *argument string* _to_ the *required parameter type*.

    * The _parameter list_ of a ~@main~ method can end in a repeated parameter
        that then takes all remaining arguments given on the command line.

    - The program implemented from a @main method checks that there are enough
      arguments on the command line to fill in all parameters, and that argument
      strings are convertible to the required types. If a check fails, the
      program is terminated with an error message.
      * Examples:
        #+begin_src bash
          scala happyBirthday 22
          # Illegal command line after first argument: more arguments expected

          scala happyBirthday sixty Fred
          # Illegal command line: java.lang.NumberFormatException: For input string: "sixty"
        #+end_src

    - Code generation:
      The Scala compiler generates a program from a ~@main~ method ~f~ as follows:
      1. It creates a /class/
          * name ~f~
          * in the package where the ~@main~ method was found

    2. The generated /class/ has a /static method/ ~main~ with the *usual*
          /signature/: it takes an ~Array[String]~ as argument and returns ~Unit~.

        3. The generated ~main~ /method/
          * calls /method/ ~f~ with arguments converted using methods in the
            ~scala.util.CommandLineParser~ object.

    - Code generation example:
    #+begin_src scala
          final class happyBirthday:
        import scala.util.CommandLineParser as CLP
          <static> def main(args: Array[String]): Unit =
            try
              happyBirthday(
                CLP.parseArgument[Int](args, 0),
                CLP.parseArgument[String](args, 1),
                CLP.parseRemainingArguments[String](args, 2))
            catch
              case error: CLP.ParseError => CLP.showError(error)
      #+end_src
      * NOTE:
        The ~<static>~ modifier above expresses that the main method is
        generated as a /static method/ of /class/ ~happyBirthDay~.
          It is *NOT* available for user programs in Scala. Regular "static"
        members are generated in Scala using objects instead.

    - ~@main~ methods are the recommended scheme to generate programs that can be
      invoked from the command line in Scala 3.

    - They replace the previous scheme to write program as objects with a special
      ~App~ parent class. In Scala 2, ~happyBirthday~ could be written also like this:
      #+begin_src scala
        object happyBirthday extends App:
          // needs by-hand parsing of arguments vector
          // ...
      #+end_src
      * The previous functionality of ~App~, which relied on the "magic"
        ~DelayedInit~ trait, is *no longer available*.

      * ~App~ still exists in limited form for now,
        but
        + it does *not support* /command line arguments/
        + it will be *deprecated* in the future.

    * If programs need to *cross-build* between Scala 2 and Scala 3,
        it is *RECOMMENDED* to use an _EXPLICIT_ ~main~ method with an
      ~Array[String]~ argument instead.

**** TODO Escapes in interpolations - =FIX TITLE=

*** TODO Dropped Features
**** DONE Dropped: ~DelayedInit~
CLOSED: [2021-01-24 Sun 16:51]
The special handling of the ~DelayedInit~ trait is _NO LONGER SUPPORTED_.

- Consequence:
  the ~App~ /class/, which used ~DelayedInit~ is now partially *BROKEN*.
  * ~App~ still can be used as an easy and concise way to set up a _main program_.
    + However, the code is now run in the initializer of the object, which on
      some JVM's means that it will only be interpreted. So, better not use
      it for benchmarking!

    + Also, if you want to access the /command line arguments/, you need to use
      an *EXPLICIT* ~main~ method for that.
      =from Jian=
      The point of *can't access* the /command line arguments/ is similar to the
      ~Application~, which had been dropped since Scala 2.11.

**** DONE Dropped: Scala 2 Macros
CLOSED: [2020-11-22 Sun 21:59]
1. The previous, _experimental macro system_ has been dropped.

2. Instead, there is a _cleaner_, _more restricted_ system.
    * This system is based on two complementary concepts: ~inline~ and
      ~'{ ... }~ / ~${ ... }~ code generation.
      + ~'{ ... }~ (/quotes/) delays the compilation of the code and produces
        an object containing the code,

      + *DUALLY* ~${ ... }~ (/splice/) evaluates an expression which produces
        code and inserts it in the surrounding ~${ ... }~.

    * In this setting, a definition marked as /inlined/ containing a ~${ ... }~
      is a /macro/, the code inside the ~${ ... }~ is executed _at compile-time_
      and produces code in the form of ~'{ ... }~.

    * Additionally,
      the contents of code can be inspected and created with a *more complex*
      /reflection API (TASTy Reflect)/ *as an extension* of ~'{ ... }~ / ~${ ... }~
      framework.

**** TODO Dropped: Existential Types
**** DONE Dropped: General Type Projection
CLOSED: [2020-12-16 Wed 21:56]
Scala so far allowed /general type projection/ ~T#A~
where ~T~ is an ARBITRARY /type/ and ~A~ names a /type member/ of ~T~.

- Scala 3 *disallows* this if ~T~ is an /abstract type/ (/class types/ and
  /type aliases/ are fine).
  * This change was made _because /unrestricted type projection/ is *unsound*._
    https://github.com/lampepfl/dotty/issues/1050

- This restriction *rules out* the _type-level encoding of a combinator calculus_.
  * [[https://michid.wordpress.com/2010/01/29/scala-type-level-encoding-of-the-ski-calculus][Scala type level encoding of the SKI calculus]]

- To rewrite code using /type projections on abstract types/,
  consider using
  * /path-dependent types/
    OR
  * /implicit parameters/

**** DONE Dropped: Do-While
CLOSED: [2020-12-16 Wed 22:08]
The /syntax construct/ ~do <body> while <cond>~ is *no longer supported*.

- The recommended way is:
  ~while ({ <body>; <cond> }) ()~
  * Under the new syntax rules, this code can be written also without the
    awkward ~({...})~ bracketing like this:
    #+begin_src scala
      while
        i += 1
        f(i) == 0
      do ()
    #+end_src

- The idea to
  *use a block as the condition* of a ~while~
  also gives a solution to the "loop-and-a-half" problem.
  For instance:
  #+begin_src scala
    while
      val x: Int = iterator.next()
      x >= 0
    do print(".")
  #+end_src

***** Why Drop The Construct?
  - do-while is used *relatively rarely*
    and
    it can expressed faithfully using just ~while~.
    * So there seems to be little point in having it as a separate syntax
      construct.

  - Under the *NEW syntax rules* ~do~ is used AS a _statement continuation_,
    which would clash with its meaning AS a _statement introduction_ (in ~do
    ... while~).

**** DONE Dropped: Procedure Syntax
CLOSED: [2020-12-09 Wed 01:50]
Procedure syntax ~def f() { ... }~ *has been dropped*.

- Should use
  #+begin_src scala
    def f() = { ... }

    def f(): Unit = { ... }
  #+end_src

- Dotty *will accept* the _old syntax_ under the =-source:3.0-migration= option.
  * If the =-migration= option is set, it can _even *rewrite* OLD syntax to
    NEW_.

  * The _ScalaFix tool_ also can *rewrite* /procedure syntax/ to make it
    Dotty-compatible.

**** DONE Dropped: Package Objects
CLOSED: [2020-12-16 Wed 21:28]
/Package objects/ will be dropped.

- /Package objects/ are still available in Scala 3.0, but will be deprecated
  and removed afterwards. =from Jian= Not clear, 3.1 or ???

- /Package objects/ are no longer needed
  since _all kinds of definitions can now be written at the top-level._

- There may be *SEVERAL* _source files_ in a /package/ containing such /toplevel
  definitions/, and
  _source files_ can freely mix TOPLEVEL /value/, /method/, and /type definitions/
  with /classes/ and /objects/.

- The compiler *generates* /synthetic objects/ that wrap toplevel definitions
  falling into one of the following categories:
  * *ALL* /pattern/, /value/, /method/, and /type definitions/,
  * /implicit classes and objects/,
  * /companion objects of opaque type aliases/.

- If a source file =src.scala= contains such toplevel definitions, they will
  be put in a /synthetic object/ named =src$package=.
  * The wrapping is *transparent*, HOWEVER.
  * The definitions in =src= can still be accessed as members of the ENCLOSING
    package.

- Note 1:
  This means that the *name* of a _source file_ containing WRAPPED /toplevel
  definitions/ *is relevant for* /binary compatibility/:
  *If the name changes,*
  so does the name of the generated /object/ and its /class/.

- Note 2:
  A TOPLEVEL ~main~ /method/ ~def main(args: Array[String]): Unit = ...~ is
  wrapped as any other /method/.
  * If it appears in a _source file_ =src.scala=, it could be invoked from
    the command line using a command like =scala src$package=.

  * Since _the "program name" is mangled_
    it is recommended to always put ~main~ /methods/ in /EXPLICITLY NAMED
    objects/.

- Note 3:
  The notion of ~private~ is independent of whether a definition is wrapped or
  not.
    A ~private~ /toplevel definition/ is ALWAYS _visible from everywhere in the
  enclosing package._

- Note 4:
  If SEVERAL /toplevel definitions/ are /overloaded variants/ with the SAME
  NAME, *they must all come from the _SAME_ source file.*

**** DONE Dropped: Early Initializers - =TODO= =READ=
CLOSED: [2020-12-16 Wed 20:14]
/Early initializers/ of the form
#+begin_src scala
  class C extends { ... } with SuperClass ...
#+end_src
have been *dropped*.

- They were rarely used, and mostly to _COMPENSATE for the lack of /trait
  parameters/,_ which are now directly supported in Scala 3.

- =TODO=
  Learn more about the usages of /early Initializers/ in Scala 2.

- For more information, see [[https://www.scala-lang.org/files/archive/spec/2.13/05-classes-and-objects.html#early-definitions][SLS §5.1.6]]. =TODO= =READ=

**** DONE Dropped: Class Shadowing
CLOSED: [2020-12-16 Wed 20:05]
Scala 2 so far *allows* patterns like this:
#+begin_src scala
  class Base {
    class Ops {
    }
  }

  class Sub extends Base {
    class Ops {
    }
  }
#+end_src

Scala 3 *rejects* this with the error message:
#+begin_src text
  6 |      class Ops {  }
    |            ^
    |class Ops cannot have the same name as class Ops in class Base -- class definitions cannot be overridden
#+end_src

- The issue is that the _TWO_ ~Ops~ /classes/ _look like one overrides_ the other,
  BUT *classes in Scala 2 _CANNOT_ be overridden.*

- To _keep things clean_ (and its internal operations consistent)
  the Scala 3 compiler _FORCES_ you to *rename* the /inner classes/ so that
  their names are different.

***** More Details
  - Spec diff:
    in section _5.1.4 Overriding_,
    *add* M' must NOT be a /class/.

  - Q :: Why do we want to make this change to the language?
  - A :: /Class shadowing/ is *irregular* compared to other types of overrides.
        Indeed, /inner classes/ are *NOT* _actually overriden_ *but* _simply
        shadowed_.

  - Q :: How much existing code is going to be affected?
  - A :: The only instance in Dotty is in its stdlib, and it was accidental.

  - Q :: How exactly is existing code going to be affected?
  - A :: Stop compiling.

  - Q :: Is this change going to be migratable automatically?
  - A :: No.

**** DONE Dropped: Limit 22
CLOSED: [2020-12-09 Wed 02:12]
- _The limits of 22_ for the _maximal number of parameters_ of /function types/
  and the _maximal number of fields_ in /tuple types/ have been *dropped*.

  * /Functions/ can now have an *ARBITRARY NUMBER of parameters*.
    + /functions/ beyond ~scala.Function22~ are erased to a *NEW* /trait/
      ~scala.runtime.FunctionXXL~;

  * /Tuples/ can also have an arbitrary number of fields.
    + /tuples/ beyond ~scala.Tuple22~ are erased to a *NEW* /class/
      ~scala.runtime.TupleXXL~ (which extends the /trait/ ~scala.Product~).

    + Furthermore, they support /generic operation/ such as *concatenation* and
      *indexing*.
      =IMPROVE-DOC= =FIXME=
      - =from Jian=
        #+begin_src scala
          // Concatenation:
          val t = 1 *: "Str" *: EmptyTuple

          // the RHS is equivalent to

          (1, "Str")


          // Indexing:
          t(0)  // 1
          t(1)  // "Str"
        #+end_src
        Index from 0,
        and the syntax ~t._1~ and ~t._2~ is *no longer supported*.

- _Both of these are *IMPLEMENTED using /arrays/._

**** DONE Dropped: XML Literals
CLOSED: [2021-03-14 Sun 00:57]
/XML Literals/ are _STILL supported_,
BUT will _be *dropped* in the near future_,
to be *REPLACED* with /XML string interpolation/:
#+begin_src scala
  import dotty.xml.interpolator.*

  case class Person(name: String):
    override def toString = name

  @main def test: Unit =
    val bill = Person("Bill")
    val john = Person("John")
    val mike = Person("Mike")
    val todoList = List(
      (bill, john, "Meeting", "Room 203, 11:00am"),
      (john, mike, "Holiday", "March 22-24")
    )

    // XML literals (to be dropped)
    val mails1 = for (from, to, heading, body) <- todoList yield
      <message>
        <from>{from}</from><to>{to}</to>
        <heading>{heading}</heading><body>{body}</body>
      </message>
    println(mails1)

    // XML string interpolation
    val mails2 = for (from, to, heading, body) <- todoList yield xml"""
      <message>
        <from>${from}</from><to>${to}</to>
        <heading>${heading}</heading><body>${body}</body>
      </message>"""
    println(mails2)
#+end_src
=FIXME= _fix indentation width: 2 spaces to 3 spaces_

- For more information, see the semester project
  [[https://infoscience.epfl.ch/record/267527][XML String Interpolator for Dotty]] by Yassin Kammoun (2019).
  =TODO= =TODO= =TODO=

**** DONE Dropped: Symbol Literals
CLOSED: [2020-12-09 Wed 01:43]
/Symbol literals/ are *no longer supported*.
- The ~scala.Symbol~ /class/ _still exists_, so a literal translation of the
  /symbol literal/ ~'xyz~ is ~Symbol("xyz")~.

- However, it is _recommended_ to use a /plain string literal/ ~"xyz"~ instead.
  * The ~Symbol~ /class/ will _be *deprecated* and *removed* in the future_.

**** DONE Dropped: Auto-Application - =TODO= =RE-NOTE=
CLOSED: [2020-12-10 Thu 01:08]
- Previously an /empty argument list/ ~()~ was *IMPLICITLY inserted*
  when calling a /nullary method/ *without arguments*. E.g.
  #+begin_src scala
    def next(): T = ...
    next  // is expanded to `next()`
  #+end_src
  * In Dotty, this idiom is an error.
    #+begin_src scala
      next
      ^
      missing arguments for method next
    #+end_src

- In Dotty, the /application syntax/ has to *follow EXACTLY the /parameter
  syntax/.*
  * *EXCLUDED from this rule* are /methods/ that are defined in Java or that
    override methods defined in Java.
      The reason for being more lenient with such methods is that otherwise
    everyone would have to write ~xs.toString().length()~ instead of
    ~xs.toString.length~.

- The latter is idiomatic Scala because it conforms to the /uniform access
  principle/.
  * Uniform Access Principle ::
    One should be able to *change* an object member
    _FROM_ a /field/ _TO_ a /non-side-effecting method/ and _BACK_
    *WITHOUT affecting* clients that access the member.

- For reasons of /backwards compatibility/,
  * Dotty *for the moment* also auto-inserts ~()~ for /nullary methods/ that
    are defined in Scala 2, or that *override* a /method defined in Scala 2/.

  * It turns out that, because the correspondence between definition and call
    was _NOT enforced in Scala so far,_ there are quite a few /method
    definitions/ in Scala 2 libraries that use ~()~ in an inconsistent way.
    For instance, we find in ~scala.math.Numeric~
    #+begin_src scala
      def toInt(): Int
    #+end_src
    whereas ~toInt~ is written without parameters everywhere else.
    1. ENFORCING /strict parameter/ correspondence for references to such
      /methods/ would project the inconsistencies to client code, which is
      undesirable.

    2. So Dotty opts for more leniency
        when *type-checking* references to such /methods/ until most core
        libraries in Scala 2 have been cleaned up.

- Stricter conformance rules also apply to *overriding* of /nullary methods/.
  It is _NO LONGER allowed_ to *override* a /parameterless method/ by a /nullary
  method/ or vice versa.
    Instead, both /methods/ *must agree exactly* in their /parameter lists/.
  #+begin_src scala
    class A:
      def next(): Int

    class B extends A:
      def next: Int  // overriding error: incompatible type
  #+end_src
  *Methods overriding* /Java or Scala-2 methods/ are again *exempted from*
  this requirement.

***** DONE Migrating code
  CLOSED: [2020-12-10 Thu 00:51]
  Existing Scala code with inconsistent parameters can still be compiled in
  Dotty under =-source 3.0-migration=.
  - When *paired with* the =-rewrite= option,
    the code will be _AUTOMATICALLY rewritten_ to conform to Dotty's
    *stricter checking*.

***** TODO Reference
  From more info, see [[https://github.com/lampepfl/dotty/issues/2570][Issue #2570]] and [[https://github.com/lampepfl/dotty/pull/2716][PR #2716]].

**** DONE Dropped: Weak Conformance
CLOSED: [2020-12-10 Thu 00:45]
- =from Jian=
  At end of the node for this section, you can see the *conclusion*!

- In some situations, Scala used a /weak conformance relation/
  WHEN *testing* /type compatibility/ or *computing* the /least upper bound/
  of a set of /types/.

- The _PRINCIPAL motivation_ behind /weak conformance/ was to
  make an expression like this have type ~List[Double]~:
  #+begin_src scala
    List(1.0, math.sqrt(3.0), 0, -3.3)  // : List[Double]
  #+end_src
  * It's "obvious" that this should be a ~List[Double]~.
    However, _WITHOUT_ some special provision, the /least upper bound/ of the
    lists's /element types/ ~(Double, Double, Int, Double)~ would be ~AnyVal~,
    hence the list expression would be given type ~List[AnyVal]~.

- A _LESS obvious_ example is the following one, which was also typed as a
  ~List[Double]~, using the /weak conformance relation/.
  #+begin_src scala
    val n: Int = 3
    val c: Char = 'X'
    val d: Double = math.sqrt(3.0)

    // used to be: `List[Double]`,
    // now, after dropping Weak Conformance: `List[AnyVal]`
    List(n, c, d)
  #+end_src
  * Here, it is less clear why the type should be widened to ~List[Double]~,
    a ~List[AnyVal]~ seems to be an equally valid -- and more principled --
    choice.

- /Weak conformance/ applies to ALL "numeric" types (including ~Char~), and
  independently of whether the expressions are /literals/ or NOT.
  * However, in hindsight,
    + the *ONLY intended use case* is for /integer literals/ to be adapted to
      the /type/ of the _OTHER_ expressions.

    + OTHER /types of numerics/ have an *EXPLICIT* /type annotation/ embedded
      in their syntax (~f~, ~d~, ~.~, ~L~ or ~'~ for ~Char~'s) which ensures
      that their author really meant them to have that specific type).


- Therefore, Dotty drops the general notion of /weak conformance/, and instead
  keeps one rule:
  ~Int~ /literals/ are adapted to *OTHER* /numeric types/ if necessary.
  =IMPORTANT= =HERE IS THE CONCLUSION=

- [[https://dotty.epfl.ch/docs/reference/dropped-features/weak-conformance-spec.html][More details]]
  * Detailed rules are listed in this linked page.

**** DONE Deprecated: Nonlocal Returns - =hidden= =FIXME: SHOULD BE Deprecated --> Dropped=
CLOSED: [2020-12-09 Wed 01:31]
Returning from /nested anonymous functions/ has been deprecated.

- /Nonlocal returns/ are implemented by throwing and catching
  ~scala.runtime.NonLocalReturnException~'s.
  _This is rarely what is intended by the programmer._

- /Nonlocal returns/ can be *problematic*
  * BECAUSE OF *the hidden performance cost* of _throwing and catching
    exceptions._

  * Furthermore, it is a /leaky implementation/:
    a catch-all exception handler can intercept a ~NonLocalReturnException~.

- A drop-in library replacement is provided in
  ~scala.util.control.NonLocalReturns~:
  #+begin_src scala
    import scala.util.control.NonLocalReturns.*

    extension [T](xs: List[T])
        def has(elem: T): Boolean = returning {
          for x <- xs do
              if x == elem then throwReturn(true)

          false
        }

    @main def test(): Unit =
      val xs = List(1, 2, 3, 4, 5)
      assert(xs.has(2) == xs.contians)
  #+end_src

- =from Jian=
  See also
  * https://github.com/lampepfl/dotty/issues/4240

  * https://tpolecat.github.io/2014/05/09/return.html

**** DONE Dropped: ~private[this]~ and ~protected[this]~
CLOSED: [2020-04-30 Thu 12:49]
The ~private[this]~ and ~protected[this]~ /access

modifiers/ are *deprecated*
and will be phased out.

- Previously, these /modifier/ were needed
  * for *avoiding the generation* of /getters/ and /setters/ (~private[this]~
    ONLY).

  * for *excluding from variance checks* (~private[this]~ ONLY).
    + Scala 2 also excludes ~protected[this]~ but this was found to be unsound
      and was therefore removed.
      TODO More details and examples about the unsoundness!!! TODO

- _REASON_ of Dropped:
  * The compiler now *can infers for ~private~ members the fact that they are ONLY
    accessed via ~this~.* Such members are treated as if they had been declared
    ~private[this]~ -- the previous requirements can be satisfied without manually
    write ~[this]~ out.

  * ~protected[this]~ is dropped without a replacement.
    =from Jian=
    The only requirement for ~protected[this]~ is to tell the compiler NOT
    do /variance checks/, which is already been pointed out that it is unsound!
    Therefore, the requirement is not real.

- =TODO=
  =from Jian=
  Learn more about this. There are more discussion about this topic.

**** DONE Dropped: Wildcard Initializer
CLOSED: [2021-02-06 Sat 04:39]
The syntax
#+begin_src scala
  var x: A = _
#+end_src
that was used to indicate an /uninitialized field/, has been dropped.
  At its place there is a special value ~uninitialized~ in the ~scala.compiletime~
package. To get an /uninitialized field/, you now write
#+begin_src scala
  import scala.compiletime.uninitialized

  var x: A = uninitialized
#+end_src

- To enable cross-compilation,
  1. ~_~ is _still supported_,
  2. BUT it _will be dropped_ in a future 3.x version.

*** TODO Experimental
**** TODO ~CanThrow~ Capabilities
~import language.experimental.saferExceptions~
***** Why Exceptions?
***** Why Not Exceptions?
***** The Problem With Java's Checked Exceptions
***** Monadic Effects
***** From Effects to Capabilities
***** The ~CanThrow~ Capabilities
***** Example
***** Gradual Typing Via Imports
***** Scope Of the Extension
***** Caveats
***** Outlook =FIXME= _title level_

**** TODO Erased Definitions
- Per source file: ~import scala.language.experimental.erasedDefinitions~,
- Command line flag: ~-language:experimental.erasedDefinitions~

***** Why erased terms?
***** How to define erased terms?
***** What happens with erased values at runtime?
***** State machine with erased evidence example
***** Erased Classes

**** TODO Named Type Arguments
***** TODO Motivation

**** DONE Numeric Literals
CLOSED: [2022-05-29 Sun 02:27]
- *NOTE*:
  This feature is _NOT yet_ part of the Scala 3 language definition.
  It can be made available by a language import:
  #+begin_src scala
    import scala.language.experimental.genericNumberLiterals
  #+end_src

- *OLD*:
  In Scala 2, /numeric literals/ were *confined* to the /primitive numeric
  types/:
  * ~Int~
  * ~Long~
  * ~Float~
  * ~Double~

- *NEW*:
  Scala 3 allows to write /numeric literals/ also for /user defined types/.
  Example:
  #+begin_src scala
    val x: Long = -10_000_000_000

    val y: BigInt = 0x123_abc_789_def_345_678_901
    val z: BigDecimal = 110_222_799_799.99

    (y: BigInt) match
      case 123_456_789_012_345_678_901 =>
  #+end_src

- (In Scala 3)
  The _syntax_ of /numeric literals/ is the same as before,
  * *EXCEPT* there are *NO pre-set limits* _how large they can be_.

***** DONE Meaning of Numeric Literals
CLOSED: [2020-08-23 Sun 00:10]
- The meaning of a numeric literal is determined as follows:
  + If the literal ends with ~l~ or ~L~,
    it is a ~Long~ /integer/ (and *must fit* in its legal /range/).

  + If the literal ends with ~f~ or ~F~,
    it is a _single precision_ /floating point number/ of type ~Float~.

  + If the literal ends with ~d~ or ~D~,
    it is a _double precision_ /floating point number/ of type ~Double~.

- In each of these cases the conversion to a number is exactly as in Scala 2
  or in Java.
    If a /numeric literal/ does NOT end in one of these suffixes, its meaning
  is _determined by the expected type_:
  1. If the expected type is ~Int~, ~Long~, ~Float~, or ~Double~,
    the literal is treated as a standard literal of that type.

  2. If the _expected type_ is a fully defined type ~T~ that has a /given
    instance/ of /type/ ~scala.util.FromDigits[T]~, the literal is
    converted to a value of type ~T~ by passing it as an argument to the
    ~fromDigits~ /method/ of that instance (more details below).

  3. Otherwise, the literal is treated as a ~Double~ /literal/ (if it has a
    decimal point or an exponent), or as an ~Int~ /literal/ (if not).
    (This last possibility is again as in Scala 2 or Java.)

- With these rules, =FIX-DOC= =(wrong syntax highlight)=
  + The definition ~val x: Long = -10_000_000_000~ is legal by *rule 1*,
    since the _expected type_ is ~Long~.

  + The definitions
    #+begin_src scala
      val y: BigInt = 0x123_abc_789_def_345_678_901
      val z: BigDecimal = 111222333444.55
    #+end_src
    are legal by *rule 2*, since both ~BigInt~ and ~BigDecimal~ have ~FromDigits~
    instances (which implement the ~FromDigits~ /subclasses/ ~FromDigits.WithRadix~
    and ~FromDigits.Decimal~, respectively).


  + On the other hand,
    ~val x = -10_000_000_000~ gives a type error, since without an _expected
    type_ ~-10_000_000_000~ is treated by *rule 3* as an ~Int~ literal, but
    it is _too large_ for ~Int~.

***** DONE The ~FromDigits~ Trait
CLOSED: [2020-08-23 Sun 00:10]
To allow /numeric literals/, a /type/ simply has to define a /given instance/
of the ~scala.util.FromDigits~ /type class/, or one of its /subclasses/.

- ~FromDigits~:
  #+begin_src scala
    trait FromDigits[T]:
      def fromDigits(digits: String): T
  #+end_src

- Implementations of the ~fromDigits~
  _CONVERT_ strings of digits _TO_ the values of the implementation type ~T~.
  + The _digits string_ consists of
    * digits between 0 and 9,
    * possibly preceded by a sign ("+" or "-").

  + Number separator characters _ are *filtered out* _BEFORE_ the string is
    passed to ~fromDigits~.

  + =from Jian=
    Process _decimal point_ and _exponent_ is *NOT* a duty of ~FromDigits~.
    This is why they are not mentioned above. /Sub-traits/ of ~FromDigits~
    will handle _decimal point_ and _exponent_. See below!

- The /companion object/ ~FromDigits~ also defines /subclasses/ of ~FromDigits~
  + for /whole numbers/ with a given _radix_,
  + for _numbers with a decimal point_,
  + for _numbers that can have both a decimal point and an exponent_:
  #+begin_src scala
    object FromDigits:

      /** A subclass of `FromDigits` that also allows to convert whole number literals
        *  with a radix other than 10
        */
      trait WithRadix[T] extends FromDigits[T]:
        def fromDigits(digits: String): T = fromDigits(digits, 10)
        def fromDigits(digits: String, radix: Int): T

      /** A subclass of `FromDigits` that also allows to convert number
        *  literals containing a decimal point ".".
        */
      trait Decimal[T] extends FromDigits[T]

      /** A subclass of `FromDigits` that allows also to convert number
        *  literals containing a decimal point "." or an
        *  exponent `('e' | 'E')['+' | '-']digit digit*`.
        */
      trait Floating[T] extends Decimal[T]

      // ...
  #+end_src
  A /user-defined number type/ can implement one of those, which signals to
  the compiler that hexadecimal numbers, decimal points, or exponents are
  also accepted in literals for this type.

***** DONE Error Handling
CLOSED: [2020-08-23 Sun 00:34]
~FromDigits~ implementations can signal errors by throwing /exceptions/ of some
/subtype/ of ~FromDigitsException~.
  ~FromDigitsException~ is defined with _THREE_ /subclasses/ in the ~FromDigits~
/object/ as follows:
#+begin_src scala
  abstract class FromDigitsException(msg: String) extends NumberFormatException(msg)

  class NumberTooLarge(msg: String = "number too large")          extends FromDigitsException(msg)
  class NumberTooSmall(msg: String = "number too small")          extends FromDigitsException(msg)
  class MalformedNumber(msg: String = "malformed number literal") extends FromDigitsException(msg)
#+end_src

***** DONE Example
CLOSED: [2020-08-23 Sun 00:52]
As a fully worked out example, here is an implementation of a new numeric
class, ~BigFloat~, that accepts /numeric literals/. ~BigFloat~ is defined in
terms of a ~BigInt~ /mantissa/ and an ~Int~ /exponent/:
#+begin_src scala
  case class BigFloat(mantissa: BigInt, exponent: Int):
    override def toString = s"${mantissa}e${exponent}"
#+end_src
- ~BigFloat~ /literals/ can have a /decimal point/ as well as an /exponent/.
  E.g. the following expression should produce the ~BigFloat~ number
  ~BigFloat(-123, 997)~: ~-0.123E+1000: BigFloat~

- The /companion object/ of ~BigFloat~ defines an apply /constructor method/
  to construct a ~BigFloat~ from a _digits string_.
  Here is a possible implementation:
  #+begin_src scala
    object BigFloat:
      import scala.util.FromDigits

      def apply(digits: String): BigFloat =
        val (mantissaDigits, givenExponent) =
          digits.toUpperCase.split('E') match
            case Array(mantissaDigits, edigits) =>
              val expo =
                try FromDigits.intFromDigits(edigits)
                catch case ex: FromDigits.NumberTooLarge =>
                  throw FromDigits.NumberTooLarge(s"exponent too large: $edigits")
              (mantissaDigits, expo)

            case Array(mantissaDigits) =>
              (mantissaDigits, 0)

        val (intPart, exponent) =
          mantissaDigits.split('.') match
            case Array(intPart, decimalPart) =>
              (intPart ++ decimalPart, givenExponent - decimalPart.length)

            case Array(intPart) =>
              (intPart, givenExponent)

        BigFloat(BigInt(intPart), exponent)

      given FromDigits: FromDigits.Floating[BigFloat] with
        def fromDigits(digits: String) = apply(digits)
    end BigFloat
  #+end_src
  + To accept ~BigFloat~ /literals/, all that's needed in addition is a
    /given instance/ of type ~FromDigits.Floating[BigFloat]~

  + Note that the ~apply~ method does *NOT check* the format of the digits
    argument. It is assumed that only VALID arguments are passed:
    For calls coming from the compiler that assumption is valid, since the
    compiler will FIRST check whether a /numeric literal/ has the correct
    format BEFORE it gets passed on to a conversion method.

***** DONE Compile-Time Errors
CLOSED: [2020-08-23 Sun 01:25]
- With the setup of the previous section, a literal like
  #+begin_src scala
    1e10_0000_000_000: BigFloat
  #+end_src
  would be expanded by the compiler to
  #+begin_src scala
    BigFloat.FromDigits.fromDigits("1e100000000000")
  #+end_src
  Evaluating this expression throws a ~NumberTooLarge~ /exception/ at /runtime/.

- Required enhancement ::
  We would like it to produce a compile-time error instead.

- Solution ::
  We can achieve this by tweaking the ~BigFloat~ /class/ with a small dose of
  metaprogramming. The idea is to turn the ~fromDigits~ /method/ into a /macro/,
  i.e. make it an /inline method/ with a /splice/ as right hand side.
    To do this, replace the ~FromDigits~ /instance/ in the ~BigFloat~ /object/
  by the following two definitions:
  #+begin_src scala
    object BigFloat:
      // ...

      class FromDigits extends FromDigits.Floating[BigFloat]:
        def fromDigits(digits: String) = apply(digits)

      given FromDigits with
        override inline def fromDigits(digits: String) = ${
          fromDigitsImpl('digits)
        }

      private def fromDigitsImpl(digits: Expr[String])
                                (using ctx: Quotes): Expr[BigFloat] =
        digits.value match
          case Some(ds) =>
            try
              val BigFloat(m, e) = apply(ds)
              '{BigFloat(${Expr(m)}, ${Expr(e)})}
            catch case ex: FromDigits.FromDigitsException =>
                ctx.error(ex.getMessage)
                '{BigFloat(0, 0)}

          case None =>
            '{apply($digits)}
    end BigFloat
  #+end_src
  + The /macro/ implementation takes an argument of /type/ ~Expr[String]~ and
    yields a result of /type/ ~Expr[BigFloat]~. It tests whether its argument
    is a _constant string_. If that is the case, it converts the string using
    the ~apply~ /method/ and lifts the resulting ~BigFloat~ back to ~Expr~
    level. For _non-constant strings_ ~fromDigitsImpl(digits)~ is simply
    ~apply(digits)~, i.e. everything is evaluated at /runtime/ in this case.
    * =from Jian=
      WHY DO WE NEED THE ~'{BigFloat(0, 0)}~ in the ~catch~ part???
      I know it want to match the /type/, however, in non-macro definition, we
      can ignore the dummy value creation in the ~catch~ part. Does this mean
      /macro/ has this special requirement? Is there a way to drop it???

  + The interesting part is the catch part of the case where digits is constant.
    If the ~apply~ /method/ throws a ~FromDigitsException~, the exception's message
    is issued as a /compile time error/ in the ~ctx.error(ex.getMessage)~ call.

  + With this new implementation, a definitiion like
    ~val x: BigFloat = 1234.45e3333333333~
    would give a compile time error message:
    #+begin_src text
      3 |  val x: BigFloat = 1234.45e3333333333
        |                    ^^^^^^^^^^^^^^^^^^
        |                    exponent too large: 3333333333
    #+end_src

**** DONE Explicit Nulls
CLOSED: [2021-03-14 Sun 00:38]
/Explicit nulls/ is an /opt-in feature/ (can be enabled via the flag
~-Yexplicit-nulls~) that *modifies* /the Scala type system/, which *makes
/reference types/ (anything that extends ~AnyRef~) non-nullable.*

- After introducing this feature, some old style code will no longer typecheck:
  #+begin_src scala
    val x: String = null  // error: found `Null`, but required `String`
  #+end_src

  Instead, if consider the code above is a piece of Scala 2 code which can
  typecheck, translate it into Scala 3 form:
  #+begin_src scala
    val x: String | Null = null  // ok
  #+end_src

- A /nullable type/ could have ~null~ value during runtime;
  hence, it is not safe to select a member without checking its nullity.
  #+begin_src scala
    x.trim  // error: trim is not member of String | Null
  #+end_src

***** DONE New Type Hierarchy
CLOSED: [2020-12-30 Wed 16:48]
- *Without* /explicit nulls/:
  * ~Null~ is the subtype of all ~AnyRef~ subtypes.
  * The only subtype of ~Null~ is the /bottom type/ ~Noting~.

- *With* /explicit nulls/:
  * ~Null~ is a subtype of ~Any~.
  * Its only subtype doesn't change, still ~Noting~.

- Of course, the /NEW type hierarchy/ descried above is the one for typechecker
  -- before /type erasure/.
    After /type erasure/, ~Null~, _as JVM enforced_, remains a /subtype/ of
  all /reference types/
  =from Jian= Implementation details??? =TODO=

***** DONE Working with "Null"
CLOSED: [2021-03-10 Wed 11:23]
To make working with /nullable values/ easier,
we propose adding a few utilities to the standard library.
So far, we have found the following useful:

- An /extension method/ ~.nn~ to *"cast away"* _nullability_:
  #+begin_src scala
    extension [T](x: T | Null)
      inline def nn: T =
        assert(x != null)
        x.asInstanceOf[T]
  #+end_src
  * *DON'T* use ~.nn~ on /mutable variable/ directly,
    because it may introduce an unknown type into the type of the variable.
    =from Jian= =TODO=
    Need a concrete example!

- An ~unsafeNulls~ language feature. =FIXME= _period_
  When imported, ~T | Null~ can be used as ~T~, similar to regular Scala
  (without /explicit nulls/).
  =TODO= =NEXT=
  See the UnsafeNulls (=FIXME= add a inner file link) section for more
  details.

***** DONE Unsoundness
CLOSED: [2020-12-30 Wed 16:56]
The new type system is *unsound* with respect to ~null~.
=from Jian=
See the last paragraph of this section, flag ~-Ysafe-init~, and this
/unsoundness/ can be caught.

- The /unsoundness/ happens because /uninitialized fields/ in a class start
  out as ~null~:
  #+begin_src scala
    // -Yexplicit-nulls
    class C:
      val f: String = foo(f)
      def foo(f2: String): String = f2

    val c = new C
    // c.f == "field is null"
  #+end_src

- The /unsoundness/ above *can be caught* by the compiler with the option
  ~-Ysafe-init~.
  =TODO= More details can be found in "safe initialization" (next section).

***** DONE Equality
CLOSED: [2020-12-30 Wed 16:59]
*Compare a value of ~AnyRef~ /subtypes/ with ~null~,
by using operators are ~==~, ~!=~, ~eq~, and ~ne~, is not allowed!!!*

- ~null~ can *ONLY* be compared with
  * ~Null~,
  * nullable union (~T | Null~), or
  * ~Any~ type.

- ~null~ can _only_ be compared with values of type
  * ~Null~
  * nullable union ~(T | Null)~
  * ~Any~ type.

- For some reason,
  if we really want to compare ~null~ with _non-null values_,
  *we can provide a type hint (e.g. ~: Any~).*
  * For example,
    #+begin_src scala
      val x: String = ???
      val y: String | Null = ???

      x == null        // error: Values of types String and Null cannot be compared with == or !=
      x eq null        // error
      "hello" == null  // error

      y == null  // ok
      y == x     // ok

      (x: String | Null) == null  // ok
      (x: Any) == null            // ok
    #+end_src

***** DONE Java Interoperability
CLOSED: [2021-03-10 Wed 14:32]
- The Scala compiler can load /Java classes/ in _two_ ways:
  _from SOURCE_ or _from BYTECODE_.
    In either above case, when a /Java class/ is loaded,
  we *"patch"* the /type/ of its members to reflect that /Java types/ remain
  implicitly nullable.
  * Specifically, we *patch*
    + the /type/ of /fields/
    + the /argument type/, and /return type/ of /methods/.

- We illustrate the rules with following examples:
  * The first _TWO rules_ are easy:
    we *nullify* /reference types/ *but not* /value types/.
    #+begin_src java
      class C {
          String s;
          int x;
      }
    #+end_src

    ==>

    #+begin_src scala
      class C:
        val s: String | Null
        val x: Int
    #+end_src

  * We *nullify* /type parameters/ because in Java a /type parameter/ is
    _ALWAYS_ /nullable/, so the following code compiles.
    ~class C<T> { T foo() { return null; } }~

    ==>

    ~class C[T] { def foo(): T | Null }~

    + *Notice*
      this rule is _sometimes too conservative_, as witnessed by
      #+begin_src scala
        class InScala:
          val c: C[Bool] = ???  // `C` as above
          val b: Bool = c.foo()  // no longer typechecks, since `foo` now returns `Bool | Null`
      #+end_src

  * We reduce the number of REDUNTANT /nullable types/ we need to add.
    =FIXME=
    Consider
    #+begin_src java
      class Box<T> {
          T get();
      }

      class BoxFactory<T> {
          Box<T> makeBox();
      }
    #+end_src

    ==>

    #+begin_src scala
      class Box[T] {
          def get() T | Null:
      }

      class BoxFactory[T] {
          def makeBox(): Box[T] | Null
      }
    #+end_src

    + Suppose we have a ~BoxFactory[String]~.
      Notice that calling ~makeBox()~ on it returns a ~Box[String] | Null~,
      not a ~Box[String | Null] | Null~.
      This _SEEMS at first glance /unsound/ ("What if the box itself has
      ~null~ inside?"),_ but it *sound* because calling ~get()~ on a
      ~Boxt[T]~ returns a ~T | Null~.

    * *Notice*
      we need to *patch ALL* /Java-defined classes/ that transitively
      appear in the /argument or return type/ of a /field/ or /method/
      accessible from the Scala code being compiled.
        Absent crazy reflection magic, we think that ALL such /Java classes/
      must be visible to the /Typer/ (=???=) in the first place, so they
      will be patched.

  * We will append ~Null~ to the /type arguments/ if the /generic class/ is
    defined in Scala.
    #+begin_src java
      class BoxFactory<T> {
          Box<T> makeBox();  // Box is Scala-defined
          List<Box<List<T>>> makeCrazyBoxes();  // List is Java-defined
      }
    #+end_src

    ==>

    =IMPROVE ME=
    #+begin_src scala
      class BoxFactory[T]:
        def makeBox(): Box[T | Null] | Null
        def makeCrazyBoxes(): java.util.List[Box[java.util.List[T] | Null]] | Null
    #+end_src
    + In this case, since ~Box~ is Scala-defined, we will get
      ~Box[T | Null] | Null~. This is needed because our _nullability function_
      is only applied (modularly) to the /Java classes/, but not to the Scala
      ones, so we need a way to tell ~Box~ that it contains a _nullable value_.

    + The ~java.util.List~ is Java-defined,
      so we *don't* append ~Null~ to its /type argument/.
      BUT we still need to nullify its inside.

  * We *don't* nullify /SIMPLE literal constant (~final~) fields/, since they
    are known to be non-null
    #+begin_src java
      class Constants {
          final String NAME = "name";
          final int AGE = 0;
          final char CHAR = 'a';

          final String NAME_GENERATED = getNewName();
      }
    #+end_src

    ==>

    #+begin_src scala
      class Constants:
          val NAME: String("name") = "name"
          val AGE: Int(0) = 0
          val CHAR: Char('a')  = 'a'

          val NAME_GENERATED: String | Null = getNewName();
    #+end_src
    =FIXME=

  * We don't append ~Null~ to a field nor to a return type of a method which
    is annotated with a ~NotNull~ annotation.
    #+begin_src java
      class C {
          @NotNull String name;
          @NotNull List<String> getNames(String prefix);  // List is Java-defined
          @NotNull Box<String> getBoxedName();  // Box is Scala-defined
      }
    #+end_src

    ==>

    #+begin_src scala
      class C {
          val name: String
          // we still need to nullify the paramter types
          def getNames(prefix: String | Null): java.util.List[String]
          // we don't append `Null` to the outmost level, but still need to nullify inside
          def getBoxedName(): Box[String | Null]
      }
    #+end_src

    + The /annotation/ must be from the list below to be recognized as
      ~NotNull~ by the compiler. Check =Definitions.scala= *for an updated
      list* (=from Jian= can keep changing):
      #+begin_src scala
        // A list of annotations that are commonly used to indicate
        // that a field/method argument or return type is not null.
        // These annotations are used by the nullification logic in
        // JavaNullInterop to improve the precision of type nullification.
        // We don't require that any of these annotations be present
        // in the class path, but we want to create Symbols for the
        // ones that are present, so they can be checked during nullification.
        @tu lazy val NotNullAnnots: List[ClassSymbol] = ctx.getClassesIfDefined(
          "javax.annotation.Nonnull" ::
          "edu.umd.cs.findbugs.annotations.NonNull" ::
          "androidx.annotation.NonNull" ::
          "android.support.annotation.NonNull" ::
          "android.annotation.NonNull" ::
          "com.android.annotations.NonNull" ::
          "org.eclipse.jdt.annotation.NonNull" ::
          "org.checkerframework.checker.nullness.qual.NonNull" ::
          "org.checkerframework.checker.nullness.compatqual.NonNullDecl" ::
          "org.jetbrains.annotations.NotNull" ::
          "lombok.NonNull" ::
          "io.reactivex.annotations.NonNull" :: Nil map PreNamedString)
      #+end_src

****** Override check
  - When we check _OVERRIDING *between* /Scala classes/ and /Java classes/,_
    the rules are relaxed for ~Null~ /type/ with this feature, in order to
    help users to working with Java libraries.

  - Suppose we have /Java method/ ~String f(String x)~, we can /override/
    this /method/ in Scala in any of the following forms:
    #+begin_src scala
      def f(x: String | Null): String | Null

      def f(x: String): String | Null

      def f(x: String | Null): String

      def f(x: String): String
    #+end_src

***** DONE Flow Typing
CLOSED: [2021-03-14 Sun 00:38]
We added a simple form of flow-sensitive type inference.
  The idea is that if ~p~ is a /stable path/ or a /trackable variable/,
then we can know that ~p~ is non-null if it's compared with ~null~. This
information can then be propagated to the ~then~ and ~else~ branches of an
if-statement (among other places).

- Example:
  #+begin_src scala
    val s: String | Null = ???

    if s != null then
      // s: String

    // Outside the above `if`
    // s: String | Null

    assert(s != null)
    // After this point, the type of `s` is `String`
    // s: String
  #+end_src

- A similar inference can be made for the ~else~ case if the test is
  ~p == null~
  #+begin_src scala
    if s == null then
      // s: String | Null
    else
      // s: String
  #+end_src

- ~==~ and ~!=~ is considered a comparison for the purposes of the /flow
  inference/.

****** DONE Logical Operators
CLOSED: [2020-12-31 Thu 01:05]
We also support logical operators (~&&~, ~||~, and ~!~):
#+begin_src scala
  val s: String | Null = ???
  val s2: String | Null = ???

  if s != null && s2 != null then
    // s: String
    // s2: String
  else
    // s: String | Null
    // s2: String | Null

  if s == null || s2 == null then
    // s: String | Null
    // s2: String | Null
  else
    // s: String
    // s2: String
#+end_src
=FIXME= insert one space before and after ~|~.

****** DONE Inside Conditions
CLOSED: [2020-12-31 Thu 01:07]
We also support /type specialization/ within the condition, taking into
account that ~&&~ and ~||~ are /short-circuiting/:
#+begin_src scala
  val s: String | Null = ???

  if s != null && s.length > 0 then  // s: String in `s.length > 0`
    // s: String

  if s == null || s.length > 0 then  // s: String in `s.length > 0`
    // s: String | Null
  else
    // s: String
#+end_src

****** DONE Match Case
CLOSED: [2020-12-31 Thu 01:08]
The non-null cases can be detected in match statements.
#+begin_src scala
  val s: String | Null = ???

  s match
    case _: String =>  // s: String
    case _         =>
#+end_src

****** DONE Mutable Variable - =RE-READ=
CLOSED: [2021-03-10 Wed 15:17]
We are able to detect the nullability of some /local mutable variables/.

- A simple example is:
  #+begin_src scala
    class C(val x: Int, val next: C | Null)

    var xs: C | Null = C(1, C(2, null))
    // xs is trackable, since all assignments are in the same method

    while xs != null do
      // xs: C
      val xsx: Int = xs.x
      val xscpy: C = xs
      xs = xscpy // since xscpy is non-null, xs still has type C after this line
      // xs: C
      xs = xs.next // after this assignment, xs can be null again
      // xs: C | Null
  #+end_src

- When dealing with /local mutable variables/, there are _TWO questions_:
  1. WHETHER to track a /local mutable variable/ during /flow typing/.
      We track a /local mutable variable/ if the variable is *not assigned in
      a /closure/.*
      * For example,
        in the following code ~x~ is assigned to by the /closure/ ~y~, so we
        _do *NOT* do /flow typing/ on ~x~._
        #+begin_src scala
          var x: String | Null = ???

          def y =
            x = null

          if x != null then
            // y can be called here, which would break the fact

            // error: x is captured and mutated by the closure, not trackable
            val a: String = x
        #+end_src

  2. WHETHER to generate and use /flow typing/ on a specific use of a /local
      mutable variable/.
        We only want to do /flow typing/ on a use that belongs to the
      *SAME /method/* as the definition of the /local variable/.

      * For example,
        in the following code, even ~x~ is *not* assigned to by a /closure/,
        +but+ =FIXME= we can only use /flow typing/ in one of the occurrences
        (because the other occurrence happens within a /nested closure/).
        #+begin_src scala
          var x: String | Null = ???

          def y =
            if x != null then
              // not safe to use the fact (x != null) here
              // since y can be executed at the same time as the outer block
              val _: String = x

          if x != null then
            val a: String = x  // ok to use the fact here
            x = null
        #+end_src
        =from Jian=
        I don't quite understand the comment
        "since y can be executed at the same time as the outer block".
        =???= =TODO= =???=

- =TODO=
  See more examples in tests/explicit-nulls/neg/var-ref-in-closure.scala.
  =FIXME= Should use a hyperlink

- Currently, we are *unable to track* /paths/ with a /mutable variable prefix/.
  For example, ~x.a~ if ~x~ is mutable.

****** DONE Unsupported Idioms
CLOSED: [2020-12-31 Thu 01:37]
We don't support:
  =FIXME=
- flow facts NOT related to nullability
  (~if x == 0 then { /* x: 0.type not inffered */ }~)

- tracking aliasing between non-nullable paths
  #+begin_src scala
    val s: String | Null = ???
    val s2: String | Null = ???

    if s != null && s == s2 then
      // s:  String inferred
      // s2: String not inferred
  #+end_src
  =from Jian=
  WHY NOT SUPPORT THIS????????

****** DONE ~UnsafeNulls~
CLOSED: [2021-03-14 Sun 00:38]
- It is difficult to work with many nullable values, we introduce a language
  feature unsafeNulls. Inside this "unsafe" scope, all ~T | Null~ values can
  be used as ~T~.

- Users can import ~scala.language.unsafeNulls~ to create such scopes, or
  use =-language:unsafeNulls= to enable this feature globally (for migration
  purpose only).

- Assume ~T~ is a /reference type/ (a /subtype/ of ~AnyRef~), the following
  _unsafe operation rules_ are applied in this /unsafe-nulls scope/:
  1. the members of ~T~ can be found on ~T | Null~

  2. a value with type ~T~ can be compared with ~T | Null~ and ~Null~

  3. suppose ~T1~ is not a /subtype/ of ~T2~ using /explicit-nulls subtyping/
      (where ~Null~ is a direct /subtype/ of ~Any~), /extension methods/ and
      /implicit conversions/ designed for ~T2~ can be used for ~T1~
      if ~T1~ is a /subtype/ of ~T2~ using /regular subtyping rules/ (where
      ~Null~ is a /subtype/ of every /reference type/)

  4. suppose ~T1~ is not a /subtype/ of ~T2~ using /explicit-nulls subtyping/,
      a value with type ~T1~ can be used as ~T2~
      if ~T1~ is a /subtype/ of ~T2~ using /regular subtyping rules/

- Addtionally, null can be used as ~AnyRef~ (~Object~), which means you can
  select ~.eq~ or ~.toString~ on it.

- The program in ~unsafeNulls~ will have a
  *SIMILAR semantic* as
  _regular Scala (=FIXME= regular Scala => Scala without ~-Yexplicit-nulls~),_
  BUT *not equivalent*.

  * For example,
    the following code CANNOT be compiled even using *unsafe nulls*. Because
    of the /Java interoperation/, the /type/ of the get /method/ becomes
    ~T | Null~.
    #+begin_src scala
      def head[T](xs: java.util.List[T]): T = xs.get(0)  // error
    #+end_src
    Since the compiler doesn't know whether ~T~ is a /reference type/, it
    is UNABLE to cast ~T | Null~ to ~T~.
    + A ~.nn~ need to be inserted after ~xs.get(0)~ by user manually to fix
      the error, which strips the ~Null~ =FIXME= from its /type/.

- The _intention_ of this ~unsafeNulls~ is to
  give users a better migration path for /explicit nulls/.
  * =from Jian=
    It can be imagine that this migration for the whole community need a
    very long time.

  * The process:
    Projects for Scala 2 or _regular dotty_ =FIXME=
    1. Add ~-Yexplicit-nulls -language:unsafeNulls~ to the compile options.
        A small number of manual modifications are expected.

    2. To migrate to the *FULL* /explicit nulls/ feature in the future,
        ~-language:unsafeNulls~ can be dropped and add import
        ~scala.language.unsafeNulls~ only when needed.

- Example:
  #+begin_src scala
    def f(x: String): String = ???
    def nullOf[T >: Null]: T = null

    import scala.language.unsafeNulls

    val s: String | Null = ???
    val a: String = s // unsafely convert String | Null to String

    val b1 = s.trim() // call .trim() on String | Null unsafely
    val b2 = b1.length()

    f(s).trim() // pass String | Null as an argument of type String unsafely

    val c: String = null // Null to String

    val d1: Array[String] = ???
    val d2: Array[String | Null] = d1 // unsafely convert Array[String] to Array[String | Null]
    val d3: Array[String] = Array(null) // unsafe

    class C[T >: Null <: String] // define a type bound with unsafe conflict bound

    val n = nullOf[String] // apply a type bound unsafely
  #+end_src
  * _WITHOUT the ~unsafeNulls~, all these /unsafe operations/ will *NOT* be
    type-checked._

  * =from Jian=
    + Q :: Why does the line ~val d2: Array[String | Null] = d1~ is
            commented as *unsafe*?
    + A :: ~Array~ is invariant in Scala.
            This can been seen from the definition of ~Array~:
            ~final class Array[T] extends ...~
            Here it uses ~T~, not ~+T~.

  * ~unsafeNulls~ also works for /extension methods/ and /implicit search/.
    #+begin_src scala
      import scala.language.unsafeNulls

      val x = "hello, world!".split(" ").map(_.length)

      given Conversion[String, Array[String]] = _ => ???

      val y: String | Null = ???
      val z: Array[String | Null] = y
    #+end_src

***** DONE Binary Compatibility
CLOSED: [2021-03-10 Wed 14:35]
Our STRATEGY
for /binary compatibility/ WITH
_Scala binaries that predate explicit nulls_ AND
_new libraries compiled WITHOUT the ~-Yexplicit-nulls~ flag_:

leave the *types unchanged* and be compatible but *unsound*.

**** TODO MainAnnotation
**** TODO The ~into~ Type Modifier
***** Function arguments
***** Vararg arguments
***** Retrofitting Scala 2 libraries
***** Restrictions
***** Syntax changes

**** TODO Capture Checking
***** Overview
***** Capabilities and Capturing Types
***** Function Types
***** By-Name Parameter Types
***** Subtyping and Subcapturing
***** Capability Classes
***** Capture Checking of Closures
***** Capture Checking of Classes
***** Capture Tunnelling
***** Escape Checking
***** Checked Exceptions
***** A Larger Example
***** Existential Capabilities
***** Reach Capabilities
***** Capabilities Polymorphism
***** Compilation Options
***** Capture Checking Internals

**** TODO Pure Function Syntax
=from Jian= Read the PR (https://github.com/lampepfl/dotty/pull/14134) for more details
***** TODO Why Enable It Now?
***** TODO More info:
TBD

**** DONE Tupled Function - =TODO= =RE-READ=
CLOSED: [2020-07-14 Tue 15:15]
# Subtitle "Tupled Function" should be removed!!! =FIX-DOC=
=from Jian= =Rephrase=
- Requirement:
  GENERALIZE some operation on *ALL* /function types/

- Solutions:
  * In Scala 2:
    Since /functions/ bounded to /arities/ *up to* 22, it was possible and
    the solution is straightforward.

  * In Scala 3:
    Since /functions/ and /tuples/ generalized to /arities/ *above* 22,
    /overloading/ is NOT an option anymore.
    + The /type class/ ~TupleFunction~ provides a way to abstract DIRECTLY
      over a /function/ of *ANY* /arity/ CONVERTING it to an EQUIVALENT
      /function/ that *receives ALL /arguments/ in a SINGLE /tuple/.*

- XX
  #+begin_src scala
    /** Type class relating a `FunctionN[..., R]` with an equivalent tupled function `Function1[TupleN[...], R]` ,*
      \ast{}  @tparam F a function type
      \ast{}  @tparam G a tupled function type (function of arity 1 receiving a tuple as argument)
      */
    @implicitNotFound("${F} cannot be tupled as ${G}")
    sealed trait TupledFunction[F, G] {
      def tupled(f: F): G
      def untupled(g: G): F
    }
  #+end_src

- The compiler will synthesize an /instance/ of ~TupledFunction[F, G]~ if:
  * ~F~ is a /function type/ of arity ~N~

  * ~G~ is a /function/ with a _single /tuple/ argument_ of size ~N~
    and
    its /types/ are equal to the /arguments/ of ~F~

  * The /return type/ of ~F~ is EQUAL TO the /return type/ of ~G~

  * ~F~ and ~G~ are the same sort of function
    (both are ~(...) => R~ or both are ~(...) ?=> R~)

  * If only one of ~F~ or ~G~ is /instantiated/ the second one is /inferred/.

***** Examples
- ~TupledFunction~ can be used to GENERALIZE the ~Function1.tupled~, ...
  ~Function22.tupled~ /methods/ to /functions/ of _ANY_ /arities/.
  The following defines ~tupled~ as /extension method/ ([[https://github.com/lampepfl/dotty/blob/master/tests/run/tupled-function-tupled.scala][full example]]).
  #+begin_src scala
    /** Creates a tupled version of this function: instead of N arguments,
    \ast{}  it accepts a single [[scala.Tuple]] with N elements as argument.
    *
    \ast{}  @tparam F the function type
    \ast{}  @tparam Args the tuple type with the same types as the function arguments of F
    \ast{}  @tparam R the return type of F
    */
    extension [F, Args <: Tuple, R](f: F)
      def tupled(using tf: TupledFunction[F, Args => R]): Args => R = tf.tupled(f)
  #+end_src

- ~TupledFunction~ can be used to GENERALIZE the ~Function.untupled~ to a
  /function/ of ANY /arities/ ([[https://github.com/lampepfl/dotty/blob/master/tests/run/tupled-function-untupled.scala][full example]])
  #+begin_src scala
    /** Creates an untupled version of this function: instead of a single argument of type [[scala.Tuple]] with N elements,
    \ast{}  it accepts N arguments.
    *
    \ast{}  This is a generalization of [[scala.Function.untupled]] that work on functions of any arity
    *
    \ast{}  @tparam F the function type
    \ast{}  @tparam Args the tuple type with the same types as the function arguments of F
    \ast{}  @tparam R the return type of F
    */
    extension [F, Args <: Tuple, R](f: Args => R)
      def untupled(using tf: TupledFunction[F, Args => R]): F = tf.untupled(f)
  #+end_src

- ~TupledFunction~ can also be used to GENERALIZE the ~Tuple1.compose~ and
  ~Tuple1.andThen~ /methods/ to ~compose~ functions of *larger* /arities/ and
  with /functions/ that return /tuples/.
  #+begin_src scala
    /** Composes two instances of TupledFunction into a new TupledFunction, with this function applied last.
    *
    \ast{}  @tparam F a function type
    \ast{}  @tparam G a function type
    \ast{}  @tparam FArgs the tuple type with the same types as the function arguments of F and return type of G
    \ast{}  @tparam GArgs the tuple type with the same types as the function arguments of G
    \ast{}  @tparam R the return type of F
    */
    extension [F, G, FArgs <: Tuple, GArgs <: Tuple, R](f: F)
      def compose(g: G)(using tg: TupledFunction[G, GArgs => FArgs],
                              tf: TupledFunction[F, FArgs => R]): GArgs => R =
        (x: GArgs) => tf.tupled(f)(tg.tupled(g)(x))
  #+end_src

**** TODO Named Tuples - =NEW=
***** Conformance and Convertibility
***** Pattern Matching
***** Pattern Matching with Named Fields in General
***** Expansion
***** Compute Field Names
***** The NamedTuple.From Type
***** Operations on Named Tuples
***** Restrictions
***** Syntax Changes
***** Source Incompatibilities
**** TODO Modularity Improvements - =NEW=
***** Tracked Parameters
***** Tracked members
***** Tracked syntax change
***** Allow Class Parents to be Refined Types
***** A Small Relaxation To Export Rules

**** TODO Better Support for Type Classes - =NEW=
***** Generalizing Context Bounds
***** Auxiliary Type Alias is
****** Better Default Names for Context Bounds

***** Fixing Singleton
***** Examples
****** Example 1
****** Example 2
****** Example 3
****** Example 4

***** Suggested Improvement unrelated to Type Classes
****** Using as also in Patterns

***** Summary
***** Conclusion

**** TODO The runtimeChecked method - =NEW=
***** Example
***** Safety
***** Specification
***** Motivation
****** Restoring Scala 2.13 semantics with runtimeChecked

**** TODO Better fors - =NEW=

*** TODO Scala 3 Syntax Summary
**** Lexical Syntax
**** Optional Braces
**** Keywords
***** Regular keywords
***** Soft keywords

**** Context-free Syntax
***** Literals and Paths
***** Types
***** Expressions
***** Type and Value Parameters
***** Bindings and Imports
***** Declarations and Definitions

*** TODO Language Versions
**** Source Compatibility
**** Binary Compatibility

*** Soft Keywords
*** A Classification of Proposed Language Features

** TODO Contributing
*** TODO Getting Started
   =FIXME= =Unify md style=
**** Scala CLA
**** Making sure the team is aware
**** Requirements
**** Nice To Have
**** Compiling and Running
**** Starting a REPL
**** Publish to local repository
**** Generating Documentation
**** Community

*** TODO Setting up your IDE
*** TODO Diagnosing your issue
**** TODO Reproducing an Issue
**** TODO Finding the Cause of an Issue
**** TODO Common Issue Locations

*** TODO Debugging your Compiler
**** TODO Debugging with your IDE
**** TODO How to Inspect Values
**** TODO Other Debugging Techniques

*** TODO Testing Your Changes
*** TODO Scaladoc
*** TODO Community Build
*** TODO Sending in a pull request
*** TODO Command Cheatsheet
*** TODO Procedures
**** Release Procedure
***** Model
***** Example
****** At the Dotty Repo
****** At the CI
******* Canceling CI builds

****** Documentation
******* Release Procedure Checklist
******* GitHub Releases and Blog Post

****** Ecosystem

***** Procedure in Bash Scripts

**** Test Vulpix Framework
    =FIXME= =DELETE TITLE=

*** TODO High Level Architecture
**** TODO Compiler Overview
**** TODO Contexts
**** TODO Compiler Phases
**** TODO Compiler Types
**** TODO Time in the Compiler
**** TODO Symbols



*** TODO Workflow
**** Compiling files with scalac
**** Inspecting Types with Type Stealer
**** Pretty-printing
**** SBT Commands Cheat Sheet
**** Shell Commands

*** TODO IDEs and Tools
**** Using an IDE
**** Basic Operations with Mill
**** Working with Scalafix
    =FIXME= =DELETE TITLE=

** TODO Internals
*** Backend Internals
**** Data Flow
**** Architecture
***** (a) The queue subsystem
***** (b) Bytecode-level types, ~BType~
***** (c) Utilities offering a more "high-level" API to bytecode emission
***** (d) Mapping between type-checker types and ~BType~'s
***** (e) More "high-level" utilities for bytecode emission
***** (f) Building an ASM ~ClassNode~ given an AST ~TypeDef~

*** Classpaths
*** Contexts
**** Contexts in the typer
**** In other phases
**** Using contexts

*** Differences between Scalac and Dotty
**** Some background
***** Too little
***** Too much

**** Denotation
***** Denotation vs. SymDenotation
***** Implicit Conversion

**** Symbol
**** Flags
**** Tree
**** Type

*** Higher-Kinded Types in Dotty
   *This page is out of date and preserved for posterity. Please see
   Implementing Higher-Kinded Types in Dotty for a more up to date version*

**** Higher-Kinded Types in Dotty V2
***** The duality
***** Named type parameters
***** Wildcards
***** Type parameters in the encodings
***** Partial applications
***** Modelling polymorphic type declarations
***** Modelling polymorphic type aliases: simple case
***** Modelling polymorphic type aliases: general case
***** Modelling higher-kinded types
***** Full example
***** Status of ~#~

*** Dotty Overall Structure
**** Package Structure
**** Contexts
**** Compiler Phases

*** Explicit Nulls
**** Explicit-Nulls Flag
**** Type Hierarchy
**** Working with Nullable Unions
**** Java Interoperability
**** Relaxed Overriding Check
**** Nullified Upper Bound
**** Unsafe Nulls Feature and SafeNulls Mode
**** Flow Typing

*** Dotc's concept of time
*** Scala 3 Syntax Summary
**** Lexical Syntax
**** Optional Braces
**** Keywords
***** Regular keywords
***** Soft keywords

**** Context-free Syntax
***** Literals and Paths
***** Types
***** Expressions
***** Type and Value Parameters
***** Bindings and Imports
***** Declarations and Definitions

*** Type System
   The types are defined in =dotty/tools/dotc/core/Types.scala=

**** Class diagram
**** Proxy types and ground types
**** Representations of types
***** Representation of methods

**** Subtyping checks
***** Type rebasing

**** Type caching
    # TODO

**** Type inference via constraint solving
    # TODO

*** Dotty Internals 1: Trees & Symbols (Meeting Notes)
**** Entry point
**** Phases
**** Trees
***** Untyped trees
***** Typed trees
***** Notes on some tree types
****** ThisTree

***** Creating trees
***** Meaning of trees
***** Errors
***** Assignment

**** Symbols
***** ~ClassSymbol~
***** ~SymDenotation~

*** Debug Macros
**** Enable checks
**** position not set
**** unresolved symbols in pickling

*** GADTs - Broad overview
**** Introduction
**** Useful widgets
***** ~Expr~
***** ~EQ~
***** ~SUB~

**** Details of above
***** What abstract types can have GADT constraints
***** What are necessary relationships? Any examples?
****** Covariance means no constraint is necessary

***** Breaking down the constraints
***** Relation between ~GadtConstraint~ and ~OrderingConstraint~
****** Internal and external types

**** Other details
***** ~TypeComparer~ approximations
***** Necessary/sufficient either
***** Types bound in patterns
***** Internal structure of ~OrderingConstraint~

**** Possible broad improvements
***** Allow ~OrderingConstraint~ to record bounds for things other than ~TypeParamRef~'s
***** Not mixing ~OrderingConstraint~ and ~ConstraintHandling~ in ~GadtConstraint~
***** Creating a separate ~TypeComparer~ for breaking down types into GADT constraints

*** Code Coverage for Scala 3
**** Instrument code for coverage analysis
**** Details: how the code is instrumented

** TODO Blog (archived)
*** TODO Scala 3.0.1-RC2 – backports of critical bugfixes
*** TODO Scala 3.0.1-RC1 – further stabilising the compiler
*** TODO Scala 3.0.0-RC3 – bug fixes for 3.0.0 stable
*** Scala 3.0.0-RC2 – getting ready for 3.0.0
*** Scala 3.0.0-RC1 – first release candidate is here

* API
** Package structure
** Automatic imports
** Package
*** ~dotty.tools.tasty~
**** Type memebers
***** Classlikes
****** (C) ~TastyHeaderUnpickler~
****** (C, O) ~TastyBuffer~
****** (C) ~UnpickleException~
****** (O) ~TastyHash~
****** (O) ~TastyFormat~ - =FIXME= =DOC=
****** (C) ~TastyReader~

*** ~dotty.tools.tasty.util~
**** Type members
***** Classlikes
****** (O) ~Util~

*** ~scala~
**** Type members
***** Types
****** (T) ~EmptyTuple~
****** (T) ~IArray[+T]~
****** (T) ~Cloneable~
****** (T) ~Serializable~
****** (T) ~Throwable~
****** (T) ~Exception~
****** (T) ~Error~
****** (T) ~RuntimeException~
****** (T) ~NullPointerException~
****** (T) ~ClassCastException~
****** (T) ~IndexOutOfBoundsException~
****** (T) ~ArrayIndexOutOfBoundsException~
****** (T) ~StringIndexOutOfBoundsException~
****** (T) ~UnsupportedOperationException~
****** (T) ~IllegalArgumentException~
****** (T) ~NumberFormatException~
****** (T) ~AbstractMethodError~
****** (T) ~InterruptedException~
****** (T) ~IterableOnce[+A]~
****** (T) ~Iterable[+A]~
****** (T) ~Seq[+A]~
****** (T) ~IndexedSeq[+A]~
****** (T) ~Iterator[+A]~
****** (T) ~List[+A]~
****** (T) ~::[+A]~
****** (T) ~LazyList[+A]~
****** (T) ~Vector[+A]~
****** (T) ~StringBuilder~
****** (T) ~Range~
****** (T) ~BigDecimal~
****** (T) ~BigInt~
****** (T) ~Equiv[T]~
****** (T) ~Fractional[T]~
****** (T) ~Integral[T]~
****** (T) ~Numeric[T]~
****** (T) ~Ordered[T]~
****** (T) ~Ordering[T]~
****** (T) ~PartialOrdering[T]~
****** (T) ~PartiallyOrdered[T]~
****** (T) ~Either[+A, +B]~
****** (T) ~Left[+A, +B]~
****** (T) ~Right[+A, +B]~

***** TODO Classlikes
****** (O) ~EmptyTuple~
****** (O) ~IArray~
****** (O) ~#::~
****** (O) ~language~
****** (sT, O) ~Tuple~
****** (C) ~main~ extends ~Annotation~
****** (O) ~opaques~
****** (T) ~PolyFunction~
****** (sT, O) ~CanEqual[-L, -R]~
****** (aC) ~Conversion~
****** (T, O) ~Selectable~
****** (sT) ~NonEmptyTuple~
****** (aC, O) ~*:[+H, +T <: Tuple]~

**** Value members
***** Defined value memebers
****** (v) ~AnyRef: Specializable~
****** (v) ~Iterable: Iterable~
****** (v) ~Seq: Seq~
****** (v) ~IndexedSeq: IndexedSeq~
****** (v) ~Iterator: Iterator~
****** (v) ~List: List~
****** (v) ~Nil: Nil~
****** (v) ~::: ::~
****** (v) ~+:: +:~
****** (v) ~:+: :+~
****** (v) ~LazyList: LazyList~
****** (v) ~Vector: Vector~
****** (v) ~StringBuilder: StringBuilder~
****** (v) ~Range: Range~
****** (v) ~BigDecimal: BigDecimal~
****** (v) ~BigInt: BigInt~
****** (v) ~Equiv: Equiv~
****** (v) ~Fractional: Fractional~
****** (v) ~Integral: Integral~
****** (v) ~Numeric: Numeric~
****** (v) ~Ordered: Ordered~
****** (v) ~Ordering: Ordering~
****** (v) ~Either: Either~
****** (v) ~Left: Left~
****** (v) ~Right: Right~

*** ~scala.annotation~
**** Type members
***** Classlikes
****** (aC) ~Annotation~
****** (T) ~ClassfileAnnotation~ extends ~ConstantAnnotation~
****** (T) ~ConstantAnnotation~ extends ~StaticAnnotation~
****** (T) ~RefiningAnnotation~ extends ~StaticAnnotation~
****** (T) ~StaticAnnotation~ extends ~Annotation~
****** (T) ~TypeConstraint~ extends ~Annotation~
****** (fC) ~alpha(externalName: String)~ extends ~StaticAnnotation~ - (deprecated, use ~@targetName~ instead)
****** (fC) ~compileTimeOnly(message: String)~ extends ~StaticAnnotation~
****** (C) ~constructorOnly~ extends ~StaticAnnotation~
****** (fC) ~elidable(val level: Int)~ extends ~StaticAnnotation~
****** (fC) ~implicitAmbiguous(msg: String)~ extends ~StaticAnnotation~
****** (fC) ~implicitNotFound(msg: String)~ extends ~StaticAnnotation~
****** (C) ~nowarn(value: String)~ extends ~ConstantAnnotation~
****** (C) ~showAsInfix(enabled: Boolean)~ extends ~StaticAnnotation~
****** (fC) ~static~ extends ~StaticAnnotation~
****** (C) ~strictfp~ extends ~StaticAnnotation~
****** (fC) ~switch~ extends ~StaticAnnotation~
****** (fC) ~tailrec~ extends ~StaticAnnotation~
****** (fC) ~targetName~ extends ~StaticAnnotation~
****** (fC) ~threadUnsafe~ extends ~StaticAnnotation~
****** (fC) ~transparentTrait~ extends ~StaticAnnotation~
****** (C) ~unspecialized~ extends ~StaticAnnotation~
****** (C) ~unused(message: String)~ extends ~StaticAnnotation~
****** (fC) ~varargs~ extends ~StaticAnnotation~

*** TODO ~scala.annotation.meta~
*** DONE ~scala.annotation.unchecked~
   CLOSED: [2020-12-11 Fri 11:13]
**** Type members
***** Classlikes
****** (fC) ~uncheckedVariance~
****** (fC) ~uncheckedStable~

*** DONE ~scala.beans~
   CLOSED: [2020-12-11 Fri 11:14]
**** Type members
***** Classlikes
****** (fC) ~BooleanBeanProperty~
****** (fC) ~BeanProperty~

*** ~scala.collection~
*** ~scala.collection.concurrent~
*** ~scala.collection.convert~
*** ~scala.collection.generic~
*** ~scala.collection.immutable~
*** ~scala.collection.mutable~
*** ~scala.compat~
*** ~scala.compiletime~
**** Types
***** ~Widen[Tup <: Tuple]~
***** ~S[N <: Int] <: Int~

*** ~scala.compiletime.ops~
**** Classlikes
***** (O) ~any~
***** (O) ~string~
***** (O) ~int~
***** (O) ~boolean~

*** ~scala.compiletime.testing~
**** Classlikes
***** (fcC) ~Error~
***** (sT, O) ~ErrorKind~

*** ~scala.concurrent~
*** ~scala.concurrent.duration~
*** ~scala.deriving~
**** Classlikes
***** (sT, O) ~Mirror~
***** IGNORE _deprecated_

*** ~scala.io~
*** ~scala.jdk~
*** ~scala.jdk.javaapi~
*** ~scala.math~
*** ~scala.quoted~
**** Classlikes
***** (O) ~Unlifted~
***** (T) ~ExprMap~
***** (O) ~Varargs~
***** (aC, O) ~Type[T <: AnyKine]~
***** (O) ~Const~
***** (T, O) ~ToExpr[T]~
***** (O) ~Consts~
***** (T) ~Quotes~
***** (T, O) ~FromExpr[T]~
***** (aC, O) ~Expr[+T]~

*** ~scala.quoted.runtime~
**** Classlikes
***** (T) ~QuoteMatching~
***** (T) ~QuoteUnpickler~
***** (O) ~Patterns~ with ~@compileTimeOnly("Illegal reference to `scala.quoted.runtime.Patterns`")~
***** (C) ~SplicedType~ with ~@compileTimeOnly("Illegal reference to `scala.quoted.runtime.SplicedType`")~
***** (C) ~StopMacroException~
***** (O) ~Expr~ with ~@compileTimeOnly("Illegal reference to `scala.quoted.runtime.Expr`")~

*** ~scala.ref~
*** ~scala.reflect~
**** Types
***** (T) ~Typeable[T]~

**** Classlikes
***** (T, O) ~TypeTest[-S, T]~
***** (tT) ~Enum~
***** (T, O) ~Selectable~

*** ~scala.runtime~
**** Classlikes
***** (faC) ~MatchCase[Pat, +Body]~
***** (o) ~Tuple~
***** (tT) ~EnumValues~
***** (fac) ~TypeBox[-L <: U, +U]~
***** (fC, O) ~TupleXXL~
***** (T) ~FunctionXXL~
***** (O) ~Scala3RunTime~

*** ~scala.runtime.java8~
*** ~scala.sys~
*** ~scala.sys.process~
*** ~scala.util~
**** (T, O) ~FromDigits[T]~
**** (T) ~LowPriorityNot~
**** (O) ~CommandLineParser~
**** (fC, O) ~Not[+T]~

*** ~scala.util.control~
**** Type members
***** Classlikes
****** (O, C) ~Breaks~
****** (aC) ~ControlThrowable~
****** (O) ~Exception~
****** (O, T) ~NoStackTrace~
****** (O) ~NonFatal~
****** (O) ~NonLocalReturns~
****** (O) ~TailCalls~

*** ~scala.util.hashing~
**** Type members
***** Classlikes
****** (O, fC) ~ByteswapHashing[T]~
****** (O, T) ~Hashing[T]~
****** (O) ~MurmurHash3~

**** Value members
***** Methods
****** byteswap32(v: Int): Int
****** byteswap64(v: Long): Long

*** ~scala.util.matching~
**** Type members
***** Classlikes
****** (O, C) ~Regex~
****** (T) ~UnanchoredRegex~
