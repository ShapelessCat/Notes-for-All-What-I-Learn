#+TITLE: Advanced Programming in Scala (PrePrint)
#+SUBTITLE: An in-depth guide to advanced features - Updated for Scala 3.6
#+VERSION: 5th, PrePrint - 2025-05-20 -> 2025-08-13
#+AUTHOR: Martin Odersky, Lex Spoon, Bill Venners
#+STARTUP: entitiespretty
#+STARTUP: indent
#+STARTUP: overview

* Contents - xi
* List of Figures - xvi
* List of Tables - xviii
* List of Listings - xix
* Acknowledgments - xxv
* TODO 1 Opaque Types - 29 - =READING=
- Although types help you _achieve goals at compile time,_
  classes -- the most common way to define types in Scala -- _have runtime
  overhead._

- Using stack-resident instances (extend ~AnyVal~ instead of ~AnyRef~) can be
  more efficient than those that reside on the heap, as can avoiding
  heap-resident instances that simply wrap an ~AnyRef~ with another ~AnyRef~.

  Although often this runtime overhead may not matter to the performance of your
  application, it can sometimes be important. It is therefore useful to have a
  way to *define a type that _ONLY exists at compile time_,* which is guaranteed
  to have _zero overhead at runtime._

  Scala 3 introduced /opaque types/ for this purpose.

** DONE 1.1 The performance cost of boxing - 29
CLOSED: [2025-04-13 Sun 19:18]
=Review Later=
=IMPORTANT=

- Predicting performance when looking at source code is difficult, because the
  behavior of the JVM's just-in-time (JIT) compiler is hard to predict.

  The JIT compiler bases its decisions
  * not just on the code,
  * but also on the behavior of the running application.

- Nevertheless, despite the difficulty of making blanket statements about
  performance of Java bytecode,
  _it is possible to make some general observations about the performance cost of
  /boxing/._

- /boxing/ means
  _allocating memory for objects on the /heap/_ as opposed to the /stack/.

- The main way /boxing/ is likely to _HURT the performance_ of a Scala program
  running on the JVM is by causing /cache misses/.

  /Cache misses/ can be very costly to performance.

- =NEED REVIEW LATER=
  =Some details=
  =IMPORTANT=

- If objects are being *ALLOCATED* _at a high rate_, you are constantly
  _flushing your caches_ to bring in fresh memory to allocate objects that are
  often very short lived.

  * _The garbage collection cycles themselves will be *LOW cost*,_
    BECAUSE most objects don't survive the first collection of the young
    generation.

  _IN SUMMARY,_
  the *main cost* of /boxing/ in a garbage collected language is that allocations
  can CAUSE
  1. caches to be constantly flushed to bring in memory to allocate new objects,
  2. cache misses that result from indirections, and
  3. needing to reload objects that had previously been evicted to make room for
     new allocations.

** DONE 1.2 Use cases for zero-overhead types - 31
CLOSED: [2025-04-13 Sun 19:50]
- A /zero-overhead type/ can help you achieve
  1. /type safety/ goals at compile time
  2. _WITHOUT fear that_
     you may end up hurting performance at run time through UNNECESSARY
     /boxing/.

- Common use cases of /zero-overhead type/ (in Scala 3, /opaque type/ is the
  implementation):
  * Use different types to represent diffrent group of values which originally
    has the same Scala type. This can help improve distinguishability.

  * Different units of measure.

  * "narrowed type".
    + =from Jian=
      combined with /refined type/

  * Wrap a /mutable object/ with another whose interface _effectively reduces
    the state space of the underlying mutable,_ including
    1. reducing it to one state, enforcing that the mutable backing object is
       *UNMODIFIABLE*.

    For example, ~IArray~ in Scala 3.

** TODO 1.3 The ~AnyVal~ approach - 32 - =TODO: read ~AnyVal~ in book 1=
- As described in Section 17.4 of _Programming in Scala_, Scala allows you to
  define /new ~AnyVal~ types/ as /classes/ that
  extend ~AnyVal~ and
  follow certain rules:
  1. An ~AnyVal~ must wrap *one (and only one)* /instance/ of some _underlying
     type._

  2. You can't extend from an ~AnyVal~ /subclass/; they are *implicitly final*.
     =from Jian= I modified the statement in the book to make this meaning more
     explicit -- the original one is

  3. The *ONLY members* you can define inside an ~AnyVal~ are /methods/.

     * You
       + _CAN'T_ define /inner classes/ inside an ~AnyVal~,
       + _NOR_ can you define any field (_other than_ by making the lone class
         parameter of the underlying type public),
       + _NOR_ can you define /lazy vals/.

     * You
       can _mix in traits_,
       BUT only if they are *universal* -- this concept is listed below.

- Universal trait ::
  =IMPORTANT=
  =IMPORTANT=
  =IMPORTANT=
  Any /trait/ that
  2) extends ~Any~
  3) has only /methods/ as members, and
  4) contains _no initialization code._

- =TODO=
  Wherever possible, instances of user-defined ~AnyVal~'s are represented at
  runtime by their underlying type, but under certain circumstances, they will
  be boxed. When boxed, they will be an instance of the AnyVal wrapper type.
  Thus although user-defined AnyVals allow you to define types that may have
  reduced boxing overhead at runtime, they do not guarantee zero boxing
  overhead. In exchange, AnyVals can be used in ways that a truly zero-overhead
  type could not.

- An AnyVal is compiled like an AnyRef with some extra static methods. For each
  method declared in the AnyVal that isn’t inherited from a universal trait
  (these are called extractable methods), the compiler will create a
  static method that takes an extra parameter of the AnyVal’s underlying type.
  Where possible, the compiler will use the underlying type rather than the
  AnyVal wrapper type to represent instances. When an extractable instance
  method is invoked while the instance is in its unboxed form, the compiler
  invokes the static method instead, passing the underlying type as a
  parameter.

- *Intent* and *the original motivating use case*:
  1. The *intent* of the ~AnyVal~'s design was to allow you to create a /wrapper
     class/ that
     1) _behaves like a regular class,_
     2) BUT can sometimes be _represented by_ its _underlying type_, especially
        when /extractable instance methods/ are invoked.

  2. The /motivating use case/ for this feature was the addition of /implicit
     classes/ to Scala 2.10.
     =IMPORTANT=
     =IMPORTANT=
     =IMPORTANT=
     An /implicit class/ that extended ~AnyVal~ would *never need to box* to
     invoke any extractable methods.

     =IMPORTANT=
     =IMPORTANT=
     =IMPORTANT=
     This gave /Scala's implicit conversions/ the _SAME performance_ as enjoyed
     by /extension methods/ in other languages.
     *In Scala 3, HOWEVER*, /implicit classes/ were *replaced by* the special
     /extension method syntax/ described in Chapter 22 of Programming in Scala.

- ~AnyVal~'s will be boxed in many situations:
  =IMPORTANT=
  =CAUTION=
  =CAUTION=
  =CAUTION=
  =IMPORTANT=
  * /Universal traits/ allow you to use ~AnyVal~'s via more /abstract types/, as
    you can with ~AnyRef~'s, but it _requires boxing_ whenever an ~AnyVal~ is
    used from such a type.

  * You can also /override/ non-final methods declared in ~Any~ on an ~AnyVal~
    -- ~equals~, ~hashCode~, and ~toString~ -- BUT *any invocation of these
    methods will require a /box/.*

  * /Type tests/ on ~AnyVal~'s will perform as expected -- BOTH
      in ~isInstanceOf~ calls and
      in typed and constructor patterns --
    BUT any such use will require /boxing the ~AnyVal~./

    Because any of these uses could happen
    on an ~AnyVal~ used via an abstract type, whenever an abstract type is
    instantiated to an AnyVal, the AnyVal will be boxed. For example, if the
    type parameter of foldLeft on List is instantiated as an AnyVal type, the
    AnyVal instance passed as the initial zero parameter to foldLeft will be
    boxed. Another example is when you place an AnyVal into a collection such as
    a List. Each element of the collection will be boxed to the AnyVal form.
    This is also true of Arrays, even if the underlying type is a Java
    primitive: in a Java array of Scala AnyVals, each element will be boxed.

- In summary,
  ~AnyVal~'s let you avoid boxing in some situations, but not others.

  =IMPORTANT=
  =IMPORTANT=
  =IMPORTANT=
  If an ~AnyVal~ is REPEATEDLY /boxed/ and /unboxed/ throughout its lifetime, it
  could give you *worse performance than* a corresponding ~AnyRef~, which is
  just *boxed once*.

  User-defined ~AnyVal~'s successfully made /implicit conversions/ via /implicit
  classes/ as efficient as /extension methods/ in other languages,

  =IMPORTANT=
  =IMPORTANT=
  =IMPORTANT=
  _BUT_ there was still *a need in Scala for a TRULY /zero-overhead type/.*
  Scala 3's answer was /opaque types/.

=from Jian=
In Scala 2, I, also including others, I guess, combine /value classes/ and
/universal traits/, and use them as the role of /opaque types/ today.
After reading this chapter, it is clear that /opaque types/ is a better way,
_EXECPT_ that it can't do something reflectively during /runtime/ -- /opaque
types/ disappear after compilation.

- /Value classes/ in current Scala:
  =from Jian= This may change in the future because of JVM evolution.

  /Classes/ that extend ~AnyVal~ and follow certain rules:
  1. An ~AnyVal~ must wrap one (and only one) instance of some underlying type.

  2. You can't extend from an ~AnyVal~; they are *implicitly final*.

  3. The only members you can define inside an ~AnyVal~ are /methods/.
     * You *can't* define /inner classes/ inside an ~AnyVal~,
           *nor* can you define any /field/ (other than by making the lone class
                 parameter of the underlying type public =from Jian= public by
                 default),
           *nor* can you define ~lazy val~'s.
     * You can *mix in* /traits/, but only if they are "universal."
       + universal trait :: a /trait/ extends ~Any~, has only /methods/ as
         members, and _contains *NO* initialization code._ =???=

** DONE 1.4 The ~opaque type~ approach - 34
CLOSED: [2025-04-13 Sun 20:23]
- Syntax:
  An /opaque type/ is declared _LIKE_ a /type alias/ with an extra modifier,
  ~opaque~.
  * Example:
    #+begin_src scala
      object DefScope:
        opaque type LastName = String

        object LastName:
          def apply(s: String): LastName = s
    #+end_src

- =IMPORTANT=
  The compiler will treat any use of an /opaque type/ in one of TWO
  ways, DEPENDING ON *whether the use is INSIDE or OUTSIDE of _the opaque type's
  definition scope_.*

  * A /definition scope/ is the nearest enclosing /template/ in which an
    opaque type is defined.
    + template :: a class, trait, or singleton object.

  * *INSIDE* /definition scope/, an /opaque type/ is treated as if it were a
    /regular type alias/.

    Inside /definitions scope/, the compiler behave like:
    #+begin_src scala
      object DefScope:
        // Inside DefScope, LastName is treated as if it
        // were a regular type alias, defined like this:
        type LastName = String
    #+end_src

  * *OUTSIDE* of an /opaque type/'s definition scope, the compiler treats it as
    if it were an /abstract type/.

    Outside /definitions scope/, the compiler behave like:
    #+begin_src scala
      object DefScope:
        // Outside DefScope, LastName is treated as if it
        // were a abstract type, defined like this:
        type LastName
    #+end_src
    + Essentially, OUTSIDE ~DefScope~ the compiler treats ~LastName~ and
      ~String~ as two *completely different, unrelated* /types/.


- Listing 1.1 - Opaque "tiny" types.
  #+begin_src scala
    object TinyTypes:
      opaque type Anchor = String
      opaque type Style = String
      opaque type Text = String
      opaque type Html = String

      def title(text: Text, anchor: Anchor, style: Style): Html =
        s"<a id='$anchor'><h1 class='$style'>$text</h1></a>"

      object Anchor:
        def apply(s: String): Anchor = s

      object Style:
        def apply(s: String): Style = s

      object Text:
        def apply(s: String): Text = s

      object Html:
        def apply(s: String): Html = s
    end TinyTypes

    import TinyTypes.*

    //// Can't compile
    // def wontCompile(text: Text, anchor: Anchor, style: Style): Html =
    //   s"<a id='$anchor'><h1 class='$style'>$text</h1></a>"

    title(Text("Opaque Types"), Anchor("chap:otps"), Style("bold"))
  #+end_src

** DONE 1.5 Extension methods on opaque types - 37
CLOSED: [2025-04-13 Sun 20:40]
- Every /opaque type/ is a /subtype/ of ~Any~, and you can call methods defined
  on ~Any~ -- such as ~equals~, ~hashCode~, and ~toString~ -- on an /opaque
  type/.
  * Invoking these has the effect of invoking the like-named methods on the
    backing type.

- Because /opaque types/ are *NOT* /classes/, however, you *CANNOT* define any
  other methods DIRECTLY on them. Instead, you must use /extension methods/.
  Listing 1.2 shows an example in which /extension methods/ are added to two
  /opaque types/ backed by ~Double~: ~Inches~ and ~Centimeters~.

  * Listing 1.2 - Adding extension methods to Inches and Centimeters.
    #+begin_src scala
      object UnitsOfMeasure:
        opaque type Inches = Double
        object Inches:
          def apply(inches: Double): Inches = inches
          extension (inches: Inches)
            def value: Double = inches
            def toCentimeters: Centimeters = inches * 2.54

        opaque type Centimeters = Double
        object Centimeters:
          def apply(centimeters: Double): Centimeters = centimeters
          extension (centimeters: Centimeters)
            def value: Double = centimeters
            def toInches: Inches = centimeters / 2.54


      import UnitsOfMeasure.*

      val inches = Inches(42.0)     // 42.0 (type Inches)
      inches.value                  // 42.0 (type Double)
      val cm = inches.toCentimeters // 106.68 (type Centimeters)
      cm.value                      // 106.68 (type Double)
    #+end_src

** DONE 1.6 Bounds on opaque types - 38
CLOSED: [2025-04-13 Sun 21:02]
- The DISTINCT /values/ of a /type/ are referred to as the /inhabitants of the
  type/.

- One important use case for /opaque types/ is defining a /type/ that represents
  _a SUBSET of an *immutable* underlying type's values._
  * For example,
    you might want to define a type, ~NonEmptyString~, which can be backed by
    any string value other than an empty string.

- This means ~NonEmptyString~ could be seen as a subtype of ~String~.
  * ~NonEmptyString~ would have one lessinhabitant than String: the empty
    string.

- In the case of ~NonEmptyString~, it would be convenient if the compiler could
  treat it as a /subtype/ of ~String~, at least in terms of /automatic widening
  conversions/:
  If some method asks for a ~String~, and you have a ~NonEmptyString~ in hand,
  it would be nice to just be able to pass the ~NonEmptyString~ as is,
  *WITHOUT converting it to a String explicitly.* It will *always be a safe*
  conversion, and intuitively a non-empty string is-a string.

  * You can
    _establish that sort of /subtyping relationship/ by including an /upper
    boun/d on the ~NonEmptyString~ /opaque type/._

    Listing 1.3 shows how you would do that for ~NonEmptyString~.
    #+begin_src scala
      object NonEmptyStrings:
        opaque type NonEmptyString <: String = String

        object NonEmptyString:
          def apply(s: String): NonEmptyString =
            require(s.nonEmpty)
            s

          def from(s: String): Option[NonEmptyString] =
            if s.nonEmpty then Some(s) else None
    #+end_src

- Defined this way, you can now use a ~NonEmptyString~ where a String is
  required:
  #+begin_src scala
    import NonEmptyStrings.*

    val nes: NonEmptyString = NonEmptyString("hi")
    val s: String = nes // A NonEmptyString isa String
  #+end_src
  =FIXME=: ~import NonEmptyStrings._~ ==> ~import NonEmptyStrings.*~

- Note that adding an /upper bound/ to an /opaque type/ acts much like
  the ~extends~ keyword does when defining a /class/.

  In particular, an /opaque type/ "inherits" the interface of its /upper bound/.
  #+begin_src scala
    "hi".charAt(1)                 // i
    NonEmptyString("hi").charAt(1) // i
  #+end_src

- If you want to add new methods to ~NonEmptyString~ that don't exist on
  ~String~, define /extension methods/ on ~NonEmptyString~.

** DONE 1.7 Peaking behind the curtain - 40
CLOSED: [2025-04-14 Mon 00:37]
- One _CONSEQUENCE_ of the _zero overhead promise_ for /opaque types/ is that
  there will be *NO information available about an /opaque type/ at runtime.*

  The ONLY information available _at runtime_ will be for *the opaque type's backing
  object*.
  Because of this absence of runtime information, reflection performed on an
  object with an /opaque type/ will behave in ways that *may SURPRISE you.*

  =IMPORTANT=
  =IMPORTANT=
  =IMPORTANT=
  In short,
  if you try to do anything reflectively with an /opaque type/, you will be
  peering behind the curtain at the backing object's class.

- Example:
  Listing 1.4 · Opaque types for street and city.
  #+begin_src scala
    object StreetAndCity:
      opaque type Street = String
      opaque type City = String
      object Street:
        def apply(s: String): Street = s
      object City:
        def apply(s: String): City = s

    import StreetAndCity.*

    City("Paris").isInstanceOf[String] // true

    "Rue Cler".isInstanceOf[City] // true
    // -- Unchecked Warning: ------------------
    // 15 |    "Rue Cler".isInstanceOf[City])
    //    | ˆˆˆˆˆˆˆˆˆˆ
    //    |the type test for StreetAndCity.City
    //    |cannot be checked at runtime

    Street("Rue Cler").isInstanceOf[City] // true
    // -- Unchecked Warning: ------------------
    // 16 |    Street("Rue Cler").isInstanceOf[City]
    //    |    ˆˆˆˆˆˆˆˆˆˆˆˆˆˆˆˆˆˆ
    //    |the type test for StreetAndCity.City
    //    |cannot be checked at runtime
  #+end_src

- Compare /opaque types/ with ~AnyVal~'s about in this scenario:
  Note that with ~AnyVal~'s, these features do work consistently with
  ~AnyRef~'s
  BECAUSE the compiler inserts a /boxing/ operation before any such runtime
  test. The /boxing/ operation establishes the runtime information that
  enables ~isInstanceOf~ to work as expected, _but COSTS a /box/._

  By contrast,
  /opaque types/ _NEVER cost a /box/,_
  BUT are *unable* to make ~isInstanceOf~ work as consistently with ~AnyRef~'s.

** TODO 1.8 The ~Matchable~ trait - 41 - =TODO: read equality and multiversal equality first=
** DONE 1.9 Conclusion - 46
CLOSED: [2025-04-14 Mon 01:38]
/Opaque types/ allow you to get benefit of /compile time checking/ *WITHOUT* any
_runtime performance cost_,
BUT don't fit well with Scala's tradition of allowing _pattern matches on
~Any~._ The ~Matchable~ /universal trait/ was added in Scala 3 to mitigate this
issue.

* DONE 2 Inlining - 47
CLOSED: [2025-04-08 Tue 14:57]
- This feature
  * _ENABLES_ the compiler to perform certain computations at compile time that
    reduce the computational demands at runtime

    or

  * _ENABLE_ (=FIXME=) metaprogramming at compile-time.

- Through techniques such as /constant folding/ and /partial evaluation/, the
  Scala compiler can perform computations prior to the program's execution.

- Inlining in Scala 3 also facilitates metaprogramming:
  it allows you to write code that generates code.


- This chapter will cover
  1. the basics of inlining,
     including inline constants and methods, and

  2. along the way also discuss
     /singleton types/,
     /literal constant types/, and
     _the dualism between inlining and factoring._ =TODO= =???=

** DONE 2.1 Singleton types - 47
CLOSED: [2025-04-07 Mon 18:56]
- inhabitants :: as mentioned in Section 1.6, one way to view types is as _sets_
  of values.
  * When viewed this way the notion of _subset_ corresponds to /subtype/.

- singleton set :: a set with just one element.
  * singleton type :: a type with just one inhabitant.

- Scala 2 included support for singleton types, and
  Scala 3 gives them more roles to play.

- You can FORM a /singleton type/ for ANY /singleton object/ by APPENDING
  ~.type~ to the name of the /singleton object/.
  * Example:
    #+begin_src scala
      def descibe(ds: DoorState): String = ds.toString
      def descOpen(o: Open.type): String = o.toString

      descOpen(open) // "Open"
      descOpen(Closed) // DOES NOT COMPILE

      val door: DoorState = Open
      descOpen(dorr) // DOES NOT COMPILE

      val openDoor: Open.type = Open
      descOpen(openDoor) // "Open"
    #+end_src

- You can also form a /singleton type/ for ANY ~val~ by APPENDING ~.type~ to the
  ~val~ name.
  *Must be val, NOT var*
  * Example:
    #+begin_src scala
      val msg: Some[String] = Some("hello") // `Some[Stirng]` is NOT a singleton type
      def getString(s: msg.type): String = s.getOrElse("hi")

      getString(msg)           // "hello"
      getString(Some("hello")) // DOES NOT COMPILE
    #+end_src

  * *NOTE*:
    EVEN THOUGH TWO ~val~'s may refer to the SAME object, their /singleton
    types/ are *DISTINCT*.
    For example, you can't do ~val greeting: Some[Stirng] = msg~ and pass it
    to the ~getString~, which only accept a ~msg.type~ parameter.

- Lastly, you cannot make a /singleton type/ out of a ~var~, because the object
  referred to by the ~var~ can change over time.

  The reason a ~val~ can be used to form a /singleton type/ is precisely because
  a ~val~ *CANNOT be reassigned*: _it will always refer to the same, single
  object_.

** DONE 2.2 Literal singleton types - 51
CLOSED: [2025-04-07 Mon 20:07]
- Scala 3 introduced /literal singleton types/, also called /literal constant
  types/.

  These are /singleton types/ for ~Int~, ~Long~, ~Float~, ~Double~, and
  ~String~: types with literals supported by the Scala language, such as ~3~,
  ~2.0~, or ~"one"~.

  * No need for ~.type~.

** DONE 2.3 Inlined constants - 52
CLOSED: [2025-04-07 Mon 20:42]
- inlined constants :: ~val~'s declared as ~inline~.
  * All usage sites of an ~inline val~ will be rewritten in place to the
    initializer expression of that ~val~.

- ~Inline val~'s SUPPORT /constant folding/ and /constant propagation
  optimizations/ by the Scala compiler.

  * Constant folding :: EVALUATING expressions that involve constants at compile
    time.

  * Constant propagation :: REPLACING variables with known constant values at
    compile time, including those whose constant values become known through
    prior /constant folding and propagation/.

    + Example:
      #+begin_src scala
        val x = rewriteTo2 + rewriteTo2
      #+end_src
      1. Rewrited using /constant propagation/:
         ~val x = 2 + 2~

      2. Rewrited using /constant folding/:
         ~val x = 4~

- =IMPORTANT=
  When you define an ~inline val~, the /initializer expression/ *MUST* have
  a /literal constant type/.
  * _NO need_ to be EXPLICIT.

  * if you provide an *EXPLICIT* /literal constant type annotation/, you can
    optionally LEAVE OFF the ~inline~ modifier.

    =IMPORTANT=
    =IMPORTANT=
    =IMPORTANT=
    the actual trigger of this behavior is the literal constant type, *NOT* the
    ~inline~ modifier.

    The ~inline~ modifier mainly serves as a way to tell the compiler you _want
    it to infer_ a /literal constant type/.

- The *ACTUAL REASON* that ~aTwo~ will be used in /constant propagation and
  folding/, whereas ~anInt~ will not, therefore, is because ~aTwo~ has a
  /literal constant type/ and ~anInt~ does not.

  To observe this behavior, you can define a ~val~ that is not marked as
  ~inline~, *BUT* is annotated with a /literal constant type/, like this:
  #+begin_src scala
    val explicitlyTwo: 2 = 2
  #+end_src
  Use this ~explicitlyTwo~ variable in an initializer expression of an ~inline
  val~
  #+begin_src scala
    inline val z = explicitlyTwo + explicitlyTwo
  #+end_src
  This will compile. BECAUSE through /constant folding and propagation/, the
  compiler will reduce the /initializer expression/ to 4.

** DONE 2.4 Inline methods - 54
CLOSED: [2025-04-07 Mon 23:12]
- define an /inline method/ :: You can also mark a ~def~ with the ~inline~
  modifier.
  * For /inline method/, compiler will replace the invocation site with the
    method's body.

- Q :: How does /inline method/ expand?
  #+begin_src scala
    inline def add(regularParam: Int, byNameParam: => Int): Int =
      regularParam + byNameParam

    val n = 8
    val res = add(10, n + 2)
  #+end_src

- A :: Code
  #+begin_src scala
    val res =
      // Inlined invocation of add:
      val regularParam = 10
      def byNameParam = n + 2
      regularParam + byNameParam
  #+end_src

- Q :: How about /inline method/, which has /inline parameter(s)/, expand?
  #+begin_src scala
    inline def add(regularParam: Int,
                   byNameParam: => Int,
                   inline inlineParam: Int): Int =
      regularParam + byNameParam + inlineParam + inlineParam

    val n = 8
    val m = 9
    val res = sum(10, n + 2, m * n)
  #+end_src
  =from Jian=:
  The second ~inlineParam~ in ~add~ is added by me.
  I think with it, the following expansion can be clearer!

- A :: Code
  #+begin_src scala
    val res =
      // Inlined invocation of sum:
      val regularParam = 10
      def byNameParam = n + 2
      regularParam + byNameParam + m * n + m * n
  #+end_src

  Or using ~inline val~ to achieve the same final result
  #+begin_src scala
    val res =
      // Inlined invocation of sum:
      val regularParam = 10
      def byNameParam = n + 2
      inline val inlineParam = m * n
      regularParam + byNameParam + inlineParam + inlineParam
  #+end_src
  After inline of ~inlineParam~, the body will look as in the previous
  expansion.

** DONE 2.5 Preserving semantics - 57
CLOSED: [2025-04-08 Tue 00:37]
The Scala 3 compiler will ensure that the semantics of a method invocation will
*NOT change* whether you add or remove an ~inline~ modifier to a ~def~.

*The performance of a method might change, but not its semantics.*

- The purpose of _the semantics preservation design_ goal for Scala's /inline
  methods/ was to make them easier to reason about:
  you can count on an /inline method/ to compute the same result and have the same
  side effects, if any, as the equivalent method without the ~inline~ modifier.

  To achieve this goal, the Scala compiler makes ALL /type-directed decisions/
  -- such as /overload resolution/, /implicit lookup/, and /extension method
  resolution/ -- *on the method body while typing it, _BEFORE_ inlining it.*
  =IMPORTANT=
  =IMPORTANT=
  =IMPORTANT=

- Example:
  #+begin_src scala
    enum Fruit:
      val color: String
      def name = getClass.getSimpleName
      case Plum(color: String)
      case Apricot(color: String)

    import Fruit._

    class Processor:
      def withFruit(fruit: Fruit): String =
        s"process ${fruit.color} ${fruit.name}"

    class Juicer extends Processor:
      def withFruit(plum: Plum): String =
        s"make ${plum.color} juice"
  #+end_src

  #+begin_src scala
    inline def processFruit[T](pr: Processor, fr: Fruit): String =
      pr.withFruit(fr)

    val pr = new Juicer
    val fr = new Plum("purple")
    pr.withFruit(fr)
  #+end_src
  If /type-directed decisions/ are performed after inlining, we will see
  ="make purple juice"=, which change the semantics! If we do /type-directed
  decisions/ before inlining or remove ~inline~, we we see the output
  ="process purple Plum"=.

** DONE 2.6 Partial evaluation - 58
CLOSED: [2025-04-08 Tue 00:51]
When the compiler encounters an /inline method/, it will attempt to evaluate as
much of the method's body as it can at compile time. Because the compiler may
only be able to evaluate part of an expression at compile time, this behavior is
called /partial evaluation/.

- Example:
  #+begin_src scala
    inline def factorial(x: Int): Int =
      if x == 0 then 1
      else x * factorial(x 1)
  #+end_src
  1. If a constant expression is passed,
     this process *reduces* _runtime overhead_, BECAUSE the computation of the
     factorial is done during compilation instead of at runtime.

  2. If a non-constant expression is passed, the
     expansion *can't stop* because each step may contains the /inline method/ call.

     *To avoid this,* you can add ~inline~ modifier to ~if~ indicates that you
     expect the compiler to
     * EITHER evaluate the ~if~ expression at compile time
     * OR give a compiler error.

     #+begin_src scala
       inline def fact(x: Int): Int =
         inline if x == 0 then 1
         else x * fact(x - 1)
     #+end_src

- CONCLUSION:
  =IMPORTANT=
  =IMPORTANT=
  =IMPORTANT=
  In a /recursive inline method/, ~inline if~ is a good way to do a _convergence
  check_.

  The semantics of the ~if~ expression will be preserved whatever you make it is
  a good way to indicate that it is designed to be /partially evaluated/.

** DONE 2.7 Inline methods and inheritance - 62
CLOSED: [2025-04-08 Tue 11:57]
- Because the compiler replaces /inline method invocations/ with their /method
  bodies/, *some limitations exist* in _how you can combine inline methods with
  inheritance._
  * First,
    /inline methods/ are *EFFECTIVELY ~final~:* they can't be overridden by
    /subclasses/.

    Because an /inline method/'s code is embedded directly into the call site
    during compilation,
    =IMPORTANT=
    =IMPORTANT=
    =IMPORTANT=
    *there's NO POSSIBILITY for a /dynamic call/ that resolves to a subclass
    implementation at runtime*.

  * On the other hand,
    although *YOU CAN'T* OVERRIDE an /inline method/ with another method,
    *YOU CAN*
    IMPLEMENT an /abstract method/, or
    OVERRIDE a NONINLINE method, with an /inline method/.

    + In this case,
      - when the method is invoked on the /subclass type/, the _subclass's
        method body_ will be inlined at that call site.

      - If the method is invoked on the superclass type, the method
        implementation must be determined by the object's class at runtime.

    + In particular,
      =from Jian= _if runtime method resolution is required,_
      if the actual class at runtime is the /subclass type/, the /inline method/
      in the subclass must be invoked.

      This can be useful when you want to provide an optimized implementation of
      a method in a subtype, but you still want to use the same method signature
      in a supertype interface.

      =from Jian=
      This means _NOT ALL_ /inline methods/ can be inlined at runtime. When
      subtyping polymorphism feature is used and only methods in subtype(s) are
      /inline methods/, because things need to be decided at runtime, _inline
      may not happen_.

- =from Jian=
  The above are the requirements,
  now let's see the implementation details:

- To support this use case, the compiler generates
  _a RETAINED OR NON-INLINED version of an inline method_
  WHENEVER
  it overrides a _concrete or abstract noninline method._

  * A /retained method/ will be EXECUTED
    WHEN the method is _invoked on a supertype reference._

    *This preserves the expected semantics, just without any inlining.*

- Example:
  #+begin_src scala
    trait Fruit:
      def peel(n: Int): String

    class Orange extends Fruit:
      inline def peel(n: Int): String =
        s"Peeled into $n pieces."

    val orange: Orange = new Orange
    // will be inlined
    orange.peel(3) // Peeled into 3 pieces

    val fruit: Fruit = orange
    // on inlinement happens
    fruit.peel(3) // Peeled into 3 pieces
  #+end_src

** DONE 2.8 Abstract methods can be inline - 63
CLOSED: [2025-04-08 Tue 14:33]
/inline abstract method/

- Example:
  #+begin_src scala
    trait Vegetable:
      inline def slice(n: Int): String

    class Broccoli extends Vegetable:
      inline def slice(n: Int): String =
        s"Sliced into $n pieces."
  #+end_src
  * Compilable:
    #+begin_src scala
      val broccoli: Broccoli = new Broccoli
      broccoli.slice(5) // Ok (and inlined)
    #+end_src

  * NOT Compilable:
    #+begin_src scala
      val vegetable: Vegetable = broccoli
      // Error
      vegetable.slice(5)
    #+end_src

- One *RESTRICTION* on /inline methods/ that _override non-inline methods_:
  they _CANNOT_ take /inline parameters/.

  This restriction arises
  BECAUSE the overriding inline method needs to have the same signature as the
  non-inline method it's overriding, and _non-inline methods *CANNOT* have
  inline parameters._
  Inline parameters can only be declared, therefore, in inline methods that
  don’t override non-inline methods.

** DONE 2.9 Performance considerations - 65
CLOSED: [2025-04-08 Tue 14:56]
- Although inlining could potentially help your application's performance,
  it could also hurt it.

  Mostly, you can trust JVM JIT compiler and optimizer, instead of do inlining
  manually.

- Inline can increase the code size of the method that receives the inlined
  code. If the size of a method's code grows too large, it can hurt your
  application's performance by *EXCEEDING* _the CPU's capacity to cache
  instructions._

  * *Consequently, inline methods are not universally faster than regular methods.*

  Except in unique scenarios where specific knowledge informs your decision, you
  should
  *avoid using /inline methods/ solely to avoid the cost of a /method call/
  alone.*

- That said, /inlining/ can be an effective tool for performing computations at
  compile time through /constant folding/, /constant propagation/, and /partial
  evaluation/.

  _BY *reducing* the amount of code executed at runtime_, you not only
  facilitate instruction caching but also enhance performance by not executing
  code at runtime.

  * There is a *trade-off*, however:
    /partial evaluation/ and /constant folding and propagation/ may increase
    your compile time.

    Essentially when you use /inline constants and methods/ you are trading off
    /compile time/ for /runtime cost/.

- _The moral of the story_:
  you should
  in general consider /inline/ in Scala as *a gateway to metaprogramming*,
  *NOT* as a path to better performance through the elimination of method calls.

- *Constant folding across method boundaries*
  #+begin_src scala
    inline val pi = math.Pi // Initializing with a final val
    inline def area(inline radius: Double): Double =
      pi * radius * radius
  #+end_src
  _Were it not for the existence of /inline methods/, /constant folding/ would
  only be possible within the body of methods._
  =from Jian=:
  for this example, if there weren't /inline method/, no /constant folding/,
  only /constant propagation/ exists.

- *Factoring and inlining are duals*
  In short, /inlining/ enables you to *reduce code duplication* in your source
  code *without reducing* it in the binaries.

  Or, in the best of both worlds, (=from Jian= If use ~inline if~ properly) you
  can
  * *reduce* code duplication in your source code and through
    + partial evaluation
    + constant folding and propagation,

  * *also reduce* the code in your binaries.

- *Side effects and performance costs*
  When writing an /inline function/ with /inline or by-name parameters/, it is
  important to keep in mind the potential for /side effects/ and /long-running
  computations/ in the passed expressions.

  Because these types of parameters cause the *re-execution of code* each time
  they appear in the body of the function, multiple uses of such parameters
  could cause /side effects/ or /long-running computations/ to be *executed
  REPEATEDLY*. Consider the following function:
  #+begin_src scala
    inline def addTwice(inline ip: Int, bnp: => Int): Int =
      ip + bnp + ip + bnp

    addTwice({ print("ip "); 1 }, { print("bnp "); 20 })
  #+end_src

  *To AVOID duplication of side effects or long-running computation,*
  make sure execute /inline parameter/ or /by-name parameter/ once and bind the
  results to local variables
  #+begin_src scala
    inline def addTwice(inline ip: Int, bnp: => Int): Int =
      val ipsRes = ip
      val bnpRes = bnp
      ipRes + bnpRes + ipRes + bnpRes
  #+end_src

** DONE 2.10 Conclusion - 68
CLOSED: [2025-04-08 Tue 14:57]

* DONE 3 Metapgrogramming - 69 - _TODO: NOTE_
CLOSED: [2025-08-19 Tue 23:01]
No matter which programming language you are using, you may at times find
yourself writing _repetitive, error-prone code._
_/Metaprogramming/ is well-suited for these situations._

- _TRADITIONALLY_, /metaprogramming/ has been accomplished done by writing a
  /code generator/: a program that runs as part of your build and outputs source
  code that then gets compiled alongside the source code you wrote by hand.

  * You can certainly take this _TRADITIONAL APPROACH_ when programming with
    Scala 3, but Scala 3 offers a powerful alternative: *you can write code
    generators _WITHIN_ the language itself.*

- Scala 3 includes several features that facilitate metaprogramming.
  /Inline methods/, described in the previous chapter, are one example.

  This chapter will introduce more _metaprogramming facilities_ of Scala 3,
  including
  * /inline matches/
  * /transparent inlines/
  * /other compile-time functionality/

** DONE 3.1 Inline matches - 69
CLOSED: [2025-08-19 Tue 12:00]
- One of the language features introduced in Scala 3 that gives you new and
  powerful metaprogramming capabilities is ~inline match~.

  * Although similar in many ways to ~inline if~,
    ~inline match~ *differs in a significant way.*

  * Like an ~inline if~, an ~inline match~ will
    + either _be REDUCED at compile time,_
    + or if that's not possible, result in a _compiler error_.

  * But there's a big difference:
    =IMPORTANT=
    =IMPORTANT=
    =IMPORTANT=
    ~inline if~ is designed to *preserve semantics*;
    ~inline match~ is *not*.

    + Because ~inline if~ is aimed at /partial evaluation/, the compiler ensures
      the if expression semantics will be the same whether you add or remove an
      ~inline~ modifier.

    + BY CONTRAST,
      ~inline match~ is AIMED AT *unlocking metaprogramming capabilities* that
      are POSSIBLE ONLY at compile time.
      =IMPORTANT=
      =IMPORTANT=
      =IMPORTANT=
      As a result, the /semantics of the match expression/
      *may be different* _IF_ you add or remove the ~inline~ modifier.

- scrutinee of a match :: the /variable/ or /expression/ on which you are
  matching.
  * such as the ~s~ in ~s match~.

- Listing 3.1 · An inline method with an inline match.
  #+begin_src scala
    inline def sigBitsInlineMatch(s: String): Int =
      inline s match
        case "Byte" => 8
        case "Short" => 16
        case "Int" => 32
        case "Long" => 64
        case "Float" => 32
        case "Double" => 64
        case _ => -1 // Use Int -1 as default result
  #+end_src
  * This /inline match/ includes a _VALID default case_, meaning you won't get a
    compiler error during evaluation.

  * Note from Jian:
    Since this uses /inline syntax/ that only works with compile-time knowledge,
    any input not matching the specific cases exactly and literally before the
    catch-all case ~case _ => -1~ will trigger the /catch-all case/.

    For example:
    + Input ~"Byte"~ matches the first branch
    + Input ~"Byte": String~ would fall to the default case
      This behavior is *different from* the method without ~inline~ modifier:

      Listing 3.2 · The corresponding method with a regular match.
      #+begin_src scala
        inline def sigBitsRegularMatch(s: String): Int =
          s match
             case "Byte" => 8
             case "Short" => 16
             case "Int" => 32
             case "Long" => 64
             case "Float" => 32
             case "Double" => 64
             case _ => -1 // Use Int -1 as default result
      #+end_src
      Both ~"Byte"~ and ~"Byte": String~ go into the first branch ~case ~"Byte"
      => 9~.

- Listing 3.3 · An inline match with typed patterns.
  #+begin_src scala
    inline def zeroForElemType[T](xs: List[T]): AnyVal =
      inline xs match
        case byte: List[Byte] => 0.toByte
        case short: List[Short] => 0.toShort
        case long: List[Long] => 0L
        case float: List[Float] => 0.0f
        case double: List[Double] => 0.0
        case _ => 0 // Use an Int as default result

    zeroForElemType(List(1.0, 2.0, 3.0)) // 0.0: Double
    zeroForElemType(List(1L, 2L, 3L)) // 0: Long
    zeroForElemType(List(1, 2, 3)) // 0: Int
  #+end_src
  Unlike a _regular match_, an _inline match_ *can tell the difference* between a
  ~List[Double]~ and a ~List[Int]~, even though both are instances of trait
  ~List[A]~, whose /type parameter/, ~A~, will be *erased* by the compiler and
  therefore _unknown at runtime._

- Note that ~isInstanceOf~ in the condition of an ~inline if~ does *NOT
  compile*, and ~inline match~ can be used to resolve this:
  #+begin_src scala
    inline def whatIsGood(av: AnyVal): String =
      inline av match
        case _: Byte => "Byte"
        case _ => "Other"
  #+end_src

** TODO 3.2 Transparent inline methods - 73
Another powerful metaprogramming feature of Scala 3 is /transparent inline
methods/, which enable you to _refine the /types/ of your program AT COMPILE
TIME._

- _By default,_
  the Scala compiler performs _inlining_ *after* /the typer phase/,
  * the typer phase :: the phase in which it decides on all types in the
    program. When the compiler performs inlining after this phase, it cannot
    change the types.

- _By contrast,_
  the compiler will _inline_ /transparent methods/ *before* /the typer phase/,
  when it is still possible to refine the types.

  This allows the type of the inlined code to be more specific. To indicate you
  want this compiler behavior, you put the soft modifier ~transparent~ in front
  of ~inline def~.

- Listing 3.5 · A transparent inline method.
  #+begin_src scala
    transparent inline def transparentInlineDef(s: String): AnyVal =
      inline s match
        case "Byte" => 1.toByte
        case "Short" => 1.toShort
        case "Long" => 1L
        case "Float" => 1.0f
        case "Double" => 1.0
        case _ => 1 // Use an Int as default result


    transparentInlineDef("Byte") // 1.toByte: Byte
    transparentInlineDef("Float") // 1.0f: Float
    transparentInlineDef("Other") // 1: Int
  #+end_src

** TODO 3.3 Constructor patterns in inline matches - 75
** TODO 3.4 Compiler errors from inline matches - 77
** TODO 3.5 Summoning in inline methods - 78
** TODO 3.6 Converting from type to term - 81
** TODO 3.7 Conclusion - 84

* TODO 4 Type-level functions - 85 - =START HERE=
At the CORE of /functional programming/ is the /function/, a way to _transform
input into output._

- In this chapter we will look at _several features INTRODUCED or ENHANCED in
  Scala 3_ that can be understood as
  /functions/ that operate either in whole or part *at the type level*,
  * often COMPARING them to their *value-level* counterparts.

- We'll look at /abstract types/ and /type aliases/ from the perspective of
  /type-level variables and functions/.

- We will introduce /polymorphic functions/ and /type lambdas/.

- We'll
  * explore /kinds/, and
    + kinds :: the "type" of a /type/.
  * look at _the /variance/ of PARAMETER and RESULT /kinds/._

** DONE 4.1 Value-level functions - 85 - NOTE
CLOSED: [2025-08-21 Thu 18:44]
Scala 3 introduced several new flavors of /function/ that operate
_at the type level._
To help you understand these, it can help to take another look at Scala's
/value-level functions/. These functions existed in Scala 2 and work the same
in Scala 3.

- Scala offers _TWO distinct ways_ to write /value-level functions/:
  * /methods/ (or "defs") and
  * /function literals/

- =TODO=
  Note for details!!!

- Q :: Why does Scala have these two ways to describe a /function/:
  * /method/
  * /function literal/?

- A :: Because it is convenient to have concise syntax
  * dedicated to writing /named functions/
    + convenient when you plan to invoke them many times.

  * for defining a function that you aren't forced to name
    + useful when you only plan to use them once.

** TODO 4.2 Reasoning with substitution - 87
** TODO 4.3 Substitution and currying - 89
- The arrow symbol (=>) in Scala *associates to the right*.

** TODO 4.4 Polymorphic functions - 90
- *Types classify terms*

** TODO 4.5 Viewing types as set of values - 95
** TODO 4.6 Covariant method result types - 98
** TODO 4.7 Variance and function literals - 99
** TODO 4.8 Viewing kinds as sets of types - 101 - =START HERE=
** TODO 4.9 Monomorphic type members - 108
** TODO 4.10 Polymorphic type members - 110
** TODO 4.11 Type lambdas - 112
*** Type lambdas in the type lattice - 114

** TODO 4.12 Result kind inference - 115
** TODO 4.13 Type lambdas subtyping - 119
** TODO 4.14 Bringing it all together - 126
- *Type lambdas versus polymorphic function types*

** TODO 4.15 Conclusion - 136

* TODO 5 Type constructors - 137 - =RANK 0 for reading=
** 5.1 Monomorphic classes - 137
** 5.2 Nonvariant polymorphic classes - 139
** 5.3 Covariant and contravariant polymorphic classes - 144
** 5.4 Parameterized types - 151
** 5.5 Eta expansion at the type level - 152
** 5.6 Variance of type constructors - 156
** 5.7 Omnivariance - 162
** 5.8 Inferred variance of type lambdas - 167
** 5.9 Conclusion - 169

* TODO 6 Abstracting with Kinds - 170
** 6.1 Intervals as sets - 170
** 6.2 Wildcard type arguments - 174
** 6.3 Reasoning with substitution - 178
** 6.4 Wildcard type arguments and variance - 186
** 6.5 Abstract type members - 191
** 6.6 Types as propositions - 196
** 6.7 Wildcard capture - 204
** 6.8 Type parameters versus abstract type members - 208
** 6.9 Conclusion - 218

* TODO 7 Programming the Compiler - 219
** 7.1 Context parameter resolution - 219
** 7.2 Context parameters as constraints - 222
** 7.3 Logic programming - 223
** 7.4 Context functions - 229
** 7.5 Match types - 237
** 7.6 Conclusion - 243

* TODO 8 Implementing Lists - 244
- Chapter 16 showed you how to use lists.
  This chapter “opens up the covers” and explains a bit about how lists are
  implemented in Scala.

- Knowing the internal workings of the ~List~ /class/ is useful for several
  reasons:

  * Gain a better idea of _the relative efficiency of list operations_,
    which will help you in writing fast and compact code using lists.

  * From the implementation of Scala ~List~ to _learn how to design_ your own
    libraries.

  * Finally, the ~List~ /class/ is a sophisticated application of Scala's type
    system in general and its genericity concepts in particular.
      So studying class List will deepen your knowledge in these areas.

** DONE 8.1 The ~List~ class in principle - 244
CLOSED: [2018-03-20 Tue 02:19]
- Scala ~List~'s is NOT built-in.
  They are defined by an /abstract class/ ~List~ in the ~scala~ package, which
  comes with two /subclasses/ for ~::~ and ~Nil~.
  #+BEGIN_SRC scala
    package scala

    abstract class List[+T] {
      // ...
    }
  #+END_SRC

  * Since it is /abstract/, you cannot ~new~ a ~List~.
    You can only use the /factory method/!

- This section presents a somewhat *simplified* account of the class,
  compared to its _real implementation_ in the Scala standard library, which
  is covered in Section 22.3.

- This chapter will present a somewhat simplified account of ~List~.

- ~List[T]~ has two subtypes:
  * the /case object/ ~scala.Nil~

  * the ~final~ /case class/ ~scala.::[T]~

- All list operations can be defined in terms of three basic methods:
  * ~def isEmpty: Boolean~

  * ~def head: T~

  * ~def tail: List[T]~

  They are all /abstract/ in ~List~

*** DONE The ~Nil~ object - 245
CLOSED: [2018-03-20 Tue 02:10]
#+BEGIN_SRC scala
  // Simplified
  case object Nil extends List[Nothing] {
    override def isEmpty = true

    override def head: Nothing =
      throw new NoSuchElementException("head of empty list")

    override def tail: List[Nothing] =
      throw new NoSuchElementException("tail of empty list")
  }
#+END_SRC

Here ~Nothing~ is NOT only reasonable but also guarantee the /convariance/.

*** DONE The ~::~ class - 246
CLOSED: [2018-03-20 Tue 02:10]
#+BEGIN_SRC scala
  final case class ::[B](head: B, private[scala] var tail: List[B]) extends List[B] {
    override def isEmpty: Boolean = false
  }


  /* The implementation in the standard library */

  // final case class ::[B](override val head: B, private[scala] var tl: List[B]) extends List[B] {
  //   override def tail: List[B] = tl
  //   override def isEmpty: Boolean = false
  // }
#+END_SRC

*** DONE Some more methods - 247
CLOSED: [2018-03-20 Tue 02:13]
All other List methods can be written using the basic three. For instance:
#+BEGIN_SRC scala

  def length: Int =
    if (isEmpty) 0 else 1 + tail.length

  // or:
  def drop(n: Int): List[T] =
    if (isEmpty) Nil  else
    if (n <= 0)  this else
                 tail.drop(n 1)

  // or:
  def map[U](f: T => U): List[U] =
    if (isEmpty) Nil
    else         f(head) :: tail.map(f)
#+END_SRC

*** DONE List construction - 247
CLOSED: [2018-03-20 Tue 02:19]
The list construction methods ~\colon{}\colon{}~ and ~:::~ are SPECIAL.
Because they end in a colon, they are _bound to their right operand_.
#+BEGIN_SRC scala
  def ::[U >: T](x: U): List[U] = new scala.::(x, this)

  def :::[U >: T](prefix: List[U]): List[U] =
    if (prefix.isEmpty) this
    else                prefix.head :: prefix.tail ::: this
#+END_SRC

** DONE 8.2 The ~ListBuffer~ class - 250
CLOSED: [2018-03-20 Tue 02:27]
- ~List~ is inefficient on adding elements to the end of its tail.
  Try to use ~ListBuffer~.

- ~ListBuffer~ is a class in package ~scala.collection.mutable~.

- Use ~ListBuffer~ to build a list-like structure, and use ~toList~ /method/
  to convert itself to a ~List~ at the end of a sequence of operations.
    For example,
  #+BEGIN_SRC scala
    import scala.collection.mutable.ListBuffer


    val buf = new ListBuffer[Int]
    for (x <xs)
      buf += x + 1
    buf.toList
  #+END_SRC

- This is a *very efficient* way to build lists.

  In fact, the list buffer implementation is organized so that both the
  append operation (~+=~) and the ~toList~ operation take (very short)
  constant time.

** DONE 8.3 The ~List~ class in practice - 251
CLOSED: [2018-03-20 Tue 03:47]
- The implementations of list methods given in Section 22.1 are concise and
  clear, but _suffer from the same stack overflow problem_ as the /non-tail
  recursive implementation/ of ~incAll~.

- Therefore, most methods in the *REAL implementation* of /class/ ~List~
  *avoid* /recursion/ and *use* /loops/ with /list buffers/ instead.

  For example,
  #+BEGIN_SRC scala
    final override def map[U](f: T => U): List[U] = {
      val b = new ListBuffer[U]

      var these = this

      while (!these.isEmpty) {
        b += f(these.head)
        these = these.tail
      }
      b.toList
    }
  #+END_SRC
  * This is very efficient.

  * A /tail recursive/ implementation would be similarly efficient,
    but _a general recursive implementation, in Scala, would be slower and
    less scalable_.

  * The last /method/ invoke ~toList~ takes only a small number of cycles,
    which is *independent of the length of the list*.

    + To understand why, take a second look at /class/ ~::~, which
      constructs non-empty lists -- the real one, NOT the one in Section 22.1!
      #+BEGIN_SRC scala
        final case class ::[U](hd: U,
            private[scala] var tl: List[U]) extends List[U] {
          def head = hd
          def tail = tl
          override def isEmpty: Boolean = false
        }
      #+END_SRC
      - One peculiarity here is the ~tl~ argument is a ~var~ -- it can be
        modified, but only by the members in package ~scala~.

        ~ListBuffer~ is inside package ~scala.collection.mutalbe~, and it can
        access the ~tl~ field of a cons cell.

      - In fact the elements of a /list buffer/ are represented as a /list/
        and appending new elements involves a modification of the ~tl~ field
        of the last ~::~ cell in that /list/. Here's the start of class
        ~ListBuffer~:
        #+BEGIN_SRC scala
          package scala.collection.immutable

          final class ListBuffer[T] extends Buffer[T] {
            private var start: List[T] = Nil  // points to the list of all elements stored in the buffer
            private var last0: ::[T] = _      // points to the last :: cell in that list

            // indicates whether the buffer has been turned into a list using
            // a toList operation
            private var exported: Boolean = false
            // ...
          }
        #+END_SRC

      - The ~toList~ operation is very simple:
        #+BEGIN_SRC scala
          override def toList: List[T] = {
            exported = !start.isEmpty
            start
          }
        #+END_SRC
        This is very efficient because it _does NOT copy_ the list which is
        stored in a ~ListBuffer~.

      - But what happens if the list is further extended after the ~toList~
        operation?
        _Of course, once a list is returned from ~toList~, it MUST be
        *immutable*._
        And appending to the ~last0~ element will modify the list which is
        referred to by ~start~. To avoid this and maintain the correctness of
        the /list buffer/ operations, a fresh list is required! This is
        achieved by the first line in the implementation of the ~+=~
        operation:
        #+BEGIN_SRC scala
          override def += (x: T) = {
            if (exported) copy()

            if (start.isEmpty) {
              last0 = new scala.::(x, Nil)
              start = last0
            } else {
              val last1 = last0
              last0 = new scala.::(x, Nil)
              last1.tl = last0
            }
          }
        #+END_SRC
        You see that ~+=~ _copies_ the list pointed to by ~start~ if
        ~exported~ is _true_. So, in the end, there is *no free lunch*.

        If you want to go from lists which can be extended at the end to
        immutable lists, there needs to be some copying.

        However, the implementation of ~ListBuffer~ is such that copying is
        necessary *only* for /list buffers/ that are _FURTHER extended *after*
        they have been turned into /lists/._ *This case is quite rare in
        practice.* Most use cases of /list buffers/ add elements incrementally
        and then do one ~toList~ operation at the end. In such cases, no
        copying is necessary.

** DONE 8.4 Functional on the outside - 254
CLOSED: [2018-03-20 Tue 03:16]
- You saw that ~List~'s are
  * purely functional on the "outside"
    but
  * have an imperative implementation using ~ListBuffer~'s on the "inside."

  This is a typical strategy in Scala programming -- trying to combine purity
  with efficiency by carefully *delimiting* the effects of impure operations.

- Q: Why *NOT* just make ~tl~ accessible and mutable?

  A: For example, if we do so, the code below will introduce side effects that
     are hard to track.
     #+BEGIN_SRC scala
       // `ys` and `zs` share the tail `xs`
       val ys = 1 :: xs
       val zs = 2 :: xs

       // ILLEGAL
       // code in Scala, but this is reasonable if `tail` (actually `tl`) is mutable
       ys.drop(2).tail = Nil

       // This can affect the tail of `ys` and `zs`
     #+END_SRC

- The ~ListBuffer~ /class/ still allows you to build up lists imperatively and
  incrementally, if you wish. But since /list buffers/ are *not* /lists/, the
  types _keep /mutable buffers/ and /immutable lists/ *separate*._

- The design of Scala's ~List~ and ~ListBuffer~ is quite similar to what's
  done in Java's pair of classes ~String~ and ~StringBuffer~ (or since Java
  5, the mostly used ~StringBuilder~) . This is *NOT* coincidence.

** DONE 8.5 Conclusion - 255
CLOSED: [2018-03-20 Tue 03:24]
This chapter talks about the implementation of the ~List~ in Scala.

- Instead of recursing through this structure,
  however, _many core list /methods/_ are implemented using a ~ListBuffer~.

- ~ListBuffer~, in turn, is carefully implemented so that it can
  _efficiently build_ lists *without* allocating extraneous memory.

- Functional on the outside for the clarity.
  Somehow, imperative inside to speed up the common case where a buffer is
  discarded after ~toList~ has been called.

* TODO 9 For Expressions Revisited - 256 - =RANK 0 for reading=
- More generally,
  * ALL ~for~ expressions that ~yield~ a result are _translated_ by the
    compiler into combinations of invocations of the higher-order methods
    ~map~, ~flatMap~, and ~withFilter~.

  * ALL ~for~ loops WITHOUT ~yield~ are translated into a smaller set of
    higher-order functions: just ~withFilter~ and ~foreach~.

- In this chapter, you'll find out
  1. the precise rules of writing for expressions
  2. how they can make combinatorial problems easier to solve.
  3. how ~for~ expressions are translated, and how as a result, ~for~
     expressions can help you "grow" the Scala language into new application
     domains.

** DONE 9.1 For expressions - 257
CLOSED: [2017-10-21 Sat 21:52]
Syntax: ~for ( seq ) yield expr~

- Here, ~seq~ is a sequence of /generators/, /definitions/, and /filters/,
  with semicolons between successive elements.

- Enclose the ~seq~ in /braces/ instead of /parentheses/. Then the semicolons
  become _optional_:
  #+BEGIN_SRC scala
    for (p <- persons; n = p.name; if (n startsWith "To"))
    yield n

    // OR

    for {
      p <- persons             // a generator
      n = p.name               // a definition
      if (n startsWith "To")   // a filter
    } yield n
  #+END_SRC

  * A /generator/ is of the form: ~pat <- expr~
    The ~pat~ gets matched one-by-one against all elements. If the match fails
    the element is simply discarded from the iteration (=From Jian= this will
    be proved a good feature)

    + the most common case: a variable. Then simply iterates over all elements

  * If there are multiple generators, later ones are for inner iterations.

    =From Jian= I don't think write a embeded structure in a flat form is a
    good idea.

** DONE 9.2 The n-queens problem - 259
CLOSED: [2018-03-28 Wed 23:43]
- Start numbering cells at one:
  * upper-left cell of N \times{} N board has coordinate (1, 1)
  * lower-right cell of N \times{} N board has coordinate (N, N)

- Give up and re-do the search if you *cannot* find a location to a queen
  anymore!

- The imperative solution:
  it would place queens one by one, moving them around on the board.

    But it looks _difficult to_ come up with a scheme that really _tries all
  possibilities_.

- A more functional approach *represents a solution directly, as a value*.
  A solution consists of a list of coordinates, one for each queen placed on
  the board (you still need to build the solution gradually!).

- 0-queuen problem has one solution, and the solution list is ~List(List())~.

- 2-queuen problem has no solution, and the solution list is ~List()~.

- Code (get all solutions -- this can be very slow for large N):
  #+BEGIN_SRC scala
    def queens(n: Int): List[List[(Int, Int)]] = {
      def placeQueens(k: Int): List[List[(Int, Int)]] =
        if (k == 0)
          List(List())
        else
          for {
            queens <- placeQueens(k - 1)
            column <- 1 to n
            queen = (k, column)
            if isSafe(queen, queens)
          } yield queen :: queens
      placeQueens(n)
    }

    def isSafe(queen: (Int, Int), queens: List[(Int, Int)]) =
      queens forall (q => !inCheck(queen, q))

    def inCheck(q1: (Int, Int), q2: (Int, Int)) =
      // q1._1 == q2._1 || // same row -- we have already pick queens by row to guarantee this
      q1._2 == q2._2 || // same column
       (q1._1 - q2._1).abs == (q1._2 - q2._2).abs // on diagonal
  #+END_SRC

** DONE 9.3 Querying with ~for~ expressions - 262
CLOSED: [2017-10-21 Sat 22:00]

** DONE 9.4 Translation of ~for~ expressions - 264 =Re-READ=
CLOSED: [2017-10-21 Sat 22:25]
*** DONE Translating ~for~ expressions with one generator - 264
CLOSED: [2017-10-21 Sat 22:10]
~for (x <- expr1) yield expr2~  ------->  ~expr1.map(x => expr2)~

*** DONE Translating ~for~ expressions starting with a generator and a filter - 264
CLOSED: [2017-10-21 Sat 22:10]
~for (x <- expr1 if expr2) yield expr3~
------->    ~for (x <- expr1 withFilter (x => expr2)) yield expr3~
------->    ~expr1 withFilter (x => expr2) map (x => expr3)~


~for (x <- expr1 if expr2; seq) yield expr3~
------->    ~for (x <- expr1 withFilter (x => expr2); seq) yield expr3~
Then translation continues with the second expression, which is again shorter
by one element than the original one.

*** DONE Translating ~for~ expressions starting with two generators - 265
CLOSED: [2017-10-21 Sat 22:10]
~for (x <- expr1; y <expr2; seq) yield expr3~
------->    ~expr1.flatMap (x => for (y <- expr2; seq) yield expr3)~

- Example:
  In Section 23.3 we have
  #+BEGIN_SRC scala
    for (b1 <- books; b2 <- books if b1 != b2;
         a1 <- b1.authors; a2 <- b2.authors if a1 == a2)
    yield a1

    // Translation
    books flatMap (b1 =>
      books withFilter (b2 => b1 != b2) flatMap (b2 =>
        b1.authors flatMap (a1 =>
          b2.authors withFilter (a2 => a1 == a2) map (a2 =>
            a1))))
  #+END_SRC

*** DONE Translating patterns in generators - 266
CLOSED: [2017-10-21 Sat 22:15]
~for ((x1, ..., xn) <- expr1) yield expr2~
------->    ~expr1.map { case (x1, ..., xn) => expr2 }~

More general patterns,
~for (pat <- expr1) yield expr2~
------->
#+BEGIN_SRC scala
  expr1 withFilter {
    case pat => true
    case _ => false
  } map {
    case pat => expr2
  }
#+END_SRC

More than one patterns cases don't add much new insight, just omit them here.
(More info about this in *Scala Language Specification*)

*** DONE Translating definitions - 267
CLOSED: [2017-10-21 Sat 22:21]
~for (x <- expr1; y = expr2; seq) yield expr3~
Assume again that ~seq~ is a (possibly empty) sequence of /generators/,
/definitions/, and /filters/. This expression is translated to this one:

------->
#+BEGIN_SRC scala
  // From Jian: expr2 is often a function of x.
  //            If not, no reason to re-evaluate expr2 every iteration
  for ((x, y) <- for (x <- expr1) yield (x, expr2); seq)
  yield expr3
#+END_SRC

*** DONE Translating ~for~ loops - 267
CLOSED: [2017-10-21 Sat 22:24]
In principle, wherever the previous translation scheme used a ~map~ or a
~flatMap~ in the translation, the translation scheme for /for loops/ uses
just a ~foreach~.

~for (x <- expr1) body~
-------> ~expr1 foreach (x => body)~

~for (x <- expr1; if expr2; y <- expr3) body~
-------> ~expr1 withFilter (x => expr2) foreach (x =>
            expr3 foreach (y => body))~

** DONE 9.5 Going the other way - 268
CLOSED: [2017-10-21 Sat 22:29]
Every application of a ~map~, ~flatMap~, or ~filter~ can be represented as a
/for expression/.

#+BEGIN_SRC scala
  object Demo {
    def map[A, B](xs: List[A], f: A => B): List[B] =
      for (x <- xs) yield f(x)

    def flatMap[A, B](xs: List[A], f: A => List[B]): List[B] =
      for (x <- xs; y <- f(x)) yield y

    def filter[A](xs: List[A], p: A => Boolean): List[A] =
      for (x <- xs if p(x)) yield x
  }
#+END_SRC

Not surprisingly, the body of the above definitions (for expression) will be
translated to higher order functions by Scala in the background.

** DONE 9.6 Generalizing ~for~ - 269 =Re-Read the last some paragraph=
CLOSED: [2018-03-28 Wed 22:46]
- Because the translation of ~for~ expressions only relies on the presence of
  methods ~map~, ~flatMap~, and ~withFilter~, it is possible to apply the
  ~for~ notation to a large class of data types.

- We have see /for expressions/ over /lists/ and /arrays/.
  There are supported because they have ~map~, ~flatMap~, and ~withFilter~.

- We have see /for loop/ over /lists/ and /arrays/.
  There are supported because they have ~foreach~.

- Examples that support /for expressions/ and /for loops/:
  * /ranges/
  * /iterators/
  * /streams/
  * all implementations of /sets/.

- You can have your own defined /class/ that support /for expressions/ and
  /for loops/.

  It is also possible to define a _subset_ of these /methods/, and thereby
  support a _subset_ of all possible /for expressions/ and /for loops/.

- Here are the precise rules:
  * If your type defines just ~map~, it allows /for expressions/ consisting of a
    *SINGLE generator*.

  * If it defines ~flatMap~ as well as ~map~, it allows /for expressions/
    consisting of *SEVERAL generators*.

  * If it defines ~foreach~, it allows /for loops/ (both with *single and
    multiple generators*).

  * If it defines ~withFilter~, it allows /for filter expressions/ starting
    with an ~if~ in the
    for expression. =From Jian= I think this should work for both /for loops/
    and /for expressions/.

- The translation of /for expressions/ happens *before* /type checking/.
  This allows for maximum _flexibility_ because the _only requirement_ is
  that the result of expanding a /for expression/ /type checks/.

  Scala defines *NO* /typing rules/ for the /for expressions/ themselves, and
  does *NOT* require that /methods/ ~map~, ~flatMap~, ~withFilter~, or
  ~foreach~ have any particular type signatures.

  Nevertheless, there is a *typical setup* that captures the most common
  intention of the /higher order methods/ to which /for expressions/
  translate.
  #+BEGIN_SRC scala
    abstract class C[A] {
      def map[B](f: A => B): C[B]
      def flatMap[B](f: A => C[B]): C[B]
      def withFilter(p: A => Boolean): C[A]  // Not perfect, same as `filter`
      def foreach(b: A => Unit): Unit
    }
  #+END_SRC
  * For example, ~List~ has
    ~def withFilter(p: (A) ⇒ Boolean): FilterMonadic[A, List[A]]~

- TODO =???=
  Concentrating on just the first three functions of /class/ ~C~, the following
  facts are noteworthy:
  In functional programming, there’s a general concept called a /monad/,
  which can explain a large number of types with computations, ranging from
  collections, to computations with state and I/O, backtracking computations,
  and transactions, to name a few.

  TODO
    *You can formulate functions ~map~, ~flatMap~, and ~withFilter~ on a
  /monad/, and, if you do, they end up having exactly the types given here.*

- TODO /monad/ related TODO =Learn More= =!!!=

** DONE 9.7 Conclusion - 271
CLOSED: [2017-10-21 Sat 22:29]

* TODO 10 The Architecture of Scala Collections - 272
- This chapter describes _the architecture of the Scala collections framework_
  in detail.
  * Continuing the theme of Chapter 24,
    you will find out _more about the internal workings_ of the framework.

  * You will also learn _HOW this architecture helps you define your own
    collections in a few lines of code_, while reusing the overwhelming part
    of collection functionality from the framework.

- TODO =SUMMARIZE= TODO
  Chapter 24 enumerated a large number of collection operations, which
  exist uniformly on many different collection implementations. Implementing
  every collection operation anew for every collection type would lead to an
  enormous amount of code, most of which would be copied from somewhere
  else. Such code duplication could lead to inconsistencies over time, when an
  operation is added or modified in one part of the collection library but not
  in others.

  The principal design objective of the collections framework is to avoid any
  duplication, defining every operation in as few places as possible.1

  The approach is to implement most operations in “template traits” that can
  be mixed into individual collection base and implementation classes. In this
  chapter, we will examine these templates, and other classes and traits that
  constitute the building blocks of the framework, as well as the construction
  principles they support.

** 10.1 Factoring out common operations - 272
- The main design objective of the collection library is to provide natural
  types to users while sharing as much implementation code as possible.

- In particular, Scala's collection framework needs to support the following
  aspects of various concrete collection types:
  * Some /transformation operations/ return the _SAME concrete collection type_.
    + For example, ~filter~ on ~List[Int]~ returns ~List[Int]~.

  * Some /transformation operations/ return the _SAME concrete collection type_
    with possibly a _DIFFERENT type of elements_.
    + For example, ~map~ on ~List[Int]~ can return ~List[String]~.

  * Some collection types, such as ~List[A]~, have a _single_ /type parameter/,
    whereas others, like ~Map[K, V]~, have _two_.

  * Some operations on collections return a _DIFFERENT concrete collection
    DEPENDING ON an element type._
    + For example, ~map~ on ~Map~ returns
      - another ~Map~ if the mapping function results in a key-value pair,
      - but otherwise returns an ~Iterable~.

  * Transformation operations on certain collection types _require additional
    /implicit parameters/._
    + For example, map on ~SortedSet~ requires an _implicit_ ~Ordering~.

  * Lastly,
    some collections, such as ~List~, are /strict/,
    while other collections, like ~View~ and ~LazyList~, are /non-strict/.

*** Abstracting over collection types - 274
*** Handling strictness - 277
*** When strict evaluation is preferable or unavoidable - 280

** 10.2 Integrating new collections - 281
*** Capped sequences - 281
**** Capped collection, first version - 281
**** Capped collection, second version - 284
**** Capped collection, final version - 286

*** RNA sequences - 286
**** RNA strands class, first version - 289
**** RNA strands class, second version - 292
**** RNA strands class, final version - 294

*** Prefix maps - 297
*** Summary - 304

** 10.3 Conclusion - 304

* TODO 11 Extractors - 305 - =RANK 0 for reading=
This chapter explains
- what /extractors/ are

- how you can use them to define patterns that are _decoupled from_ an object's
  representation.
  * =from Jian=
    if the patterns are _not decoupled from_ an object's representation, the
    default /extractors/ of /case classes/ are enough.

** DONE 11.1 An example: extracting email addresses - 305
CLOSED: [2020-09-25 Fri 01:01]
- Compare
  + Access function:
    #+BEGIN_SRC scala
      def isEMail(s: String): Boolean = ???
      def domain(s: String): String = ???
      def user(s: String): String = ???

      if (isEMail(s)) println(user(s) + " AT " + domain(s))
      else            println("not an email address")
    #+END_SRC

  + Pattern matching:
    #+BEGIN_SRC scala
      s match {
        case EMail(user, domain) => println(user + " AT " + domain)
        case _                   => println("not an email address")
      }
    #+END_SRC

- More complicated example - find two successive email addresses with the same
  user part:
  + Access function:
    Assume we have the function given above.
    #+BEGIN_SRC scala
      val result: Option[List[String]] = ss.
        sliding(2).
        find { case List(e1, e2) =>
          isEMail(e1) && isEMail(e2) && user(e1) == user(e2)
        }

      (result: @unchecked) match {
        case None   =>
          println("not successive email addresses with the same user part")

        case Some(List(e1, e2)) =>
          println(f"Two successive email addresses with the same user part ${user(e1)}")
      }
    #+END_SRC

  + Pattern matching:
    #+BEGIN_SRC scala
      @annotation.tailrec
      def findSuccessiveSameUser(ss: List[String]): Unit = {
        ss match {
          case Nil | _ :: Nil =>
            println("not successive email addresses with the same user part")

          case EMail(u1, d1) :: EMail(u2, d2) :: _ if u1 == u2 =>
            println(f"Two successive email addresses with the same user part ${u1}")

          case _ :: tl =>
            findSuccessiveSameUser(tl)
        }
      }

      findSuccessiveSameUser(ss.sliding(2))
    #+END_SRC

- The pattern matching examples above are expressive!
  + Q :: However, the problem is that strings are NOT /case classes/.
          How an we use pattern matching code like above.

  + A :: Scala's /extractors/ let you define new /patterns/ for _pre-existing_
          /types/, where the /pattern/ need *NOT* follow the internal
          representation of the /type/.

** DONE 11.2 Extractors - 306
CLOSED: [2020-09-26 Sat 14:26]
- extractor :: an /object/ that has a /method/ called ~unapply~ as one of its
               members.
  + The purpose of these ~unapply~ /method/ are used to to *match* a value and
    *take it apart*.
    * =from Jian=
      it doesn't do this, this ~unapply~ /method/ is _not a real_ (not satisfy
      the purpose of the design idea of /extractors/) /extractor/ in concept,
      even though they are used when compiler searching for a /extractor/.

- Often,
  the /extractor object/ also defines a _dual_ /method/ ~apply~ for *building*
  values, but *this is _NOT_ required*.
  + =from Jian=
    /case classes/ always generate these mutually dual /methods/ ~apply~ and
    ~unapply~.

- Listing 26.1
  #+BEGIN_SRC scala
    object EMail {
      // The injection method (optional)
      def apply(user: String, domain: String) = f"$user@$domain"

      def unapply(str: String): Option[(String, String)] =
        (str split "@") match {
          case List(u, d) => Some(u, d)
          case _          => None
        }
    }
  #+END_SRC

- ~selectorString match { case EMail(user, domain) => ... }~
  would lead to the call:
  ~EMail.unapply(selectorString)~. This call will lead to two kinds of return
  value:
  + ~Some(user, domain)~
    If this is the case, then bind and run the expression after ~=>~

  + ~None~
    If this is the case, then try next pattern or fail (when NO pattern left)
    with a ~MatchError~ exception.

- If the being matched value's annotated doesn't conform the parameter type
  that ~unapply~ require, check if this value can be the required type:
  + If it is, just cast and proceed.
  + If not, the pattern fails immediately.

- injection :: ~apply~

- extraction :: ~unapply~

- Design principle:
  Dual methods ~apply~ and ~unapply~, it they both exist in a class, should
  satisfy the requirements:
  #+BEGIN_SRC scala
    // #1 - a direction
    Email.unapply(EMail.apply(user, domain))
    // SHOULD return `Some(user, domain)`


    // #2 - another redirection
    EMail.unapply(obj) match {
      case Some(u,d) => EMail.apply(u, d)
    }
    // The generated `EMail` SHOULD be equal to the input `obj`
  #+END_SRC

** DONE 11.3 Patterns with zero or one variables - 309
CLOSED: [2020-09-27 Sun 01:06]
- Patterns with zero or one variables are special and not covered in the
  previous section:
  * Since there is no one-tuple, to return just one pattern element, the
    ~unapply~ /method/ simply wraps the element itself in a ~Some~.
    + Example:
      The /extractor object/ defined for strings that consist of the same
      substring appearing _twice_ in a row:
      #+begin_src scala
        object Twice {
          def apply(s: String): String = s + s

          def unapply(s: String): Option[String] = {
            val length = s.length / 2
            val half = s.substring(0, length)
            if (half == s.substring(length)) Some(half) else None
          }
        }
      #+end_src

  * It's also possible that an extractor pattern does _NOT bind any_ variables.
    In this case the corresponding ~unapply~ /method/ returns a ~Boolean~.

    Example:
    #+BEGIN_SRC scala
      object UpperCase {
        def unapply(s: String): Boolean = s.toUpperCase == s
      }
    #+END_SRC
    In this case, only ~unapply~, NO ~apply~:
    it would make NO sense to define an ~apply~, as there's _nothing to
    construct_.

- Apply all the previously defined /extractors/ together in its /pattern
  matching/ code:
  #+BEGIN_SRC scala
    def userTwiceUpper(s: String) = s match {
      case EMail(Twice(x @ UpperCase()), domain) =>
        f"match: $x in domain $domain"

      case _ =>
        "no match"
    }
  #+END_SRC
  You *MUSTN'T omit* the empty parameter list in ~UpperCase()~, otherwise
  the match would test for equality with /object/ ~UpperCase~!

** DONE 11.4 Optionless extractors - 311
** DONE 11.5 Variable argument extractors - 314
CLOSED: [2020-09-27 Sun 01:25]
Sometimes, /extractors/ that extract FIXED NUMBER of element values are not
flexible enough, and we also have /extractors/ that can support vararg matching
-- ~unapplySeq~.

- Use ~unapplySeq~ can do something like
  #+BEGIN_SRC scala
    dom match {
      case Domain("org", "acm")         => println("acm.org")
      case Domain("com", "sun", "java") => println("java.sun.com")
      case Domain("net", _*)            => println("a .net domain")
    }
  #+END_SRC

- Implementation of ~Domain~:
  #+BEGIN_SRC scala
    object Domain {
      // The injection method (optional)
      def apply(parts: String*): String =
        parts.reverse.mkString(".")

      // The extraction method (mandatory)
      def unapplySeq(whole: String): Option[Seq[String]] =
        Some(whole.split("\\.").reverse)
    }
  #+END_SRC

- Example:
  #+BEGIN_SRC scala
    def isTomInDotCom(s: String): Boolean = s match {
      case EMail("tom", Domain("com", _*)) => true
      case _                               => false
    }

    isTomInDotCom("tom@sun.com")    // true
    isTomInDotCom("peter@sun.com")  // false
    isTomInDotCom("tom@acm.org")    // false
  #+END_SRC

- It's also possible to
  RETURN _some fixed elements_ from an ~unapplySeq~
  TOGETHER WITH the _variable part_.

  + *HOWTO*:
    This is expressed by returning _all elements in a tuple_, where the
    _variable part_ *comes last*, AS USUAL.
    * Example:
      #+begin_src scala
        object ExpandedEMail {
          def unapplySeq(email: String): Option[(String, Seq[String])] = {
            val parts = email split "@"

            if (parts.length == 2)
              Some(parts(0), parts(1).split("\\.").reverse)
            else
              None
          }
        }

        val s = "tom@support.epfl.ch"

        val ExpandedEMail(name, topdom, subdoms @ _*) = s
        // name: String = tom
        // topdom: String = ch
        // subdoms: Seq[String] = WrappedArray(epfl, support)
      #+end_src

** DONE 11.6 Optionlees variable argument extractors - 318
** DONE 11.7 Extractors and sequence patterns - 320
CLOSED: [2020-09-27 Sun 01:38]
/Sequence patterns/ are all implemented using /extractors/ in the standard
Scala library:
#+BEGIN_SRC scala
  package scala

  object List {
    def apply[T](elems: T*) = elems.toList

    def unapplySeq[T](x: List[T]): Option[Seq[T]] = Some(x)
  }
#+END_SRC
Similar to ~Array~

** DONE 11.8 Extractors versus case classes - 322
CLOSED: [2020-09-27 Sun 02:24]
- Even though they are very useful,
  /case classes/ have one _SHORTCOMING_:
  they *expose* _the concrete representation of data_.
  * This means that the _name_ of the /class/ in a /constructor pattern/
    *corresponds to* the concrete /representation type/ of the /selector object/.

- /Extractors/ *BREAK* this link between /data representations/ and /patterns/,
  and it provides /representation independence/, which allows you to change an
  /implementation type/ used in a set of components WITHOUT affecting clients
  of these components.

- */Representation independence/ is an important advantage of /extractors/
  over /case classes/.*

- /Case classes/:
  * *cons*:
    Since /case classes/ have *NO* /representation independence/, if your component
    had _defined and exported_ a set of /case classes/, you'd be stuck with them
    BECAUSE client code could already contain pattern matches against these /case
    classes/. Renaming some /case classes/ or changing the /class hierarchy/ would
    affect client code.

  * *pros*:
    + _More concise_

    + Usually _more efficient_ pattern matches than /extractors/.
      - The Scala compiler can optimize patterns over /case classes/ much better
        than patterns over /extractors/ -- the mechanisms of /case classes/ are
        fixed

      - whereas an ~unapply~ or ~unapplySeq~ method in an /extractor/ could do
        almost anything, =from Jian= and this flexibility make it hard to do
        very specific optimization.

    + /Exhaustiveness check/ can be applied if a set of /case classes/ inherit
      from /sealed classes/.

- Summary: *It depends*
  * closed application: you usually prefer /case classes/

  * Expose a type to unknown clients: /extractors/ can help you maintain
    /representation independence/.

- If it is NOT clear when you start a new project, you can always start from
  /case classes/, and then, when you think you need /representation
  independence/, change to (manually coded) /extractors/.
  * You can do this because the syntax for /pattern matching/ is always the
    same, NO MATTER there are /extractors/ or /case classes/.

** DONE 11.9 Regular expressions - 324
CLOSED: [2020-09-27 Sun 04:29]
One particularly useful application area of /extractors/ are /regular
expressions/.

- Like Java, Scala provides /regular expressions/ through a library,
  BUT /extractors/ make it *much nicer* to interact with them.

*** DONE Forming regular expressions - 324
CLOSED: [2020-09-27 Sun 04:17]
- ~java.util.regex.Pattern~

- Scala regex inherits its _regex syntax_ comes from Java, and Java inherits
  most of the regex features of Perl.

- ~scala.util.matching.Regex~

- Create a new regex value from Regex constructor:
  #+begin_src scala
    val Decimal = new Regex("(-)?(\\d+)(\\.\\d*)?")
  #+end_src
  * A short syntax
    #+begin_src scala
      val Decimal = """(-)?(\d+)(\.\d*)?""".r
    #+end_src
    Here /method/ ~r~ comes from ~StringOps~

- The definition of ~r~ is like
  #+BEGIN_SRC scala
    package scala.runtime

    import scala.util.matching.Regex

    class StringOps(self: String) ... {
      // ...
      def r = new Regex(self)
    }
  #+END_SRC

- =from Jian=  =TODO= READ
  StackOverflow question [[https://stackoverflow.com/questions/25632924/whats-the-difference-between-raw-string-interpolation-and-triple-quotes-in-scal][What's the difference between raw string interpolation and triple quotes in scala]]
  and the answer from *som-snytt*

*** DONE Searching for regular expressions - 326
CLOSED: [2020-09-27 Sun 04:13]
- ~regex findFirstIn str~
  Return an ~Option~ value

- ~regex findAllIn str~
  Return an ~Iterator~ value

- ~regex findPrefixOf str~
  Return an ~Option~ value

- Example:
  #+BEGIN_SRC scala
    val input = "for -1.0 to 99 by 3"

    for (s <- Decimal findAllIn input)
      println(s)
    // -1.0
    // 99
    // 3

    Decimal findFirstIn input
    // Some("-1.0")

    Decimal findPrefixOf input
    // None
  #+END_SRC

*** DONE Extracting with regular expressions - 326
CLOSED: [2020-09-27 Sun 04:11]
Every ~Regex~ object in Scala defines an /extractor/.
  The /extractor/ is used to identify substrings that are matched by the
/groups/ of the regular expression. =from Jian= if no group, a /extractor/
is a _zero variable pattern_.

#+BEGIN_SRC scala
  val Decimal(sign, integerPart, decimalPart) = "-1.23"
  // sign: String = -
  // integerPart: String = 1
  // decimalPart: String = .23


  val Decimal(sign, integerPart, decimalPart) = "1.0"
  // sign: String = null
  // integerPart: String = 1
  // decimalPart: String = .0


  for (Decimal(s, i, d) <- Decimal findAllIn input)
    println("sign: " + s + ", integer: " +
        i + ", decimal: " + d)
  // sign: -, integer: 1, decimal: .0
  // sign: null, integer: 99, decimal: null
  // sign: null, integer: 3, decimal: null
#+END_SRC

- *CAUTION*: =From Jian=
  An optional group that is not matched will bind ~null~ to the target variable.

** DONE 11.10 Conclusion - 327 - =RE-READ=
CLOSED: [2017-12-02 Sat 23:27]
In this chapter you saw how to *generalize* /pattern matching/ with /extractors/.

- /Extractors/ let you define your own kinds of patterns, which *need _NOT_
  correspond to* the /type/ of the expressions you select on.
  * This gives you more flexibility in the kinds of patterns you can use for
    matching.

  * In effect it's like *having DIFFERENT possible VIEWS on the same data*.

  * It also gives you a layer =IMPORTANT=
    BETWEEN a /type's representation/ and _the way clients view it_.
    + This lets you do /pattern matching/ WHILE *maintaining representation
      independence*, a property which is very useful in large software systems.

- /Extractors/ are one more element in your tool box that let you define
  flexible library abstractions.

* TODO 12 Annotations - 328
- annotations :: structured information added to program source code.

  * Like /comments/,
    they can be sprinkled throughout a program and attached to any variable,
    method, expression, or other program element.

  * Unlike /comments/,
    _they have structure, thus making them easier to machine process._

- This chapter
  * shows how to use annotations in Scala,
  * shows their general syntax and how to use several standard annotations.

- This chapter does NOT show how to write new annotation processing tools,
  because it is _beyond the scope of this book_.

    Chapter 31 shows one technique, but not the only one.

  _This chapter focuses on how to use annotations._

** DONE 12.1 Why have annotations? - 328
CLOSED: [2017-10-21 Sat 18:59]
- There are many things you can do with a program _other than_ compiling and
  running it. Some examples are:
  1. Automatic generation of documentation as with *Scaladoc*.
     TODO

  2. Pretty printing code so that it matches your preferred style.
     TODO

  3. Checking code for common errors such as opening a file but, on some
     control paths, never closing it.
     TODO

  4. Experimental type checking, for example to manage side effects or ensure
     ownership properties.
     TODO

- Such tools are called /meta-programming/ tools, because they are programs
  that take other programs as input.

- /Annotations/ can improve the previously listed tools as follows:
  1. A documentation generator could be instructed to document certain methods
     as _deprecated_.

  2. A pretty printer could be instructed to skip over parts of the program
     that have been carefully hand formatted.

  3. A checker for non-closed files could be instructed to ignore a particular
     file that has been manually verified to be closed.

  4. A side-effects checker could be instructed to verify that a specified
     method has no side effects.
     TODO =???=

** DONE 12.2 Syntax of annotations - 329
CLOSED: [2017-10-21 Sat 18:59]
- Annotations can also be applied to an expression, as with the ~@unchecked~
  annotation for pattern matching (see Chapter 15). To do so, place a colon
  (~:~) after the expression and then write the annotation. Syntactically, it
  looks like the annotation is being used as a type:
  #+BEGIN_SRC scala
    (e: @unchecked) match {
      // nonexhaustive
      cases...
    }
  #+END_SRC

- /Annotations/ have a richer general form: @annot(exp1, exp2, ...)
  Though much simpler form annotations are often seen.

- Internally,
  Scala represents an annotation as just a constructor call of an annotation
  class -- replace the ~@~ by ~new~ and you have a valid instance creation
  expression.

- One slightly tricky bit concerns annotations that conceptually take other
  annotations as arguments, which are required by some frameworks.

  You _CANNOT_ write an annotation directly as an argument to an annotation,
  because _annotations are NOT valid expressions_. In such cases you must use
  ~new~ instead of ~@~, as illustrated here:
  #+BEGIN_SRC scala
    scala> import annotation._
    // import annotation._

    scala> class strategy(arg: Annotation) extends Annotation
    // defined class strategy

    scala> class delayed extends Annotation
    // defined class delayed

    scala> @strategy(@delayed) def f() = {}
    // <console>:1: error: illegal start of simple expression
    //        @strategy(@delayed) def f() = {}
    //                  ˆ

    scala> @strategy(new delayed) def f() = {}
    // f: ()Unit
  #+END_SRC

** DONE 12.3 Standard annotations - 331 - =TODO=
CLOSED: [2017-10-21 Sat 18:45]
*** DONE Deprecation - 331
CLOSED: [2017-10-21 Sat 18:34]
~@deprecated~

- ~@deprecated def bigMistake() = // ...~

- With message (use this in most cases):
  #+BEGIN_SRC scala
    @deprecated("use newShinyMethod() instead")
    def bigMistake() = //...
  #+END_SRC

*** DONE Volatile fields - 332
CLOSED: [2017-10-21 Sat 18:39]
~@volatile~

Scala's concurrency support is /message passing/ and a _minimum_ of /shared
mutable state/. TODO See Chapter 32

Nonetheless, sometimes programmers want to use /mutable state/ in their
concurrent programs. The ~@volatile~ annotation helps in such cases.

- The ~@volatile~ keyword gives different guarantees on different platforms.

  On the Java platform, however, you get the same behavior as if you wrote
  the field in Java code and marked it with the Java volatile modifier.

*** TODO Binary serialization - 333
*** DONE Automatic ~get~ and ~set~ methods - 334 =RE-READ=
CLOSED: [2017-10-21 Sat 18:45]
Scala doesn't need ~get~ and ~set~ methods.
Some platform-specific frameworks do expect ~get~ and ~set~ methods, however.

Scala provides the ~@scala.reflect.BeanProperty~ annotation. It informs the
compiler to generate ~get~ and ~set~ methods for you automatically. For
example, ~getCrazy~ and ~setCrazy~ for a field named ~crazy~.

=IMPORTANT= =RE-READ=
The generated ~get~ and ~set~ methods are ONLY available _AFTER_ a compilation
pass completes.

*** DONE Tailrec - 334
CLOSED: [2017-10-21 Sat 18:04]
Use ~@tailrec~, and if the _optimization CANNOT be performed_, you will then
get a warning together with an explanation of the reasons.

*** DONE Unchecked - 334
CLOSED: [2017-10-21 Sat 18:06]
~@unchecked~

Tell the compiler don't worry if the ~match~ expression seems to leave out some cases.
TODO See Section 15.5 for details.

*** TODO Native methods - 334
~@native~

TODO =???=

** TODO 12.4 Conclusion - 335
=TODO=
Chapter 31 gives additional, Java-specific information on annotations. It
covers annotations only available when targeting Java, additional meanings of
standard annotations when targeting Java, how to interoperate with Java-based
annotations, and how to use Java-based mechanisms to define and process
annotations in Scala.

* TODO 13 Modular Programming Using Objects - 336 - =Re-READ=
- In this chapter, we’ll discuss how you can use Scala's object-oriented
  features to *make a program more modular*:
  1. Show HOW *a simple /singleton object/ can be used as a module*.

  2. Explain how you can use /traits/ and /classes/ as abstractions over
     /modules/.

     These abstractions can be reconfigured into multiple modules, even
     multiple times within the same program.

  3. Show a pragmatic technique for using /traits/ _to *divide* a /module/
     across MULTIPLE files_.

** DONE 13.1 The problem - 337 =Re-Read= =Review=
CLOSED: [2018-03-19 Mon 02:19]
- As a program grows in size, it becomes increasingly important to organize it
  in a modular way.
  1. being able to compile different modules that make up the system separate-
     ly helps different teams work independently.

  2. being able to unplug one implementation of a module and plug in another
     is useful,
     because it allows different configurations of a system to be used in
     different contexts, such as unit testing on a developer’s desktop,
     integration testing, staging, and deployment.

- Any technique that aims to facilitate this kind of modularity needs to
  provide a few essentials.
  1. there should be a module construct that provides a good separation of
     interface and implementation.

  2. there should be a way to replace one module with another that has the
     same interface without changing or recompiling the modules that depend
     on the replaced one. Lastly, there should be a way to wire modules
     together.

     This wiring task can by thought of as configuring the system.

- One solution is /depedency injection/. TODO
  It is a technique supported on the Java platform by frameworks such as
  Spring and Guice.

  We can use this method in Scala.

- In the remainder of this chapter,
  we'll show HOW to _use objects as modules_ to achieve the desired "in the
  large" modularity *without using an external framework*.

** TODO 13.2 A recipe application - 338
** TODO 13.3 Abstraction - 341
- Use /abstract classes/

** TODO 13.4 Splitting modules into traits - 344
- Split /every large abstract class/ to multiple /traits/.

** TODO 13.5 Runtime linking - 346
** TODO 13.6 Tracking module instances - 347
** TODO 13.7 Conclusion - 349

* TODO 14 Object Equality - 351
Define *object equality* is more tricky than it looks at first glance.

=From Jian=
This complexity comes from /subtyping/.
This is NOT a problem of OOP, but a problem of OOP with /inheritance/.

** DONE 14.1 Equality in Scala - 351
CLOSED: [2017-11-25 Sat 00:39]
- As mentioned in Section 11.2, the definition of equality is _DIFFERENT_ in
  Scala and Java. Both of them has *TWO* equality comparison operators, but
  with _DIFFERENT design choice_.

  + Java
    * ~==~ operator ::
      - /natural equality check/ for /value types/
        AND
      - /object identity/ for /reference types/

    * ~equals~ method :: (user-defined) canonical equality for /reference types/.

  + Scala
    * ~==~ operator :: Be reserved for the "natural" equality of each type.
      - For /value types/, ~==~ is value comparison, just like in Java.

      - For /reference types/, ~==~ is the same as ~equals~ in Scala, and you
        can redefine the behavior of ~==~ for new types by overriding the
        ~equals~ /method/.

    * ~eq~ method :: /object identity/, which is NOT used much.

- Q: Why does Java's design is BAD!?

  A: The more natural symbol, ~==~, *does NOT* always correspond to the natural
     notion of equality.

- In Scala ~==~ is value comparison, just like in Java.

  For reference types, ~==~ is the same as ~equals~ in Scala.
  You can redefine the behavior of ~==~ of new types by overriding the
  ~equals~ method, which is _always inherited from_ class ~Any~.

  This inherited ~equals~, which takes effect _unless_ overridden, is /object
  identity/, as in the case in Java. So ~equals~ (and with it, ~==~) is by
  default the same as ~eq~, but you can change its behavior by overriding the
  ~equals~ method in the classes you define.

- It is not possible to override ~==~ directly, as it is defined as a /final
  method/ in class ~Any~.
  #+BEGIN_SRC scala
    // In the class `Any`
    final def == (that: Any): Boolean =
      if (null eq this) {null eq that} else {this equals that}
  #+END_SRC

** DONE 14.2 Writing an equality method - 352
CLOSED: [2018-07-19 Thu 01:19]
- footnote:
  All but the _third_ pitfall are described in the context of Java in the
  book, Effective Java Second Edition, by Joshua Bloch.

- Here are four common pitfalls2 that can cause inconsistent behavior when
  overriding equals:
  1. Defining equals with the wrong signature.

  2. Changing equals without also changing hashCode.

  3. Defining equals in terms of mutable fields.

  4. Failing to define equals as an equivalence relation.

*** DONE Pitfall #1: Defining ~equals~ with the wrong signature. - 353
CLOSED: [2017-11-25 Sat 00:54]
=FIXME= remove trailing dot! All other same level titles don't have this trailing dot.

Consider adding an /equality method/ to the following class of simple points:
~class Point(val x: Int, val y: Int)~

- At the first glance, you may want to /override/ the ~equals~ /method/ with
  the /signature/ ~equals(other: Point): Boolean~.

  *This is utterly WRONG!*

- The *right* /signature/ is ~equals(other: Any): Boolean~, which is the
  signature of the one defined in the ROOT /class/ ~Any~.

- If you use the wrong one, ~equals(other: Point): Boolean~, you just write
  an /overloaded/ alternative, *which should NOT exists, and it can make
  people confused*.

  Let's say some examples:

  * If we use the *wrong* /signature/ ~equals(other: Point): Boolean~:
    #+BEGIN_SRC scala
      // An utterly WRONG definition of equals
      def equals(other: Point): Boolean =
        this.x = other.x && this.y == other.y

      val p1, p2 = new Point(1, 2)
      // p1: Point = Point@37d7d90f
      // p2: Point = Point@3beb846d

      val coll = mutable.HashSet(p1)
      // coll: scala.collection.mutable.HashSet[Point] =
      // Set(Point@37d7d90f)

      // Use the `equals` defined above, NOT the one from `Any`, which is
      // WRONG. This is also the reason why this result is not consistent
      // with the `contains` expression below -- the implementation of the
      // `contains` uses `equals` from `Any`.
      p1 equals p2
      // res1: Boolean = true

      coll contains p2
      // res2: Boolean = false
    #+END_SRC
    The result of the last expression is *NOT* what we expect!!!

    The reason is that the ~mutable.HashSet~ is a generics, and it use the
    ~equals~ inherited from ~Any~ to test ~equality~, and ~contains~ exploits
    this ~equals~!

    We can prove that with the ~equals~ from ~Any~, with _not exact_ /static
    type/, the answer is ~false~ -- the same as the ~contains~ reported above!

    #+BEGIN_SRC scala
      val p2a: Any = p2
      // p2a: Any = Point@3beb846d

      // This result of this expression is consistent with the `contains`
      // expression above!
      p1 equals p2a
      // res3: Boolean = false
    #+END_SRC

- A BETTER definition, but still *NOT perfect*:
  #+BEGIN_SRC scala
    override def equals(other: Any) = other match {
      case that: Point => this.x == that.x && this.y == that.y
      case _ => false
    }
  #+END_SRC

- A related *pitfall* is to define ~==~ with a *wrong* /signature/.

  As we mentioned the ~==~ in ~Any~ is a /final method/, and you _CANNOT_
  redefine ~def ==(other: Any): Boolean~.

  HOWEVER, if you use a *wrong* /signature/, you just /overload/ ~==~,
  _rather than_ /override/ it, which is allowed.

*** DONE Pitfall #2: Changing ~equals~ without also changing ~hashCode~ - 355
CLOSED: [2017-11-25 Sat 01:25]
#+BEGIN_SRC scala
  val p1, p2 = new Point(1, 2)
  // p1: Point = Point@122c1533
  // p2: Point = Point@c23d097

  collection.mutable.HashSet(p1) contains p2
  //// The output is NOT certain: can be `true` or `false`
#+END_SRC
- The ~contains~ method of a ~HashSet~ instance will search ~p2~ in the same
  "hash bucket" of ~p1~. The result is ~true~ when ~p1~ and ~p2~ can be put in
  the same "hash bucket".
    However, since ~hashCode~ is *NOT* /overridden/ for ~Point~, ~p1~ and
  ~p2~ have different hash code, and they can be in the _same or different_
  "hash bucket". Then the result can be ~true~ or ~false~.

- The problem is that the last implementation of ~Point~ _violated the
  contract_ on ~hashCode~ as defined for class ~Any~:
  #+BEGIN_QUOTE
  If two objects are equal according to the equals method, then calling the
  ~hashCode~ method on each of the two objects must produce the same integer
  result.
  #+END_QUOTE

- footnote:
  The text of ~Any~'s ~hashCode~ contract is inspired by the Javadoc
  documentation of class ~java.lang.Object~.

- The new implementation (Better but *not* all right):
  #+BEGIN_SRC scala
    class Point(val x: Int, val y: Int) {
      override def hashCode = (x, y).##
      override def equals(other: Any) = other match {
        case that: Point => this.x == that.x && this.y == that.y
        case _ => false
      }
    }
  #+END_SRC
  + This is just ONE of many possible implementations of ~hashCode~.

  + ~##~ method :: a shorthand for computing hash codes that works for
    * primitive values
    * reference types
    * ~null~

    When invoked on a collection or a tuple, it computes a mixed hash that
    is _sensitive to the hash codes of all the elements_ in the collection.

*** DONE Pitfall #3: Defining ~equals~ in terms of mutable fields - 356
CLOSED: [2017-11-25 Sat 01:35]
You put an object into a ~HashSet~, this object is then put in a specific
"hash bucket" according to its hash code. After modifing its mutable fields,
its hash code is changed. Only a similar to the original hash code object
will be equality checked in this "hash bucket", a similar to the new hash
code object will mostly be equality checked in other "hash bucket".

- Example (bad definition):
  #+BEGIN_SRC scala
    class Point(var x: Int, var y: Int) {  // Problematic
      override def hashCode = (x, y).##

      override def equals(other: Any) = other match {
        case that: Point => this.x == that.x && this.y == that.y
        case _           => false
      }
    }
  #+END_SRC

- Solution:
  1. /Hash codes/ *shouldn't depend* on /mutable fields/.

  2. _IF_ /hash codes/ depend on /mutable fields/, *try NOT modify them*.

  3. If all the above can be satisfied, try to define your own method to
     check equality *without* /hash code/, for example, use a name like
     ~equalContents~.

*** DONE Pitfall #4: Failing to define ~equals~ as an equivalence relation - 358
CLOSED: [2018-07-19 Thu 01:19]
- The /contract/ of the ~equals~ /method/ in ~scala.Any~ specifies that
  ~equals~ *must implement* _an equivalence relation on non-null objects_:
  * It is /reflexive/:
    For _ANY non-null value_ ~x~, the expression ~x.equals(x)~ should return
    ~true~.

  * It is /symmetric/:
    For _ANY non-null values_ ~x~ and ~y~, ~x.equals(y)~ should return ~true~
    iff ~y.equals(x)~ returns ~true~.

  * It is /transitive/:
    For _ANY non-null values_ ~x~, ~y~, and ~z~, if ~x.equals(y)~ returns ~true~
    and ~y.equals(z)~ returns ~true~, then ~x.equals(z)~ should return ~true~.

  * It is /consistent/:
    For _ANY non-null values_ ~x~ and ~y~, multiple invocations of ~x.equals(y)~
    should _consistently_ return ~true~ or _consistently_ return ~false~,
    provided no information used in ~equals~ comparisons on the objects is
    modified.

  * For _ANY non-null value_ ~x~, ~x.equals(null)~ should return ~false~.

- The definition of ~equals~ developed for /class/ ~Point~ _up to now_ satisfies
  the contract for ~equals~.

  However, *things become more complicated once /subclasses/ are considered.*

- Say there is a /subclass/ ~ColoredPoint~ of ~Point~ that adds a field ~color~
  of type ~Color~. Assume ~Color~ is defined as an /enumeration/:
  #+BEGIN_SRC scala
    object Color extends Enumeration {
      val Red, Orange, Yellow, Green, Blue, Indigo, Violet = Value
    }

    class ColoredPoint(x: Int, y: Int, val color: Color.Value)
        extends Point(x, y) { // Problem: equals not symmetric
      override def equals(other: Any) = other match {
        case that: ColoredPoint =>
          this.color == that.color && super.equals(that)
        case _ => false
      }
    }
  #+END_SRC
  * The above ~equals~ /method/ is *WRONG*.

    If you use ~equals~ to compare ~Point~ and ~ColoredPoint~, the /symmetric/
    contract will be violated!
    #+BEGIN_SRC scala
      val p = new Point(1, 2)
      // p: Point = Point@5428bd62

      val cp = new ColoredPoint(1, 2, Color.Red)
      // cp: ColoredPoint = ColoredPoint@5428bd62

      p equals cp
      // res9: Boolean = true

      cp equals p
      // res10: Boolean = false
    #+END_SRC

  * Now you need to make a decision:
    Modify the ~equals~ /method/ to make it *more general* OR *stricter*.

    + Try the *more general* way --
      if the corresponding parts are equal, not matter what exact class they
      are, they are equal.

      This way _violate_ the /transitive/ contract. It's a dead end!!!

    + Try the *stricter* way --
      Different /run time classes/ values should always be inequal!!!

      *This way _satisfies_ all the rules.*

- For our current version of ~equals~, ~new Point(1, 2)~ does NOT equal
  to ~new Point(1, 1) { override val y = 2 }~. This is NOT reasonable!

  We know the reason, the second one is an /anonymous type/ which is a
  /subclass/ of the ~Point~ type.

  *There should be an _EXCEPTION_ that, in this case, two value of different
  classes should be equal* -- the /anonymous type/, which is a subtype of a
  /class/.

  * We introduce the ~def canEqual(other: Any): Boolean~ /method/.

    If in a subtype /override/ this /method/, it and its supertypes cannot
    be equal (you can /override/ it in a way violate this, but in the real
    world, I can guess a reason that we should do this!).

    Now the ~equals~'s of ~Point~ and ~ColoredPoint~:
    #+BEGIN_SRC scala
      class Point(val x: Int, val y: Int) {
        override def hashCode = (x, y).##
        override def equals(other: Any) = other match {
          case that: Point =>
            (that canEqual this) &&
              (this.x == that.x) && (this.y == that.y)
          case _ =>
            false
        }
        def canEqual(other: Any) = other.isInstanceOf[Point]
      }


      class ColoredPoint(x: Int, y: Int, val color: Color.Value)
          extends Point(x, y) {
        override def hashCode = (super.hashCode, color).##
        override def equals(other: Any) = other match {
          case that: ColoredPoint =>
            (that canEqual this) &&
              super.equals(that) && this.color == that.color
          case _ =>
            false
        }
        override def canEqual(other: Any) =
          other.isInstanceOf[ColoredPoint]
      }
    #+END_SRC

    In this way, since the ~new Point(1, 1) { override val y = 2 }~ does NOT
    /override/ the ~canEqual~ /method/, it is equal to ~Point(1, 2)~.

- People may think this ~canEqual~ /method/ _violate_ the /Liskov Substitution
  Principle/, but this _wrong_. *There is NO violation*.
  * /Liskov Substitution Principle/ requires that a /subclass value/ can be used
    to replace a /superclass value/, but it doesn't require they have the
    same behavior!
  * TODO =DETAILS=

** DONE 14.3 Defining equality for parameterized types - 364
CLOSED: [2017-11-25 Sat 01:50]
When /classes/ are parameterized, this scheme needs to be adapted a little
bit. *This is special due to /type erasure/.*

- Example code with parameterized types:
  #+BEGIN_SRC scala


         trait Tree[+T] {
      def elem: T
      def left: Tree[T]
      def right: Tree[T]
    }

    object EmptyTree extends Tree[Nothing] {
      def elem =
        throw new NoSuchElementException("EmptyTree.elem")
      def left =
        throw new NoSuchElementException("EmptyTree.left")
      def right =
        throw new NoSuchElementException("EmptyTree.right")
    }

    class Branch[+T](
      val elem: T,
      val left: Tree[T],
      val right: Tree[T]
    ) extends Tree[T]
  #+END_SRC

- No need to implement ~equals~ for ~Tree~ -- we assume ~equals~'s will be
  implemented separately for _EACH implementation_ of the /abstract class/.

  * For ~EmptyTree~:
    No overridden ~equals~, ~hashCode~, and ~canEqual~ is required.

    The default ~equals~ and ~hashCode~ inherited from ~AnyRef~ work just fine.
      After all, an ~EmptyTree~ is ONLY equal to itself, so equality should be
    /reference equality/, which is what's inherited from ~AnyRef~.

- Define ~equals~
  #+BEGIN_SRC scala
    class Branch[T](
      val elem: T,
      val left: Tree[T],
      val right: Tree[T]
    ) extends Tree[T] {
      override def equals(other: Any) = other match {
        case that: Branch[T] => this.elem == that.elem &&
            this.left == that.left &&
            this.right == that.right
        case _ => false
      }
    }
  #+END_SRC

  This code will issue an *unchecked warnings*.
  Use ~fsc -unchecked Tree.scala~ to check, and you'll get a warning message:
  #+BEGIN_QUOTE
  Tree.scala
  Tree.scala:14: warning: non variable typeargument T in type
  pattern is unchecked since it is eliminated by erasure
      case that: Branch[T] => this.elem == that.elem &&
  #+END_QUOTE

  This is due to /type erasure/.

- How to deal with this *unchecked warning*?
  * Fix it

      ~case that: Branch[T]~ to
    + ~case that: Branch[t]~ TODO details
      OR
    + ~case that: Branch[_]~

  * Rationale:
    You need NOT necessarily check that two ~Branch~'es have the same element
    types when comparing them -- it's quite possible that two ~Branch~'es with
    _different element types_ are equal, as long as their fields are the same.
    #+BEGIN_SRC scala
      val b1 = new Branch[List[String]](Nil, EmptyTree, EmptyTree)
      // b1: Branch[List[String]] = Branch@9d5fa4f

      val b2 = new Branch[List[Int]](Nil, EmptyTree, EmptyTree)
      // b2: Branch[List[Int]] = Branch@56cdfc29

      b1 == b2
      // res19: Boolean = true
    #+END_SRC

    + *CONTROVERSY*: Should ~b1 == b2~ _true_ or _false_?
      - In the /type erasure model/ (JVM - Scala):
        /type parameters/ are present ONLY at compile-time, and it's natural to
        consider the two ~Branch~ values ~b1~ and ~b2~ to be equal at run
        time if all fields are equal.

      - If in a model that the /type parameters/ are considered form part of
        an object's value, it's equally natural to consider them different.

- Override ~hashCode~ for ~Branch~ as usual
  ~override def hashCode: Int = (elem, left, right).##~

- Override ~canEqual~ for ~Branch~:
  #+BEGIN_SRC scala
    def canEqual(other: Any) = other match {
      case that: Branch[_] => true
      case _               => false
    }

    // OR

    def canEqual(other: Any) = otherisInstanceOf[Branch[_]]
  #+END_SRC
  How is it possible to leave some parts of it (the ~_~ in the second form
  above) undefined? TODO TODO TODO The /type parameter/, rather than
  /type pattern/, ~_~ is explained in the next chapter.

- The final version:
  #+BEGIN_SRC scala
    class Branch[T](
      val elem: T,
      val left: Tree[T],
      val right: Tree[T]
    ) extends Tree[T] {
      override def equals(other: Any) = other match {
        case that: Branch[_] => (that canEqual this) &&
                              this.elem == that.elem &&
                              this.left == that.left &&
                              this.right == that.right
        case _ => false
      }

      def canEqual(other: Any) = other.isInstanceOf[Branch[_]]

      override def hashCode: Int = (elem, left, right).##
    }
  #+END_SRC

** DONE 14.4 Recipes for ~equals~ and ~hashCode~ - 368
CLOSED: [2018-07-19 Thu 18:27]
In this section, we'll provide *step-by-step recipes for creating ~equals~ and
~hashCode~ /methods/ that should suffice for _most situations_.*

As an illustration, we'll use the /methods/ of /class/ ~Rational~, shown in
Listing 30.5. This is a *modified version* of Listing 6.5 on page 151:
- Remove mathematical operators methods that are not related to this _equality
  check_ topic.

- Enhance the ~toString~ /method/.

- Code:
  #+BEGIN_SRC scala
    class Rational(n: Int, d: Int) {
      require(d != 0)

      private val g = gcd(n.abs, d.abs)
      val numer = (if (d < 0) -n else n) / g
      val denom = d.abs / g

      private def gcd(a: Int, b: Int): Int =
        if (b == 0) a else gcd(b, a % b)

      override def equals(other: Any): Boolean =
        other match {
          case that: Rational =>
            (that canEqual this) &&
              numer == that.numer &&
              denom == that.denom
          case _ => false
        }

      def canEqual(other: Any): Boolean =
        other.isInstanceOf[Rational]

      override def hashCode: Int = (numer, denom).##

      override def toString =
        if (denom == 1) numer.toString else numer + "/" + denom
    }
  #+END_SRC

*** DONE Recipe for ~equals~ - 693
CLOSED: [2018-07-19 Thu 13:50]
1. To override equals in a non-final class, create a canEqual method.

   + If the inherited definition of equals is from ~AnyRef~ (that is, ~equals~
     was not redefined higher up in the class hierarchy), the definition of
     ~canEqual~ should be *new*;

   + otherwise, it will /override/ a previous definition of a method with the
     same name.

   + ONLY Exception:
     for /final classes/ that redefine the ~equals~ method inherited from
     ~AnyRef~.

     For them the /subclass/ anomalies described in Section 30.2 _cannot arise_;
     consequently they _need not_ define ~canEqual~.

     The type of object passed to ~canEqual~ should be ~Any~:
     ~def canEqual(other: Any): Boolean =~

2. The ~canEqual~ method should yield ~true~ if the argument object is an instance
   of the *CURRENT class* (i.e., the /class/ in which ~canEqual~ is defined), and
   ~false~ otherwise:
   ~other.isInstanceOf[Rational]~

3. In the ~equals~ method, make sure you declare the type of the object
   passed as an ~Any~:
   ~override def equals(other: Any): Boolean =~

4. Write the body of the ~equals~ method _as a single ~match~ expression_.
   The selector of the ~match~ should be _the object passed to ~equals~:_
   #+BEGIN_SRC scala
     other match {
       // ...
     }
   #+END_SRC

5. The ~match~ expression should have *two* ~case~'s.

   The first ~case~ should declare a typed pattern for the type of the
   /class/ on which you're defining the ~equals~ method:
   ~case that: Rational =>~

6. In the body of this ~case~, write *an expression that logical-ands* together
   the *individual expressions that must be ~true~ for the objects to be equal*.

   + If the ~equals~ /method/ you are /overriding/ is *NOT* that of ~AnyRef~,
     you will most likely want to include an invocation of the /superclass/'s
     ~equals~ /method/: ~super.equals(that) &&~

   + If you are defining ~equals~ for a /class/ that first introduced ~canEqual~,
     you should invoke ~canEqual~ on the argument to the _equality method_,
     passing ~this~ as the argument: ~(that canEqual this) &&~

   + Overriding redefinitions of ~equals~ *should also include* the ~canEqual~
     invocation, *unless they contain a call to ~super.equals~.* In the latter
     case, the ~canEqual~ test will already be done by the _superclass call_.

   + Lastly, _for *EACH* /field/ relevant to equality_, verify that the field
     in this object is equal to the corresponding field in the passed object:
     #+BEGIN_SRC scala
       numer == that.numer &&
       denom == that.denom
     #+END_SRC

7. For the *second* ~case~, use a /wildcard pattern/ that yields ~false~:
   ~case _ => false~

*** DONE Recipe for ~hashCode~ - 695
CLOSED: [2018-07-19 Thu 18:27]
- If the ~equals~ method does _NOT_ invokes ~super.equals(that)~ as part of
  its calculation, you should create a tuple that include all the fields of
  this class, and then use the ~##~ /method/ to get the hash code.

- If the ~equals~ method invokes ~super.equals(that)~ as part of its calcula-
  tion, you should start your ~hashCode~ calculation with an invocation of
  ~super.hashCode~. For example,
  #+BEGIN_SRC scala
    override def hashCode: Int = (super.hashCode, numer, denom).##
  #+END_SRC

- Keep in mind as you write ~hashCode~ /methods/ using this approach is that
  your hash code will only be as good as the hash codes you build out of it
  (call the ~hashCode~ on the relevant fields)

- Sometime you may need to do something extra besides just calling ~hashCode~
  on the field to get a useful hash code for that field.

  For example, if one of your fields is a collection,
  + you probably want a hash code for that field that is based on all the
    elements contained in the collection.

  + If the fields is a ~Vector~, ~List~, ~Set~, ~Map~, or /tuple/, you can
    simply include it in the list of items you are hashing over, because
    ~equals~ and ~hashCode~ are /overridden/ in those /classes/ to take into
    account the contained elements.

  + ~Array~'s are special, which do not take elements into account when
    calculating a /hash code/.
      Thus for an array, you should treat each element of the array like an
    individual field of your object, calling ~##~ on each element explicitly
    or passing the array to one of the ~hashCode~ /methods/ in singleton
    object ~java.util.Arrays~.

- If you find that a particular /hash code/ calculation is harming the performance
  of your program, you can consider *caching* the /hash code/.
    This is especially useful for /immutable/ objects, their /hash code/ can
  be calculated once when the object is created, and save it.

  In this way, you will /override/ ~hashCode~ with a ~val~ instead of a ~def~.

** DONE 14.5 Conclusion - 374
CLOSED: [2018-07-19 Thu 00:54]
- In retrospect, defining a correct implementation of ~equals~ has been
  *surprisingly subtle*.
  * You must be careful about the /type signature/;

  * you must /override/ ~hashCode~;

  * you should *avoid dependencies* on /mutable state/;

  * you should implement and use a ~canEqual~ /method/
    _if your /class/ is non-~final~._

- Given how difficult it is to implement a correct equality method,
  you might prefer to define your classes of comparable objects as /case
  classes/.

  That way, the Scala compiler will add ~equals~ and ~hashCode~ /methods/
  with the right properties *automatically*.

* TODO 15 Combining Scala and Java - 375 - =RANK 0 for reading=
This chapter describes two aspects of combining Java and Scala:

- it discusses *how Scala is translated to Java*, which is especially important
  if you _call Scala code from Java_.

- it discusses *the use of Java annotations in Scala*, an important feature if
  you want to use Scala with an existing Java framework.

** DONE 15.1 Using Scala from Java - 375
CLOSED: [2018-11-25 Sun 15:00]
1. _Most of the time_ you can think of Scala _at the source code level_.

2. However,
   you will have _a richer understanding_ of how the system works if you know
   something about its *translation*.

3. Further,
   if you call Scala code from Java,
   you will _need to know_ *what Scala code looks like from a Java point of
   view*.

*** DONE General rules - 375
CLOSED: [2018-02-06 Tue 22:46]
- Scala is implemented as a translation to standard Java bytecodes.
  *As much as possible*, Scala features map directly onto the equivalent
  Java features.

- For example,
  * Scala classes
  * Scala methods
  * Scala strings
  * Scala exceptions
  are *all compiled to the _SAME_ in Java bytecode as their Java
  counterparts*.

- To make this happen required an occasional hard choice in the design of
  Scala.

  For example, TODO =???= =WHY=
  1. For Scala *resolve overloaded methods at run time, using run-time types,
     rather than at compile time* is a good design choice. TODO =???= =WHY=

  2. However,
     such a design would *break* with Java's, making it much trickier to mesh
     Java and Scala.

  3. In this case, *Scala stays with Java’s overloading resolution*, and thus
     Scala methods and method calls can map directly to Java methods and
     method calls.

- Scala has its own design for other features.

  For example,
  * /traits/ have _NO equivalent in Java_.

  * Similarly, while both Scala and Java have /generic types/, the details of
    the two systems clash. =HOW=

  For language features like these, Scala code cannot be mapped directly to
  a Java construct, so it must be encoded using some combination of the
  structures Java does have.

  For these features that are mapped indirectly, the encoding is not fixed.

  There is an ongoing effort to make the translations as simple as possible
  so, by the time you read this, some details may be different than at the
  time of writing. You can find out what translation your current Scala
  compiler uses by examining the “.class” files with tools like *javap*. Those
  are the general rules. Consider now some special cases.

*** DONE Value types - 376
CLOSED: [2018-02-06 Tue 22:46]
=From Jian= Review this concept (in Appendix A)
Use ~Int~ as example,

- _Whenever possible_,
  the compiler translates a Scala ~Int~ to a Java ~int~
  _to get better performance._

- Translate to ~java.lang.Integer~
  when the compiler is not sure if ~int~ is applicable.
    For example, even if a particular ~List[Any]~ hold only ~Int~'s, the
  compiler has to use ~java.lang.Integer~ when doing translation.

- TODO =RE-READ=
  footnote:
  The implementation of /value types/ was discussed in details in Section 11.2

*** DONE Singleton objects - 376 =Outdated Info= =Re-Read=
CLOSED: [2018-11-25 Sun 15:00]
=From Jian=
Some information of this section is outdated!!!
Update required!

*Java has NO EXACT EQUIVALENT to a singleton object.*

- The Scala translation of /singleton objects/ uses a combination of
  * /static methods/
  * /instance methods/

- There are two types of /singleton object/:
  * "standalone" /singleton object/;
  * "companion" /singleton object/;

  _NO matter which case, *TWO* files will be generated!_

  Suppose the name of this /singleton object/ in the source code is ~ABC~,
  and the generated =.class= files are: =ABC.class= and =ABC$.class=.

- "standalone" /singleton object/;
  #+BEGIN_SRC scala
    object App {
      def main(args: Array[String]): Unit = {
        println("Hello, world!")
      }
    }
  #+END_SRC

  is translated to

  #+BEGIN_SRC java
    // Use `javap -c -p` command

    // Compiled from "App.scala"
    public final class App {
        public static void main(java.lang.String[]);
        // Code:
        // 0: getstatic     #17                 // Field App$.MODULE$:LApp$;
        // 3: aload_0
        // 4: invokevirtual #19                 // Method App$.main:([Ljava/lang/String;)V
        // 7: return
    }

    // Compiled from "App.scala"
    public final class App$ {
        public static App$ MODULE$;

        public static {};
        // Code:
        // 0: new           #2                  // class App$
        // 3: invokespecial #12                 // Method "<init>":()V
        // 6: return

        public void main(java.lang.String[]);
        // Code:
        // 0: getstatic     #20                 // Field scala/Predef$.MODULE$:Lscala/Predef$;
        // 3: ldc           #22                 // String Hello, world!
        // 5: invokevirtual #26                 // Method scala/Predef$.println:(Ljava/lang/Object;)V
        // 8: return

        private App$();
        // Code:
        // 0: aload_0
        // 1: invokespecial #29                 // Method java/lang/Object."<init>":()V
        // 4: aload_0
        // 5: putstatic     #31                 // Field MODULE$:LApp$;
        // 8: return
    }
  #+END_SRC

- "companion" /singleton object/;
  #+BEGIN_SRC scala
    class App {
      val x: Int = 3

      def addX(y: Int): Int =
        x + y
    }

    object App {
      def main(args: Array[String]): Unit = {
        println("Hello, world!")
      }
    }
  #+END_SRC

  is translated to

  #+BEGIN_SRC java
    // Compiled from "App.scala"
    public class App {
        private final int x;

        public static void main(java.lang.String[]);
        // Code:
        // 0: getstatic     #19                 // Field App$.MODULE$:LApp$;
        // 3: aload_0
        // 4: invokevirtual #21                 // Method App$.main:([Ljava/lang/String;)V
        // 7: return

        public int x();
        // Code:
        // 0: aload_0
        // 1: getfield      #24                 // Field x:I
        // 4: ireturn

        public int addX(int);
        // Code:
        // 0: aload_0
        // 1: invokevirtual #31                 // Method x:()I
        // 4: iload_1
        // 5: iadd
        // 6: ireturn

        public App();
        // Code:
        // 0: aload_0
        // 1: invokespecial #35                 // Method java/lang/Object."<init>":()V
        // 4: aload_0
        // 5: iconst_3
        // 6: putfield      #24                 // Field x:I
        // 9: return
    }


    // Compiled from "App.scala"
    public final class App$ {
        public static App$ MODULE$;

        public static {};
        // Code:
        // 0: new           #2                  // class App$
        // 3: invokespecial #12                 // Method "<init>":()V
        // 6: return

        public void main(java.lang.String[]);
        // Code:
        // 0: getstatic     #20                 // Field scala/Predef$.MODULE$:Lscala/Predef$;
        // 3: ldc           #22                 // String Hello, world!
        // 5: invokevirtual #26                 // Method scala/Predef$.println:(Ljava/lang/Object;)V
        // 8: return

        private App$();
        // Code:
        // 0: aload_0
        // 1: invokespecial #29                 // Method java/lang/Object."<init>":()V
        // 4: aload_0
        // 5: putstatic     #31                 // Field MODULE$:LApp$;
        // 8: return
    }
  #+END_SRC

- Compare the code above, you'll notice if you did have a /class/ named ~App~,
  Scalac would create a corresponding /Java ~App~ class/ to hold the
  /members/ of the ~App~ /class/ you defined.
    In that case it would NOT add any /forwarding methods/ for the same-named
  singleton object, and Java code would have to access the singleton *via*
  the ~MODULE$~ field.

- =Comment from Jian=
  The book use an outdated version of Scala in this section!!!
  From the result of ~javap~, we know it's Scala 2.9-.

  * From Scala 2.10 on, ~ScalaObject~ was eradicated, and th so does its member
    ~public int $tag()~

  * ~MODULE$~ was ~final~, but not ~final~ anymore.
    =from Jian= WHY??? I think ~final~ is more reasonable!!!

*** DONE Traits as interfaces - 378 =Learn MORE!=
CLOSED: [2018-02-06 Tue 22:46]
- Compiling any trait creates a Java interface of the same name. This
  interface is usable as a Java type, and it lets you call methods on Scala
  objects through variables of that type.

- Implementing a trait in Java is another story.
  In the general case it is not practical; however, _one special case is
  important_:
    When all the methods in a /trait/ are /abstract/, this /trait/ can be
  translated directly to a /Java interface/ with no other code to worry
  about. You actually _create a /Java interface/ in Scala syntax_.

** DONE 15.2 Annotations - 378
CLOSED: [2018-02-06 Tue 22:45]
- Scala's general /annotations/ system is discussed in Chapter 27.

- _This section discusses Java-specific aspects of /annotations/._

*** DONE Additional effects from standard annotations - 378
CLOSED: [2018-02-06 Tue 21:38]
- Several annotations cause the compiler to emit extra information when
  targeting the Java platform. When the compiler sees such an /annotation/,
  1. it processes this /annotation/ according to the general Scala rules
  2. then it does something extra for Java

- Deprecation :: TODO

- Volatile fields :: TODO

- Serialization :: TODO

*** TODO Deprecation - 378
*** TODO Volatile fields - 378
*** TODO Serialization - 378
*** DONE Exceptions thrown - 379
CLOSED: [2018-02-06 Tue 21:38]
- Scala has NO EQUIVALENT to Java's ~throws~ declarations on /methods/:
  Scala does NOT check that /thrown exceptions/ are caught.
  *footnote* The Java compiler checks the /thrown exceptions/,
             but *not* the Java bytecode verifier -- /thrown exceptions/ is
             *not* supported in the Java bytecode level.

- *Rationale* (why Scala omits this feature)
  TODO

- Sometimes when interfacing to Java,
  however, you may need to write Scala code that has _Java-friendly_
  /annotations/ describing the /thrown exceptions/ if from the Java point of
  view.

  Sometimes, this is mandatory. For example, each /method/ in an RMI remote
  interface is required to mention ~java.io.RemoteException~ in its ~throws~
  clause.

  Use Scala's ~@thorws~ /annotation/ to satisfy this kind of requirement.
  For example,
  #+BEGIN_SRC scala
    import java.io._

    class Reader(fname: String) {
      private val in = new BufferedReader(new FileReader(fname))

      @throws(classOf[IOException])
      def read() = in.read()
    }
  #+END_SRC

  You can use ~javap~ to check its =.class= file:
  #+BEGIN_SRC java
    // Compiled from "Reader.scala"
    public class Reader {
            public Reader(java.lang.String);
            public int read() throws java.io.IOException;
    }
  #+END_SRC

*** DONE Java annotations - 380
CLOSED: [2018-02-06 Tue 21:38]
- Existing annotations from Java frameworks can be used directly in Scala
  code.

  Any Java framework will see the annotations you write just as if you were
  writing in Java.

- For example,
  JUnit use the ~@Test~ to mark which part of the code is a /test/.

  An example of using JUnit in Scala:
  #+BEGIN_SRC scala
    import org.junit.Test
    import org.junit.Assert.assertEquals

    class SetTest {

      @Test
      def testMultiAdd = {
        val set = Set.empty[Int] + 1 + 2 + 3 + 1 + 2 + 3
        assertEquals(3, set.size)
      }
    }
  #+END_SRC

   Run this test:
   #+BEGIN_SRC bash
     $ scala -cp junit4.3.1.jar:. org.junit.runner.JUnitCore SetTest
     ## JUnit version 4.3.1
     ## .
     ## Time: 0.023
     ##
     ## OK (1 test)
   #+END_SRC

*** DONE Writing your own annotations - 381
CLOSED: [2018-02-06 Tue 22:45]
- To make an /annotation/ that _is VISIBLE to /Java reflection/,_ you MUST
  + use Java notation
    and
  + compile it with ~javac~.

  For this use case, _writing the /annotation/ *in Scala* does *NOT* seem
  helpful_,

  *CONCLUSION*: so the standard compiler does _NOT support_ it.

- Two reason for no support:
  + Inevitably non-fully support

  + Scala will probably one day have its own reflection,
    then you want to access /Scala annotations/ with /Scala reflection/.

- Now we know current limitation.
  We will show an example of _call Java reflection from Scala_ to _get info
  from Scala code_ that use /Java annotaion/.
  + /Java annotation/
    #+BEGIN_SRC java
      // Compile this code with `javac`
      // Define annotation
      import java.lang.annotation.*; // This is Java
      @Retention(RetentionPolicy.RUNTIME)
      @Target(ElementType.METHOD)
      public @interface Ignore { }
    #+END_SRC
    TODO
    I don't quite understand how to define /Java annotaion/.
    Try to understand this part in the future.

  + Tests code in =Tests.scala=
    #+BEGIN_SRC scala
      object Tests {
        @Ignore
        def testData = List(0, 1, -1, 5, -5)

        def test1 = {
          assert(testDate == (testData.head :: testData.tail))
        }

        def test2 = {
          assert(testDate.contains(testData.head))
        }
      }
    #+END_SRC

  + The call-Java-reflection Scala code.
    #+BEGIN_SRC scala
      object Main extends App {
        for {
          method <- Tests.getClass.getMethods
          if method.getName.startsWith("test")
          if method.getAnnotation(classOf[Ignore]) == null
        } {
          println("found a test method: " + method)
        }
      }
    #+END_SRC

  Summary:
  #+BEGIN_SRC bash
    # $
    javac Ignore.java

    #$
    scalac Tests.scala

    #$
    scalac FindTests.scala

    #$
    scala FindTests
    # found a test method: public void Tests$.test2()
    # found a test method: public void Tests$.test1()
  #+END_SRC
  (you can see the /methods/ is defined in ~Tests~ /object/ source code, and
   when they are visited by /Java reflection/, the display name is ~Tests$~,
   which is explained in a former sectoin of this chapter)

- Take care:
  When you use /Java annotatoins/ you have to work within their limitations.
  For example, you can *only use constants*, NOT expressions, in the
  /arguments to annotations/. This means ~@serial(1234)~ is legal, but
  ~@serial(x * 2)~ is _NOT legal_.

** DONE 15.3 Wildcard types - 383
CLOSED: [2018-02-07 Wed 00:31]
*ALL* /Java types/ have a Scala equivalent.
This is necessary so that Scala code can access any legal Java class.

- Most of the time the translation is straightforward.

- For some cases, though,
  the /Scala types/ you have seen so far are not enough.

  For /Java wildcard types/ like ~Iterator<?>~ or ~Iterator<? extends
  Component>~ and /Java raw types/ like ~Iterator~,
  Scala uses an extra kind of type also called a /wildcard type/.

- /Scala wildcard types/ are *written* using /placeholder syntax/.
  * ~Iterator[_]~ represents ~Iterator~ where the element type is NOT known.
  * ~Iterator[_ <: Component]~ represents ~Iterator<? extends Component>~.

- How to *use*:
  * What you see when you use?
    Here is an example:
    #+BEGIN_SRC java
      // This is a Java class with wildcards
      public class Wild {
        public Collection<?> contents() {
          Collection<String> stuff = new Vector<String>();
          stuff.add("a");
          stuff.add("b");
          stuff.add("see");
          return stuff;
        }
      }
    #+END_SRC

    #+BEGIN_SRC scala
      // scala>
      val contents = (new Wild).contents
      // contents : java.util.Collection[_] = [a, b, see]
    #+END_SRC

  * For simple usage, not type parameter required.
    #+BEGIN_SRC scala
      // scala>
      contents.size
      res0: Int = 3
    #+END_SRC

  * More complicated cases:
    #+BEGIN_SRC scala
      import scala.collection.mutable
      val iter = (new Wild).contents.iterator
      val set = mutable.Set.empty[?]  // Illegal code. What type goes here?
      while (iter.hasMore) {
        set += iter.next()
      }
    #+END_SRC
    What should be in the ~?~ place?
    + There is *no way to name the type of elements* in the Java collection,
      so you *cannot* write down a satisfactory type for set.

    + Two tricks to work around:
      1. When *passing a wildcard type* into a /method/,
         give a /parameter/ to the /method/ for the placeholder.
         You now have a name for the type that you can use as many times as
         you like.

      2. About *returning*:
         INSTEAD OF returning wildcard type from a method,
         *return an object that has /abstract members/ for each of the
         placeholder types*.

         TODO =REVIEW=
         (See Chapter 20 for information on /abstract members/.)

    + The corrected code:
      #+BEGIN_SRC scala
        import scala.collection.mutable
        import java.util.Collection

        abstract class SetAndType {
          type Elem  // abstract members
          val set: mutable.Set[Elem]
        }

        // give the wildcard type a placeholder name
        def javaSet2ScalaSet[T](jset: Collection[T]): SetAndType = {
          val sset = mutable.Set.empty[T]  // now T can be named!

          val iter = jset.iterator
          while (iter.hasNext)
            sset += iter.next()
          return new SetAndType {
            type Elem = T
            val set = sset
          }
        }
      #+END_SRC

- From the _more complicated example above_, we see why Scala code *normally
  does NOT use /wildcard types/*:
  To do anything sophisticated with them, you TEND TO *convert them to use
  /abstract members/.* So you may as well use /abstract members/ to begin
  with.

** DONE 15.4 Compiling Scala and Java together - 385
CLOSED: [2018-02-06 Tue 23:32]
- For the most simplest cases (=From Jian= what I usually meet):
  Scala code depends on Java code or vise versa.
  *Compile the dependencies first!*

- For more complicated cases:
  Scala code and Java code mutually refer each other.

  To support such builds, Scala allows compiling against /Java source code/
  as well as /Java class files/. The Scala compiler won't compile those Java
  (source) files, but it will scan them to see that they contain.

  =Comment from Jian= Scala is created later than Java, and its design ideas
  include using Java code. The Java design idea dose NOT have any plan about
  using Scala. Using compiled Scala code in Java is an fact, not a rule it
  must follow. Therefore, it must be Scala that support this feature, NOT Java

  The steps:
  1. _Compile the Scala code_ using /Java source files/;
  2. _Compile the Java code_ using /Scala class files/.

- Example:
  #+BEGIN_SRC bash
    #$
    scalac -d bin InventoryAnalysis.scala InventoryItem.java Inventory.java

    #$
    javac -cp bin -d bin Inventory.java InventoryItem.java InventoryManagement.java

    #$
    scala -cp bin InventoryManagement
    # Most expensive item = sprocket($4.99)
  #+END_SRC

** DONE 15.5 Java 8 integration - 386
CLOSED: [2018-02-07 Wed 02:10]
- Java 8 added a few IMPROVEMENTS to
  * _the Java language_
    and
  * bytecodes

  Scala takes advantage of in its 2.12 release, this version *requires* Java 8

- By exploiting new features of Java 8,
  the Scala 2.12 compiler can
  * generate *smaller* /class and jar files/
    and
  * improve the *binary compatibility* of /traits/.

*** DONE Lambda expressions and "SAM" types - 386
CLOSED: [2018-02-07 Wed 01:14]
- Before Scala 2.12 (before Java 8's support to /lambda expressions/), in the
  /SAM types/ position,
  * you CANNOT directly pass a /Scala function literal/
  * if you want to write it concisely, you need to write an /implicit
    conversion (Java code to Scala code)/ first!
    TODO =REVIEW= Section 21.1 =IMPORTANT=

  You no longer need to do this after !

- Example (no /implict conversion/ -- after Scala 2.12):
  * Define in Java
    #+BEGIN_SRC java
      JButton button = new JButton();  // This is Java 8
      button.addActionListener(event -> System.out.println("pressed!"))
    #+END_SRC

  * Use in Scala
    #+BEGIN_SRC scala
      val button = new JButton
      button.addActionListener(_ => println("pressed!"))
    #+END_SRC

- This will work with any SAM in Scala 2.12. Even if the SAM type is defined
  in Scala. For example,
  #+BEGIN_SRC scala
    trait Increaser {
      def increase(i: Int): Int
    }

    def increaseOne(increaser: Increaser): Int =
      increaser.increase(1)
  #+END_SRC

  * If NO (Scala code to Scala code) /implict conversion/, this code can work
    old versions of Scala
    #+BEGIN_SRC scala
      increaseOne(
        new Increaser {
          def increase(i: Int): Int = i + 7
        }
      )

      // res0: Int = 8
    #+END_SRC

  * Scala 2.12+, we can write it in a more concise way:
    #+BEGIN_SRC scala
      increaseOne(_ + 7)
      // res1: Int = 8
    #+END_SRC

*** DONE Using Java 8 ~Stream~'s from Scala - 388
CLOSED: [2018-02-07 Wed 02:09]
- NOTE
  *ONLY* /function literals/ will be adapted to /SAM types/,
  *NOT* arbitrary expressions that have a /function type/.

- For example,
  * Right
    1. Use anonymous instance
       #+BEGIN_SRC scala
         // scala>
         import java.util.function.IntUnaryOperator

         // scala>
         import java.util.Arrays

         // scala>
         val stream = Arrays.stream(Array(1, 2, 3))

         // scala>
         stream.map(
           new IntUnaryOperator {
             def applyAsInt(i: Int): Int = i + 1
           }
         ).toArray
         // res3: Array[Int] = Array(2, 3, 4)
       #+END_SRC

    2. Use a /funtion literal/
       #+BEGIN_SRC scala
         // scala>
         val stream = Arrays.stream(Array(1, 2, 3))
         // stream can only be used once, you must create a new one to use

         // scala>
         stream.map(_ + 1).toArray
         // res4: Array[Int] = Array(2, 3, 4)
       #+END_SRC

  * Wrong
    #+BEGIN_SRC scala
      // scala>
      val f = (i: Int) => i + 1
      // f: Int => Int = ...

      // scala>
      val stream = Arrays.stream(Array(1, 2, 3))

      // scala>
      stream.map(f).toArray
      // <console>:16: error: type mismatch;
      //  found   : Int => Int
      //  required: java.util.function.IntUnaryOperator
      //        stream.map(f).toArray
      //                   ^
    #+END_SRC

  * Correction 1

    =From Jian= More applicable -- no need to change the definition, though
                not that concise)

    #+BEGIN_SRC scala
      // scala>
      val stream = Arrays.stream(Array(1, 2, 3))

      // scala>
      stream.map(i => f(i)).toArray
      // res5: Array[Int] = Array(2, 3, 4)
    #+END_SRC

  * Correction 2

    =From Jian= rarely used -- you must import ~IntUnaryOperator~ first, and
                you must have permission to define ~f~ with
                ~IntUnaryOperator~ type. However, if you can, why NOT just
                use a /function literal/? The only two reasons I can imagine
    + ~f~ is not short, and you need to use it multiple times!
    + ~f~ is too long, you want to make you code clear!

    #+BEGIN_SRC scala
      // scala>
      val f: IntUnaryOperator = i => i + 1
      // f: java.util.function.IntUnaryOperator = ...

      // scala>
      val stream = Arrays.stream(Array(1, 2, 3))

      // scala>
      stream.map(f).toArray
      // res6: Array[Int] = Array(2, 3, 4)
    #+END_SRC

- TODO =RE-READ= =RE-THINK=
  With Scala 2.12 and Java 8, you can also invoke methods compiled with Scala
  from Java, passing Scala function types using Java lambda expressions.

  Although Scala /function types/ are defined as /traits/ that include
  /concrete methods/, *Scala 2.12 compiles traits to Java interfaces with
  /default methods/,* a new feature of Java 8.
  As a result, /Scala function types/ appear to Java as /SAMs/.

** DONE 15.6 Conclusion - 389
CLOSED: [2018-02-07 Wed 02:10]

* TODO 16 Futures and Concurrency - 364
- Java provides concurrency support built around /shared memory/ and /locking/.
    Although this support is sufficient, this approach turns out to be _quite
  DIFFICULT to get right in practice_.

- Scala's standard library offers an ALTERNATIVE that avoids these
  difficulties by focusing on /asynchronous transformations of immutable state/:
  the ~Future~.

- Java also offers a ~Future~, but it is _very different from Scala's_.
  TODO =???=

- ??????? TODO =???=

  This allows you to describe /asynchronous computations/ as _a series of
  transformations of immutable values_, *with no need to reason about shared
  memory and locks*.

** DONE 16.1 Trouble in paradise - 364 =Re-Do=
CLOSED: [2018-03-06 Tue 14:37]
- The Java way:
  * Model:
    each object is associated with a logical /monitor/, which can be used to
    control multi-threaded access to data.

  * Use this model:
    Mark the data that will be shared by multiple threads as *synchronized*.

    The Java runtime employs a locking mechanism to *ensure* that *only one*
    thread at a time enters synchronized sections guarded by the same /lock/.

- For compatibility's sake,
  Scala provides access to Java's concurrency primitives.
  The ~wait~, ~notify~, and ~notifyAll~ /methods/ can be called in Scala, and
  _they have the same meaning as in Java_.

- Scala
  * does *NOT* have the ~synchronized~ /keyword/

  * has a *predefined* ~synchronized~ /method/ that can be called
    as follows:
    #+BEGIN_SRC scala
      var counter = 0

      synchronized {
        // One thread in here at a time
        counter = counter + 1
      }
    #+END_SRC

- Why is this model hard to be used?
  * You must reason about
    + what data you are modifying or accessing that might be modified or
      accessed by other trheads

    + what locks are being held.

  * At each method call,
    you must reason about
    + what locks it will try to hold and convince yourself that it will not
      /deadlock/ while trying to obtain them.

  * Compounding the problem, the locks you reason about are *not fixed at
    compile time*, _because the program is free to create new locks at run
    time as it progresses._

  * Making things worse, testing is not reliable with multi-threaded code, which
    has *non-deterministic* nature.

  * Over-synchronizing also does NOT work!
    New lock operations may _remove_ POSSIBILITIES for /race condition/, they
    simutaneously _add_ POSSIBILITIES for /deadlocks/.

- Higher level abstractions: ~java.util.concurrent~
  It's far less error prone than the low-level synchronization primitives.

  Nevertheless, it is also based on /the shared data and locks models/, and
  it does NOT solve the fundamental difficulties of using that model!

** DONE 16.2 Asynchronous execution and ~Try~'s - 366
CLOSED: [2018-04-11 Wed 01:19]
- Many operations on ~Future~ require an implicit /execution context/ that
  provides a strategy for executing functions asychronously.

- Example (lack of /execution context/):
  #+BEGIN_SRC scala
    import scala.concurrent.Future

    val fut = Future { Thread.sleep(10000); 21 + 21 }
    // <console>:11: error: Cannot find an implicit ExecutionContext.
    //     You might pass an (implicit ec: ExecutionContext)
    //     parameter to your method or import
    //     scala.concurrent.ExecutionContext.Implicits.global.
    //        val fut = Future { Thread.sleep(10000); 21 + 21 }
  #+END_SRC

- Example (with /execution context/):
  #+BEGIN_SRC scala
    import scala.concurrent.Future
    import scala.concurrent.ExecutionContext.Implicits.global

    val fut = Future { Thread.sleep(10000); 21 + 21 }
  #+END_SRC

- Use the ~isCompleted~ and ~value~ /methods/:
  #+BEGIN_SRC scala
    /* BEFORE finish */
    fut.isCompleted
    // res0: Boolena = false

    fut.value
    // res1: Option[scala.util.Try[Int]] = None



    /* AFTER finish */
    fut.isCompleted
    // res2: Boolena = true

    fut.value
    // res3: Option[scala.util.Try[Int]] = Some(Success(42))
  #+END_SRC

- ~Try~ has two /subclasses/, and an instance of a ~Failure~ always contains
  an /exception/.

- Why should we have ~Try~?
  * For *synchronous* computations, you can use ~try/catch~ to ensure that a
    thread that invokes a /method/ catches and handles /exceptions/ thrown by
    the /method/.

  * For *asynchronous* computations, the thread that initiates the computation
    often moves on to other tasks.
      Later if that asynchronous computation fails with an exception, _the
    *original* thread_ is _no longer_ able to handle the exception in a
    ~catch~ clause. Thus, we use ~Try~ to handle the /exceptions/.

- Example:
  #+BEGIN_SRC scala
    import scala.concurrent.Future
    import scala.concurrent.ExecutionContext.Implicits.global

    val fut = Future { Thread.sleep(10000); 21 / 0 }
    // fut: scala.concurrent.Future[Int] = ...

    /* When the computation complete */
    fut.value
    // res4: Option[scala.util.Try[Int]] = None
    //     Some(Failure(java.lang.ArithmeticException: / by zero))

  #+END_SRC

** DONE 16.3 Working with ~Future~'s - 369
CLOSED: [2018-04-11 Wed 15:06]
Scala's ~Future~ allows you to specify /transformations/ on ~Future~ results and
obtain a new /future/ that represents the composition of the _two_ /asynchronous
computations/: the original and the transformation.

*** DONE Transforming ~Futures~ with ~map~ - 395
CLOSED: [2018-04-11 Wed 02:19]
#+BEGIN_SRC scala
  import scala.concurrent.Future
  import scala.concurrent.ExecutionContext.Implicits.global

  val fut = Future { Thread.sleep(10000); 21 + 21 }
  val result = fut.map(x => x + 1)
  /* When computation complete */
  result.value
  // res6: Option[scala.util.Try[Int]] = Some(Success(43))
#+END_SRC

*** DONE Transforming ~Futures~ with ~for~ expressions - 396 =RE-READ=
CLOSED: [2018-04-11 Wed 02:30]
Because Scala's ~Future~ also declares a ~flatMap~ /method/, you can
transform /futures/ using a ~for~ expression.
#+BEGIN_SRC scala
  val fut1 = Future { Thread.sleep(10000); 21 + 21 }
  val fut2 = Future { Thread.sleep(10000); 23 + 23 }

  for {
    x <- fut1
    y <- fut2
  } yield x + y
  // res7: scala.concurrent.Future[Int] = ...

  /* When computation complete */
  res7.value
  // res8: Option[scala.util.Try[Int]] = Some(Success(88))

#+END_SRC

- Because ~for~ expressions serialize their /transformations/,
  *if you don't create the /futures/ before the ~for~ expression, they won't
  run in parallel.* TODO

    A similar look example, which will _run at least 20 seconds, rather then
  10 seconds_ as in the code above. TODO
  #+BEGIN_SRC scala
    // fut1.flatMap(x => fut2.map(y => x + y))
    for {
      x <- Future { Thread.sleep(10000); 21 + 21 }
      y <- Future { Thread.sleep(10000); 23 + 23 }
    } yield x + y
    // res7: scala.concurrent.Future[Int] = ...

    /* When computation complete */
    res7.value
  #+END_SRC

- =FROM JIAN= Consider the code above, and find out the difference.
  Guess: check their forms of using ~flatMap~

*** =PAGE NUMBER=
*** DONE Creating the ~Future~: ~Future.failed~, ~Future.successful~, ~Future.fromTry~, and ~Promises~ - 397
CLOSED: [2018-04-11 Wed 03:05]
- The ~Future~ /companion object/ includes three /factory methods/ for
  creating already-completed /futures/:
  * ~Future.successful~
    #+BEGIN_SRC scala
      Future.successful { 21 + 21 }
      // res2: scala.concurrent.Future[Int] = ...
    #+END_SRC

  * ~Future.failed~
    #+BEGIN_SRC scala
      Future.failed(new Exception("bummer!"))
      // res3: scala.concurrent.Future[Nothing] = ...
    #+END_SRC

  * ~Future.fromTry~
    #+BEGIN_SRC scala
      import scala.util.{Success,Failure}

      Future.fromTry(Success { 21 + 21 })
      // res4: scala.concurrent.Future[Int] = ...

      Future.fromTry(Failure(new Exception("bummer!")))
      // res5: scala.concurrent.Future[Nothing] = ...
    #+END_SRC

  These /factory methods/ do NOT require an ~ExecutionContext~

- The most general way to create a /future/ is to use a ~Promise~.
  * Given a /promise/ you can obtain a /future/ that is *controlled by* the
    /promise/.

  * The /future/ will *complete* _when_ you complete the /promise/.

- Example:
  #+BEGIN_SRC scala
    val pro = Promise[Int]
    // pro: scala.concurrent.Promise[Int] = ...

    val fut = pro.future
    // fut: scala.concurrent.Future[Int] = ...

    fut.value
    // res8: Option[scala.util.Try[Int]] = None
  #+END_SRC

- You can *complete* the /promise/ with /methods/
  * ~success~
    Example:
    #+BEGIN_SRC scala
      pro.success(42)
      // res9: pro.type = ...

      fut.value
      // res10: Option[scala.util.Try[Int]] = Some(Success(42))
    #+END_SRC

  * ~failure~
    Accept an /exception/ that will cause the /future/ to fail with that
    /exception/.

  * ~complete~
    Take a ~Try~.

  * ~completeWith~
    TODO =???= =Example?=
    TODO =???= =Example?=
    Take a /future/.
    The /promise/'s /future/ will thereafter mirror the completion status of
    the /future/ you passed to ~completeWith~.

*** DONE Filtering: ~filter~ and ~collect~ - 398
CLOSED: [2018-04-11 Wed 03:19]
- The ~filter~ and ~collect~ /methods/ allow you to *ensure a property holds
  true* about a /future value/.

- Example:
  #+BEGIN_SRC scala
    val fut = Future { 42 }

    /* If valid */
    val valid = fut.filter(res => res > 0)
    valid.val
    // res0: Option[scala.util.Try[Int]] = Some(Success(42))


    /* If invalid */
    val invalid = fut.filter(res => res < 0)
    invalid.val
    // res1: Option[scala.util.Try[Int]] =
    //   Some(Failure(java.util.NoSuchElementException:
    //   Future.filter predicate is not satisfied))
  #+END_SRC

- ~Future~ offers a ~withFilter~ /method/, and you can perform the same
  operation with ~for~ expression filters:
  #+BEGIN_SRC scala
    val valid = for (res <- fut if res > 0) yield res
    valid.value
    // res2: Option[scala.util.Try[Int]] = Some(Success(42))

    val invalid = for (res <- fut if res < 0) yield res
    // res3: Option[scala.util.Try[Int]] =
    //   Some(Failure(java.util.NoSuchElementException:
    //   Future.filter predicate is not satisfied))
  #+END_SRC

- The ~collect~ /method/ allows you to
  1. validate the /future value/ (=From Jian= like a filter)
  2. transform it in one operation (=From Jian= like a map)

- If the /partial function/ passed to ~collect~ is defined at the /future
  result/, the /future/ returned by ~collect~ will succeed with that value
  transformed by the function:
  #+BEGIN_SRC scala
    val valid = fut collect { case res if res > 0 => res + 46 }
    // valid: scala.concurrent.Future[Int] = ...

    valid.value
    // res17: Option[scala.util.Try[Int]] = Some(Success(88))
  #+END_SRC

  Otherwise, the /future/ will fail with ~NoSuchElementException~:
  #+BEGIN_SRC scala
    val invalid =
      fut collect { case res if res < 0 => res + 46 }
    // invalid: scala.concurrent.Future[Int] = ...

    invalid.value
    // res18: Option[scala.util.Try[Int]] =
    //   Some(Failure(java.util.NoSuchElementException:
    //   Future.collect partial function is not defined at: 42))
  #+END_SRC

*** DONE Dealing with failure: ~failed~, ~fallBackTo~, ~recover~, and ~recoverWith~ - 400
CLOSED: [2018-04-11 Wed 05:15]
- Scala's /future/ provides ways to work with /futures/ that *fail*, including:
  * ~failed~
    Transform a failed /future/ of any type into a successful
    ~Future[Throwable]~ that holds onto the /exception/ that caused the failure.
    + If it is a fail
      #+BEGIN_SRC scala
        val failure = Future { 42 / 0 }
        // failure: scala.concurrent.Future[Int] = ...

        failure.value
        // res23: Option[scala.util.Try[Int]] =
        //   Some(Failure(java.lang.ArithmeticException: / by zero))

        val expectedFailure = failure.failed
        // expectedFailure: scala.concurrent.Future[Throwable] = ...

        expectedFailure.value
        // res25: Option[scala.util.Try[Throwable]] =
        //   Some(Success(java.lang.ArithmeticException: / by zero))
      #+END_SRC

    + If it is NOT a fail, the saved /exception/ is the ~NoSuchElementException~:
      #+BEGIN_SRC scala
        val success = Future { 42 / 1 }
        // success: scala.concurrent.Future[Int] = ...

        success.value
        // res21: Option[scala.util.Try[Int]] = Some(Success(42))

        val unexpectedSuccess = success.failed
        // unexpectedSuccess: scala.concurrent.Future[Throwable] = ...

        unexpectedSuccess.value
        // res26: Option[scala.util.Try[Throwable]] =
        //   Some(Failure(java.util.NoSuchElementException:
        //   Future.failed not completed with a throwable.))
      #+END_SRC

  * ~fallBackTo~
    Provide a _fall back_ /future/ in case the future on which you invoke
    ~fallbackTo~ fails.
    + When success, return the result /future/
    #+BEGIN_SRC scala
      val fallback = failure.fallbackTo(success)
      // fallback: scala.concurrent.Future[Int] = ...

      fallback.value
      // res27: Option[scala.util.Try[Int]] = Some(Success(42))
    #+END_SRC

    + When fail, return the result _fall back_ /future/
      #+BEGIN_SRC scala
        val fallback = failure.fallbackTo(
          Future { val res = 42; require(res < 0); res }
        )

        failedFallback.value
        // res28: Option[scala.util.Try[Int]] =
        //   Some(Failure(java.lang.ArithmeticException: / by zero))
      #+END_SRC

  * ~recover~
    + transform a _failed_ /future/ into a _successful_ one
      #+BEGIN_SRC scala
        val recovered = failedFallback recover {
          case ex: ArithmeticException => -1
        }

        recovered.value
        // res32: Option[scala.util.Try[Int]] = Some(Success(-1))
      #+END_SRC

    + allowing a the result of a _successful_ /future/ to _pass through
      unchanged_.
      #+BEGIN_SRC scala
        /* No exception - Success */
        val unrecovered = fallback recover {
          case ex: ArithmeticException => 1
        }

        unrecovered.value
        // res33: Option[scala.util.Try[Int]] = Some(Success(42))

        /* With exception - Fail - unmatch exception */
        val alsoUnrecovered = failedFallback recover {
          case ex: IllegalArgumentException => -2
        }

        alsoUnrecovered.value
        // res34: Option[scala.util.Try[Int]] =
        //   Some(Failure(java.lang.ArithmeticException: / by zero))
      #+END_SRC

  * ~recoverWith~
    It's like ~recover~, except instead of recovering to a value like
    ~recover~, it allows you to _recover to a ~Future~._
    #+BEGIN_SRC scala
      val alsoRecovered = failedFallback recoverWith {
        case ex: ArithmeticException => Future { 42 + 46 }
      }

      alsoRecovered.value
      // res35: Option[scala.util.Try[Int]] = Some(Success(88))
    #+END_SRC
    + As with ~recover~,
      if
      - either _the original /future/ doesn't fail_,
      - or _the partial function passed to ~recoverWith~ isn't defined at the
        exception the original future ultimately fails with_,

      the original success (or failure) will pass through to the /future/
      returned by ~recoverWith~.

*** DONE Mapping both possibilities: ~transform~ - 403
CLOSED: [2018-04-11 Wed 11:27]
- ~Future~'s ~transform~ /method/ accepts *two* functions with which to
  *transform* a /future/:
  * one to use in case of _success_

  * the other in case of _failure_

- Example:
  #+BEGIN_SRC scala
    val first = success.transform(
      res => res * 1,
      ex => new Exception("see cause", ex)
    )
    // first: scala.concurrent.Future[Int] = ...
  #+END_SRC

  * If the /future/ _succeeds_, the first function is used:
    #+BEGIN_SRC scala
      first.value
      // res42: Option[scala.util.Try[Int]] = Some(Success(-42))
    #+END_SRC

  * If the future fails, the second function is used:
    #+BEGIN_SRC scala
      val second = failure.transform(
        res => res * 1,
        ex => new Exception("see cause", ex)
      )
      // second: scala.concurrent.Future[Int] = ...


      second.value
      // res43: Option[scala.util.Try[Int]] =
      //   Some(Failure(java.lang.Exception: see cause))
    #+END_SRC

  * Note that with the ~transform~ /method/ shown in the previous examples,
    + you *CANNOT* change a /successful future/ into a /failed one/

    + you also *CANNOT* change a /failed future/ into a/ successful one/

- To make transformations between /successful futures/ and /failed futures/
  easier, Scala 2.12 introduced an alternate overloaded form of ~transform~
  that takes a function from ~Try~ to ~Try~. Here are some examples:
  #+BEGIN_SRC scala
    val firstCase = success.transform { // Scala 2.12
      case Success(res) => Success(res * -1)
      case Failure(ex)  => Failure(new Exception("see cause", ex))
    }
    // first: scala.concurrent.Future[Int] = ...


    firstCase.value
    // res6: Option[scala.util.Try[Int]] = Some(Success(-42))


    val secondCase = failure.transform {
      case Success(res) => Success(res * -1)
      case Failure(ex)  => Failure(new Exception("see cause", ex))
    }
    // secondCase: scala.concurrent.Future[Int] = ...


    secondCase.value
    // res8: Option[scala.util.Try[Int]] =
    //    Some(Failure(java.lang.Exception: see cause))
  #+END_SRC

  * Usage:
    #+BEGIN_SRC scala
      val nonNegative = failure.transform { // Scala 2.12
        case Success(res) => Success(res.abs + 1)
        case Failure(_) => Success(0)
      }
      // nonNegative: scala.concurrent.Future[Int] = ...

      scala> nonNegative.value
      // res11: Option[scala.util.Try[Int]] = Some(Success(0))
    #+END_SRC

*** TODO Combining futures: ~zip~, ~Future.foldLeft~, ~Future.reduceLeft~, ~Future.sequence~, and ~Future.traverse~ - 404
=from Jian=
*CAUTION* Include some errors -- Still use ~TraversableOnce~!!!!!!!!!!!!
Already send errata report to artima!!!
Wait for response!!!
I realdy fixed the error in this note!
*CAUTION* Include some errors -- Still use ~TraversableOnce~!!!!!!!!!!!!

=From Jian= Try to understand this part with the idea of common algebra
structures like /functor/, /monoid/, and /monad/

- ~zip~
  + Success
    #+BEGIN_SRC scala
      scala> val zippedSuccess = success zip recovered
      // zippedSuccess: scala.concurrent.Future[(Int, Int)] = ...

      zippedSuccess.value
      // res46: Option[scala.util.Try[(Int, Int)]] =
      //      Some(Success((42,1)))
    #+END_SRC

  + Fail
    * If _either of the /futures/ *FAIL*,_ however, the /future/ returned by
      ~zip~ will also *FAIL* with the *same* /exception/:
      #+BEGIN_SRC scala
        val zippedFailure = success zip failure
        // zippedFailure: scala.concurrent.Future[(Int, Int)] = ...

        zippedFailure.value
        // res48: Option[scala.util.Try[(Int, Int)]] =
        //   Some(Failure(java.lang.ArithmeticException: / by zero))
      #+END_SRC

    * If both /futures/ *FAIL*, the failed /future/ that results will contain
      the /exception/ stored in the /initial future/, the one on which zip was
      invoked (the /receiver/).

- ~Future.fold~
  Accumulate a result accross a ~Iterable~ collection of /future/'s, yielding
  a /future/ result.
  #+BEGIN_SRC scala
    val fortyTwo = Future { 21 + 21 }
    // fortyTwo: scala.concurrent.Future[Int] = ...

    val fortySix = Future { 23 + 23 }
    // fortySix: scala.concurrent.Future[Int] = ...

    val futureNums = List(fortyTwo, fortySix)
    // futureNums: List[scala.concurrent.Future[Int]] = ...

    val folded = Future.foldLeft(futureNums)(0) {(acc, num) =>
      acc + num
    }
    // folded: scala.concurrent.Future[Int] = ...

    folded.value
    // res53: Option[scala.util.Try[Int]] = Some(Success(88))
  #+END_SRC

  + If *any* /future/ in the collection _fails_, the resulting /future/ will
    _fail_. If *MULTIPLE* /futures/ _fail_, the result will _fail_ with the
    same /exception/ with which the *first* /future/ (earliest in the
    ~IterableOnce~ collection) *fails*.

- ~Future.reduce~
  It performs a /fold/ *without* an /initial value/ as the _second parameter_,
  using the *initial /future/ result* instead.
  #+BEGIN_SRC scala
    val reduced =
      Future.reduce(futureNums) { (acc, num) =>
        acc + num
      }
    // reduced: scala.concurrent.Future[Int] = ...

    reduced.value
    // res54: Option[scala.util.Try[Int]] = Some(Success(88))
  #+END_SRC
  + Pass an empty collection as the first parameter of ~reduce~, and a
    ~NoSuchElementException~ will be thrown.

- ~Future.sequence~
  It transforms a ~IterableOnce~ collection of /futures/ into a /future/
  ~IterableOnce~ of values.
    For instance, in the following example, ~sequence~ is used to
  /transform/ a ~List[Future[Int]]~ to a ~Future[List[Int]]~:
  #+BEGIN_SRC scala
    val futureList = Future.sequence(futureNums)
    // futureList: scala.concurrent.Future[List[Int]] = ...

    futureList.value
    // res55: Option[scala.util.Try[List[Int]]] =
    //   Some(Success(List(42, 46)))
  #+END_SRC

- ~Future.traverse~
  It changes a ~IterableOnce~ of any element type into a ~IterableOnce~ of
  /futures/ and /sequence/ that into a /future/ ~IterableOnce~ of values.
    For example, here a ~List[Int]~ is transformed into a
  ~Future[List[Int]]~ by ~Future.traverse~:
  #+BEGIN_SRC scala
    val traversed =
      Future.traverse(List(1, 2, 3)) { i => Future(i) }
    // traversed: scala.concurrent.Future[List[Int]] = ...

    traversed.value
    // res58: Option[scala.util.Try[List[Int]]] =
    //   Some(Success(List(1, 2, 3)))
  #+END_SRC

*** DONE Performing side-effects: ~foreach~, ~onComplete~, and ~andThen~ - 406
CLOSED: [2018-04-11 Wed 13:47]
- ~foreach~
  Perform a side effect if a future completes successfully.
  For example,
  #+BEGIN_SRC scala
    failure.foreach(ex => println(ex))

    success.foreach(res => println(res))
    // 42
  #+END_SRC

- Since ~for~ _without yield_ will rewrite to an invocation of ~foreach~, you
  can also accomplish the same effect using for expressions:
  #+BEGIN_SRC scala
    for (res <- failure) println(res)

    for (res <- success) println(res)
    // 42
  #+END_SRC

- ~Future~ also offers *two* /methods/ for registering /callback functions/.
  * The ~onComplete~ /method/ will be executed whether the /future/ ultimately
    succeeds or fails.
      The function will be passed a Try—a Success holding the
    result if the future succeeded, else a Failure holding the exception that
    caused the future to fail. Here’s an example:
    #+BEGIN_SRC scala
      import scala.util.{Success, Failure}

      success onComplete {
        case Success(res) => println(res)
        case Failure(ex) => println(ex)
      }
      // 42

      failure onComplete {
        case Success(res) => println(res)
        case Failure(ex) => println(ex)
      }
      // java.lang.ArithmeticException: / by zero
    #+END_SRC

    + ~Future~ does *NOT* guarantee any order of execution for /callback
      functions/ registered with ~onComplete~.

  * If you want to *enforce an order* for /callback functions/, you must use
    ~andThen~ instead.
      The ~andThen~ /method/ returns a _new_ /future/ that mirrors (succeeds
    or fails in the same way as) the /original future/ on which you invoke
    ~andThen~, but it does NOT complete until the /callback function/ has been
    fully executed:
    #+BEGIN_SRC scala
      val newFuture = success andThen {
        case Success(res) => println(res)
        case Failure(ex) => println(ex)
      }
      // 42
      // newFuture: scala.concurrent.Future[Int] = ...

      newFuture.value
      // res76: Option[scala.util.Try[Int]] = Some(Success(42))
    #+END_SRC

- Note that if a /callback function/ passed to ~andThen~ throws an
  /exception/ when executed,
    _That /exception/ will /not/ be propagated to subsequent callbacks or
  reported via the resulting future._
  TODO =???= =Details=

*** DONE Other methods: ~flatten~, ~zipWith~, and ~transformWith~ - 408
CLOSED: [2018-04-11 Wed 15:06]
- ~flatten~
  #+BEGIN_SRC scala
    val nestedFuture = Future { Future { 42 } }
    val flattened = nestedFuture.flatten  // Scala 2.12
    // flattened: scala.concurrent.Future[Int] = Future(Success(42))
  #+END_SRC

- ~zipWith~
  zip and then map
  #+BEGIN_SRC scala
    val futNum = Future { 21 + 21 }
    val futStr = Future { "ans" + "wer" }

    val zipWithed = futNum.zipWith(futStr) {
      case (num, str) => s"$num is the $str"
    }

    zipWithed.value
    // Option[scala.util.Try[String]] = Some(Success(42 is the answer))
  #+END_SRC

- ~transformWith~ TODO =RE-READ=
  tranform with a function from ~Try~ to ~Future~
  #+BEGIN_SRC scala
    val flipped = success.transformWith { // Scala 2.12
      case Success(res) => Future { throw new Exception(res.toString) }
      case Failure(ex)  => Future { 21 + 21 }
    }
    // flipped: scala.concurrent.Future[Int] = ...

    flipped.value
    // res5: Option[scala.util.Try[Int]] =
    //     Some(Failure(java.lang.Exception: 42))
  #+END_SRC
  * The ~transformWith~ /method/ is similar to *the new, overloaded*
    ~transform~ /method/ added in Scala 2.12, _except_ instead of yielding a
    ~Try~ in your passed function as in ~transform~, ~transformWith~ allows
    you to yield a /future/.

** DONE 16.4 Testing with ~Future~'s - 409
CLOSED: [2018-04-11 Wed 13:34]
- Scala does allow you to *block* on a /future/ result when you need to.
  Scala's ~Await~ /object/ facilitates blocking to wait for future results.
  Here’s an example:
  #+BEGIN_SRC scala
    import scala.concurrent.Await
    import scala.concurrent.duration._


    val fut = Future { Thread.sleep(10000); 21 + 21 }
    // fut: scala.concurrent.Future[Int] = ...

    val x = Await.result(fut, 15.seconds) // blocks
    // x: Int = 42
  #+END_SRC
  * ~Await.result~ takes a ~Future~ and a ~Duration~.

  * If there is NOT enough time, a ~TimeoutException~ will be thrown.

- One place where *blocking* has been generally accepted is
  _in tests of asynchronous code_.

  * Use ~Await.result~.
    #+BEGIN_SRC scala
      import org.scalatest.Matchers._
      x should be (42)
      // res0: org.scalatest.Assertion = Succeeded
    #+END_SRC

  * Extends ~ScalaFutures~ /trait/ as *alternatives*,
    For example, the ~futureValue~ /method/, implicitly added to ~Future~ by
    ~ScalaFutures~, *will block until the /future/ completes*.
    #+BEGIN_SRC scala
      import org.scalatest.concurrent.ScalaFutures._


      val fut = Future { Thread.sleep(10000); 21 + 21 }
      // fut: scala.concurrent.Future[Int] = ...

      fut.futureValue should be (42)    // futureValue blocks
      // res1: org.scalatest.Assertion = Succeeded
    #+END_SRC

    + ~TestFailedException~ on fails

- While *blocking in tests* is often fine,
  /ScalaTest 3.0/ adds "async" testing styles that allow you to test
  /futures/ *without blocking*.
  #+BEGIN_SRC scala
    import org.scalatest.AsyncFunSpec
    import scala.concurrent.Future

    class AddSpec extends AsyncFunSpec {
      def addSoon(addends: Int*): Future[Int] =
        Future { addends.sum }

      describe("addSoon") {
        it("will eventually compute a sum of passed Ints") {
          val futureSum: Future[Int] = addSoon(1, 2)
          // You can map assertions onto a Future, then return
          // the resulting Future[Assertion] to ScalaTest:
          futureSum map { sum => assert(sum == 3) }
        }
      }
    }
  #+END_SRC

- The /async testing/ use case illustrates a *general principle* for working
  with /futures/: *Once in "future space," try to _stay_ in /future/ space.*

- TODO =???=
  To *get results out of* /future/ space, register /side effects/ to be
  _performed asynchronously_ once /futures/ complete. This approach will help
  you *make _maximum use_ of your /threads/.*

** DONE 16.5 Conclusion - 411
CLOSED: [2018-04-11 Wed 15:10]
- Concurrent programming gives you great power.
  It lets you *simplify* your code and take advantage of multiple processors.

- It's *unfortunate* that the most widely used concurrency primitives,
  /threads/, /locks/, and /monitors/, are such a minefield of /deadlocks/ and
  /race conditions/.

  ~Futures~ provide a way out of that minefield, letting you write concurrent
  programs *without* as great a risk of /deadlocks/ and /race conditions/.

- This chapter has introduced several fundamental constructs for working with
  /futures/ in Scala, including
  * how to create /futures/, how to *transform* them,

  * how to *test* them, among other nuts and bolts.

  It then showed you how to use these constructs as part of a general
  /futures/ style.

* TODO 17 Combinator Parsing - 413
- These building blocks of /parser combinators/ will map one to one to the
  constructions of a /context-free grammar/, to make them easy to understand.

- The only non-Scala specific prerequisite for understanding this chapter:
  you know about /regular and context-free grammars/.

** DONE 17.1 Example: Arithmetic expressions - 414
CLOSED: [2018-03-05 Mon 15:53]
- (Context-free) Grammar for arithmetic expressions:
  #+BEGIN_SRC text
      expr ::= term {"+" term | "-" term}.
      term ::= factor {"*" factor | "/" factor}.
    factor ::= floatingPointNumber | "(" expr ")".
  #+END_SRC

  * ~|~ denotes alternative productions
  * ~{...}~ denotes repetition (zero or more times)
  * No use in this example, ~[...]~ denotes an _optional occurrence_.

  * This grammar already encodes the /relative precedence/ of operators.

- *ranslate the grammar above to Scala code (with /cominator parser library/):
  #+BEGIN_SRC scala
    import scala.util.parsing.combinator._

    class Arith extends JavaTokenParsers {
      def expr: Parser[Any] = term~rep("+"~term | "-"~term)
      def term: Parser[Any] = factor~rep("*"~factor | "/"~factor)
      def factor: Parser[Any] = floatingPointNumber | "("~expr~")"
    }
  #+END_SRC

  * The ~floatingPointNumber~ comes from the /trait/ ~JavaTokenParsers~.

  * This /trait/ provides the basic machinery for writing a parser
    and also provides some _primitive parsers_ that recognize some word classes:
    + identifiers
    + string literals
    + numbers

- How to convert a /context-free grammar/ to Scala parser combinator code:
  1. Every production becomes a /method/ -- add ~def~.

  2. Replace ~::=~ with ~: Parser[Any] =~.

     TODO Learn what does this type mean and how to make it more precise in
     this chater later sections.

  3. The grammar has implict sequential composition, and use ~~~ to make it
     explicit in the code.

  4. Replace ~{...}~ with ~rep(...)~;
     Replace ~[...]~ with ~opt(...)~;

  5. The period (.) at the end of each production is ommitted in the code.

** DONE 17.2 Running your parser - 416
CLOSED: [2018-03-05 Mon 16:35]
- Run the parser:
  #+BEGIN_SRC scala
    object ParseExpr extends Arith {
      def main(args: Array[String]) = {
        println("input : " + args(0))
        println(parseAll(expr, args(0)))
      }
    }
  #+END_SRC

  + Run
    #+BEGIN_SRC bash
      scala ParseExpr "2 * (3 + 7)"
      # input: 2 * (3 + 7)
      # [1.12] parsed: ((2~List((*~(((~((3~List())~List((+
      # ~(7~List())))))~)))))~List())
    #+END_SRC

  + Besides ~parseAll~, there's also a method ~parse~, which allows you to
    * parse an input prefix
    * leaving some remainder unread.

- Error messages:
  #+BEGIN_SRC bash
    scala ParseExpr "2 * (3 + 7))"
    # input: 2 * (3 + 7))
    # [1.12] failure: `-' # expected but `)' found
    #
    # 2 * (3 + 7))
    #            ˆ
  #+END_SRC

** DONE 17.3 Basic regular expression parsers - 417
CLOSED: [2018-03-05 Mon 19:35]
- ~JavaTokenParsers~ provides some basic parsers for patterns in Java format.

- Q :: How to parse patterns not like Java? For example, parse /floating
       numbers/ not in Java format (CANNOT use ~floatingPointNumber~).

- A :: Use /regular expression parser/.

- The idea is that you can use any regular expression as a parser.
  The regular expression parses all strings that it can match.
  Its result is the parsed string.

- For instance, parse a (subset of) Java identifiers:
  #+BEGIN_SRC scala
    object MyParsers extends RegexParsers {
      val ident: Parser[String] = """[azAZ_]\
    w*""".r
    }
  #+END_SRC

** DONE 17.4 Another example: JSON - 418
CLOSED: [2018-03-05 Mon 19:35]
~JSON~ parser

** DONE 17.5 Parser output - 420
CLOSED: [2018-03-05 Mon 20:29]
- ~stringLiteral~ from ~JavaTokenParsers~

- To produce this _representation_, you need to make use of one more
  combination form for parsers: ~ˆˆ~: ~P^^f~ returns ~f(P)~
    For example, ~floatingPointNumber ^^ (_.toDouble)~

*** DONE Symbolic versus alphanumeric names - 423
CLOSED: [2018-03-05 Mon 20:29]
Symbolic names:
- cons: abstract and learn and remember before use

- pros: do not distract the reader

** DONE 17.6 Implementing combinator parsers - 426
CLOSED: [2018-03-06 Tue 10:48]
In the rest of this chapter you’ll take a look “under the hood” of the
combinator parser library.

- The core of Scala's combinator parsing framework is contained in the /trait/
  ~scala.util.parsing.combinator.Parsers~.

  This trait defines the ~Parser~ type as well as _all fundamental
  combinators_. If not being stated explicitly,

  (Except where stated explicitly otherwise, the definitions explained in the
   following two subsections all reside in this trait.)

- As a first _approximation_, the type could be written as follows:
  ~type Parser[T] = Input => ParseResult[T]~

  =From Jian=
  Actually, ~abstract class Parser[T] extends (Input => ParseResult[T])~

*** DONE Parser input - 427
CLOSED: [2017-11-23 Thu 01:21]
- Sometimes, a parser reads _a stream of tokens_ instead of _a raw sequence
  of characters_.
    A separate /lexical analyzer/ =???= is then used to convert _a stream of
  raw characters_ into _a stream of tokens_.

  The type of parser inputs is defined as follows:
  ~type Input = Reader[Elem]~
  The class ~Reader~ comes from the package ~scala.util.parsing.input~

  A ~Reader~ is similar to a ~Stream~, but also keeps track of the positions
  of all the elements it reads.

  + ~Elem~ is abstract, which is written in the ~Parsers~ trait as
    ~type Elem~.
      For instance, the subtraits of ~Parser~, ~RegexParsers~ and
    ~JavaTokenParsers~ fix ~Elem~ to be equal to ~Char~.

    It would also be possible to set ~Elem~ to some other type, such as the
    type of /tokens/ returned from a separate /lexer/.

*** DONE Parser results - 428
CLOSED: [2017-11-23 Thu 01:32]
A parser might either _succeed_ or _fail_ on some given input.
Consequently class ~ParseResult~ has two subclasses for representing them:
#+BEGIN_SRC scala
  sealed abstract class ParseResult[+T]
  case class Success[T](result: T, in: Input)
    extends ParseResult[T]
  case class Failure(msg: String, in: Input)
    extends ParseResult[Nothing]
#+END_SRC
- The type parameter ~T~ is arbitrary.
  It represents the kinds of results returned by a given parser.
  =IMPORTANT=

- ~Success~: the field ~in~ is needed for chaining parsers.

- ~Failure~: the field ~in~ is, of course, not used for chaining, but to
  position the error message at the correct place in the input stream.

- That ~ParseResult~'s are defined to be /covariant/ in the type parameter
  ~T~.

*** DONE The ~Parser~ class - 429
CLOSED: [2017-11-23 Thu 03:04]
- The previous characterization of parsers as functions from inputs to parse
  results was a bit oversimplified.
    Parsers are acutally /subclass/ of ~Input => ParseResult[T]~, and this is
  also why they have /methods/ like ~~~, ~|~, etc.
  #+BEGIN_SRC scala
    abstract class Parser[+T] extends (Input => ParseResult[T])
    { p =>
      // An unspecified method that defines
      // the behavior of this parser.
      def apply(in: Input): ParseResult[T]
      def ~ ...
      def | ...
      ...
    }
  #+END_SRC

- ~Input => ParseResult[T]~ is equivalent to
  ~scala.Function1[Input, ParseResult[T]]~, which means is should have an
  ~apply~ /method/.

  The ~Parsers~ /class/ has an abstract ~apply~, and users need to implement
  this /method/ when they implement a subclass or instance object of the
  ~Parsers~.

*** DONE Aliasing ~this~ - 430
CLOSED: [2017-11-23 Thu 03:18]
- The definition given in the last subsection
  ~abstract class Parser[+T] extends ... { p =>~

  A clause such as ~id =>~ immediately after the opening brace of a /class/
  template defines the identifier ~id~ as an alias for ~this~ in the class.

  From the alias point of view, it's like ~val id = this~. However, this is
  not what exactly it is -- ~id~ will be considered as a normal identifier by
  the compiler, and it cannot use the /private members/ of ~this~.

- Aliasing can also be a good abbreviation when you need to access the ~this~
  of an /outer class/. Here's an example:
  #+BEGIN_SRC scala
    class Outer { outer =>
      class Inner {
        println(Outer.this eq outer)  // prints: true
      }
    }
  #+END_SRC
  * The ~Outer.this~ is the Java way.
  * The ~outer~ is the Scala way.

*** DONE Single-token parsers - 431
CLOSED: [2018-03-06 Tue 10:02]
Trait ~Parsers~ defines a generic parser ~elem~ that can be used to parse any
single token:
#+BEGIN_SRC scala
  def elem(kind: String, p: Elem => Boolean) =
    new Parser[Elem] {
      def apply(in: Input) =
        if (p(in.first)) Success(in.first, in.rest)
        else             Failure(kind + " expected", in)
    }
#+END_SRC
- ~kind~ describing what kind of token should be parsed.

*** DONE Sequential composition - 431
CLOSED: [2018-03-06 Tue 10:26]
- About ~
  #+BEGIN_SRC scala
    abstract class Parser[+T] extends (Input => ParserResult[T]) { p =>
      // ...

      def ~ [U](q: => Parser[U]) = new Parser[T~U] {
        def apply(in: Input) = p(in) match {
          case Success(x, in1) =>
            q(in1) match {
              case Success(y, in2) => Success(new ~(x, y), in2)
              case failure => failure
            }
          case failure => failure
        }
    }
  #+END_SRC
  + ~[T~U]~ is the same as ~~[T, U]~

- Similarly, about <~ and ~>:
  #+BEGIN_SRC scala
    def <~ [U](q: => Parser[U]): Parser[T] =
      (p~q) ˆˆ { case x~y => x }

    def ~> [U](q: => Parser[U]): Parser[U] =
      (p~q) ˆˆ { case x~y => y }
  #+END_SRC

*** DONE Alternative composition - 432
CLOSED: [2018-03-06 Tue 10:28]
#+BEGIN_SRC scala
  def | (q: => Parser[T]) = new Parser[T] {
    def apply(in: Input) = p(in) match {
      case s1 @ Success(_, _) => s1
      case failure => q(in)
    }
  }
#+END_SRC

- _CAUTION_:
  Note that if ~P~ and ~Q~ _BOTH_ fail, then the failure message is
  *determined by ~Q~.*
  TODO This subtle choice is discussed later, in Section 33.9.

*** DONE Dealing with recursion - 433
CLOSED: [2018-03-06 Tue 10:31]
Note that the ~q~ parameter in methods ~ and | is *by-name*.

This makes it possible to write recursive parsers.

If it's *by-value*, call them will lead to a stack overflow immediately.

*** DONE Result conversion - 433
CLOSED: [2018-03-06 Tue 10:34]
- The parser ~P ^^ f~ succeeds exactly when ~P~ succeeds.

- Definition of ~^^~:
  #+BEGIN_SRC scala
    def ˆˆ [U](f: T => U): Parser[U] = new Parser[U] {
      def apply(in: Input) = p(in) match {
        case Success(x, in1) => Success(f(x), in1)
        case failure => failure
      }
    }
  #+END_SRC

*** DONE Parsers that don't read any input - 434
CLOSED: [2018-03-06 Tue 10:44]
Two useful parsers that do *NOT* consume any input:
#+BEGIN_SRC scala
  def success[T](v: T) = new Parser[T] {
    def apply(in: Input) = Success(v, in)
  }

  def failure(msg: String) = new Parser[Nothing] {
    def apply(in: Input) = Failure(msg, in)
  }
#+END_SRC

*** DONE Option and repetition - 434
CLOSED: [2018-03-06 Tue 10:47]
#+BEGIN_SRC scala
  def opt[T](p: => Parser[T]): Parser[Option[T]] = (
    p ˆˆ Some(_)
      | success(None)
  )

  def rep[T](p: => Parser[T]): Parser[List[T]] = (
    p~rep(p) ˆˆ { case x~xs => x :: xs }
      | success(List.empty[T])
  )

  def repsep[T](p: => Parser[T],
                q: => Parser[Any]): Parser[List[T]] = (
    p~rep(q~> p) ˆˆ { case r~rs => r :: rs }
      | success(List.empty[T])
  )
#+END_SRC

** DONE 17.7 String literals and regular expressions - 435
CLOSED: [2018-03-06 Tue 12:02]
- The parsers of ~literal~ and ~regex~ come from the trait ~RegexParsers~, a
  subtrait of ~Parsers~.

- In ~RegexParsers~, ~type Elem = Char~.

- Definition headers:
  #+BEGIN_SRC scala
    implicit def literal(s: String): Parser[String] = ...
    implicit def regex(s: Regex): Parser[String] = ...
  #+END_SRC
  Due to the ~implicit~'s, you can write ~String~ or ~Regex~ in your parser,
  and they are converted to object of ~Parser[String]~ implicitly.
    This means, for example,
    #+BEGIN_SRC scala
      "("~expr~")"

      // will be automatically expanded to

      literal("(") ~ expr ~ literal(")")
    #+END_SRC

- The ~RegexParsers~ trait also takes care of handling white space between
  symbols. To do this, it calls a method named ~handleWhiteSpace~ before
  running a ~literal~ or ~regex~ parser.

  The ~handleWhiteSpace~ /method/ skips the longest input sequence that
  conforms to the ~whiteSpace~ regular expression, which is defined by default
  as follows: ~protected val whiteSpace = """\s+""".r~

- If you want to change the treatment of white space, you can override the
  ~whiteSpace~ ~val~. For instance, if you want white space not to be skipped
  at all, ~override val whiteSpace = "".r~

** DONE 17.8 Lexing and parsing - 436
CLOSED: [2018-03-06 Tue 12:30]
- The task of syntax analysis is often split into two phases:
  1. The /lexer phase/ ::
       it recognizes *individual* words in the input and *classifies* them
       into some token classes. This phase is also called /lexical analysis/.

  2. The /syntactical analysis phase/ ::
       it analyzes *sequences* of tokens.
       Syntactical analysis is also sometimes just called parsing, even though
       this is slightly *imprecise*, as /lexical analysis/ can also be
       regarded as a parsing problem.

- The ~Parsers~ trait as described in the previous section _can be used for
  either phase_, *because its input elements are of the _abstract_ type
  ~Elem~.*
  + For lexical analysis, ~Elem~ would be instantiated to ~Char~, meaning the
    individual characters that make up a word are being parsed.

  + The syntactical analyzer would in turn instantiate ~Elem~ to the type of
    token returned by the lexer.

- Scala's parsing combinators provide _several utility classes_ for /lexical
  and syntactic analysis/.

  These are contained in two sub-packages, one for each kind of analysis:
  ~scala.util.parsing.combinator.lexical~
  ~scala.util.parsing.combinator.syntactical~

- TODO
  If you want to _split your parser into a separate lexer and syntactical
  analyzer_, you should consult the Scaladoc documentation for these packages.

  But for simple parsers, the regular expression based approach shown
  previously in this chapter is usually sufficient.

** DONE 17.9 Error reporting - 436
CLOSED: [2018-03-06 Tue 12:47]
- Scala's parsing library implements a simple heuristic:
  among all failures, the one that occurred at the *latest position* in the
  input is chosen.

  In other words,
  the parser
  1. _picks the longest prefix that is still valid_

  2. issues an error message that describes why parsing the prefix could not
     be continued further.

- If there are several failure points at that *latest position*,
  the one that was *visited last is chosen*.

- The error reporting is useful for experts, but may be quite misleading for
  non-experts.

    A better error message can be engineered by adding a "catch-all" failure
  point as last alternative of a value production:
  #+BEGIN_SRC scala
    def value: Parser[Any] =
      obj | arr | stringLit | floatingPointNumber | "null" |
        "true" | "false" | failure("illegal start of value")
  #+END_SRC

- The implementation of the “latest possible” scheme of error reporting uses a
  field named ~lastFailure~ in trait ~Parsers~ to mark the failure that
  occurred at the latest position in the input:
  ~var lastFailure: Option[Failure] = None~

  + This ~lastFailure~ is a ~var~, and it is initialized to ~None~.

  + It is updated in the constructor of the ~Failure~ class:
    #+BEGIN_SRC scala
      case class Failure(msg: String, in: Input)
          extends ParseResult[Nothing] {
        if (lastFailure.isDefined &&
              lastFailure.get.in.pos <= in.pos)
          lastFailure = Some(this)
      }
    #+END_SRC

  + The field is read by the phrase method, which emits the final error
    message if the parser failed. TODO =???=
    #+BEGIN_SRC scala
      def phrase[T](p: Parser[T]) = new Parser[T] {
        lastFailure = None
        def apply(in: Input) = p(in) match {
          case s @ Success(out, in1) =>
            if (in1.atEnd) s
            else           Failure("end of input expected", in1)
          case f : Failure =>
            lastFailure
        }
      }
    #+END_SRC

  + The treatment of ~lastFailure~ is *non-functional*;
    it is updated as a /side effect/ by the constructor of ~Failure~ and
    by the ~phrase~ method itself.

    TODO =???=
    A functional version of the same scheme would be possible, but it would
    require threading the ~lastFailure~ value through every parser result, no
    matter whether this result is a ~Success~ or a ~Failure~.

** DONE 17.10 Backtracking versus LL(1) - 438
CLOSED: [2018-03-06 Tue 13:31]
- The /parser combinators/ employ /backtracking/ to choose between different
  parsers in an alternative.

- /Backtracking/ imposes only a few *restrictions* on how to formulate a
  grammar so that it can be parsed.
    Essentially, you just need to *avoid /leftrecursive productions/.* =IMPORTANT=
  For example, ~expr ::= expr "+" term | term.~ will always fail because
  ~expr~ immediately calls itself and thus never progresses any further.

  + footnote:
    There are ways to _avoid stack overflows_ even in the presence of
    /left-recursion/, but this requires a more refined parsing combinator
    framework, which to date has not been implemented.

- On the other hand, /backtracking/ is *potentially costly* because _the same
  input can be parsed SEVERAL times_. Consider for instance the production:
  ~expr ::= term "+" expr | term.~

- It is often possible to modify the grammar so that /backtracking/ can be
  avoided. For instance, re-write the above grammar:
  + ~expr ::= term ["+" expr].~
  + ~expr ::= term {"+" term}.~

- Many languages admit so-called /"LL(1)" grammars/.
    When a /combinator parser/ is formed from such a grammar, *it will never
  /backtrack/,*
    For instance, the grammars for _arithmetic expressions_ and _JSON_ terms
  earlier in this chapter are _BOTH_ LL(1), so the /backtracking/ capabilities
  of the parser combinator framework are never exercised for inputs from these
  languages.

  (=From Jian= However, the defintion in our code before should be modified a
  little bit like the definitions below??? OR this can be done by the
  compiler???)

- The combinator parsing framework allows you to express the expectation that
  a grammar is LL(1) explicitly, using a new operator ~~!~.

  #+BEGIN_SRC text
    def expr : Parser[Any] =
      term ~! rep("+" ~! term | "-" ~! term)

    def term : Parser[Any] =
      factor ~! rep("*" ~! factor | "/" ~! factor)

    def factor: Parser[Any] =
      "(" ~! expr ~! ")" | floatingPointNumber
  #+END_SRC

  You see the definition of ~factor~ changes the order of alternatives!!!

- One advantage of an LL(1) parser is that it can use a simpler input
  technique - no need to remember the position before the first alternatives.

  Another advantage is it's more efficient!

** DONE 17.11 Conclusion - 440 =Re-Read=
CLOSED: [2018-03-06 Tue 14:01]
- One downside of combinator parsers is that they are _not very efficient_, at
  least not when compared with parsers generated from special purpose tools
  such as Yacc or Bison.

  Two reasons:
  + /backtracking/
    * Solution: use ~~！~ to make the grammar LL(1).

  + combinator parsers is that they *mix* _parser construction_ and _input
    analysis_ in the same set of operations.

    In effect, a parser is generated anew for each input that's parsed.

    * Solution: _Different implementation_ of the parser combinator framework
      -- a parser should be no longer a function from inputs to parse results.
      Instead, *it would be represented as a tree, where every construction
      step was represented as a case class*. For example, /case class/ ~Seq~
      for sequential composition, ~Alt~ for alternative, and so on.
        TODO The “outermost” parser method, ~phrase~, could then take this
      symbolic representation of a parser and convert it to highly efficient
      /parsing tables/, using standard parser generator algorithms. TODO =???=

    * What's nice of this solution is, from the user point of view, they can
      still write parsers in terms of the old way -- use objects like ~ident~,
      ~floatingPointNumber~, ~~~, ~|~, and so on.

    * The advantage of this scheme with respect to performance is _two-fold_:
      - You can now *factor out* parser construction from input analysis.
        If you were to write: ~val jsonParser = phrase(value)~ and then apply
        ~jsonParser~ to several different inputs, the ~jsonParser~ would be
        *constructed only once, not every time an input is read (like the
        current framework)*.

      - The parser generation can _use efficient parsing algorithms such
        as LALR(1)_. These algorithms usually lead to much faster parsers than
        parsers that operate with /backtracking/.

- _HOWEVER_, there are reasons for keeping the current parser combinator
  framework around:
  + It is much easier to understand and to adapt than a parser generator

  + the difference in speed would often not matter in practice, unless you
    want to parse very large inputs.

* Glossary - 442
* Bibliography - 458
* About the Authors - 462
* Index - 463
