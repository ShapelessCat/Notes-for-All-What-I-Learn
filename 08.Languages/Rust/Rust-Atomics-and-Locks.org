#+TITLE: Rust Atomics and Locks
#+SUBTITLE: Low-Level Concurrency in Practice
#+VERSION: 2023
#+AUTHOR: Mara Bos
#+STARTUP: entitiespretty
#+STARTUP: indent
#+STARTUP: overview

* DONE Foreword - xi - =TODO: NOTE=
CLOSED: [2025-01-14 Tue 15:34]
* DONE Preface - xiii
CLOSED: [2025-01-30 Thu 00:17]
- Rust has played, and keeps playing, a significant role in making systems
  programming more accessible.

  However, _low-level concurrency topics_ such as /atomics/ and /memory
  ordering/ are still often thought of as somewhat mystical subjects that are
  best left to a very small group of experts.

- No enough resources on atomics, memory, thread and related topics specific for
  Rust. Most resources focus entirely on C and C++.

- *The TARGET of this book:*
  This book is an attempt to put relevant information in one place, connecting it all
  together, providing everything you need to

  BUILD your own correct, safe, and ergonomic concurrency primitives,
  WHILE understanding enough about
  * the underlying hardware and
  * the role of the operating system

  to be able to

  make design decisions and basic optimization trade-offs.

** DONE Who This Book Is For - xiii
CLOSED: [2025-01-30 Thu 00:07]
- The _primary audience_ for this book:
  Rust developers who want to learn more about low-level concurrency.

- It is assumed you
  1. know the basics of Rust,
  2. have a recent Rust compiler installed, and
  3. know how to compile and run Rust code using _cargo_.

  Rust concepts that are important for concurrency are briefly explained when
  relevant, so _NO PRIOR KNOWLEDGE about Rust concurrency is necessary_.

** DONE Overview of the Chapters - xiv
CLOSED: [2025-01-30 Thu 00:07]
Summaries for each chapter.
=TODO= NOTE

** DONE Code Examples - xvi
CLOSED: [2025-01-30 Thu 00:14]
- All code in this book is written for and tested using *Rust 1.66.0*, which was
  released on December 15, 2022.

  Earlier versions do not include all features used in this book. Later versions,
  however, should work just fine.

- As a convenience, the following _prelude_ can be used to import everything
  necessary to compile any of the code examples in this book:
  #+begin_src rust
    #[allow(unused)]
    use std::{
        cell::{Cell, RefCell, UnsafeCell},
        collections::VecDeque,
        marker::PhantomData,
        mem::{ManuallyDrop, MaybeUninit},
        ops::{Deref, DerefMut},
        ptr::NonNull,
        rc::Rc,
        sync::{*, atomic::{*, Ordering::*}},
        thread::{self, Thread},
    };
  #+end_src

- =TODO=
  Supplemental material, including complete versions of all code examples, is
  available at https://marabos.nl/atomics/.

- You may use all example code offered with this book for any purpose.

** DONE Conventions Used in This Book - xvi - =TODO=
CLOSED: [2025-01-30 Thu 00:17]
O'Reilly Book Conventions:
- animal A =???=: This element signifies a tip or suggestion.
- Crow: This element signifies a general note.
- Scorpion: This element indicates a warning or caution.

** DONE Contact Information - xvii
CLOSED: [2025-01-30 Thu 00:17]
** DONE Acknowledgments - xvii
CLOSED: [2025-01-30 Thu 00:17]

* DONE 1. Basics of Rust Concurrency - 1 - =TODO: NOTE=
CLOSED: [2023-10-25 Wed 17:23]
- _LONG BEFORE_ *multi-core processors* were commonplace,
  OSs allowed for a single computer to run many programs concurrently:

  * This is achieved BY
    rapidly switching between /processes/, allowing each to repeatedly make a
    little bit of progress, one by one.

- _NOWADAYS_,
  virtually all our computers and even our phones and watches have *processors
  with multiple cores*, which can
  TRULY execute multiple /processes/ *in parallel*.

- Paragraphs about:
  1. The isolation between /processes/.
     ACCESS THE MEMORY of another /process/, or COMMUNICATE WITH it in any way
     ARE NOT ALLOWED WITHOUT asking the OS's kernel first.

  2. /Threads/, not isolated in the same /process/.
     /Threads/ share memory and can interact with each other through that memory.

- This chapter will explain
  1. how /threads/ are *spawned* in Rust, and
     all the basic concepts around them, such as
  2. HOW TO _safely *share* data between MULTIPLE /threads/._
  =IMPORTANT=
  The concepts explained in this chapter are foundational to the rest of the
  book.

** TODO Threads in Rust - 2 - =NOTE=
- Every program starts with EXACTLY *one* /thread/:
  /the main thread/.

  This /thread/ will execute your ~main~ function and can be used to _spawn more
  threads_ if necessary.

- In Rust,

  * NEW /threads/ are spawned using the ~std::thread::spawn~ function from
    the standard library.

    + ~std::thread::spawn~ takes a single argument: the function the new /thread/
      will execute.

  * The /thread/ STOPS once this function returns.

- Example:
  #+begin_src rust
    use std::thread;

    fn main() {
        thread::spawn(f);
        thread::spawn(f);

        println!("Hello from the main thread.");
    }

    fn f() {
        println!("Hello from another thread!");

        let id = thread::current().id();
        println!("This is my thread id: {id:?}");
    }
  #+end_src

- *Thread ID*
  _The Rust standard library assigns every /thread/ a unique identifier._

  * This identifier is accessible through ~Thread::id()~ and is of the type
    ~ThreadId~.

  * There's not much you can do with a ~ThreadId~ other than
    + copying it around and
    + checking for equality.

  * There is _no guarantee_ that these IDs will be assigned consecutively, only
    that they will be different for each /thread/.

- If we want to *make sure* the /threads/ are finished BEFORE we return from
  ~main~, we can wait for them by *joining* them.

  To do so, we have to use the ~JoinHandle~ returned by the ~spawn~ function:
  #+begin_src rust
    fn main() {
        let t1 = thread::spawn(f);
        let t2 = thread::spawn(f);

        println!("Hello from the main thread.");

        t1.join().unwrap();
        t2.join().unwrap();
    }
  #+end_src
  * No output order are guaranteed.

  * The ~.join()~ method *waits until* the /thread/ has *finished* executing and
    *returns* a ~std::thread::Result~.

  * If the /thread/ did not successfully finish its function because it
    _panicked_, this will contain the panic message.

    We could attempt to
    + handle that situation, or
    + just call ~.unwrap()~ to panic
    WHEN joining a panicked /thread/.

- *Output Locking*
  The ~println~ macro uses ~std::io::Stdout::lock()~ to make sure its output
  does not get interrupted.

  A ~println!()~ expression will *wait until* any concurrently running one is
  finished BEFORE writing any output.

  * IF this was not the case, we could've gotten more interleaved output such as:
    #+begin_src text
      Hello fromHello from another thread!
      another This is my threthreadHello fromthread id: ThreadId!
      ( the main thread.
      2)This is my thread
      id: ThreadId(3)
    #+end_src

- Rather than passing the name of a function to std::thread::spawn, as in our
  example above, itâ€™s far more common to pass it a closure. This allows us to
  capture values to move into the new thread:
  #+begin_src rust
    let numbers = vec![1, 2, 3];

    thread::spawn(move || {
        for n in numbers {
            println!("{n}");
        }
    }).join().unwrap();
  #+end_src

- *Thread Builder*

** TODO Scoped Threads - 5 - =READING=
- *The Leakpocalypse*

** TODO Shared Ownership and Reference Counting - 7
*** Statics - 7
*** Leaking - 8
*** Reference Counting - 8
- *Naming Clones*

** TODO Borrowing and Data Races - 11
- *Undefined Behavior*

** TODO Interior Mutability - 13
*** ~Cell~ - 14
*** ~RefCell~ - 14
*** ~Mutex~ and ~RwLock~ - 15
*** ~Atomics~ - 15
*** ~UnsafeCell~ - 16

** TODO Thread Safety: ~Send~ and ~Sync~ - 16
** TODO Locking: Mutexes and RwLocks - 18
*** Rust's ~Mutex~ - 18
*** Lock Poisoning - 21
- *Lifetime of the MutexGuard*

*** Reader-Writer Lock - 22
- *Mutexes in Other Languages*

** TODO Waiting: Parking and Condition Variables - 24
*** Thread Parking - 24
*** TODO Condition Variables - 26

** TODO Summary - 29

* DONE 2. Atomics - 31 - =TODO: NOTE=
CLOSED: [2023-10-26 Thu 21:16]
- atomic (in computer science) ::
  an operation that is indivisible: it is either fully completed, or it didn't
  happen yet.

** Atomic Load and Store Operations - 32
*** Example: Stop Flag - 32
*** Example: Progress Reporting - 33
**** Synchronization - 34

*** Example: Lazy Initialization - 35

** Fetch-and-Modify Operations - 36
*** Example: Progress Reporting from Multiple Threads - 38
*** Example: Statistics - 39
*** Example: ID Allocation - 41

** Compare-and-Exchange Operations - 42
*** Example: ID Allocation Without Overflow - 44
- *Fetch-Update*

*** Example: Lazy One-Time Initialization - 45

** Summary - 47

* TODO 3. Memory Ordering - 49
** Reordering and Optimizations - 49
** The Memory Model - 51
** Happens-Before Relationship - 51
*** Spawning and Joining - 53

** Relaxed Ordering - 54
- *Out-of-Thin-Air Values*

** Release and Acquire Ordering - 57
- *More Formally*

*** Example: Locking - 60
*** Example: Lazy Initialization with Indirection - 62

** Consume Ordering - 65
** Sequentially Consistent Ordering - 66
** Fences - 67
- *Compiler Fences*

** Common Misconceptions - 71
** Summary - 73

* TODO 4. Building Our Own Spin Lock - 75
** A Minimal Implementation - 75
** An Unsafe Spin Lock - 78
** A Safe Interface Using a Lock Guard - 80
** Summary - 83

* TODO 5. Building Our Own Channels - 85
** A Simple Mutex-Based Channel - 85
** An Unsafe One-Shot Channel - 87
** Safety Through Runtime Checks - 90
- *Using a Single Atomic for the Channel State*

** Safety Through Types - 94
** Borrowing to Avoid Allocation - 98
** Blocking - 101
** Summary - 104

* TODO 6. Building Our Own "Arc" - 105
** Basic Reference Counting - 105
*** Testing It - 109
- *Miri*

*** Mutation - 110

** Weak Pointers - 111
*** Testing It - 117

** Optimizing - 118
** Summary - 125

* TODO 7. Understanding the Processor - 127
** Processor Instructions - 128
- *Brief Introduction to Assembly*

*** Load and Store - 132
*** Read-Modify-Write Operations - 133
**** x86 lock prefix
**** x86 compare-and-exchange instruction

*** Load-Linked and Store-Conditional Instructions - 137
**** ARM load-exclusive and store-exclusive
- *ARMv8.1 Atomic Instructions*

**** Compare-and-exchange on ARM
- *Optimization of Compare-and-Exchange Loops*

** Caching - 141
*** Cache Coherence - 142
**** The write-through protocol
**** The MESI protocol

*** Impact on Performance - 144
- *Failing Compare-and-Exchange Operations*

** Reordering - 149
** Memory Ordering - 150
- *Other-Multi-Copy Atomicity*

*** x86-64: Strongly Ordered - 151
*** ARM-64: Weakly Ordered - 153
- *ARMv8.1 Atomic Release and Acquire Instructions*

*** An Experiment - 155
*** Memory Fences - 158

** Summary - 159

* TODO 8. Operating System Primitives - 161
** Interfacing with the Kernel - 161
** POSIX - 163
*** Wrapping in Rust - 164

** Linux - 166
*** Futex - 167
*** Futex Operations - 169
- *New Futex Operations*

*** Priority Inheritance Futex Operations - 173

** macOS - 174
*** ~os_unfair_lock~ - 175

** Windows - 175
*** Heavyweight Kernel Objects - 175
*** Lighter-Weight Objects - 176
**** Slim reader-writer locks - 176

*** Address-Based Waiting - 177

** Summary - 179

* TODO 9. Building Our Own Locks - 181
** Mutex - 183
- *Lock API*

*** Avoiding Syscalls - 186
*** Optimizing Further - 188
- *Cold and Inline Attributes*

*** Benchmarking - 191

** Condition Variable - 193
*** Avoiding Syscalls - 198
*** Avoiding Spurious Wake-ups - 200
- *Thundering Herd Problem*

** Reader-Writer Lock - 203
*** Avoiding Busy-Looping Writers - 206
*** Avoiding Writer Starvation - 208

** Summary - 211

* TODO 10. Ideas and Inspiration - 213
** Semaphore - 213
** RCU - 214
** Lock-Free Linked List - 215
** Queue-Based Locks - 217
** Parking Lotâ€“Based Locks - 218
** Sequence Lock - 218
** Teaching Materials - 219

* Index - 221
