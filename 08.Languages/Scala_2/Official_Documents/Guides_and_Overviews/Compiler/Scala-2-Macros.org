#+TITLE: Scala 2 Macros (Removed in Scala 3)
#+AUTHOR: Eugene Burmako
#+CONTRIBUTORS: SethTisue, komainu8, ashawley, f0ster, heathermiller
#+VERSION: 2.13.3
#+STARTUP: entitiespretty
#+STARTUP: indent
#+STARTUP: overview

* DONE Use Cases
  CLOSED: [2020-07-04 Sat 23:32]
  - Author:
    Eugene Burmako

  - Contributors:
    + SethTisue
    + komainu8
    + ashawley
    + f0ster
    + heathermiller

  - The recent talk _"What Are Macros Good For?"_ describes and systemizes uses that
    /macros/ found among Scala 2.10 users. The thesis of the talk is that /macros/
    are good for
    + code generation,

    + static checking

    + DSLs

  - The adoption of /Scala macros/ is illustrated with a number of examples from
    research and industry.

  - We have also published a paper in the Scala'13 workshop, _"Scala Macros: Let
    Our Powers Combine!"_, covering the state of the art of macrology in Scala
    2.10 from a more academic point of view. In the paper we show how the /rich
    syntax/ and /static types/ of Scala synergize with /macros/ and explore how
    /macros/ enable new and unique ways to use pre-existing language features.

* TODO Blackbox Vs Whitebox
  _SEPARATION_ of /macros/ into *blackbox* ones and *whitebox* ones is a feature
  of Scala 2.11+.

  - The blackbox/whitebox separation is *NOT supported* _in Scala 2.10.x._

  - It is also *NOT supported* in /macro paradise/ _for Scala 2.10.x._

** TODO Why macros work? - =RE-READ=
** TODO Blackbox and whitebox macros
   - However sometimes def macros transcend the notion of "just a regular method".
     For example, it is possible for a macro expansion to yield an expression of
     a type that is more specific than the return type of a macro. In Scala
     2.10, such expansion will retain its precise type as highlighted in the
     “Static return type of Scala macros” article at Stack Overflow.

   - This curious feature provides additional flexibility, enabling fake type
     providers, extended vanilla materialization, fundep materialization and
     extractor macros, but it also sacrifices clarity - both for humans and for
     machines.

   - To concretize the crucial distinction between macros that behave just like
     normal methods and macros that refine their return types, we introduce the
     notions of blackbox macros and whitebox macros. Macros that faithfully
     follow their type signatures are called blackbox macros as their
     implementations are irrelevant to understanding their behaviour (could be
     treated as black boxes). Macros that can’t have precise signatures in
     Scala’s type system are called whitebox macros (whitebox def macros do have
     signatures, but these signatures are only approximations).

   - We recognize the importance of both blackbox and whitebox macros, however we
     feel more confidence in blackbox macros, because they are easier to
     explain, specify and support. Therefore our plans to standardize macros
     only include blackbox macros. Later on, we might also include whitebox
     macros into our plans, but it’s too early to tell.

** TODO Codifying the distinction
   - In the 2.11 release, we take first step of standardization by expressing the
     distinction between blackbox and whitebox macros in signatures of def
     macros, so that scalac can treat such macros differently. This is just a
     preparatory step, so both blackbox and whitebox macros remain experimental
     in Scala 2.11.

   - We express the distinction by replacing ~scala.reflect.macros.Context~ with
     ~scala.reflect.macros.blackbox.Context~ and ~scala.reflect.macros.whitebox.Context~.
     If a /macro impl/ is defined with ~blackbox.Context~ as its first argument,
     then /macro defs/ that are using it are considered /blackbox/, and analogously
     for ~whitebox.Context~. Of course, the vanilla ~Context~ is still there for
     compatibility reasons, but it issues a deprecation warning encouraging to
     choose between /blackbox and whitebox macros/.

   - /Blackbox def macros/ are *treated DIFFERENTLY* from /def macros/ of Scala 2.10.
     The following restrictions are applied to them by the /Scala typechecker/:
     1. When an application of a blackbox macro expands into tree x, the expansion
        is wrapped into a type ascription (x: T), where T is the declared return
        type of the blackbox macro with type arguments and path dependencies
        applied in consistency with the particular macro application being
        expanded. This invalidates blackbox macros as an implementation vehicle
        of type providers.

     2. When an application of a blackbox macro still has undetermined type
        parameters after Scala’s type inference algorithm has finished working,
        these type parameters are inferred forcedly, in exactly the same manner
        as type inference happens for normal methods. This makes it impossible
        for blackbox macros to influence type inference, prohibiting fundep
        materialization.

     3. When an application of a blackbox macro is used as an implicit candidate,
        no expansion is performed until the macro is selected as the result of
        the implicit search. This makes it impossible to dynamically calculate
        availability of implicit macros.

     4. When an application of a blackbox macro is used as an extractor in a
        /pattern match/, it triggers an unconditional compiler error, preventing
        customizations of pattern matching implemented with macros.

   - /Whitebox def macros/ work *exactly like* /def macros/ used to work in Scala 2.10.
     + No restrictions of any kind get applied, so everything that could be done with
       /macros in 2.10/ should be possible in 2.11 and 2.12.

* TODO Def Macros - =TODO= - =Tips and tricks=
** DONE Intuition
   CLOSED: [2020-09-16 Wed 21:57]
   Here is a prototypical macro definition:
   #+begin_src scala
     def m(x: T): R = macro implRef
   #+end_src

   - Example:
     Here ~<[ expr ]>~ denotes the ast that represents the expression ~expr~, and
     this notation is not real Scala code. In reality, the syntax trees would be
     constructed from the /types/ in /trait/ ~scala.reflect.api.Trees~.
     #+begin_src scala
       def assert(cond: Boolean, msg: Any) = macro Asserts.assertImpl

       // TODO: use `whitebox.Context` or `blackbox.Context`
       //       `scala.reflect.macros.Context` is already deprecated.
       import scala.reflect.macros.Context
       import scala.language.experimental.macros

       object Asserts {
         def raise(msg: Any) = throw new AssertionError(msg)

         def assertImpl(c: Context)
                       (cond: c.Expr[Boolean], msg: c.Expr[Any]) : c.Expr[Unit] =
           if (assertionsEnabled)
             <[ if (!cond) raise(msg) ]>
           else
             <[ () ]>
       }
     #+end_src

*** DONE Generic macros
    CLOSED: [2020-09-16 Wed 21:57]
    - /Macro definitions/ and /macro implementations/ may both be /generic/.
      /Type parameters/ in an implementation may come with ~WeakTypeTag~ /context
      bounds/.

    - The following code snippet declares a /macro definition/ ~Queryable.map~
      that references a /macro implementation/ ~QImpl.map~:
      #+begin_src scala
        class Queryable[T] {
          def map[U](p: T => U): Queryable[U] = macro QImpl.map[T, U]
        }

        object QImpl {
          def map[T: c.WeakTypeTag, U: c.WeakTypeTag](c: Context)
                                                     (p: c.Expr[T => U]): c.Expr[Queryable[U]] = ...
        }
      #+end_src
      + Expansion of ~q.map[Int](_.length)~
        #+begin_src scala
          QImpl.map(c)(<[ s => s.length ]>)
                      (implicitly[WeakTypeTag[String]], implicitly[WeakTypeTag[String]])
        #+end_src

** DONE A complete example
   CLOSED: [2020-09-17 Thu 01:32]
   An end-to-end implementation of a ~printf~ macro, which validates and applies
   the format string at compile-time

   - For the sake of simplicity the discussion uses console Scala compiler, but
     as explained below macros are also supported by Maven and sbt.

   - A /macro definition/ represents the facade of the /macro/.
     #+begin_src scala
       import scala.language.experimental.macros

       def printf(format: String, params: Any*): Unit = macro printf_impl
     #+end_src
     As mentioned above, to define a macro one needs to
     + *import* ~scala.language.experimental.macros~
       OR
     + *enable* a special compiler switch, =-language:experimental.macros=.

   - /Macro implementation/ must correspond to /macro definitions/ that use it
     (typically there's only one, but there might also be many).
     #+begin_src scala
       import scala.reflect.macros.Context

       def printf_impl(c: Context)
                      (format: c.Expr[String], params: c.Expr[Any]*): c.Expr[Unit] = ...
     #+end_src
     + EVERY _parameter of type_ ~T~ in the signature of a /macro definition/ MUST
       correspond to a _parameter of type_ ~c.Expr[T]~ in the /signature/ of a
       /macro implementation/.

   - Compiler API is exposed in ~scala.reflect.macros.blackbox.Context~ or
     ~scala.reflect.macros.whitebox.Context~.
       Its most important part, reflection API, is accessible via ~c.universe~.
     It's customary to import ~c.universe._~, because it includes a lot of
     _routinely used_ /functions/ and /types/
     #+begin_src scala
       import c.universe._
     #+end_src

   - First of all, the /macro/ ~printf~ needs to *parse* the provided _format string_.
     #+begin_src scala
       val Literal(Constant(s_format: String)) = format.tree
     #+end_src
     + /Macros/ run during the /compile-time/, so *they operate on /trees/, NOT
        on /values/.* This means
       * the /format parameter/ of the ~printf~ /macro/ will be a /compile-time
         literal/, *NOT* an /object/ of ~type java.lang.String~.

       * the code below *WON'T work* for ~printf(get_format(), ...)~,
         because in that case format _WON'T_ be a /string literal/, BUT rather an
         AST that represents a /function application/.

   - Typical macros (and this macro is not an exception) need to create ASTs which
     represent Scala code. To learn more about generation of Scala code, take a
     look at the overview of reflection.

     Along with creating ASTs the code provided below also manipulates types.
     Note how we get a hold of Scala types that correspond to ~Int~ and ~String~.
     Reflection overview linked above covers type manipulations in detail.
     The final step of code generation combines all the generated code into a
     Block. Note the call to ~reify~, which provides a shortcut for creating
     ASTs.
     #+begin_src scala
       val evals = mutable.ListBuffer.empty[ValDef]

       def precompute(value: Tree, tpe: Tree): Ident = {
         val freshName = TermName(c.freshName("eval$"))
         evals += ValDef(NoMods, freshName, TypeTree(tpe), value)
         Ident(freshName)
       }

       val paramsStack = mutable.Stack[Tree]((params.map(_.tree)): _*)
       val refs = s_format.split() map {
         case "%d" => precompute(paramsStack.pop, typeOf[Int])
         case "%s" => precompute(paramsStack.pop, typeOf[String])
         case "%%" => Literal(Constant("%"))
         case part => Literal(Constant(part))
       }

       val stats = evals ++ refs.map(ref => reify(print(c.Expr[Any](ref).splice)).tree)
       c.Expr[Unit](Block(stats.toList, Literal(Constant(()))))
     #+end_src

   - The snippet below represents a complete definition of the ~printf~ /macro/.
     To follow the example, create an empty directory and copy the code to a new
     file named =Macros.scala=.
     #+begin_src scala
       import scala.reflect.macros.Context
       import scala.collection.mutable

       object Macros {
         def printf(format: String, params: Any*): Unit = macro printf_impl

         def printf_impl(c: Context)
                        (format: c.Expr[String], params: c.Expr[Any]*): c.Expr[Unit] = {
           import c.universe._
           val Literal(Constant(s_format: String)) = format.tree

           val evals = mutable.ListBuffer.empty[ValDef]
           def precompute(value: Tree, tpe: Type): Ident = {
             val freshName = TermName(c.freshName("eval$"))
             evals += ValDef(NoMods, freshName, TypeTree(tpe), value)
             Ident(freshName)
           }

           val paramsStack = mutable.Stack[Tree]((params map (_.tree)): _*)
           val refs = s_format.split("(?<=%[\\w%])|(?=%[\\w%])") map {
             case "%d" => precompute(paramsStack.pop, typeOf[Int])
             case "%s" => precompute(paramsStack.pop, typeOf[String])
             case "%%" => Literal(Constant("%"))
             case part => Literal(Constant(part))
           }

           val stats = evals ++ refs.map(ref => reify(print(c.Expr[Any](ref).splice)).tree)
           c.Expr[Unit](Block(stats.toList, Literal(Constant(()))))
         }
       }
     #+end_src
     + Call the /macro definition/:
       #+begin_src scala
         object Test extends App {
           import Macros._
           printf("hello %s!", "world")
         }
       #+end_src
       * An important aspect of macrology is *SEPARATE compilation*.
         /Macros/ must be compiled _BEFORE_ the main compilation!
         - =from Jian=
           How to config SBT to do manage the order of compiling IF I DON'T want
           to put all macros in a separate subproject?

** TODO Tips and tricks
*** DONE Using macros with the command-line Scala compiler
    CLOSED: [2020-09-18 Fri 01:37]
    If you use REPL, then it's even better, because REPL processes every line in
    a *separate* _compilation run_, so you'll be able to define a macro and use it
    right away.

*** DONE Using macros with Maven or sbt
    CLOSED: [2020-09-18 Fri 01:42]
    - /Macros/ work fine with Maven and sbt.

    - In a nutshell you only need to know _TWO_ things:
      + /Macros/ needs =scala-reflect.jar= in library dependencies.

      + The /separate compilation/ restriction requires macros to be placed in a
        *separate* project.

*** DONE Using macros with Scala IDE or Intellij IDEA
    CLOSED: [2020-09-18 Fri 01:38]
    Both in Scala IDE and in Intellij IDEA macros are known to work fine, given
    they are moved to a *separate* project.

*** DONE Debugging macros - =TODO=
    CLOSED: [2020-09-18 Fri 02:08]
    - Debugging macros (i.e. the logic that drives macro expansion) is fairly
      straightforward: *Since macros are expanded within the compiler, all that
      you need is to run the compiler under a debugger.* To do that, you need to:
      1. add *ALL* (!) the libraries from the lib directory in your Scala home
         (which include such jar files as =scala-library.jar=, =scala-reflect.jar=
         and =scala-compiler.jar=) to the /classpath/ of your debug configuration,

      2. set ~scala.tools.nsc.Main~ as an entry point -- *"Main class"* in IntelliJ,

      3. provide the ~-Dscala.usejavacp=true~ system property for the JVM (very
         important!) -- *"VM options"* in IntelliJ,

         *"Program arguments"* in IntelliJ,
      4. set command-line arguments for the compiler as
         ~-cp <path to the classes of your macro> Test.scala~,
         where =Test.scala= stands for a test file _CONTAINING_ *macro invocations*
         to be /expanded/.
           After all that is done, you should be able to put a /breakpoint/ inside
         your /macro implementation/ and launch the debugger.
         + In IntelliJ, if *"use classpath of Module"* is given a proper value
           that includes the being tested /macros/, only the =Test.scala= need to
           be specified.

         + *TODO* =from Jian= *TODO*
           Learn to debug Scala macros
           * with VS Code (Metals plugin should be installed),
           * without any IDE.

    - What really requires special support in tools is debugging the results of
      /macro expansion/ (i.e. the code that is *generated by* a /macro/). Since
      this code is never written out manually, you _CANNOT_ set /breakpoints/ there,
      and you won't be able to step through it.
        Scala IDE and Intellij IDEA teams will _probably add support_ for this in
      their debuggers at some point, but for now the only way to debug /macro
      expansions/ are diagnostic prints: =-Ymacro-debug-lite= (as described below),
      which prints out the code emitted by macros, and println to trace the
      execution of the generated code.

*** DONE Inspecting generated code
    CLOSED: [2020-09-18 Fri 02:15]
    - =-Ymacro-debug-lite= can show
      + pseudo-Scala representation of the code generated by macro expansion
        * USEFUL for surface analysis

      + raw AST representation of the expansion
        * invaluable for fine-grained debugging

    - In IntelliJ, add =-Ymacro-debug-lite= to the "Program arguments".

    - Run =scalac -Ymacro-debug-lite Test.scala=, and =from Jian= check this doc
      webpage to see the output.

*** TODO Macros throwing unhandled exceptions
*** TODO Reporting warnings and errors
*** TODO Writing bigger macros

* DONE Quasiquotes
  CLOSED: [2020-09-20 Sun 04:41]
  Quasiquote guide has been moved to /overviews/quasiquotes/intro.html.
  =from Jian= Notes are in a separate file.

* DONE Macro Bundles
  CLOSED: [2020-09-20 Sun 05:41]
  - /Macro bundles/ are a feature of Scala 2.11.x and Scala 2.12.x.

  - /Macro bundles/ are *not* supported in Scala 2.10.x. They are also *not*
    supported in macro paradise for Scala 2.10.x.

** Macro bundles
   - In Scala 2.10.x, /macro implementations/ are *represented with* /functions/.
     Once the compiler sees an application of a /macro definition/, it calls the
     /macro implementation/ - as simple as that.
       HOWEVER practice shows that just simple /function representation/ are
     often *not* enough due to the following reasons:
     =from Jian= _Try to do more practice to understand these two points_
     1. Being *limited to* /function representation/ makes /modularizing/ complex
        /macros/ AWKWARD.
          It's quite typical to see macro logic concentrate in helper traits
        outside /macro implementations/, turning implementations into trivial
        wrappers, which just instantiate and call helpers.

     2. Moreover, since /macro parameters/ are /path-dependent/ on the /macro
        context/, _SPECIAL incantations_ (=TODO= =RE-READ=) are required to _wire_
        implementations and helpers together.

   - /Macro bundles/ provide a solution to these problems by allowing /macro
     implementations/ to be declared in *classes* that take
     ~c: scala.reflect.macros.blackbox.Context~ or
     ~c: scala.reflect.macros.whitebox.Context~ as their *ONLY* /constructor parameters/,
     *RELIEVING /macro implementations/ FROM having to declare the /context/ in
     their /signatures/, which _simplifies_ /modularization/.*

     + *Referencing* /macro implementations/ defined in /bundles/ works in the same
       way as with /impls/ defined in /objects/:
       You specify a /bundle/ name and then select a /method/ from it, providing
       /type arguments/ if necessary.
       #+begin_src scala
         import scala.reflect.macros.blackbox

         class Impl(val c: blackbox.Context) {
           import c.universe._

           def mono() =
             q"()"

           def poly[T: c.WeakTypeTag] =
             q"${c.weakTypeOf[T].toString}"

         }

         object Macros {
           def mono(): Unit = macro Impl.mono

           def poly[T]: String = macro Impl.poly[T]
         }
       #+end_src
       * =from Jian= =TODO=
         I think this syntax is wierd -- use /class name/, rather than certain
         instance, to refer its /method/ -- in semantics, how can we call a /method/
         when there is no /instance/ of a corresponding class???

** DONE Blackbox vs whitebox
   CLOSED: [2020-09-20 Sun 04:52]
   /Macro bundles/ can be used to implement *BOTH* ~blackbox~ and ~whitebox~
   /macros/.

* TODO Implicit Macros
  - Implicit macros are shipped as an experimental feature of Scala since version
    2.10.0, including the upcoming 2.11.0, but require a critical bugfix in
    2.10.2 to become fully operational. Implicit macros do not need macro
    paradise to work, neither in 2.10.x, nor in 2.11.

  - An extension to implicit macros, called fundep materialization, is unavailable
    in 2.10.0 through 2.10.4, but has been implemented in macro paradise, Scala
    2.10.5 and Scala 2.11.x. Note that in 2.10.0 through 2.10.4, expansion of
    /fundep materializer macros/ requires _macro paradise_, which means that your
    users will have to add macro paradise to their builds in order to use your
    /fundep materializers/. However, after /fundep materializers/ expand, the
    resulting code will no longer have any references to _macro paradise_ and
    won't require its presence at /compile-time/ or at /runtime/. Also note that
    in 2.10.5, expansion of /fundep materializer macros/ can happen WITHOUT /macro
    paradise/, but then your users will have to enable the ~-Yfundep-materialization~
    /compiler flag/.

** Implicit macros
*** Type classes
*** Proliferation of boilerplate
*** Implicit materializers

** Fundep materialization
*** Problem statement
*** Proposed solution

** Blackbox vs whitebox

* TODO Extractor Macros
** The pattern
** Use cases
** Blackbox vs whitebox

* TODO Type Providers
** Introduction
** Anonymous type providers
** Public type providers
*** Addressing the erasure problem

** Blackbox vs whitebox

* TODO Macro Annotations - _TODO, READING_
  - Macro annotations are available in Scala 2.13 with the -Ymacro-annotations
    flag, and with the macro paradise plugin from Scala 2.10.x to Scala 2.12.x.
    Follow the instructions at the “Macro Paradise” page to download and use our
    compiler plugin if using those older Scala versions.

  - Note that the macro paradise plugin is needed both to compile and to expand
    macro annotations, which means that your users will have to also add macro
    paradise to their builds in order to use your macro annotations. However,
    after macro annotations expand, the resulting code will no longer have any
    references to macro paradise and won’t require its presence at compile-time
    or at runtime.

** Walkthrough
   - Macro annotations bring textual abstraction to the level of definitions.
     Annotating any top-level or nested definition with something that Scala
     recognizes as a macro will let it expand, possibly into multiple members.
     Unlike in the previous versions of macro paradise, macro annotations in 2.0
     are done right in the sense that they: 1) apply not just to classes and
     objects, but to arbitrary definitions, 2) allow expansions of classes to
     modify or even create companion objects. This opens a number of new
     possibilities in code generation land.

   - In this walkthrough we will write a silly, but very useful macro that does
     nothing except for logging the annottees. As a first step, we define an
     annotation that inherits StaticAnnotation and defines a macroTransform
     macro (the name macroTransform and the signature annottees: Any* of that
     macro are important as they tell the macro engine that the enclosing
     annotation is a macro annotation).
     #+begin_src scala
       import scala.annotation.{StaticAnnotation, compileTimeOnly}
       import scala.language.experimental.macros
       import scala.reflect.macros.whitebox

       @compileTimeOnly("enable macro paradise to expand macro annotations")
       class identity extends StaticAnnotation {
         def macroTransform(annottees: Any*): Any = macro ???
       }
     #+end_src

   - First of all, note the @compileTimeOnly annotation. It is not mandatory, but
     is recommended to avoid confusion. Macro annotations look like normal
     annotations to the vanilla Scala compiler, so if you forget to enable the
     macro paradise plugin in your build, your annotations will silently fail to
     expand. The @compileTimeOnly annotation makes sure that no reference to the
     underlying definition is present in the program code after typer, so it
     will prevent the aforementioned situation from happening.

   - Now, the macroTransform macro is supposed to take a list of untyped annottees
     (in the signature their type is represented as Any for the lack of better
     notion in Scala) and produce one or several results (a single result can be
     returned as is, multiple results have to be wrapped in a Block for the lack
     of better notion in the reflection API).

   - At this point you might be wondering. A single annottee and a single result
     is understandable, but what is the many-to-many mapping supposed to mean?
     There are several rules guiding the process:
     1. If a class is annotated and it has a companion, then both are passed into
        the macro. (But not vice versa - if an object is annotated and it has a
        companion class, only the object itself is expanded).

     2. If a parameter of a class, method or type member is annotated, then it
        expands its owner. First comes the annottee, then the owner and then its
        companion as specified by the previous rule.

     3. Annottees can expand into whatever number of trees of any flavor, and the
        compiler will then transparently replace the input trees of the macro
        with its output trees.

     4. If a class expands into both a class and a module having the same name,
        they become companions. This way it is possible to generate a companion
        object for a class even if that companion was not declared explicitly.

     5. Top-level expansions must retain the number of annottees, their flavors
        and their names, with the only exception that a class might expand into a
        same-named class plus a same-named module, in which case they automatically
        become companions as per previous rule.

   - Here’s a possible implementation of the identity annotation macro. The logic
     is a bit complicated, because it needs to take into account the cases when
     @identity is applied to a value or type parameter. Excuse us for a low-tech
     solution, but we haven’t encapsulated this boilerplate in a helper, because
     compiler plugins cannot easily change the standard library. (By the way,
     this boilerplate can be abstracted away by a suitable annotation macro, and
     we’ll probably provide such a macro at a later point in the future).
     #+begin_src scala
       import scala.annotation.{StaticAnnotation, compileTimeOnly}
       import scala.language.experimental.macros
       import scala.reflect.macros.whitebox

       @compileTimeOnly("enable macro paradise to expand macro annotations")
       class identity extends StaticAnnotation {
         def macroTransform(annottees: Any*): Any = macro identityMacro.impl
       }

       object identityMacro {
         def impl(c: whitebox.Context)(annottees: c.Expr[Any]*): c.Expr[Any] = {
           import c.universe._
           val inputs = annottees.map(_.tree).toList
           val (annottee, expandees) = inputs match {
             case (param: ValDef) :: (rest @ (_ :: _)) => (param, rest)
             case (param: TypeDef) :: (rest @ (_ :: _)) => (param, rest)
             case _ => (EmptyTree, inputs)
           }
           println((annottee, expandees))
           val outputs = expandees
           c.Expr[Any](Block(outputs, Literal(Constant(()))))
         }
       }
     #+end_src

   - XXX
     | Example code                | Printout                           |
     |-----------------------------+------------------------------------|
     | @identity class C           | (<empty>, List(class C))           |
     |-----------------------------+------------------------------------|
     | @identity class D; object D | (<empty>, List(class D, object D)) |
     |-----------------------------+------------------------------------|
     | class E; @identity object E | (<empty>, List(object E))          |
     |-----------------------------+------------------------------------|
     | def twice[@identity T]      | (type T, List(def twice))          |
     | (@identity x: Int) = x * 2  | (val x: Int, List(def twice))      |

   - In _the spirit of Scala macros_,
     + /macro annotations/ are
       * as untyped as possible to stay flexible
       * as typed as possible to remain useful.

     + Explanation:
       * On the one hand, macro annottees are untyped, so that we can change their
         signatures (e.g. lists of class members).
       * But on the other hand, the thing about all flavors of Scala macros is
         integration with the typechecker, and macro annotations are not an
         exceptions.

     + During expansion we can have all the type information that's possible to
       have (e.g. we can reflect against the surrounding program or perform type
       checks / implicit lookups in the enclosing context).

** DONE Blackbox vs whitebox
   CLOSED: [2020-09-20 Sun 06:02]
   Must be ~whitebox~!!!

* TODO Macro Paradise
* TODO Roadmap
* TODO Changes in Scala 2.11
** Quasiquotes
** New macro powers
** Changes to the macro engine
** Changes to the reflection API
** How to make your 2.10.x macros work in 2.11.0
** How to make your 2.11.0 macros work in 2.10.x
