#+TITLE: Hands-on Scala
#+SUBTITLE: Learn The Scala Language in A Practical, Project-Based Way
#+AUTHOR: Haoyi Li
#+VERSION: 2020-06-01
#+STARTUP: entitiespretty
#+STARTUP: indent
#+STARTUP: overview

* DONE Foreword - 3
  CLOSED: [2020-08-02 Sun 08:22]
* Author's Note - 5
* TODO Part I: Introduction to Scala - 13
** DONE Chapter 1: Hands-on Scala - 15
   CLOSED: [2020-06-01 Mon 10:01]
*** 1.1 Why Scala? - 16
**** 1.1.1 A Compiled Language that feels Dynamic - 16
**** 1.1.2 Easy Safety and Correctness - 17
**** 1.1.3 A Broad and Deep Ecosystem - 17
     
*** 1.2 Why This Book? - 17
**** 1.2.1 Beyond the Scala Language - 17
**** 1.2.2 Focued on Real Project - 17
**** 1.2.3 Code Firt - 18
     
*** 1.3 How This Book Is Organized - 18
**** 1.3.1 Chapter Dependency Graph - 19
     
*** 1.4 Code Snippet and Examples - 20
**** 1.4.1 Command-Line Snippets - 20
**** 1.4.2 Scala REPL Snippets - 20
**** 1.4.3 Source Files - 21
**** 1.4.4 Diffs - 22
     
*** 1.5 Online Materials - 22
**** 1.5.1 Code Snippets - 22
**** 1.5.2 Executable Code Examples - 23
**** 1.5.3 Exercises - 23
**** 1.5.4 Resources - 24
**** 1.5.5 Online Discussion - 24
     
*** 1.6 Conclusion - 24

** DONE Chapter 2: Setting Up - 25
   CLOSED: [2020-06-01 Mon 10:01]
*** 2.1 Windows Setup (Optional) - 26
*** 2.2 Installing Java - 27
*** 2.3 Installing Ammonite - 28
**** 2.3.1 The Scala REPL - 28
**** 2.3.2 Scala Scripts - 29
**** 2.3.3 Using Scripts from the REPL - 30
     
*** 2.4 Installing Mill - 31
**** 2.4.1 Mill Project - 31
**** 2.4.2 Running Unit Tests - 33
**** 2.4.3 Creating a Stand-Alone Executable - 33
     
*** 2.5 IDE Support - 34
**** 2.5.1 Installing IntelliJ for Scala - 34
**** 2.5.2 Integrating IntelliJ with Scala - 34
**** 2.5.3 Visual Studio Code Support - 36
     
*** 2.6 Conclusion - 38

** DONE Chapter 3: Basic Scala - 39
   CLOSED: [2020-06-02 Tue 02:27]
*** 3.1 Values - 40
**** 3.1.1 Primitives - 40
**** 3.1.2 Strings - 41
**** 3.1.3 Local Values and Variables - 42
**** 3.1.4 Tuples - 43
**** 3.1.5 Arrays - 44
     - For ~Array~ s created using ~new Array~,
       ALL entries start off with some values correspond to their types:
       + for numeric arrays: 0,
       + for ~Boolean~ arrays: ~false~
       + for Other types of arrays: ~null~

**** 3.1.6 Options - 46
     
*** 3.2 Loops, Conditionals, Comprehensions - 47
**** 3.2.1 For-Loops - 47
**** 3.2.2 If-Else - 47
**** 3.2.3 Fizzbuzz - 49
**** 3.2.4 Comprehensions - 50
     
*** TODO 3.3 Methods and Functions - 52
**** 3.3.1 Methods - 52
***** 3.3.1.1 Returning Values from Methods - 52
      
**** TODO 3.3.2 Functions Values - 53
***** 3.3.2.1 Methods taking Functions - 53
      
*** 3.4 Classes and Traits - 55
**** 3.4.1 Traits - 56
     
*** 3.5 Conclusion - 57

** TODO Chapter 4: Scala Collections - 60
*** DONE 4.1 Operations - 60
    CLOSED: [2020-06-02 Tue 02:44]
**** TODO 4.1.1 Builders - 60
**** TODO 4.1.2 Factory Methods - 60
**** 4.1.3 Transforms - 61
**** 4.1.4 Queries - 62
**** 4.1.5 Aggregations - 62
***** 4.1.5.1 ~mkString~ - 62
      #+begin_src scala
        Array(1, 2, 3, 4, 5, 6, 7).mkString("[", ",", "]")
      #+end_src
      =TODO=: This example in the book has a bad syntax highlight!!!
      
***** 4.1.5.2 ~foldLeft~ - 62
***** 4.1.5.3 ~groupBy~ - 63

**** 4.1.6 Combining Operations - 63
**** 4.1.7 Converters - 63
     =from Jian= new in Scala 2.13
     #+begin_src scala
       Array(1, 2, 3).to(Vector)  // res35: Vector[Int] = Vector(1, 2, 3)
       Vector(1, 2, 3).to(Array)  // res36: Array[Int] = Array(1, 2, 3)
       Array(1, 1, 2, 2, 3, 3, 4).to(Set)  // res37: Set[Int] = Set(1, 2, 3, 4)
     #+end_src

**** 4.1.8 Views - 64
     
*** TODO 4.2 Immutable Collections - 65
**** 4.2.1 Immutable Vectors - 67
     - ~Vector~ s are _fixed-size_, _immutable_ _linear sequences_.

     - =TODO= time complexity =???=
       
**** TODO 4.2.2 Structural Sharing - 68
**** TODO 4.2.3 Immutable Sets - 69
**** TODO 4.2.4 Immutable Maps - 70
**** TODO 4.2.5 Immutable Lists - 71

*** TODO 4.3 Mutable Collections - 70
**** 4.3.1 Mutable ArrayDeques - 71
**** 4.3.2 Mutable Sets - 74
**** 4.3.3 Mutable Maps - 75
**** 4.3.4 In-Place Operations - 76

*** TODO 4.4 Common Interfaces - 77
*** TODO 4.5 Conclusion - 78
    
** TODO 5 Notable Scala Features - 81
   #+begin_src scala
     def getDayMonthYear(s: string): Unit = {
       val found = s match {
         case s"$day-$month-$year" => s"found day: $day, month: $month, year: $year"
         case _                    => "not a date"
       }
       println(found)
     }
   #+end_src
 
   - In Dotty we can do:
     #+begin_src scala
       def getDayMonthYear(s: string): Unit =
         s match {
           case s"$day-$month-$year" => s"found day: $day, month: $month, year: $year"
           case _                    => "not a date"
         } pipe println
     #+end_src
     + https://contributors.scala-lang.org/t/give-the-pipe-method-of-scala-util-chainingops-an-operator-representation/4462/3
       explains, for performance reason,
       why we should do this in Scala 2, but we can do this in Scala 3
   
*** DONE 5.1 Case Classes and Sealed Traits - 82
    CLOSED: [2020-08-02 Sun 21:00]
**** DONE 5.1.1 Case Classes - 82
     CLOSED: [2020-08-02 Sun 20:29]
**** 5.1.2 Sealed Traits - 83
**** DONE 5.1.3 Use Cases for Normal v.s. Sealed Traits - 83
     CLOSED: [2020-08-02 Sun 21:00]
     - Normal ~trait~'s and ~sealed trait~'s make different things easy:
       + Normal ~trait~'s:
         * Easy to add additional /sub-classes/
           Just _define_ your /class/ and _implement_ the necessary /methods/.

         * Difficult to add new /methods/:
           A new /method/ needs to be added to all existing /subclasses/,
           of which there _may be many_.

       + ~sealed trait~'s:
         * Easy to add new methods:
           A new /method/ can simply /pattern match/ on each /sub-class/.

         * Difficult to add new /sub-classes/:
           Go to all existing /pattern matches/,
           and add the ~case~ to handle your new /sub-class/.
           
     - In general, ~sealed trait~ are good for
       *modeling hierachies where you expect the number of sub-classes to change
       very little or not-at-all*.
       + Example: JSON
         * The JSON value can be enumerated, and not many -- 6

         * The JSON has not changed in 20 years -- it is unlikely that anyone will
           need to extends our JSON ~trait~.
           
         * While the set of /sub-classes/ is fixed,
           the range of operations that can be applied on a JSON blob is _unbounded_:
           - parse it
           - serialize it
           - pretty-print it
           - minify it
           - santitize it
           - etc.
     
*** DONE 5.2 Pattern Matching - 85
    CLOSED: [2020-08-02 Sun 21:00]
**** DONE 5.2.1 Match - 85
     CLOSED: [2020-08-02 Sun 21:25]
***** 5.2.1.1 Matching on ~Int~'s
***** 5.2.1.2 Matching on ~String~'s
***** 5.2.1.3 Matching on tuple ~(Int, Int)~'s
***** 5.2.1.4 Matching on tuple ~(Boolean, Boolean)~'s
***** 5.2.1.5 Matching on Case Classes
***** 5.2.1.6 Matching on String Patterns
      =from Jian= Only be supported by Scala 2.13+
      #+begin_src scala
        def splitDate(s: String): String = s match {
          case s"$day-$month-$year" => s"day: $day, mon: $month, yr: $year"
          case _                    => "not a date"
        }

        splitDate("9-8-1965")
        // res32: String = "day: 9, mon: 8, yr: 1965"

        splitDate("9-8")
        // res33: String = "not a date"
      #+end_src
      - =TODO=
        (Note that pattern matching on string patterns only supports /simple
        glob-like patterns/, and doesn't support richer patterns like Regular
        Expressions. For those, you can use the functionality of the
        ~scala.util.matching.Regex~ class)
        + =TODO=
          Find a exact decription about when to use this /simple glob-like patterns/,
          and when to use ~Regex~.
      
**** DONE 5.2.2 Nested Matches - 86
     CLOSED: [2020-08-02 Sun 21:23]
**** DONE 5.2.3 Loops and Vals - 87
     CLOSED: [2020-08-02 Sun 21:23]
     - =from Jian=
       A better title is:
       ~for~ loops/comprehensions and ~val~'s

     - =from Jian=
       About the ~for~ loops/comprehensions, this book not mention the filtering
       effect of /pattern matching/ in the expression follows ~for~:
       + /Pattern matching/ in the expression follows ~for~ is not a simple /pattern
         matching/, and it also means the not matched cases will be dropped, or say
         filtered out -- like the ~if~ guard functionality in ~for~.
     
**** DONE 5.2.4 Pattern Matching on Sealed Traits and Case Classes - 88
     CLOSED: [2020-08-02 Sun 21:24]
     =from Jian= =TODO=
     Not mention /exhaustive check/. I think it should mention it when talking
     about sealed traits case classes /pattern matching/.
     
***** 5.2.4.1 Stringifying Our Expressions - 88
***** 5.2.4.2 Evaluating Our Expressions - 89

*** TODO 5.3 By-Name Parameters - 90
**** 5.3.1 Avoiding Evaluation - 90
**** TODO 5.3.2 Wrapping Evaluation - 91 - =IMPORTANT=
**** TODO 5.3.3 Repeating Evaluation - 92 - =IMPORTANT=
     
*** TODO 5.4 Implicit Parameters - 93
    - /Implicit parameters/ are SIMILAR TO the /default values/ of _function
      parameters_.
      + SAME:
        Both of them allow you to pass in a value explicitly or fall back to
        some default.
        
      + DIFFERENCE:
        * _/Default values/ of function parameters_ are
          *"hard coded"* at the /definition site/

        * /implicit parameters/
          - Take the passed-in value if it is given.

          - Take their /default value/ from whatever /implicit/ is _in scope at
            the call-site_. =from Jian= More flexible

**** 5.4.1 Passing ExecutionContext to Futures - 94
**** 5.4.2 Dependency Injection via Implicits - 95

*** TODO 5.5 Typeclass Inference - 96 - =RE-READ=
**** 5.5.1 Problem Statement: Parsing Command Line Arguments - 96
     A _first sketch_ may be writing a /generic method/ to parse the values.
     The signature might look something like this:
     #+begin_src scala
       def parseFromString[T](s: String): T = ...

       val args = Seq("123", "true", "7.5")
       val myInt = parseFromString[Int](args(0))
       val myBoolean = parseFromString[Boolean](args(1))
       val myDouble = parseFromString[Double](args(2))
     #+end_src
     On the surface this _seems *impossible* to IMPLEMENT_:
     - How does the ~parseCliArgument~ know how to convert the given ~String~ into
       an arbitrary ~T~?

     - How does it know what types ~T~ a command-line argument _can_ be parsed into,
       and which it _cannot_?
       * For example, we should _not_ be able to parse a ~java.net.DatagramSocket~
         from an input string.
     
**** 5.5.2 Separate Parser Objects - 96
     A _second sketch_ at a solution may be to define _SEPARATE parser objects,
     one for each type_ we need to be able to parse. For example:
     #+begin_src scala
       trait StrParser[T]{ def parse(s: String): T }
       object ParseInt extends StrParser[Int]{ def parse(s: String) = s.toInt }
       object ParseBoolean extends StrParser[Boolean]{ def parse(s: String) = s.toBoolean }
       object ParseDouble extends StrParser[Double]{ def parse(s: String) = s.toDouble }
     #+end_src

     - Use them:
       #+begin_src scala
         val args = Seq("123", "true", "7.5")
         val myInt = ParseInt.parse(args(0))
         val myBoolean = ParseBoolean.parse(args(1))
         val myDouble = ParseDouble.parse(args(2))
       #+end_src

     - This works.
       However, it then leads to _ANOTHER PROBLEM_:
       if we wanted to write a method that _didn't parse a ~String~ directly_,
       but _parsed a value from the console_,
       how would we do that? We have *TWO* options.

***** 5.5.2.1 Re-Using Our StrParsers - 97
      - The first option:
        _writing a whole NEW set of object_ s dedicated to parsing from the console:
        #+begin_src scala
          trait ConsoleParser[T] { def parse(): T }

          object ConsoleParseInt extends ConsoleParser[Int] {
            def parse() = scala.Console.in.readLine().toInt
          }

          object ConsoleParseBoolean extends ConsoleParser[Boolean] {
            def parse() = scala.Console.in.readLine().toBoolean
          }

          object ConsoleParseDouble extends ConsoleParser[Double] {
            def parse() = scala.Console.in.readLine().toDouble
          }

          val myInt = ConsoleParseInt.parse()
          val myBoolean = ConsoleParseBoolean.parse()
          val myDouble = ConsoleParseDouble.parse()
        #+end_src

      - The second option:
        defining a /helper method/ that receives a ~StrParser[T]~ as an argument,
        which we would need to pass in to tell it how to parse the type ~T~:
        #+begin_src scala
          def parseFromConsole[T](parser: StrParser[T]) = parser.parse(scala.Console.in.readLine())

          val myInt = parseFromConsole[Int](ParseInt)
          val myBoolean = parseFromConsole[Boolean](ParseBoolean)
          val myDouble = parseFromConsole[Double](ParseDouble)
        #+end_src
      
      - BOTH of these solutions ARE CLUNKY:
        1. The first because we need to *duplicate* all the ~Int~ / ~Boolean~ /
           ~Double~ /etc. _parsers_.
           + What if we need to parse input
             * from the network?
             * from files?
             We would need to duplicate every parser for each case.
           
        2. The second because we need to _pass_ these ~ParseFoo~ objects _everywhere_.
           Often there is only a single ~StrParser[Int]~ we can pass to
           ~parseFromConsole[Int]~.
           + Why can't the compiler infer it for us?

**** TODO 5.5.3 Solution: Implicit ~StrParser~ - 98
***** 5.5.3.1 Re-Using Our Implicit StrParsers - 99
***** 5.5.3.2 Context-Bound Syntax - 99
***** 5.5.3.3 Compile-Time Implicit Safety - 99

**** TODO 5.5.4 Recursive Typeclass Inference - 100
***** 5.5.4.1 Parsing Sequences - 100
***** 5.5.4.2 Parsing Tuples - 101
***** 5.5.4.3 Parsing Nested Structures - 101

*** TODO 5.6 Conclusion - 102
    - =NOTE=
    - Exercise:
    - Exercise:
    - Exercise:

* TODO Part II: Local Development - 105
** TODO Chapter 6: Implementing Algorithms in Scala - 107
   #+begin_src scala
     // 6.1
     import scala.collection.mutable

     def breadthFirstSearch[T](start: T, graph: Map[T, Seq[T]]): Set[T] = {
       val seen = mutable.Set(start)
       val queue = mutable.ArrayDeque(start)

       while (queue.nonEmpty) {
         val current = queue.removeHead()
         for (next <- graph(current) if !seen(next)) {
           seed.add(next)
           queue.append(next)
         }
       }
       seen.toSet
     }
   #+end_src
   
*** DONE 6.1 Merge Sort - 108
    CLOSED: [2020-07-21 Tue 18:46]
    #+begin_src scala
      def mergeSort(items: Array[Int]): Array[Int] =
        if items.length <= 1
        then items
        else
          val (left, right) = items.splitAt(items.length / 2)
          val (sortedLeft, sortedRight) = (mergeSort(left), mergeSort(right))
          var (leftIdx, rightIdex) = (0, 0)
          val output = Array.newBuilder[Int]

          lazy val (l, r) = (leftIdx < sortedLeft.length, rightIdx < sortedRight.length)
          while l || r
            val takeLeft = (l, r) match
              case (true, false) => true
              case (false, true) => false
              case (true, true)  => sortedLeft(leftIdx) < sortedRight(rightIdx)

            if takeLeft
            then
              output += sortedLeft(leftIdx)
              leftIdx += 1
            else
              output += sortedRight(rightIdx)
              rightIdx += 1

          output.result()
    #+end_src

**** 6.1.1 Generic Merge Sort - 110
     #+begin_src scala
       def mergeSort[T: Ordering](items: IndexedSeq[T]): IndexedSeq[T] =
         if items.length <= 1
         then items
         else
           val (left, right) = items.splitAt(items.length / 2)
           val (sortedLeft, sortedRight) = (mergeSort(left), mergeSort(right))
           var (leftIdx, rightIdex) = (0, 0)
           val output = IndexedSeq.newBuilder[T]

           lazy val (l, r) = (leftIdx < sortedLeft.length, rightIdx < sortedRight.length)
           while l || r
             val takeLeft = (l, r) match
               case (true, false) => true
               case (false, true) => false
               case (true, true)  => Ordering[T].lt(sortedLeft(leftIdx), sortedRight(rightIdx))

             if takeLeft
             then
               output += sortedLeft(leftIdx)
               leftIdx += 1
             else
               output += sortedRight(rightIdx)
               rightIdx += 1

           output.result()
     #+end_src

*** TODO 6.2 Prefix Tries - 112
**** 6.2.1 Trie Set Operations - 112
***** 6.2.1.1 ~Trie.add~ - 113
***** 6.2.1.2 ~Trie.contains~ - 114

**** 6.2.2 Trie Prefix Operations - 115
***** 6.2.2.1 ~Trie.prefixesMatchingString~ - 115
***** 6.2.2.2 ~Trie.stringsMatchingPrefix~ - 116

*** 6.3 Breadth First Search - 119
**** 6.3.1 Implementing Breadth First Search - 120

*** 6.4 Shortest Paths - 122
*** 6.5 Conclusion - 124

** TODO Chapter 7: Files and Subprocesses - 127
   #+name: Snippet 7.1: a short Scala code snippet to find the five largest file in a directory tree
   #+begin_src scala
     os.walk(os.pwd).filter(os.isFile).map(p => (os.size(p), p)).sortBy(-_._1).take(5)
   #+end_src
   
   - This chapter will walk you through how to perform basic file and subprocess operations in Scala.

   - This chapter finishes with two small projects:
     * Build a simple file synchronizer
     * Build a streaming subprocess pipeline

   - This chapter will form the basis for
     * Chapter 17: Multi-Process Applications
     * Chapter 18: Building a Real-time File Synchronizer

   - This chapter uses:
     * OS-Lib library
     * Ammonite (OS-Lib comes bundled with Ammonite, and can be used within the
       REPL and =*.sc= script files)
   
*** DONE 7.1 Paths - 128
    CLOSED: [2020-10-17 Sat 03:10]
    - Two subtypes of ~os.Path~:
      + ~os.RelPath~ 
      + ~os.SubPath~ 

    - Three built-in paths of ~os~:
      + ~os.pwd~
      + ~os.root~
      + ~os.home~

    - Get /path segement(s)/:
      + ~.segements~ -- All segments (~Iterator~)
      + ~.last~ -- Last segments

**** DONE 7.1.1 Constructing Paths - 128
     CLOSED: [2020-10-17 Sat 02:47]
     Concatenate /path segments/ (~os.PathChunk~) with the ~/~ operator.

     - *CAUTION*:
       The ~os.PathChunk~ can't contains /, and because of implicits, the passed
       in /path segments/ can be a string instead of the exact ~os.PathChunk~.
    
     - ~os.up~, combine with a /path/ and ~/~, lets you move up one level.
       #+begin_src scala
         os.pwd / os.up
         os.pwd / os.up / os.up
       #+end_src

     - ~os.Path(...)~ is used to *parse* ~os.Path~'s from strings.
       + BY DEFAULT, only /absolute paths/ are supported.

       + With the help of an EXTRA base path parameter ~base~, a /relative path/
         string can be parsed.
         #+begin_src scala
           os.Path("post", base = os.pwd)

           os.Path("../Ammonite", base = os.pwd)
         #+end_src
     
**** DONE 7.1.2 Relative Paths - 129
     CLOSED: [2020-10-17 Sat 03:10]
     To work with /relative paths/ on disk, you can use ~os.RelPath~:
     #+begin_src scala
       os.RelPath("post")            // res13: os.RelPath = post
       os.RelPath("../hello/world")  // res14: os.RelPath = ../hello/world
     #+end_src
       
     - This helps ensure you
       *do not mix up*
       ~os.Path~'s which are always /absolute/
       AND
       ~os.RelPath~'s which are always /relative/.

     - Combination rules:
       Use ~/~, and ~os.Path~ can't be the RHS of a relative ~os.RelPath~.
       This will be identified as a /compile error/.

     - Examples:
       #+begin_src scala
         val helloRelPath = os.RelPath("../hello")

         os.home / helloRelPath  // res16: os.Path = /Users/hello

         helloRelPath / os.RelPath("post")  // res17: os.RelPath = ../hello/post
       #+end_src

     - Use ~relativeTo~ to get the /relative path/ between two /absolute paths/.
       #+begin_src scala
         val githubPath = os.Path("/Users/lihaoyi/Github")
         val usersPath = os.Path("/Users")

         githubPath.relativeTo(usersPath)  // res19: os.RelPath = lihaoyi/Github
         usersPath.relativeTo(githubPath)  // res20: os.RelPath = ../..
       #+end_src
       
**** DONE 7.1.3 Sub Paths - 130
     CLOSED: [2020-10-17 Sat 02:57]
     ~os.SubPath~'s are a special case of /relative paths/, where there CANNOT be
     any ~..~ segments at the start.

     - Similar to /relative paths/, sub-paths can be created between absolute
       ~os.Path~'s using ~.subRelativeTo~.
       #+begin_src scala
         os.SubPath("post")
         // res21: os.SubPath = post

         val p1 = os.Path("/Users/lihaoyi/Github")

         val p2 = os.Path("/Users")

         p1.subRelativeTo(p2)
         // res25: os.SubPath = lihaoyi/Github
       #+end_src

     - ~os.SubPath~ is useful for cases where you have a /relative path/ that should
       always be "within" a particular base folder.
       + This can help _RULE OUT a whole class of /directory traversal ATTACKS/_
         where an unexpected ~..~ in a /relative path/ allows the attacks to
         read your =/etc/passwd= or some other sensitive files.
         =TODO= =???= =TODO= =???=

*** DONE 7.2 Filesystem Operations - 130
    CLOSED: [2020-10-17 Sat 04:23]
    Most filesystem operations only accept absolute path ~os.Path~'s.

**** DONE 7.2.1 Queries - 131
     CLOSED: [2020-10-17 Sat 03:58]
***** 7.2.1.1 ~os.list~ - 131
      List direct children of a folder
      #+begin_src scala
        os.list(os.pwd)
        // res26: IndexedSeq[os.Path] = ArraySeq(
        //   /Users/lihaoyi/test/.gitignore,
        //   /Users/lihaoyi/test/post
        // )
      #+end_src

***** 7.2.1.2 ~os.walk~ - 131
      List children of a folder recursively
      #+begin_src scala
        os.walk(os.pwd)
        // res27: IndexedSeq[os.Path] = ArraySeq(
        //   /Users/lihaoyi/test/.gitignore,
        //   /Users/lihaoyi/test/post,
        //   /Users/lihaoyi/test/post/Interview.md,
        //   /Users/lihaoyi/test/post/Hub,
        //   /Users/lihaoyi/test/post/Hub/Search.png,
        //   ...
        // )
      #+end_src

***** 7.2.1.3 ~os.stat~ - 131
      Fetch the filesystem metadata for an individual file or folder.
      #+begin_src scala
        os.stat(os.pwd / ".gitignore")
        // res28: os.StatInfo = StatInfo(
        //   129L,
        //   2019-09-27T08:04:35.292056Z,
        //   2019-12-15T22:23:01.462598Z,
        //   2019-09-27T08:04:35Z,
        //   File
        // )
      #+end_src

      - Other useful queries:
        + ~os.isFile~
        + ~os.isDir~
        + ~os.mtime~
        + ~os.size~
      
**** DONE 7.2.2 Actions - 132
     CLOSED: [2020-10-17 Sat 04:15]
***** 7.2.2.1 ~os.read~, ~os.write~ - 132
      - ~os.write~ can write any datatype implementing the ~Writable~ interface:
        + ~String~
        + ~Array[Byte]~
        + even the ~ujson.Value~ (will mention in Chapter 8)
      
      - ~os.read~ reads a file as a ~String~.
      - ~os.read.lines~ reads the lines of a file as a ~IndexedSeq[String]~.
      - ~os.read.bytes~ reads a file as a ~Array[Byte]~.

      - Examples:
        #+begin_src scala
          os.write(os.pwd / "new.txt", "Hello")

          os.list(os.pwd)
          // res30: IndexedSeq[os.Path] = ArraySeq(
          //   /Users/lihaoyi/test/.gitignore,
          //   /Users/lihaoyi/test/post,
          //   /Users/lihaoyi/test/new.txt
          // )

          os.read(os.pwd / "new.txt")
          // res31: String = "Hello"
        #+end_src
        
***** 7.2.2.2 ~os.move~ - 132
      #+begin_src scala
        os.move(
          os.pwd / "new.txt",
          os.pwd / "newer.txt"
        )

        os.list(os.pwd)
        // res32: IndexedSeq[os.Path] = ArraySeq(
        //    /Users/lihaoyi/test/.gitignore,
        //    /Users/lihaoyi/test/post,
        //    /Users/lihaoyi/test/newer.txt
        // )
      #+end_src
      
***** 7.2.2.3 ~os.copy~ - 132
      #+begin_src scala
        os.copy(
          os.pwd / "newer.txt",
          os.pwd / "newer-2.txt"
        )

        os.list(os.pwd)
        // res32: IndexedSeq[os.Path] = ArraySeq(
        //    /Users/lihaoyi/test/.gitignore,
        //    /Users/lihaoyi/test/post,
        //    /Users/lihaoyi/test/newer-2.txt,
        //    /Users/lihaoyi/test/newer.txt
        // )
      #+end_src
      
***** 7.2.2.4 ~os.remove~ - 132
      #+begin_src scala
        os.remove(os.pwd / "newer.txt")

        os.list(os.pwd)
        // res32: IndexedSeq[os.Path] = ArraySeq(
        //    /Users/lihaoyi/test/.gitignore,
        //    /Users/lihaoyi/test/post,
        //    /Users/lihaoyi/test/newer-2.txt
        // )
      #+end_src
      
***** 7.2.2.5 ~os.makeDir~ - 132
      #+begin_src scala
        os.makeDir(os.pwd / "new-folder")

        os.list(os.pwd)
        // res32: IndexedSeq[os.Path] = ArraySeq(
        //    /Users/lihaoyi/test/.gitignore,
        //    /Users/lihaoyi/test/post,
        //    /Users/lihaoyi/test/new-folder,
        //    /Users/lihaoyi/test/newer-2.txt
        // )
      #+end_src

**** DONE 7.2.3 Combining Operations - 133
     CLOSED: [2020-10-17 Sat 04:15]
     #+begin_src scala
       os.walk(os.pwd).filter(os.isFile).map(p => (os.size(p), p)).sortBy(-_._1).take(5)
     #+end_src
   
     - One limitation:
       This snippet loads all files into an in-memory data structure before filtering and
       transforming it.
       + Next section use ~.stream~ variant to resolve this.
       
**** DONE 7.2.4 Streaming - 133
     CLOSED: [2020-10-17 Sat 04:22]
     ~os.read.lines.stream~ and ~os.walk.stream~
     #+begin_src scala
       os.read.lines.stream(os.pwd / ".gitignore").foreach(println)
       // target/
       // *.iml
       // .idea
       // .settings
       // ...

       os.walk.stream(os.pwd).foreach(println)
       // /Users/lihaoyi/test/.gitignore
       // /Users/lihaoyi/test/post
       // /Users/lihaoyi/test/post/Programming Interview.md
       // /Users/lihaoyi/test/post/Hub
       // /Users/lihaoyi/test/post/Hub/Search.png
     #+end_src
     
     - The return type of ~.stream~ operations is ~Generator~, which is like
       /iterators/, but *it ensure that resources are always released after
       processing.*
       + Most collection operations like ~.foreach~, ~.map~, ~.filter~, ~toArray~,
         etc. are available on ~Generator~'s.
         
**** DONE 7.2.5 Transforming Streams - 134
     CLOSED: [2020-10-17 Sat 04:23]

*** DONE 7.3 Folder Syncing - 135
    CLOSED: [2020-11-18 Wed 04:10]
    Let us start by defining the /method signature/ of our folder synchronizer:
    #+begin_src scala
      def sync(src: os.Path, dest: os.Path): Unit = ???
    #+end_src
    
    - Assumptions: =todo= =???= =todo=
      + We will *ignore* /deletions/ and /symbolic links/.
        * Ignore /deletions/ means assume all the files in ~dest~ are always in
          ~src~.

      + We will not use the too inefficient way like remove the destination folder
        contents completely, and re-copy source folder contents to it.
    
**** DONE 7.3.1 Walking the Filesystem - 135
     CLOSED: [2020-10-17 Sat 04:40]
     #+begin_src scala
       def sync(src: os.Path, dest: os.Path): Unit =
         for (srcSubPath <- os.walk(src)) {
           val subPath = srcSubPath.subRelativeTo(src)
           val destSubPath = dest / subPath
           println((os.isDir(srcSubPath), os.isDir(destSubPath)))
         }
     #+end_src
     
     - Running this on our source folder with files and destination folder WITHOUT
       files ~sync(os.pwd / "post", os.pwd / "post-copy")~, we get the following:
       #+begin_src text
         (false, false)
         (true, false)
         (false, false)
         (false, false)
         ...
       #+end_src
       For now, the destination folder doesn't exist, so ~isDir~ returns ~false~
       on all of the paths.
     
**** DONE 7.3.2 Copying New Files Over - 136
     CLOSED: [2020-11-18 Wed 01:37]
     The next step is to start syncing over files.
     We walk over the =src= and the corresponding paths in =dest= together, and
     if they differ, copy the source sub-path over the destination sub-path:
     #+begin_src scala
       def sync(src: os.Path, dest: os.Path): Unit =
         for (srcSubPath <- os.walk(src)) {
           val subPath = srcSubPath.subRelativeTo(src)
           val destSubPath = dest / subPath
           (os.isDir(srcSubPath), os.isDir(destSubPath)) match {
             case (false, true) | (true, false) =>
               os.copy.over(srcSubPath, destSubPath, createFolders = true)
        
             case _ =>  // do nothing
           }
         }
     #+end_src
     
     - Since ~isDir~ returns ~false~ both
       when the path refers to a file as well as
       if the path is empty,
       the above snippet uses ~copy.over~ to *delete* the _destination path_ and
       *copy over* the contents of the source in the following circumstances:
       * source path contains a _file_, destination path contains a _folder_
       * source path contains a _folder_, destination path contains a _file_
       * source path contains a _folder_, destination path is _empty_
     
     - There are _THREE_ cases the above code does NOT support:
       * If
         + the source path is empty,
         + the destination path contains a folder
         This is a "delete" which we will ignore for now;
         =TODO= =LATER= supporting this is left as an exercise for the reader

       * If
         + the source path is a folder 
         + the destination path is a folder
         Do nothing is fine: ~os.walk~ will enter the _source path_ folder and
                             process all the files within it recursively

       * If
         + the source path is a file
         + the destination path is a file
         + they have DIFFERENT contents
       
     - We will handle the last case next. =TODO= =NOW=      
       
**** DONE 7.3.3 Updating Files - 137
     CLOSED: [2020-11-18 Wed 01:37]
     Handle the last case mentioned in the last section is handle the ~(false, false)~
     case in our /pattern match/, but only if the _destination path is empty_ or
     _the destination path has a file with different contents than the source path_:
     #+begin_src scala
       def sync(src: os.Path, dest: os.Path): Unit =
         for (srcSubPath <- os.walk(src)) {
           val subPath = srcSubPath.subRelativeTo(src)
           val destSubPath = dest / subPath
           (os.isDir(srcSubPath), os.isDir(destSubPath)) match {
             case (false, true) | (true, false) =>
               os.copy.over(srcSubPath, destSubPath, createFolders = true)

             case (false, false)
                 if !os.exists(destSubPath)
                 ||!os.read.bytes(srcSubPath).sameElements(os.read.bytes(destSubPath)) =>
               os.copy.over(srcSubPath, destSubPath, createFolders = true)

             case _ =>  // do nothing
           }
         }
     #+end_src
     - We still use ~os.copy.over~ in the ~(false, false)~ case.
       A more fine-grained file syncer may want to update the file in place if only
       part of it has changed.
       * Use ~.sameElements~, which can take into order account, rather than ~==~
         to compare the elements of ~Array~'s.

     - For now we *ignore* the /race condition/ (when we do operation, related
       files or folders are changing) and assume that the file system is static
       while the ~sync~ is ongoing.
       * =TODO=
         Dealing with concurrent modification will be the topic of Chapter 18
     
**** DONE 7.3.4 Testing Or File Syncer - 138
     CLOSED: [2020-11-18 Wed 04:10]
     - After running ~sync~, use ~os.walk~ to verify:
       #+begin_src scala
         sync(os.pwd / "post", os.pwd / "post-copy")

         os.walk(os.pwd / "post-copy")
         // res51: IndexedSeq[os.Path] = ArraySeq(
         //   /Users/lihaoyi/test/post-copy/Optimizing Scala.md,
         //   /Users/lihaoyi/test/post-copy/Programming Interview.md,
         // ...
       #+end_src

     - Test incremental updates by adding one entry to source path, and re-~sync~:
       #+begin_src scala
         os.write(os.pwd / "post" / "ABC.txt", "Hello World")

         sync(os.pwd / "post", os.pwd / "post-copy")

         os.exists(os.pwd / "post-copy" / "ABC.txt")
         // res54: Boolean = true

         os.read(os.pwd / "post-copy" / "ABC.txt")
         // res55: String = "Hello World"
       #+end_src

     - Test incremental updates by appending some content to one of the files in
       source path, and re-~sync~:
       #+begin_src scala
         os.write.append(os.pwd / "post" / "ABC.txt", "\nI am Cow")

         sync(os.pwd / "post", os.pwd / "post-copy")

         os.read(os.pwd / "post-copy" / "ABC.txt")
         // res58: String = """Hello World
         // I am Cow"""
       #+end_src

     - The example is greatly simplified:
       * we do not consider
         + deletions
         + permissions
         + symbolic links
         + concurrency/parallelism concerns

       * our file synchronizer runs in-process on a _single_ computer, and *cannot
         be easily* used to synchronize files over a network.
         
*** TODO 7.4 Simple Subprocess Invocations - 139
**** 7.4.1 Use Case: remove non-current branches from a Git repo - 140
**** 7.4.2 Use Case: Curl to a local file - 141
**** 7.4.3 Streaming Gzip - 142

*** TODO 7.5 Interactive and Streaming Subprocesses - 142
**** 7.5.1 Interacting with a Subprocess - 143
**** 7.5.2 Streaming distinct contributors in a Git repo history - 144
**** 7.5.3 Streaming Subprocess Pipelines - 144

*** TODO 7.6 Conclusion - 146

** TODO Chapter 8: JSON and Binary Data Serialization - 147
*** 8.1 Manipulating JSON - 148
**** 8.1.1 The ~ujson.Value~ Data Type - 149
**** 8.1.2 Querying and Modifying JSON - 150
**** 8.1.3 Extracting Typed Values - 150
**** 8.1.4 Traversing JSON - 151

*** 8.2 JSON Serialization of Scala Data Types - 152
**** 8.2.1 Serializing Scala Builtins - 152
**** 8.2.2 Serializing Case Classes - 153
**** 8.2.3 Mapped Serializers - 154

*** 8.3 Writing your own Generic Serialization Methods - 156
**** 8.3.1 uPickle Context Bounds - 156
**** 8.3.2 Generic Serialization Methods - 156
**** 8.3.3 Why Context Bounds? - 157
***** 8.3.3.1 Performance with Convenience - 157
***** 8.3.3.2 Compile-Time Error Reporting - 158
***** 8.3.3.3 Security - 158

*** 8.4 Binary Serialization - 158
**** 8.4.1 writeBinary and readBinary - 158
**** 8.4.2 MessagePack Structures - 160
     
*** 8.5 Conclusion - 161

** TODO Chapter 9: Self-Contained Scala Scripts - 163
*** 9.1 Reading Files Off Disk - 164
*** 9.2 Using a Scala HTML Library - 165
*** 9.3 Using a Java Markdown Library - 167
**** 9.3.1 Translating Java Snippets to Scala - 169
**** 9.3.2 Testing our Java Markdown Parser - 170

*** 9.4 Links and Bootstrap - 172
**** 9.4.1 Page Links - 172
**** 9.4.2 Bootstrap - 174

*** 9.5 Optionally Deploying the Static Site - 175
*** 9.6 Conclusion - 178

** TODO Chapter 10: Static Build Pipelines - 179
*** 10.1 Mill Build Pipelines - 180
**** 10.1.1 Defining a Build Pipeline - 180
***** 10.1.1.1 Targets - 181
***** 10.1.1.2 Target Destination Folders- 181

**** 10.1.2 Using Your Build Pipeline - 181
**** 10.1.3 Non-linear Build Pipelines - 183
**** 10.1.4 Incremental Re-Computation - 184

*** 10.2 Mill Modules - 185
**** 10.2.1 Nested Modules - 187
**** 10.2.2 Cross Modules - 188
**** 10.2.3 Modules Based on Folder Layout - 189

*** 10.3 Revisiting our Static Site Script - 189
*** 10.4 Conversion to a Mill Build Pipeline - 190
**** 10.4.1 For-Loop to Cross Modules - 191
**** 10.4.2 An Index Page Target - 192
**** 10.4.3 Arranging Files For Distribution - 193
**** 10.4.4 Using Your Static Build Pipeline - 193

*** 10.5 Extending our Static Site Pipeline - 194
**** 10.5.1 Bundling Bootstrap - 195
**** 10.5.2 Post Previews - 197
**** 10.5.3 A Complete Static Site Pipeline - 199
     
*** 10.6 Conclusion - 201

* TODO Part III: Web Services - 203
** TODO Chapter 11: Scraping Websites - 205
*** 11.1 Scraping Wikipedia - 206
**** 11.1.1 Selection - 207
**** 11.1.2 CSS Selector Cheat Sheet - 208
**** 11.1.3 Choosing Selectors via Inspect Element - 209
**** 11.1.4 Extracting data - 210

*** 11.2 MDN Web Documentation - 210
*** 11.3 Scraping MDN - 212
**** 11.3.1 Scraping The Documentation Index - 212
**** 11.3.2 Scraping Each Documentation Page - 213
***** 11.3.2.1 Finding the First Paragraph - 214
***** 11.3.2.2 Finding Property and Method Docs - 215

*** 11.4 Putting it Together - 217
*** 11.5 Conclusion - 219

** TODO Chapter 12: Working with HTTP APIs - 221
*** 12.1 The Task: Github Issue Migrator - 222
**** 12.1.1 Old Existing Repository - 223
**** 12.1.2 Brand New Repository - 223
     
*** 12.2 Creating Issues and Comments - 224
*** 12.3 Fetching Issues and Comments - 226
**** 12.3.1 Pagination - 228
**** 12.3.2 Picking the data we want - 230
**** 12.3.3 Issue Comments - 230
     
*** 12.4 Migrating Issues and Comments - 232
**** 12.4.1 One new issue per old issue - 232
**** 12.4.2 One new comment per old comment - 233
     
*** 12.5 Conclusion - 236

** TODO Chapter 13: Fork-Join Parallelism with Futures - 239
*** 13.1 Parallel Computation using Futures - 240
**** 13.1.1 Sequential Code - 241
**** 13.1.2 Spawning Futures - 241
**** 13.1.3 Offloading Work from the Main Thread - 242

*** 13.2 N-Ways Parallelism - 243
**** 13.2.1 N Sequential Computations - 244
**** 13.2.2 N Parallel Computations - 244
**** 13.2.3 Futures vs Threads - 246

*** 13.3 Parallel Web Crawling - 246
**** 13.3.1 A Single HTTP Request - 247
**** 13.3.2 Sequential Crawling - 248
**** 13.3.3 Parallel Crawling - 249
**** 13.3.4 Testing our Parallel Webcrawler - 251

*** 13.4 Asynchronous Futures - 252
**** 13.4.1 Futures and Promises - 252
**** 13.4.2 Interfacing with Callbacks using Promises - 253
***** 13.4.2.1 Converting Futures to Callbacks - 253
***** 13.4.2.2 Converting Callbacks to Futures - 253

**** 13.4.3 Asynchronous Operators - 254
***** 13.4.3.1 ~map~, ~foreach~ - 254
***** 13.4.3.2 ~zip~ - 254
***** 13.4.3.3 ~sequence~ - 255

*** 13.5 Asynchronous Web Crawling - 255
**** 13.5.1 Web Crawling via Recursion - 255
**** 13.5.2 Asynchronous Link Fetching with AsyncHttpClient - 256
**** 13.5.3 Asynchronous Recursive Web Crawling - 258
     
*** 13.6 Conclusion - 259

** TODO Chapter 14: Simple Web and API Servers - 261
*** 14.1 A Minimal Webserver - 262
**** 14.1.1 Application Code - 262
**** 14.1.2 Webserver Build Configuration - 264
**** 14.1.3 Running and Testing our Webserver - 265

*** 14.2 Serving HTML - 266
**** 14.2.1 A Mock Chat Website - 267

*** 14.3 Forms and Dynamic Data - 268
**** 14.3.1 Dynamic Page Rendering - 269
**** 14.3.2 Form Handling - 269
**** 14.3.3 Validation - 271
**** 14.3.4 Remembering Names and Messages - 272

*** 14.4 Dynamic Page Updates via API Requests - 275
**** 14.4.1 Rendering Partial Pages - 276
**** 14.4.2 Page Updates with JavaScript - 278

*** 14.5 Real-time Updates with Websockets - 280
**** 14.5.1 Server-side Websocket Support - 281
**** 14.5.2 Browser-side Websocket Support - 282
     
*** 14.6 Conclusion - 284

** TODO Chapter 15: Querying SQL Databases - 287
*** 15.1 Setting up Quill and PostgreSQL - 288
**** 15.1.1 Library Setup - 288
**** 15.1.2 Sample Data - 289
**** 15.1.3 PG-CLI - 289
     
*** 15.2 Mapping Tables to Case Classes - 290
*** 15.3 Querying and Updating Data - 293
**** 15.3.1 Filtering - 293
**** 15.3.2 Lifting - 294
**** 15.3.3 Mapping - 295
**** 15.3.4 Joins - 296
**** 15.3.5 Inserts - 297
**** 15.3.6 Updates - 298

*** 15.4 Transactions - 299
**** 15.4.1 Why Transactions? - 300

*** 15.5 A Database-Backed Chat Website - 300
**** 15.5.1 Build Config & Database Setup - 301
**** 15.5.2 Storing Messages in the Database - 302
**** 15.5.3 Testing our Database-backed Website - 302
     
*** 15.6 Conclusion - 305

* TODO Part IV: Program Design - 307
** TODO Chapter 16: Message-based Parallelism with Actors - 309
*** 16.1 Castor Actors - 301
**** 16.1.1 Actor Classes - 310
***** 16.1.1.1 SimpleActor - 310
***** 16.1.1.2 BatchActor - 310
***** 16.1.1.3 StateMachineActor - 311
      
**** 16.1.2 Contexts, Exceptions, and State - 311

*** 16.2 Actor-based Background Uploads - 302
**** 16.2.1 Simple Upload Actor - 312
**** 16.2.2 Actors vs Futures - 313
***** 16.2.2.1 Streaming vs Request-Response - 313
***** 16.2.2.2 Preserving Ordering - 313
***** 16.2.2.3 Private Mutable State - 313
      
**** 16.2.3 Batch Upload Actor - 314
**** 16.2.4 State Machine Upload Actor - 315

*** 16.3 Concurrent Logging Pipelines - 308
**** 16.3.1 A Logging SimpleActor - 318
**** 16.3.2 Multi-stage Actor Pipelines - 319
**** 16.3.3 Non-Linear Pipelines - 321
**** 16.3.4 Re-arranging Actor Pipelines - 323

*** 16.4 Debugging Actors - 315
**** 16.4.1 Debug Logging State Machines - 324
**** 16.4.2 Running Actors Single Threaded - 325
**** 16.4.3 Debugging using Context Logging - 326
     
*** 16.5 Conclusion - 327

** TODO Chapter 17: Multi-Process Applications - 329
*** 17.1 Two-Process Build Setup - 330
**** 17.1.1 Integrating our Simple File Syncer into Mill - 332
**** 17.1.2 Testing our File Syncer - 333

*** 17.2 Remote Procedure Calls - 333
**** 17.2.1 Defining our RPC Messages - 334
**** 17.2.1 Bytes over the Wire - 335

*** 17.3 The Agent Process - 336
*** 17.4 The Sync Process - 337
**** 17.4.1 Spawning the Agent - 337
**** 17.4.2 Delegating File Operations - 339

*** 17.5 Pipelined Syncing - 341
**** 17.5.1 Pipelining RPCs - 342
**** 17.5.2 Batching Pipelined Filesystem Operations - 343
     
*** 17.6 Conclusion - 345

** TODO Chapter 18: Building a Real-time File Synchronizer - 347
*** 18.1 Watching for Changes - 337
*** 18.2 Real-time Syncing with Actors - 349
**** 18.2.1 Architecture - 349
**** 18.2.2 Build Configuration - 350
**** 18.2.3 Shared Code - 351
**** 18.2.4 Agent - 353
**** 18.2.5 Sync - 354
***** 18.2.5.1 Initializing the Agent - 354
***** 18.2.5.2 SyncActor Messages - 354
***** 18.2.5.3 SyncActor - 354
***** 18.2.5.4 agentReader and ~os.watch~ - 355

*** 18.3 Testing the Syncer - 345
*** 18.4 Pipelined Real-time Syncing - 347
**** 18.4.1 Pipelined Architecture - 358
**** 18.4.2 Pipelined Implementation - 359
     
*** 18.5 Testing the Pipelined Syncer - 362
*** 18.6 Conclusion - 363

** TODO Chapter 19: Parsing Structured Text - 365
*** 19.1 Simple Parsers - 366
**** 19.1.1 Partial & Incomplete Parses - 367
**** 19.1.2 Alternative Parsers - 367
**** 19.1.3 Sequence Parsers - 368
**** 19.1.4 Combining Alternatives with Sequences - 369
**** 19.1.5 Repeated Parsers - 370
**** 19.1.6 Optional Parsers - 370

*** 19.2 Parsing Structured Values - 371
**** 19.2.1 Capturing Strings - 371
**** 19.2.2 Parsing Case Classes - 372
**** 19.2.3 Modularizing and Typing our Parsers - 373
**** 19.2.4 Using Sub-Parsers Independently - 374
**** 19.2.5 Recursive Parsers - 374

*** 19.3 Implementing a Calculator - 364
**** 19.3.1 Defining our Syntax Tree - 376
**** 19.3.2 Parsing Literals - 376
**** 19.3.3 Parsing Arithmetic - 377
**** 19.3.4 Manipulating the Syntax Tree - 379

*** 19.4 Parser Debugging and Error Reporting - 370
**** 19.4.1 Debugging Parsers via =.log= - 381
***** 19.4.1.1 Adding Logs - 381
***** 19.4.1.2 Logging a Successful Parse - 382
***** 19.4.1.3 Logging a Failed Parse - 382

**** 19.4.2 Error Reporting with Cuts - 383
***** 19.4.2.1 Minimal Example: No Cuts - 384
***** 19.4.2.2 Minimal Example: Cuts - 384
***** 19.4.2.3 Arithmetic Parser Cuts - 385

*** 19.5 Conclusion - 386

** TODO Chapter 20: Implementing a Programming Language - 387
*** 20.1 Interpreting Jsonnet - 388
*** 20.2 Jsonnet Language Features - 389
**** 20.2.1 Primitives - 389
**** 20.2.2 Locals and Functions - 389
**** 20.2.3 Composition - 390

*** 20.3 Parsing Jsonnet - 379
**** 20.3.1 Defining the Syntax Tree - 391
**** 20.3.2 Example Parsers - 391
**** 20.3.3 Parsing Terminals - 392
***** 20.3.3.1 Parsing Strings - 393
***** 20.3.3.2 Parsing Identifiers - 393

**** 20.3.4 Parsing Plus - 394
***** 20.3.4.1 Constructing Parse Nodes with Fold Left - 395

**** 20.3.5 Parsing Dictionaries - 396
**** 20.3.6 Completing the Parser - 397
**** 20.3.7 Testing the Parser - 399

*** 20.4 Evaluating the Syntax Tree - 388
**** 20.4.1 Expr vs Value - 400
**** 20.4.2 Defining Evaluate - 400
**** 20.4.3 Evaluating Literals - 401
**** 20.4.4 Evaluating Plus - 402
**** 20.4.5 Evaluating Locals and Identifiers - 402
***** 20.4.5.1 Evaluating Locals - 403
***** 20.4.5.2 Evaluating Identifiers - 403

**** 20.4.6 Evaluating Functions - 404
***** 20.4.6.1 Evaluating Function Calls - 404
***** 20.4.6.2 Evaluating Function Definitions - 404

*** 20.5 Serializing to JSON - 394
**** 20.5.1 Complete Jsonnet Interpreter - 408

*** 20.6 Conclusion - 410

* TODO Conclusion - 413
